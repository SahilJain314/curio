{
    "list data structures": [
        {
            "videoId": "HdFG8L1sajw",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2013-03-25T23:49:11Z",
            "title": "Data Structures: List as abstract data type",
            "description": "See complete series of videos in data structures here: http://www.youtube.com/playlist?list=PL2_aWCzGMAwI3W_JlcBbtYTwiQSsOTa6P&feature=view_all In ...",
            "channelTitle": "mycodeschool",
            "transcript": "In our previous lesson, we introduced you\nto the concept of data structures and we saw how we can talk about data\nstructures in two ways, one as a mathematical and logical model  that we also call, that we also term as an abstract data type or ADT and then we also study data structures as concrete implementations. In this lesson, we will study one simple\ndata structure we will first define an abstract view of it we will first define it as an abstract data\ntype and then we will see uh... the possible implementations and this data structure is list. List is a common real world entity. List is nothing but a collection of\nobjects of the same type. we can have a list of words, we can\nhave a list of names or, we can have a list of numbers so let us first define list as an\nabstract data type. So, when we define abstract data type, we just define the data that we'll store and then\nwe define the operations available with the type and we do not\ngo into the implementation details let us first define a very basic list. I want a list that can store a given number of elements of a given data type this would be a static list as the\nnumber of elements in the list will not change and we will know the number of\nelements before creating the list We should be able to write or modify element at any position in the list and of course we should be able to read\nelement at a particular position in the list so if i ask you for an implementation\nof such a list and you have taken a basic course in programming, a basic introductory course then you\nwill be like hey i know this, an array gives us all these features, all these operations are available with\nan array, we can create an array of any data type. So, let's say if we want to create a list of integers, then we declare the array type as integer and then we can give the size as a parameter in declaration i can write or modify element at a particular\nposition The elements are A[0], A[1] and are accessed something like this we all know about arrays and then you can also read  elements at particular position. The element at i-th postion is accessed as A[i]. So, array is a data structure that gives\nus implementation for this list now i want a list and that should have\nmany more features. I want it to handle more scenarios for me so i'll redefine this list here i don't want a static list, a static collection of fixed size. I want a dynamic list that should grow as per my need so the features of my list are that i will call my list empty if there are no elements in the list i'll  say the size of the list is zero when it is empty and then i can insert an element into the list and i can insert an element at any\nposition in the list, in an existing list i can remove element from the list i can count the number of elements in\nthe list and i should be able to read or write or rather, read or modify element at a particular position in\nthe list and i should also be able to specify the\ndate type for the list so i should be able to while creating the list i should\nbe able to say whether this is a list of integers or whether this is a list of string or float or whatever. Now, i want a data structure which is implementation of this dynamic list so how do i get it? Well, actually we can implement such a\ndynamic list using arrays.  It's just that we will have to\nwrite some more operations on top of arrays to provide for all these\nfunctionalities. So, let us see how we can implement this\nparticular list using arrays Let's for the sake of simplicity of\ndesign uh... assume that that the data type for the list is integer.So, we are creating a list of, a dynamic list of integers. What we can do is to implement such a list\nwe can declare a really large array We will define some max size and declare an\narray of this max size. Now, as we know the elements in the array are indexed as A[0], A[1] A[2] and we go on like this uh... so what i'll do is i will define a variable that will mark the end of the list in this array. So, if the list is empty, we can initialize this variable or we can set\nthis variable as minus one because the lowest index possible is 0 so if end is minus one the list is\nempty at anytime a part of the array will store the list Okay, so let's say initially when the list is empty this pointer end is pointing to index minus one which is not valid which does not exist and now i insert an integer into this array and let's say if we do not give the postion at which the number is to be inserted the number is always inserted towards the tail of the list, towards the end of the list so the list will be like we'll have an\nelement at position zero and now end is index zero So, at anytime end marks the this variable end, marks the end of the list in this array Now, if i want to insert something in the list at a particular position let's say i want to insert number five at\nindex two Then, to accommodate five here at this\nparticular position we will have to shift all the elements one unit towards the right all the elements starting index two we need to shift all the elements starting index\ntwo towards the right okay i just inserted some elements into\nthe list let me also write the uh... function call for these let's say we went in this order, we inserted\ntwo then we inserted four and then inserted in the end we are inserting five and we will also give the position at which we want to insert, so this insert with two arguments would\nbe the call to insert element at a\nparticular position. So, after all these operations, after all these insertions this is what\nthe list will look like this uh... arrow here marks the end of\nthe list in the array. Now, if i want to remove an element from\na particular position. Let's say i make  a call to something to the remove function i want to remove the element two so, i will pass the index zero here i want to remove the element at index zero. So, to do so, all these elements after index zero will be shifted one unit towards the left or towards the lower indices and two will go away that this end variable here  is being adjusted after each insertion\nthat we are making. So, after each insertion end will be zero after this one, two, three and so on. After this remove, end will be four\nagain.  Okay, looks like we pretty much have an\nimplementation of this uh... list in the left that is described as an abstract data type we have a logic of calling the list\nempty when we have this variable end equal to minus one We can insert element at the\nparticular position in the list. We can remove element it's just that we have to perform some\nshifts in the array,  they can count the number of elements in\nthe list it will be equal to end plus one the\nvalue in the variable end plus one. We  can read and modify element at a position. Well, this\nis an array, so we can definitely read or modify element at a particular\nposition uh... if we wanted to choose the data type\nit was just choosing the array of that particular data type,  but this looks like a cool\nimplementation except that we have one problem uh... we said that the array will be\nof some large size, some max size. But what is a good max size? We can\nalways exhaust the array, the list can grow to exhaust the array, there is no good max size. So,we need to have a strategy for\nthe scenario when the list will fill up the whole array. So, what do we do in that case? We need to keep that into our\ndesign. We cannot extend the same array it is\nnot possible to do so. So, we will have to create a new array, a larger array So,  when the array is full, we will create a  new larger array and copy all the elements from the\nprevious array into the new array and then we can free the memory for the\nprevious array now the question is by how much should we increase the size\nof the new array this whole operation of creating a new array\nand copying all the elements from the previous array into the new array is costly in terms of time and definitely a good\ndesign would be to avoid such big cost. So, the strategy that we choose is that uh... each time the array is\nfull, we create a new larger array of double the size of the previous\narray and why this is the best strategy is\nsomething that we will not discuss in this lesson so we will create a larger array of double size and copy elements from previous array into this new array. This looks like a cool implementation The study of data structures is not just about studying the operations and the implementation of these\noperations it's also about analyzing the cost of\nthese operations so let us see what are the costs in\nterms of time for all these operations that we have in the dynamic list. The access to any element in this\ndynamic list, if we want to acces it using index for read or write, then this will take constant time\nbecause we have an array here and in array, elements are arranged in one contiguous block of memory using the starting address or the base\naddress of the block of the memory of the block of memory and the index on the position of the\nelement can calculate the address of that particular\nelement and excessive in constant time. Big oh notation, that is used to describe\nthe time complexity of operations for constant time,it is written as in terms of big oh, the time complexity is written as Big Oh of\none. If we wanted to insert element if we wanted to insert element at the end of the array uh... end of the list then that again will be cost in time but\nif we would insert element at a particular position in the list then we will have to shift elements towards higher indices. In the worst case\nwe will have to shift all the elements to the right when we will be inserting at the first position, so the time taken for insertion uh... will be proportional to the length of the list let's say the\nlength of the list is n or, in other words, we will say that insertion will be Big Oh of n  in terms of time complexity if you do not know about Big Oh notation, do not bother, just understand that, inserting an element at the\nparticular position will be a linear function in terms of the size of\nthe list. Removing an element will again be big oh of n Time taken will be proportional to the current size of the list. n is the size of the list here. ok now, inserting an element at the\nend we just said that it will happen in constant time it is not\nso if the array is full then we will create a new array uh... lets call inserting element at the end as adding an element adding an element will take constant time if the list is not full but it will take time proportional  to the size of the list,\nsize of the array, if array is full. So, adding in the worst case will be big oh of n again as we said when the list is full\nwe create a new copy double the size of the previous array and when we copy  the previous array, elements from previous array\ninto the new array, so primafacy what loooks like the good thing with this kind of\nimplementation Well, the good thing is that we can\naccess elements at any index in constant time which is the property of the array but if we have to insert some element\nin between and if we have to remove element from the list then it is costly. if the list grows and shrinks\na lot then we will also have to create a new array\nand have all this thing of copying elements from previous array to a new\narray again and again and one more problem is that a lot of time a lot of the array would be unused. The memory there,  is of no use Definitely the use of array as dynamic list is not efficient in\nterms of memory this kind of implementation is not efficient in terms\nof memory This leads us to think- can we have a data structure that will give\nus a dynamic list and use the memory more efficiently we have one data structure that gives us\ngood utilization of the memory and this data structure is linked list and we will study about the linked list in the next lesson. So that's it for this lesson. Thanks for\nwatching! ",
            "url": "www.youtube.com/watch?v=HdFG8L1sajw",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "WwfhLC16bis",
            "channelId": "UCxX9wt5FWQUAAz4UrysqK9A",
            "publishedAt": "2018-04-13T06:29:49Z",
            "title": "Introduction to Linked Lists (Data Structures &amp; Algorithms #5)",
            "description": "Learn the basics of linked lists. Java & Python sample code below. Check out Brilliant.org (https://brilliant.org/CSDojo/), a website for learning math and ...",
            "channelTitle": "CS Dojo",
            "transcript": "Hey, everyone And this video, I'm gonna give you a quick introduction to linked list And in this video, I'm only gonna cover the very basic of linked lists. But I'll cover more advanced topics in a later video. Now a linked lists is basically a data structure for storing a collection of item. For example, these numbers 6, 3, 4, 2 and 1 and it does in a different way from the way an array does it So as we saw in my previous video an array can be visualized as a long box with many partitions of the same size and a linked list can be visualzed as many boxes that are connected to each other and the difference between an array and a linked list will be more clear in a later video But let's first focus on how a linked list can be implemented in this video. Now each of these boxes in a linked list can be represent as an object And let's say the class for that objects is called the Box Actually we will rename it later. We're gonna change the name later. but let's for now call it Box And it's gonna have two attributes or 2 fields in this class. and first one of those attributes is gonna be called 'data' it's gonna be the data or the item each box contains so if you have... let's say the first box in a variable called head if you write head dot data that's gonna give us this value 6 right there that's the data - head the first box contains and the type of data could actually be anything it could be an integer. it could be a string a character or anything else for there matter but here I just assume that it's an integer. just for simplicity And that's why I wrote int data here. and the second attribute here or the second field is gonna be called next. That's gonna refers to the next box that's connected to the particular box if you write head dot next that's gonna refer to the next box                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ",
            "url": "www.youtube.com/watch?v=WwfhLC16bis",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "njTh_OwMljA",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:23Z",
            "title": "Data Structures: Linked Lists",
            "description": "Learn the basics of Linked Lists. This video is a part of HackerRank's Cracking The Coding Interview Tutorial with Gayle Laakmann McDowell.",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. Today we're going to talk about linked lists. A\nlinked list is a very simple data structure. It's essentially just a sequence of\nelements, where each element links to the  next element which links the next element. A\nlinked list can contain pretty much any type of data, strings, characters, numbers,\nthe elements can be unsorted or sorted, they can contain duplicate elements or\nall unique elements. One of the things that distinguishes a linked list from an\narray which shares many of the same properties is that in the array elements\nare indexed. That is, if you want to get to the fourth element you can just, boom,\ninstantly do that. In a linked list though you have to start with the head\nand work your way through until you get to the fourth element, That takes linear\ntime so it's quite a bit slower. So why would anyone use such a data structure?\nWell the advantage of a linked list is that insertions and deletions can be\nvery quick. If you just want to insert an element right to the beginning of the\nlinked list, that can be done in constant time. If you want to delete an element\nfrom the beginning of the linked list again constant time. So that's very very fast. Of course if you want to append an\nelement to the end of the linked list that might require walking all the way\nthrough the linked list until you get the very last element and then inserting\nthe element there. That will take linear time so it all depends really on what\nyou're looking for. Now there's one other thing we should\ntalk about before we dive into the code, and that is this alternate version\ncalled a doubly linked list. A doubly linked list is just like a singly linked\nlist but in addition to each element having a link to the next element, each\nelement also links the previous element. For certain operations that can be quite\nhandy. Now that we've covered the basics of a linked list let's take a look at\nwhat the code would look like. Implementing a linked list is reasonably\nstraightforward. We just need a class node that takes in,\nhas a next value, and a data, and then just to make our lives easier we'll add\nin a constructor. And set that value. Ok. So the first\nmethod we'll want to implement is an append method. So let's go ahead and get\nstarted with that. Append is going to take in a data value and then it's going\nto have some pointer that starts off at the current node so the head\nof the linked list and then it's going to walk through the linked list until we\nget to the end of the linked list. Well how do we know that we're not at\nthe end of the linked list? Well we're not at the end of the linked\nlist as long as there's something after it. So in other words while current dot next\ndoes not equal null, keep moving, get to the end of the linked list. Then when we get\ndown to the end of the linked list, create this new node. If we prepend an\nelement we're going to actually change what the head node is. Now this makes a\nlittle bit of an issue because we could have multiple places our code base that\nall link to the same head. But if we change the head in one place how does everybody else know that our\nhead value changed? So the workaround for this is rather than giving everybody an\naccess to the head pointer directly, we define a class linked list that's\nbasically going to wrap our head. And then the append method can go where\nit probably should have from the beginning, which is in this linked list\nclass. Let's just update this because the current node should actually point to\nthe head. And what's nice here is that we can also add in the case if the head is\nnull, so we can say if the head is null then actually we just want to create the head.\nSo if head is null, head equals new node data and then we can just return because now we're\ndone with that. Alright. Prepending is relatively easy\nnow. We just need to, so its going to avoid again, prepend taken data. Now the way\nthis method will work is that we're going to create actually a new head\nvalue. So node new head equals new node data. Then new head's next value is going\nto link over to the old head and then we need to change the head pointer. For our\nfinal operation let's implement a method delete that deletes the first node that\nhas a particular value. So first we'll just declare our method. Void delete with\nvalue that takes in a data. Ok now if head is null, we know we\njust want to return immediately. There's nothing we can do there. Now what\ndelete with value is going to do is its going to walk through the\nlinked list and it's going to stop one before the element we want to delete. And\nthen its going to say, uh oh, the very next element you want to delete? So I'm going\nto actually just update my pointers to work around it so my next pointer is\ngoing to be that deleted values next pointer. So let's see how this works. So first we'll have this little current\nmethod that walks through the linked list. And then we're going to walk through as\nlong as we're not at the last element so we don't want to run off the edge of the\nlinked list. Ok now if current dot next dot data equals\nthe data were trying to lead. So in other words if the next value is the\none you want to delete, then cut out that next value. So then current dot next\nequals current dot next dot next. And then we return. So what this is doing is saying, okay, if\nthe next value you want to delete, don't go to the element, and just walk around it.\nSet my next pointer to be my next pointer's next pointer so walk around it.\nAnd then in other cases we just move on to the\nnext element. Now there's one case we want to be very careful of here which is\nwhat happens if the node we want to  delete is actually the head node? This will\nactually cause a problem in our current scenario because we need to actually\nupdate the head value. So we can just special case that. If head dot data is the\ndata we want to delete then head equals head dot next. That is just cut me out of\nthe linked list. Now let's take a look at what our method does. So first it takes\nin this data and then says okay if head is null, return, there's nothing we can do. If we need to\ndelete the head then just go and delete it. Set head equal to head dot next, set equal\nto the next value. Otherwise walk through the linked list starting at the head\nvalue, then, as long as, walk up until the next value is the one we want to delete, in which\ncase we say, okay, set current dot next, my next pointer, over to the next next value.\nAnd then we return. Otherwise we continue walking through\nthe linked list. So those are the basic operations for deleting, inserting both\nappending and prepending into a linked list. Now that you've seen the basic\noperations why don't you give it a shot on a new linked list problem. ",
            "url": "www.youtube.com/watch?v=njTh_OwMljA",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "dmb1i4oN5oE",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-08-07T14:49:15Z",
            "title": "2.1 Introduction to linked list | Need of linked list | data structures",
            "description": "In this video, I have described linked list data structure. I have analyzed limitations of array data structure and tried to discuss need of linked list. See Complete ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "see this is what this is a snapshot of memory memory is what I have told you already in many videos that it's a long tape of bytes and each byte see these are bytes and each by it is having its own address suppose I am taking this segment of memory memories or this side all extended in this side in this side also extended so I'm taking open-ended and I'm taking the address started from hundred so the next byte address is 1 0 man 1/4 next byte it is 1 0 2 like this see this memory is very crucial data source in our system we don't have unlimited memory in a computer system fine so it is a responsibility of a memory manager to manage this resource to manage the memory to which process memory is to be located how much memory is to be allocated to which memory is free which memory is allocated now like this fine so memory manager is going to take care of this thing fine now suppose a programmer want some memory in this case a programmer is writing a program and he is going to declare a variable like this in suppose variable name is X fine now when after declaring this variable what happens the memory manager will look at how many bytes four bytes for this integer in typical compilers fine so let us suppose memory manager are located 4 bytes to this X and started from which location started from let us suppose this location from 1 1 to these 4 bytes these four bytes has been allocated to this X and memory manager will tell the programmer that I have allocated to the memory which has started from one one two one two three four bytes fine and suppose he has entered sum here is initialized at runtime this X and he can enter some integer value like 7 so now the programmer suppose we want to store three integers fine so we we have we have read the concept of airings so how he will declare int suppose array name is a and size is 3 so see array is what action of data items which are of same data-type fine so for three integers for three venues the memory manager will allocate how many bytes 3 into 4 that is 2 any bytes fine and then that 12 bytes would be in consecutive continuous location that integer the values of the areas are always stored in continuous locations so let us suppose one complete block of 12 bytes has been allocated suppose from 102 from hundred to this one one one this is free and memory manager has allocated the hello has allocated this block to this a so now programmer has entered three values here now the programmer wants to store one extra integer value an extra value and he wants to extend this array size now he will last through the many memory manager that I want to store one extra value can I extend can you extend the size and I want to extend the same block I want to extend the size of there I am NOT going to declare another variable I am going to extend the size of that I want size of array for now now what the memory manager will do see because in advance the programmer told that I want size for only three integers so he has allocated 12 bytes now what a memory manager will say he'll say I cannot extend the size of your area because I have already allocated that that consecutive block to some other variable because at starting I didn't know that you are going to extend your array size so now programmers will ask what can I do now I won't add a size 4 so now memory manager will say I can allocate you a fresh block of 16 bytes because for for size of the array how many bytes would be required 4 into 4 that is 16 but I cannot extend this block now what programmer will think programmer will think that maybe in future I need to store 10 values fine so it's starting only I asked the memory manager to allocate me the size 450 values for 50 elements that I want my array size 50 now hint en 50 maximum limit now what memory manager will do my many - little bit locate how many bytes 15 - for that is 200 bytes a fresh block of 200 bytes of consecutive locations so these 200 bytes block is from maybe you can say from 122 this 3 109 addresses 3 1 9 these blocks would be allocated to this one but now suppose the programmer only needs to store maximum 10 elements so this space is wasted now because he is going to use only how many bytes 10 into 4 that is 40 bytes he is going to use starting 40 bytes right and remaining memory is what that memory has already been allocated to this arena so memory is not free the memory manager cannot allocate this free memory to another variable but this programmer is not using that memory so this is what the wastage of memory so this is a main drawback of n because of the fixed size because the programmer has to give fixed size of the array in advance at compile time only because of this vestige of memory is there in case of arrays fine now what is the solution of this problem so now the solution of this problem is what length list and here here see if the memory manager has allocated these fresh block then these values would be copied here only so that would be a very tedious work to do and again suppose after some time thus thus the programmer wants the size programmer wants to store 52 elements then again programmer maybe is not able to extend the memory in some cases then fresh a block of 452 452 elements how many bytes 52 into 4 so 2 0 8 bytes would be allocated a new block of to 0 8 byte would be allocated and all the that elements of this previous array would be copied there so very tedious work to ruin Harry's mind the solution is what linked lists so linked lists is also a collection of elements the arrays were also a collection of elements right it is a collection of more than one date items fine link list is also a collection of more than one date items but the only difference is what in linked lists thus this data items are not storing consecutive locations because this in area these are stored in consecutive location continuous location fine now how see if the programmer make a request for one element he wants to store one element fine now the memory manager suppose are located and for integer value for bytes so suppose memory manager has allocated these four bytes right for the request of integer variable and suppose he has stored some value that is for here after this suppose he has made another separate request for one variable that is for storing an integer value so again four bytes would be allocated but it is not compulsory that that four bytes would be allocated consecutive to to this because that is a separate request that is not a requesting form of Eric so suppose now for next request memory manager has allocated from here four bytes right one two three and four and he has stored here suppose three fine now again he has requested two more requests for until for storing integer values so now this is how for the four separate request of four integer values the memory manager has allocated these four blocks to the programmer so see here these four values are also a collection find that is a linked list because here I'm not discussing that he has he has declared like this in text and into I into Z or in Thai something like this not variable separate variables this is also a collection file this is also a list now suppose if this these four are in a collection in array that is fine because these are consecutive locations so if you know this thing the base address of this one you can easily the compiler can easy compute this address of the next one but here we cannot say if this we are at this value in this collection we are at this and visa then we cannot say at where where the next integer is fine in that collection so some extra information has to be stored that is what if with the this thing with this thing with this value if we store address of that next value then we can easily reach to here fine and from here in the list with this second value if we store the address of the next value the next integer value then back we can easily go from here to here and here we can store with this value the address of the next value fine so this is what this is also a collection of four integer values but here the these values are not storing contiguous location we have removed that drawback fine now see so some extra space is to be located with this one for storing address of the next value and address of the next value which variable can store address of any another value that is a pointer variable can store address of some another variable fine so here four bytes would be allocated again because in typical compilers it there for storing the value for showing the address it takes four bytes so see here again four bytes would be located with this one two three and four fine for storing the address of this one right here four bytes would be located for storing address of this one here with this four bytes would be allocated first story this one so total how many bytes would be allocated eight bytes for for this value and four bytes for storing the pointer to the next well right so this is the memory representation logically how we will represent this linked list see four three four nodes one is this one this then in this in this with this for address of next would be stored see suppose address of this is 1 0 2 for three addresses we have started from one one three four eight we have started from one two three and address of this is 132 so here with this four one one three would be stored so this will point to the next node here 123 would be stored so this will point to this node and here 132 will be stored this will point to this node and suppose this is the last node in the list so here null would be stored so in the linked list this complete is known as a node so here you can say this is drawback of linked list with the with this well knew you how to store pointer also so some extra spaces to be located the pointer to the next node here pointer to next node this complete is known as a node here fine so this removes the drawback of array now suppose I want to extend the size of linked list I want to insert one extra element here I want to insert 10 in the in my linked list right now suppose I want to insert 10 here so here can we insert this 10 directly here or the memory manager will allocate space for all the five variables some fresh block would be allocated no why so because these values are not not in contiguous locations so if anywhere space is available for 8 bytes then memory manager can allocate space they are only fine and we can provide link to link into this node for that new node inserted but in array we cannot do this because in array drobik is what all the value should be in consecutive locations fine so maybe sometimes if it is not possible to extend this size in case of arrays now if you want to insert this thing so simply somewhere in memory somewhere in memory suppose address is 200 and Nord is to be allocated memory size of 8 bytes has to be allocated that is known as node and here this 200 would be stored in the link in the pointer part of this previous node fine and here the value is 10 and this is the last one so here you can store none so this is how you can see that insertion in a linked list is very easy so here we can say we have removed that fixed size drawback that was in array no need to specify the size that in the linked list I want ten elements 20 elements are like this you can insert anytime an element from in the linked list so when you write a program in linked list then how we will declare the snowed-in array if I want to declare simply you will write data type array name and size that is very easy but in case of linked list cygnus here this particular node is containing two values and type of two values so is different one is integer value and this one is what address so this is what a pointer not a simple variable this is a simple variable this is what a pointer to types in one node fine so you have to define your own data type fine so that user-defined data types you are going to use that is structure so you are going to write strap so after this struct keyword you are going to give the name of your datatype you want to three it fine here I'm taking the name node struct node so within this you will write C one type want to value the type of one is empty cell so here you will write int suppose of a name of variable is a but this is what for this I will declare this as a pointer because only pointer can store address of another variable and this point there is going to store address of this node right not address of any other variable or any other integer variable this pointer is going to store address of another node fine so here you will write what strap node pointer and name of the point that you can say next so this is how we are going to define our new data type that is struct node the name of the data type is complete this one struct no not only not only known that is struct node and these are members of this structure here you write struct keyword then tag and within this you'll write members man two members are there one is this one one is this one now why I am writing here struct node as you know if you want to declare a pointer which is going to store address of some another integer variable then how you will declare int star P this P is going to store address of integer variable fine if I write float history P it means this P is going to store address of a float variable it means it is pointer to float pointer to in so here this is data type this data type is what this data type is for the variable whose address this pointer is going to store fine now here this is the pointer the pointer is going to store address off this one this one this is what node and data type of this node is what this complete struct node name of data type see this is data type struct node so that is why here I am writing data type that in struct node this is same s Turek and this is pointer name you can write next you can write your hair link it's up to you fine now next thing is this is the linked list now another pointer is there you can say head pointer start pointer it it's up to you this pointer is going to store address of the first node in the linked list address so first node is 1 0 2 so this head is going to point to the first node in the linked list right if you know this this address 1 0 2 if you know the value of this head this pointer they can then you can easily reverse this linked list fine but here random access is not possible in air what is there you can directly if you want to access this three you can directly access this tree compiler can directly compute the address of this three if the compiler know the base address but here if you know the base address that is the address of this firstly the first node that is one zero two and if you want to access this one this node this data you want to access but you cannot directly go here compiler cannot directly compute this address fine that is drawback of this thing because here that data is not in consecutive locations it is in scattered locations fine so if you know this value of this head was 0-2 so here you can go from this node you can go where check out the link part see this is what data part and this is link part of the node fine so check out the link part here the address address of which node one one three it means address of this node so you can go to this node now check out the link part 1 2 3 here address is this one you can go to here 1 2 3 so now you can reach here fine so in link list only sequential access is possible you cannot directly access you cannot randomly access any data fine if you want to access this last data then also you have to traverse the complete list first of all this then this then this after 1 3 2 and after that you can go here fine so this is you can say drawback off this thing so this traversal need or you can say this searching will need the time complexity the time is order of n accessing of any elements need order of N in worst case if you want to access the first element then obviously it is 1 only order of 1 if last means in worst case it is and you have to traverse the unending sin the list so it is order of n but in array it was accessing of any elements will take order of 1 only constant time fine here insertion is easy and deletion is also easy why so because see if sorted air is there like this see let us take an area of size six only four elements we have in there air and I want to insert five here this is sorted area now where you can insert five here you can insert five only fine so you have to do what you have to shift this 40 here here you have to shift 30 here you have to shift 20 here you have to shift 10 and here now you can insert five right so it will take how many shifting of all the elements so order of n if you want to delete if suppose I want to believe this 10 I want to delete this 10 then also you have to shift 20 here 30 here and 40 here then also it is approximately I am going to take order of n fine what it depends the position from where you want to delete and at which position you want to insert the data right if you want to insert suppose between these elements right here one node I want to insert then what you have to update just you have to update see it suppose address this this memory location has been allocated here suppose that the 300 at 300 fine so what you have to do this 300 should be here and this 1 1 3 should be here so this link would be something like this as simple as that right so insertion and deletion is easy in this case rather than array so briefly you can say a linked list is what is it it is a linear data structure it is a collection of data elements which are stored in known consecutive locations next point is some extra space would be required to store the pointers with each value next point you can say insertion and deletion is easier then array next point you can say accessing of any element is going to take order of n time complexity and in array it is order of 1 only next point you can say binary search is not possible in linked list in this fundamental this structure of linked list because binary search in that case we are to find out middle element so here we cannot go directly to middle element so you can say binary search is not possible next point you can say it is of dynamic size so in next video I am going to discuss the basic operations of this linked list traversal insertion deletion something like this with the help of their code as well as we are going to discuss types of linked lists fine so I'll see in the next video till then bye bye ",
            "url": "www.youtube.com/watch?v=dmb1i4oN5oE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "Rs1KPyb9fHY",
            "channelId": "UCx-kFfzekMbhODaBss-ZnsA",
            "publishedAt": "2017-07-02T08:40:50Z",
            "title": "Introduction to Linked List in Data Structures ( very easy)",
            "description": "Introduction to Linked List in data structures. It is a very important data structure.Linked List has many advantages over Arrays.",
            "channelTitle": "Vivekanand Khyade - Algorithm Every Day",
            "transcript": "so let's have a look at link list now we are going to see the introduction to link list means here we will cover some points the advantages and disadvantages of link list and what is exactly English and why it is required now for understanding link list first you have to understand the array so an array is a collection of elements of the same data type so this definition means that now suppose you want to declare an integer you do it like in a ok so a is an integer but if you want to store more than one integer in all the one declaration if we want to say it simply so then you can declare it like this ok this means this is an array of integers means there will be more than one or one integer there can be an array of size 1 also or more means most of the times it will be of the size more than one now now suppose the size is 10 this means there are 10 locations continuous locations which will store 10 integers okay now see this is an array for example with six locations okay so the declaration will be like int a and the size is six okay now the first element of this array is located at memory location thousand then the second location is 1004 this is because an integer takes four bytes see an integer takes four bytes on typical violence if you use traditional compiler selector Buzzi it takes only two bytes on traditional compilers but just consider it as four bytes as generally today all the compilers take four bytes for one integer now so the first integer is at one thousand location second integer it is at one thousand and four obviously the third will be at one thousand eight nine twelve sixteen and twenty so this is the continuous memory allocation okay now now if you want to insert like suppose if it is the integer one on the first place then two three five six and seven okay after some time if you want to insert four in this array okay the first thing is now the array becomes of size seven it should be made of size seven two integer and extra for there right but this is not possible in the array because you cannot change the size of the array in real time means in run time of a program means suppose you feel if you are writing a program like in a of ten you have declared then after you start writing the code then while writing the code you cannot change the size of the array anytime right you have to read eclair the Volare in for that if you want to change the size so that is not possible in the arid to add an extra location in runtime then the second thing is suppose we do it means we declare the array again and we just increase the one location okay now you have to take four here and you have to rearrange their is so five is shifted by one place then six is shifted to next place and seven shifted to the next place so these many shifts should take place now so this is the disadvantage of array that while run time you cannot increase the size of the array or you cannot like in other words we can say you cannot insert the element in the array only with one memory axis because here you have to do many shifts so you have to access all the memories after that insertion place okay now so what is link relation what is its advantage over added so for that first we will understand link list see a link list consists of unload I'll just clean it okay see this is a node okay so just consider it hypothetically afterwards I will tell you the technical details so this is a node suppose this is this node is of size for example like eight bytes okay see if you know structure then you can understand why it is a bit like it can consist of any data see this is a node this node is declared here then integer data so that integer will take four bytes suppose you want to store a character again character C so this character will take two bites and again the size for the pointer this pointer the size for storing this pointer again that will be four bytes now suppose only in integer data is there and the pointer is there so it will take eight bytes now so this node is divided into two places because there is an integer data and there is a pointer now what this pointer is about see if this is the first node then this data integer data is stored here okay this is the integer data and the next place is storing the address of the next node suppose this is the first node and the second node is here okay now so this first place means the first node and this place of the next pointer will store the address of this node means suppose this node is at thousand place and this node is at 2,000 place means the memory address of this node is 2,000 then here mm will be there the value of this place the value at this place is 2,000 the memory address of the next node so that that is here now what is proc node so this is the datatype means as we declare an integer pointer like int star with here you must have seen somewhere now in star Peter which means this pointer holds the address of an element which is of an integer type that the same thing is here the next is the name of the pointer which holds the address of the element which is of struct node type see this is the data type means you can say it as if you declare like struct student C student is a data type known and inside the data type you declare like character name then integer roll number like this total encapsulated thing or it is called as encapsulation so we are taking all the things together and we are making a new data type this is our man madness we can say this is an artificial data type just hypothetical data type in your memory location there is nothing like such data type like student but we are creating it we are arranging that data type so now so here we have created the data type and that is node node is the data type means that is the structure now it holds the address of the next node so here you can see this is the first node that is on the memory location thousand that holds the address of the next node which is on the memory location 1030 then this node holds the address of the next node which is on memory location 1040 and the last node holds the address of not me because that doesn't point to anyone as that is the last node so this is the way a linked list is there it is similar to array but now what is the difference see if you want to insert a node in a linked list you can directly insert it here suppose you want to insert it here just change the pointers see create the load means blankly there is a function to create the node means to allocate the memory to the node we will see that in the program before that you just imagine we have created the node so this node I have written it here so this node has been memory has been assigned the memory location for example 3000 okay so make the next pointer of the previous node to hold the memory location 3000 okay and the next place means the next pointer of this node will hold the address 1070 C means that will point to this node so in this way this node is inserted in the linked list see there are no efforts there is no it rearrangement or there is nothing and the declared size is also not a restriction because we don't declare any size here we just go connecting the nodes now where this is important for example if you have a website where many people are visiting the website every day so do you know that how many people visit your website every day no not exactly because it can be 100 200 1 lakh 2 lakh or 1 million 2 million but not the exact number so here the dynamic memory allocation is needed so that is why linked list is important now again the next advantage is insertion or deletion easy so that I have shown here and no size limitation as you know there is no nothing prey declared for all linked list now what is the disadvantage so first is sequential access see this array I can directly access if the index of there is like 0 1 2 3 4 5 6 this is the index of the array so if I direct access a of 3 I get direct access to that memory location just off 101 time complexity but in link list if you want to go to the fourth node you have to go with that chain this you have to visit this node first then the second third and then you will go to the fourth node right so this is the reason why in link list you have to trace every node for reaching the location where you want to insert the node or for reaching any location where you want to search or delete then an extra pointer see the size increases in arrays only this integer is here but in link list you have an extra point with this extra size is wasted the extra size so the extra size is wasted here to store this next pointer so that is that is the disadvantage of linking largest link is hey friends please subscribe to my channel as I post algorithm videos every day and if you want a video on any particular topic then please mention in the comment video thank you ",
            "url": "www.youtube.com/watch?v=Rs1KPyb9fHY",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "3hyxc4juJRg",
            "channelId": "UC63URkuUvnugRBeTNqmToKg",
            "publishedAt": "2019-05-10T08:19:23Z",
            "title": "LINKED LIST (CREATION AND DISPLAY) - DATA STRUCTURES",
            "description": "Linked list is a collection of nodes which are not necessary to be in adjacent memory locations. Each node contains 2 fields. 1. Data Field 2. Next field ( or ) ...",
            "channelTitle": "Sundeep Saradhi Kanthety",
            "transcript": "[Music] hello folks welcome back to our channel so in the previous session we have seen the advantages and the limitations of errors so in this session we'll go with the list implement linked list what's the difference between the array and linkedlist so in the previous session we have discussed that in a day the elements are stored in contiguous memory locations right so here in list that is not required that means the elements need not be stored in contiguous memory locations the elements can be stored in any location but as the name itself indicates there will be a link between one element and the other element so we have to establish a link between the one element and another element that's why these elements are need not required to occupy in the contiguous memory locations for this for this we need to create a structure for a node so here an element is represented as a node element is represented as North because here it nor consists of two fields so previously in the air is element means only one field that is a value so let it be either 10 or 20 or 30 right and so on so this is called elements but here Lord here Lord means it consists of two things first one is data field second one is industry address or pointer field or next field right in this data we have to insert the value that means this time so it may be integer flow characters string or anything else the actual value will be stored in data what about this field the additional field in this additional field the name itself indicates it will represents the address of next node address of next node so this is the link of another element that's why the elements need not require to occupy the contiguous memory locations so different elements can have a different memory locations but here we are just establishing a link so one element I mean in every element there will be and one field called address field which spends its own address of the next node so that's why we have to consider it has a node rather than element so how to represent this node representation how to represent eight node so a node is represented in a blue field see so this is the data fringe this is the next place this is the data field is the next fit then if if list contains two elements or three elements that use three nodes so if list contains three nodes see let us take ten and the number location is thousand twenty the memory location is 2013 location is three thousand right so three three nodes so 10 20 and 30 the address of ten is twenty two thousand there are no soft auntie's so how do we present these England's C and 2020 so here this is the we know that this is the data this is the address of next one so here we have to store the address off next no what is it it's no 20 what is the address of 22,000 so here the 2000 DB here over your second row 20 is the value and the corresponding next that means at this address field it will seal the edges of next smooth the what is an external 30 so what is the address 3000 so 3,000 will be stored here coming to the third board that T is the value and what is the next to next three that means either screen so here that is the last element so obviously it will be model so that means the last element then it was free maybe surely not so it indicates the list the end of the list it indicates the load is end of the list right and this legal list will be having the head dead thing the two other concepts that is head and tail so heavy the head will be the starting element they will be the enjoyment head take the name of the loader right so head and tail are name of the Lord the first load name is head thus last note name is take so if it is having some 40 tell me with the 4000 address again we have to use the another mode that is 40 and here we have to insert 4000 and the tag will be here hope you understood this one right so an oar consists of two fields so so far we have studying regarding these elements only the element but here we have to treat it as a node because it consists of two fields right so before going to the program first we have to create a structure for this mode so if it is an element we can directly write without datatype we have we can declare it with a data type that is int or a float or double or anything else right so by using the primitive data types we can declare the variable for assigning the element but coming to this node how to declare a node so here it is having only one element so we can directly use the primitive datatype here it is having a two fields so for every node there will be two fields right so how do declare the so we had a data structure which can accept multiple elements of different data types so here the data can be anything that was any any data type right so it can be integer float character or a string whatever it may be right so second one is purely endless so we know that if the in order to store letters we have to create a point we have to create a pointer so this is the amount more primitive data type this is a pointer variable so we have studied in a C language is say in order to add two different elements with different data types what we have to implement we have to implement this structure structure right so structure is a collection of multiple elements with different data types the same thing how to apply by declaring a node because it consists of retired letters first we will declare a node and then we will insert the elements or we will create the list and then we will display in this session hope you have understood the basic representation and how the node is represented and how the load I mean part of the things available in this nor now let us see the current border yeah here we'll be right data and next we can simply write cut nor we have to create two things one is data next so simply we can write an integer value in the data second one is a pointer which is pointing with the cell floor right so which is pointing the cell phone so we have to create struct node star next right so this is the Declaration of a No so here we have to declare a variable that is some star see this is fun data and next next is a pointer variable but it is a self pointer because this is also a field of the same rule it is also a field of same node so we have to write a pointer variable of the same node so that is called the start node so if you want to declare a variable C if you want to declare a variable so just right so let it let it be let it be consider this structure so into data flow percentage let us take this one so if you want to create this variable variable what we have to do so we have to the syntax of structure variable is start nor some s 1 right start to load s 1 is used to declare a structure variable C so yes one will be consists of data and the percentage isn't it right now here the same node must consists of a pointer so how to create a point available struct node P that is a pointer variable pointer structure variable so the same way we are using the same thing start node star next that means self pointer the point down right so this is called self referential structure the name itself will get self-referential structure so reference means the pointer self that means which represents the same node which is a part of the same node right and here instead of using the normal structure variable we have to use or we have to declare the pointer structure variable because if it is a longer structure variable C hope you understood this one right self-referential because what is header on these next which is also representing the symbol so for this we have created this one so normally if you create the structure variables but lord new structure with you it will be having a DITA next it excuse me next so here this is a problem because here there is value there's next is others so we can't store the address in normal variable so we can store the address in pointer variable so for this purpose we have to create the pointer variable so all the structure variables for these nodes are pointer variables star you hope you understood don't get confused so if it is normal structure variable that variable will be having two fields data in next data is normal data type and next is a editors so a normal variable can store the address so in order to show the address we have to create the pointer so that's why we are creating the pointer variable now this pointer variable will be having the data and address so this is possible so next after creating a structure we have to allocate the memory so we have seen the drawback of memory allocation is the main drawback for arrays there is the static memory allocation so here for every node we can have a dynamic memory allocation by using malloc function right next we have to allocate the memory dynamically new typecast for which we have to apply I mean I can remember is that normal star pointer variable this is Mel walk how much memory should be allocated size of the sizeof operator is used to little this size or chip I'd buy that particular data size of Lord so this is for dynamic memory allocation so this statement is used to allocate the memory independent so for every node for every node before it's it's getting the value we have to allocate the memory dynamically so this is first and I cast what type of form what type of data type we are allocating the memory function is used to allocate the memory so how much memory should be allocated then is the size of so the size will be calculated that will be allocated to the new here new is it very new is just a variable point the structure pointer variable so you will be having both data next hope you understood this one right so this is all about the interaction now we will create the real-estate disciplines so as you have said that every list will be having the head and the head will be the starting position and the day will be the last position so initially initially we have to assign the head and tail to the first element because if there is a one element we have to assign the head and head to the same language same node if you keep on creating a list you if you keep on adding the list we have to change the thing okay I hope you understood so if there is only one load that itself is a hidden thing if it is having your two loads the first one will be the head and the second one will be the tail Tennessee so this is a structure so I will write the structure here right creating a list creating a list so if you want to create some 10 20 and 30 see first we have to allocate the memory and then we will get the 10 and initially it will be null mn no no this will be the hang this will be the tape okay hey take you next second iteration the new will be this one in the second iteration the new will be this one that means whatever the image we're inserting that will be them you'll now see here head is 10 right 10 is 10 no the address position is none now if it is not an empty list it's not an empty list right it is a list with volunteering so head will be fits it head will be fixed okay now coming to the thing what we have to do we have to establish the link first establish the link first so what we have to do first tale of next so he attained takeout also nodes right so similarly star new similarly star head star tail so heading tail are also the nodes tail off next that means the tail of next this one will be same with you hope you understood this one tale of snakes here tavis this one tell Nana tale of Nexen that means the address of address part of a team will be assigned with new so let us take the address positions thousand two thousand three thousand now what is the new address of new 2000 so here it will replace the mouth with mm right next they should be change now the tail will be new the tails within you so that's why again you will have the second element that is 20 and now it is null okay hope you understood initially so initially the new it's a new the new will be some garbage and lung so whenever you are taking 10 this garbage value is replaced with 10 and the address bar will be a man address position will be null so headed thing will be assigned to new initially initiated right see and whenever you are inserting the 20 element first we have to establish the link so this is very important first one means established early next create no okay created so a is equal to new this one so here the tag is replaced and it is a saint here okay so head is having the two fields 10 mm and the tail is having the fields 40 and love no once again in this next iteration the new will be third we will be turning now again the first we helped establish the live end of next tale of next so this is the next this is the data right so tale of next is equal to new newest 30 right 30 of that the memory allocation that the memory address of 30 is 3000 so that will be a saint to tale of next so this is very important we have to follow this this thing this is the most important first establish the link so 3,000 and then take is 14 you say 17 right so thing will be same here right so this is for creating a list so we have to apply this in loop so that how many number of elements will be created in the priest right so I will write the program and i will explain the logic I mean we will trace that first let us write the code and we will trace it so after creating this one we have to use a memory location dynamic memory location some mu is equal to write node star M anak size of world so no every time the new will be allocated C so we keep this in loop so for every time then you will be happy so new start more star block self so once the irrigation is done then right then we have to take the value stand up some person HD leave the value and assign the value to head you off so here it is in pointer right this is a pointer structure variable so we know that the pointer structure variable accessing the data members is done by using the added so if it is a normal structure variable that variable you can access the members for using the dot operator if it is a point structure variable it should access the members were using the adding I mean the arrow bot data is equal to value and new of next will be initially initially right now we check the condition for head if it is having the single element or multiple events so if head so head is equal to is equal to null so we have created the variables but we are not and its si so if head is equal to is equal to null what we have to do both head and tail should be two head is equal to new because both with points to the first element itself n is equal to yes condition that means if it is having multiple elements right so then we have to follow the same procedure that means well first we have to establish the link and then we have to I said change the tail pay off next is equal to MU this is for establishing the link L is equal to new right so this ends the cool now just right bring them why to continue and exit flash stadium because we have to lay the character so really the characters can have percentages see Amazon see H close the window well we now see it is equal to continue the loop until see it is equal to well wherever you press Y n automatically it will be exited right hope you understood this one this is for creating creating the list creating the list so if you place this one if you trace this one let it be some party with a thousand thirty with the three thousand from 15 with the five percent the memory locations okay now see first value so just above this loop you just declare the value see hit I have skipped everything right just I am writing the logic first egg value so value is equal to some 20 value is equal to 20 now new of data so new consists of data is equal to value that means here 40 here it will be no next Hecht is equal to is equal to null so initially we have declared this head and tail but we are not initializing so automatically head will be consisting of some garbage and null similarly take will be also having some car Belgian no takes also having the garbage value and now now see if head is equal to is equal to null yes additional it is null then head is equal to new so head will be again 20 and null similarly tail is also pointing the same heading tank will be 20 n no now if part is standing I mean if part is executed so else will be ignored automatically why to continue engine if you press Y again it will check the condition see H is equal to Y so it is true again it will go with the new now the new will be the this ends with the first iteration this ends with the first iteration so now there is a node 20 and null and the new the new will be the next rule that means the memory will be allocated for the new and scan of value some value 30 will be assign so that they will be are saying to new of data place a 30 year and next is knowledge here it will be you know then if head is equal to is equal to another so this is the head 10 thing right this is the head end thing okay now head is not another because head is pointing the first element obviously then this condition will be failed as what will be executed in their spot in of next tale of next that wins null here out of it will be done so that will be a same with the new so new address is represent so that will be assigned to tail of next so here here the mouth will be replaced with click on them and then is equal to mu nu tail is equal to u so obviously one board will be created so here 30 here well and the tail will be replacing with this one right this ends obviously again why to continue any changes if you continue with why it will go with here it will check the condition its again - again a new that means iteration completes here again the new is a memory location is created and where you scan value except 15 so 15 and another right if head is equal to null head is not enough because it is pointing with some element so this part will be node else part will be telling a of next here K is 30 but C 23 throws in 30 so this is the head this is the tail so take off next head of next is this field so this is the next field is equal to you whatever what is the address of new so the address of News 5000 so well we'll be decreasing with five of them and then a is equal to new so obviously a tail will be created here with the 15 and the thing will be removed here and it will be a saint yeah right next printf why to continue integer if you have press again that while checking the condition CH is equal to en that will set false automatically comes out from the loop so finally the list will be 20 30 and 50 so 20 the load 20 is pointing the address of 30 and the note 30 pointing the address of 50 and the node 50 is having null because the node 50 is the end of the list right so hope you understood this one the creation of a list a simple thing a creation of a list and then the second one is we have to display the list display the elements of a list see so we will see the display elements and now we will count here we will see the display and we'll stop in the next sessions we will go to the next our operations see here we have created already some notes 23 throws in finding the next node that is 35,000 for display so we have to move the head to the MD so till the head moves to the empty we have to display the kind every room so further we will take a one more variable called M temp is also similar to a dente so first we'll assign the head to temp so obviously the temp will be here the temp will be here next I don't know why temp not equal to null temp not equal to null right what we have to do we have to print everything printf percentage D temp of data so initially it will be head so temp of date and 20 will be printed and next we have to move the head to the next one so we can't do the head to the next one so that's why we have assigning the head value with a temporary variable M so M is equal to M of next close this one simple so this is the Muny logic for displaying the list so let us trace here so first temp is equal to head here temp will be here this one next at M 1 equal to none so through temp of data we print in here next temp is equal to temp of next so now temp will be temp of next that means it is pointing with the this one temp of next that means this 3000 address of 3000 means this one now again M not equal to another it will check with the null condition so it is again a 2 so temp of data that means a 30 will be printed and again temp of next so it will be a single this one now again temp not equal to null yes so temp of data so 50 will be printed and the temp is equal to temp of legs there is no other load so that's why it will be assigned to no so tan not equal to null but here the temp is null see here here the temp is mal the condition fails automatically it will stop so we are having the three nodes with 20 30 50 and here also here displaying the 20 30 50 right so here we have to create a temporary variable and just we are moving the temporary variable to end of the list so whenever the temp is equal to null automatically we can stop the loop we can terminate the look I hope you understood this one so don't get reduce it is a very easy concept so a normal element means the storing a single value but here the list consists of node which is having two fields one is a data field and another one is the address field so here a variable consists of a multiple elements with the different data types is represented as a structure so here we have to create a structure and in that structure a normal variable can't store the address so we have to create the debtor's that means a pointer variable which represents the same that's why we are using the self referential structure and also the variable should have both the value and the address so we are creating the variable as a pointer variables for representing a normal right so here the main advantage is the elements can be stored anywhere because we are establishing a link between one element and another element right and also we are using the dynamic memory allocation for the allocating the memory so hope you understood so we have covered the the list introduction and how to create a list and how to display the list so we'll stop here and in the next session we will go with the insertion of an element in different positions at the beginning and the middle position and the ending position so how to insert an element at the beginning middle and end so in the air s we have seen if you want to insert an element at the beginning all the elements should be moved towards its right side and then we have to insert the element so that doesn't happen in the concept of list so that we will see in the next session so insertion and deletion to mode we have to see right so let us stop here so if you really understood my sessions like my sessions shave my sessions with your friends and if you are having any doubts please feel free to post your dogs in the comment section so that I will definitely try to clarify on your terms and no forget to subscribe to our Channel thanks for listening thank you very much ",
            "url": "www.youtube.com/watch?v=3hyxc4juJRg",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "R-HLU9Fl5ug",
            "channelId": "UC4Xt-DUAapAtkfaWWkv4OAw",
            "publishedAt": "2015-05-24T19:52:12Z",
            "title": "Python: Data Structures - Lists, Tuples, Sets &amp; Dictionaries tutorial",
            "description": "Tutorial on data structures in Python: Lists, Tuples, Sets and Dictionaries. Also explains sequence and string functions, slicing, concatenating, iterating, sorting, ...",
            "channelTitle": "Joe James",
            "transcript": "hi I'm Joe today I'm going to cover Python lists tuples sets and dictionaries now the list is the most widely used data structure in pythons very general-purpose similar to an array in Java and it covers most of what you would need but Tuffle sets and dictionaries have some advantages and specific areas and are very very useful data structures so the list is a sequence type is sortable the tupple is immutable which means you can't change add or remove items in a tubful once it's been created it's so it's useful for fixed data and tuple is also a sequence type which we'll explain in a second the set you can store non duplicate items so it's good for storing unique items in a set it's also very good for doing mathematical comparisons to set Union intersect those kinds of set operations dictionaries contain key value pairs it's like an associative array somewhere to a job a hash map and both sets and dictionaries are unordered which means they're not sortable and they're in random order there's one amazing thing about these data structures in Python is that they can hold any data type so they can hold integers floating point values strings or other object types and even other lists tuples sets and dictionaries and the data types don't have to be homogeneous so you can mix and match data types within a single list or within a set or within a dictionary now sequences include this tuples and also strings they're a bunch of different functions are applicable to all three of these data types and we're going to go into them in detail so indexing you can access any item in the sequence instantly using its index you have a million items in your list and you want to access an item instantly you can do that if you know it's index so a string is a sequence of letters let's say we want to access one of the items in the word frog we can say print X of three using the square brackets for the three and that gives us the third index starting from index 0 for F the G is going to be index 3 and in our list if we say we want item with index 1 that's going to go Scouse second eye list slicing allows us to slice out sub strings and sub lists and sub couples using indexes and syntax is using square brackets start n plus 1 and step and these are all optional I'll cover some examples of explain that and these are applicable to strings tuples and lists but in this example I'm just going to use the word computer which is a string so let's say we have X from 1 to 4 using a colon and this will return to us items 1 2 3 which is OMP if we want to slice items 1 2 6 this actually cuts off at 5 and it'll give us every other item since we have a step of 2 here so items 1 3 and 5 opt and X with items 3 2 basically no end right we didn't put an item after the colon so that's going to give us 3 onward 2p u ter if we don't put anything before the colon then it starts at 0 so this will give us items 1 through 4 or rather 0 through 4 and if we want to use negative numbers here we can use negative 1 which is the last item in a list or a sequence so X of negative 3 : nothing is going to give us the last three items on a sequence and then if we have X : negative 2 will give us everything except the last two items in it in the sequence adding and concatenating we can do using the plus symbol so we can combine two sequences of the same type only so if we have two strings that we want to combine we can use a plus sign to add them together and if we have two lists we want to merge together we can use the plus sign and will give us one list with 3 items in it multiplying we can use the star sign to multiply sequences again at the same type so if we have a bug it will multiply the word bug three times and give us bug bug bug or if we have a list with an eight and a five in it we want to multiply that by three it will give us eight five three times in our list checking membership test whether or not an item is in or not in a sequence using keywords in and not in so it's very simple to use so if we have x equals bug and we want to print you in x will print true if you is actually an X and O print false if it's not so in our list pig cow horse print cow not and will print true if cow is not an egg however cow is an EXO prints false so that's checking membership using the in and not end keywords iterating we can iterate through the items in a sequence using for loop so if we have list of integers in X we can say for item or in any variable name in X Trinity or whatever we want to do to that variable name it returns to us one list item at a time each loop iteration and if we need both the index and the item we can use the enumerate function so we say for index and item when you basically need two variable names here the first one is going to be index sector is going to be the value or the item in enumerate X and then we can do inside this for loop we can do whatever we want those two variables here I just have a print statement that prints the index followed by the value number of items will count the number of items in a sequence and we do that using the Len function which is short for length and we can do the same thing in a list prints the length of a list three items in this list minimum finds the minimum number lexicographically which means alpha numerically but this only works when all of the items in the list are either alpha or numeric you can mix and match integers and floating point values but you cannot have both strings and integers so if x equals bug we want to find the minimum the minimum is B we have a list of three strings we're going to find the lowest one which is C cow so prints cow maximum is going to find the maximum item in a sequence again lexicographically and they have to be all the same type either numeric or string type so if we take the maximum bug we get u and if we take the maximum of pig cow and horse we're going to get pig because it comes last alphabetically some we can find the sum of the items in a sequence if they're numeric type so five seven and bug is going to give us an error because bug is is not a numeric type but if we take the sum of two five eight and twelve it's going to print 27 or if we want to do a slice we can say hey I just want the sum of the last two items of X and this here will print 20 we can sort the items of the list this sorted function actually returns a new list without changing the original list returns a new list in sorted order so bug will return two letters of bug in a list in sorted order bgu and our list pig cow horse if we call sorted of X it's going to return a cow horse pig and mind you the original X is still unchanged count of item returns the count of a specific item in the sequence so here we're looking for the account X dot count of P will tell us there are two peas in hippo and X dot count of cow will tell us how many times the word cow appears in our list X if we want to find the index of an item the index function actually returns the index of the first occurrence of an item so if the item is in the list or sequence multiple times it returns the index of the first occurrence so here the H is 0 the eye is one the P the first P is 2 so X dot index of P is going to return 2 and here we find the first cow which has an index of 1 unpacking if we want to assign all the items in a sequence to a set of variables we can say a comma B comma C equals x and then all the strings in X will be assigned in order to the variables here on the left so Pig assign to a cow assigned to be in horse assign C but this only works if the number of variables exactly matches the length of your list so here we have 3 items we must have 3 variables so that covers general functions for sequence types now let's talk about specific list functions so there are a few different ways to create lists we can say x equals list parentheses we can say x equals in square brackets whatever list items we want to add to populate the list and again we can mix and match datatypes so we have Center some strings integers floating points and we can say x equals list and then in parentheses a double and we'll get a list from the items in the tuple there's a really cool function called comprehension so we can create a new list using what is returned by the for loop for M in range 8 so M and range 8 returns the values 0 through 7 and here we're saying we'll just take those values in so the resulting list is 0 through 7 here we have a for loop that says Z and range 10 if Z is greater than 4 so in other words item is 4 through 9 but we said hey look instead of adding the item itself Z to our list we want to add Z squared so it's going to take 5 through 9 and it's going to square each one of them and add it to the list so we get 25 36 49 64 81 so list comprehensions you can have fairly complex functions inside of the square brackets to create and populate a new list with whatever values you want delete we can delete an item from a list or we can delete a complete list the item we would delete using the index or we can delete the entire list append we can append an item to the end of the list using the append function extend we can combine to this this is very similar to the plus function that we already showed X extend Y is going to combine both x and y together into list X insert allows us to insert an item into a certain index position so here we want to insert a 7 into position one it will scoot the rest of the items to the right and put the 7 into the list and here we're going to insert a sub list or an embedded list with letters a and M into position 1 which is going to scoot all the rest of the items to the right and pop our sub list right in here the pop function pops the last item off the list and returns it so if we want to let's say print an item as we pop it off the list we can say print X dot pop and it will print the last item on the list and the new list will have one less item in it remove is going to remove a specific instance of an item so if we want to remove a 3 from this list we can put X dot remove 3 in order with the first 3 that defines not every 3 just the first 3 so you can see here the first 3 is gone and reverse reverses the current order of the list so the number that is first will become the last the number of the glass is going to become first and so on sort will actually do an in-place sort so a new list you get back our list X here is going to become a sorted list so unlike the sorted function sort is an in-place sort so it actually changes the order of the items in list X now let's talk about tuples so tuples support all the operations for sequences but tuples are immutable so member objects inside a tuple may be mutable for example you may have a list inside of a couple could be one of the items in your tub whole that list is still mutable you can still change an add and delete item from the list but you cannot delete the list itself from your Tuffle so it's a little confusing I'm going to show some examples in a second if the contents of a list shouldn't be changed then you can use a tupple that's what tuples are used for it's useful when you have a constant set of values that are not going to be changed that you want to use throughout your program and tuples are more efficient than lists due to how Python implements them so how do you construct a temple well a new tuple with no values in it is going to just be created using the parentheses and we can say x equals 1 comma 2 comma 3 if we want to create a tough hole with values 1 2 & 3 in it and you don't even need the parentheses actually the parentheses are optional if you want to create a single item tuple you still have to put a comma after that item otherwise it would just sign x equals integer value 2 and X would be an integer not a double so the comma tells it hey this is a tupple but it's a single item tuple and we can create a tuple from all the members of a list just using the tupple function so tuples are immutable as I said if we try to delete an item from a tuple or change the value of an item in a temple we're going to get an error but if we have let's say a list inside of a tuple here we have a two pole called X and our first item is a list with one and two in it and our second item is an integer 3 so we can't change that 3 that's immutable however we can't change the list here we're going to delete the first item the list which is to the item in index 1 so our new tough ball has a list with just the 1 in it and integer 3 so we can change the list the list itself is mutable but the tuple is not we still have to keep the list in this position let's talk about sets now so there are some constructors how we would create a new set we use the curly braces if we want to populate a set with values and we can create a new empty set using set with parentheses and we can create a set from a list by calling a set function in parentheses the name of the list when we do this though it strips out all the duplicates from our list and returns only unique values to the set and then we also have similar to the list comprehension a set comprehension so we can use a for loop if statements and whatever functions we want to do on those X values X is probably a bad choice of variables here since we're using X for the set name but but we can use the list comprehension to put values into our set and sets our unordered so as we populate set the items are going to be in random order so some basic set operations we can add an item to set X by using X dot add item remove an item set X using X dot remove item get length of set X using a Len function we can check membership in X by simply saying item in X or item not in X that's going to return a boolean true or false we can pop a random item from set X using a pop function we don't know which item is going to be popped it's arbitrary selected and we can delete items from set X by saying X dot clear will completely empty our set some of the standard mathematical functions for sets are very useful we can find the intersection of two sets using the ampersand function and we can find a union of two sets using the vertical bar symmetric difference or exclusive or in other words items that are in set one but not in set two or in set two and not inset one using the up arrow the difference which means items that are in set 1 but not in set 2 we just take set one - set 2 and subsets and supersets a boolean value does set to contain set 1 or 2 set 1 contain set 2 for superset question so there's one set operations now let's take a look at dictionaries so a dictionary again is a key value pair and you can see three different ways here to create a dictionary you can use curly braces with the key first in this case I chose to use strings for a key and floating-point values for my value and they're separated by pullin so this is the most standard way to create a dictionary you can also call the dictionary function to create a dictionary by placing comma separated tuples inside of the set and you can also say key equals value comma separated and called dictionary on that so there's three different ways to create a dictionary I find the first one is more widely used in more standard but the all three work so some basic dictionary operations you can add or change an item in dictionary X by saying X key is equal to value if this key is already existing in the dictionary then it will change the value to this if the key doesn't exist in dictionary it will add this key value pair to the dictionary remove item from dictionary X delete X and then the key get the length of dictionaries and a Len function check membership in X item in ax or item not in X this only looks in the keys it does not compare to values so if we want to look through values I'll show it show you a way on the next slide to do that delete all items from dictionary X we could say X clear and delete the entire dictionary X delete X del X so how do we access the keys and values in the dictionary we can say X dot keys will return a list of the keys in X X values returns a list of values in X and X dot items return a list of key value couple pairs and X so if we want to check membership in values of X we can say item in X values and this will text test the membership in X and return a boolean iterating a dictionary we can use for loops for variable in X print variable right so we say key we used a word key for our variable we can print our key and then if we want access to the value as well we say X and then key in square brackets then we can get both the key and the value display by iterating however if we want to do a lot of operations or use use the value quite frequently inside of our for loop we could use items instead so we can get two separate variables for the key and the value by saying for K comma V in extra item items is going to return both a key and a value and assign them to variables K and V in this case so when we print K and B we print out each key and each value for the entire dictionary that wraps up my video on Python lists tuples sets and dictionaries I hope you enjoyed the video please click the like button at the bottom I'm Joe James thanks for watching you ",
            "url": "www.youtube.com/watch?v=R-HLU9Fl5ug",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "trees data structures": [
        {
            "videoId": "qH6yxkw0u78",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2014-01-12T08:06:59Z",
            "title": "Data structures: Introduction to Trees",
            "description": "In this lesson, we have described tree data structure as a logical model in computer science. We have briefly discussed tree as a non-linear hierarchical data ...",
            "channelTitle": "mycodeschool",
            "transcript": "Hello everyone ! In this lesson, we will introduce\nyou to an interesting data structure that has got its application in a wide number of\nscenarios in computer science and this data structure is tree. So, far in this series, we have talked about\nwhat we can call linear data structures. Array, Linked List, stack and queue, all of\nthese are linear data structures. All of these are basically collections of\ndifferent kinds in which data is arranged in a sequential manner. In all these structures that I am showing\nhere, we have a logical start and a logical end and then an element in any of these collections\ncan have a next element and e previous element. So, all in all we have linear or sequential\narrangement. Now, as we understand, these data structures\nare ways to store and organize data in computers. For different kinds of data, we use different\nkinds of data structure. Our choice of data structure depends upon\na number of factors. First of all, its about what needs to be stored. A certain data structure can be best fit for\na particular kind of data. Then, we may care for the cost of operations. Quite often, we want to minimize the cost\nof most frequently performed operations. For example, lets say we have a simple list\nand we are searching for an element in the list most of the time. Then, we may want to store the list or collection\nas an array in sorted order, so we can perform something like binary search really fast. Another factor can be memory consumption. Sometimes, we may want to minimize the memory\nusage and finally we may also choose a data structure for ease of implementation, although\nthis may not be the best strategy. Tree is one data structure that's quite often\nused to represent hierarchical data. For example, lets say we want to show employees\nin an organization and their positions in organizational hierarchy, then we can show\nit something like this. Lets say this is organization hierarchy of\nsome company. In this company, John is CEO and john has\ntwo direct reports - Steve and Rama. Then Steve has 3 direct reports. Steve is manager of Lee, Bob and Ella. They may be having some designation. Rama also has two direct reports. Then Bob has two direct reports and then Tom\nhas 1 direct report. This particular logical structure that I have\ndrawn here is a Tree. Well, you have to look at this structure upside\ndown and then it will resemble a real tree. The root here is at top and we are branching\nout in downward direction. Logical representation of tree data structure\nis always like this. Root at top and branching out in downward\ndirection. Ok, so tree is an efficient way of storing\nand organizing data that is naturally hierarchical, but this is not the only application of tree\nin computer science. We will talk about other applications and\nsome of the implementation details like how we can create such a logical structure in\ncomputer's memory later. First I want to define tree as a logical model. Tree data structure can be defined as a collection\nof entities called nodes linked together to simulate hierarchy. Tree is a non-linear data structure. Its a hierarchical structure. The topmost node in the tree is called root\nof the tree. Each node will contain some data and this\ncan be data of any type. In the tree that I am showing in right here\ndata is name of employee and designation. So, we can have an object with two string\nfields one to store name and another to store designation. Okay, so each node will contain some data\nand may contain link or reference to some other nodes that can be called its children. Now I am introducing you to some vocabulary\nthat we use for tree data structure. What I am going to do here is , I am going\nto number these Nodes in the left tree. So, I can refer to these Nodes using these\nnumbers. I am numbering these nodes only for my convenience. its not to show any order. Ok, coming back, as i had said each node will\nhave some data. We call fill in some data in these circles. It can be data of any type. it can be an integer or a character or a string\nor we can simple assume that there is some data filled inside these nodes and we are\nnot showing it. Ok, as we were discussing, a node may have\nlink or reference to some other nodes that will be called its children. Each arrow in this structure here is a link. Ok, now as you can see, the root node which\nis numbered 1 by me and once again this number is not indicative of any order. I could have called the root node number 10\nalso. So, root node has link to these two nodes\nnumbered 2 and 3. So, 2 and 3 will be called children of 1 and\nnode 1 will be called parent of nodes 2 and 3. I'll write down all these terms that I am\ntalking about. We mentioned root, children and parent. In this tree, one is a parent of , 1 is parent\nof 2 and 3. 2 is child of 1. And now, 4 , 5 and 6 are children of 2. So, node 2 is child of node 1, but parent\nof nodes 4, 5 and 6. Children of same parent are called sibling. I am showing siblings in same color here. 2 and 3 are sibling. Then, 4, 5 and 6 are sibling, then 7,8 are\nsibling and finally 9 and 10 are sibling. I hope you are clear with these terms now. The topmost node in the tree is called root. Root would be the only node without a parent. And then, if a node has a direct link to some\nother node, then we have a parent child relationship between the nodes. Any node in the tree that does not have a\nchild is called leaf node. All these nodes marked in black here are leaves. So, leaf is one more term. All other nodes with at least one child can\nbe called internal nodes. And we can have some more relationships like\nparent of parent can be called grand-parent. So, 1 is grand-parent of 4 and 4 is grand-child\nof 1. In general, if we can go from node A to B\nwalking through the links and remember these links are not bidirectional. We have a link from 1 to 2, so we can go from\n1 to 2, but we cannot go from 2 to 1. When we are walking the tree, we can walk\nin only one direction. OK, so if we can go from node A to node B,\nthen A can be called ancestor of B and B can be called descendant of A. Lets pick up this\nnode numbered 10. 1, 2 and 5 are all ancestors of 10 and 10\nis a descendant of all of these nodes. We can walk from any of these nodes to 10. Ok, let me now ask you some questions to make\nsure you understand things. What are the common ancestors of 4 and 9? Ancestors of 4 are 1 and 2 and ancestors of\n9 are 1,2 and 5. So, common ancestors will be 1 and 2. Ok, next question. Are 6 and 7 sibling? Sibling must have same parent. 6 and 7 do not have same parent. They have same grand-parent. one is grandparent of both. Nodes not having same parent but having same\ngrandparent can be called cousins. So, 6 and 7 are cousins. These relationships are really interesting. We can also say that node number 3 is uncle\nof node number 6 because its sibling of 2 which is father of 6 or i should say parent\nof 6. So, we have quite some terms in vocabulary\nof tree. Ok, now I will talk about some properties\nof tree. Tree can be called a recursive data structure. We can define tree recursively as a structure\nthat consists of a distinguished node called root and some sub-trees and the arrangement\nis such that root of the tree contains link to roots of all the sub-trees. T1, T2 and T3 in this figure are sub-trees. In the tree that I have drawn in left here,\nwe have 2 sub-trees for root node. I am showing the root node in red, the left\nsub-tree in brown and right sub-tree in yellow. We can further split the left sub-tree and\nlook at it like node number 2 is root of this sub-tree and this particular tree with node\nnumber 2 as root has 3 sub-trees. i am showing the three sub-trees in 3 different\ncolors. Recursion basically is reducing something\nin a self similar manner. This recursive property of tree will be used\neverywhere in all implementation and usage of tree. The next property that I want to talk about\nis - in a tree with n nodes, there will be exactly n-1 links or edges. Each arrow in this figure can be called a\nlink or an edge. All nodes except the root node will have exactly\n1 incoming edge. If you can see, I'll pick this node numbered\n2. There is only one incoming link. This is incoming link and these three are\noutgoing links. There will be one link for each parent-child\nrelationship. So, in a valid tree if there are n nodes,\nthere will be exactly n-1 edges. One incoming edge for each node except the\nroot. Ok, now i want to talk about these two properties\ncalled depth and height. Depth of some node X in a tree can be defined\nas length of the path from root to Node X. Each edge in the path will contribute one\nunit to the length. So, we can also say number of edges in path\nfrom root to X. The depth of root node will be zero. Lets pick some other node. For this node, numbered 5, we have 2 edges\nin the path from root. So, the depth of this node is 2. In this tree here, depth of nodes 2 and 3\nis 1. Depth of nodes 4,5,6,7 and 8 is 2 and the\ndepth of nodes 9, 10 and 11 is 3. Ok, now height of a node in tree can be defined\nas number of edges in longest path from that node to a leaf node. So, height of some node X will be equal to\nnumber of edges in longest path from X to a leaf. In this figure, for node 3, the longest path\nfrom this node to any leaf is 2. So, height of node 3 is 2. Node 8 is also a leaf node. I'll mark all the leaf nodes here. A leaf node is a node with zero child. The longest path from node 3 to any of the\nleaf nodes is 2. So, the height of Node 3 is 2. Height of leaf nodes will be 0. So, what will be the height of root node in\nthis tree. We can reach all the leaves from root node.\nnumber of edges in longest path is 3. So, height of the root node here is 3. We also define height of a tree. Height of tree is defined as height of root\nnode. Height of this tree that I am showing here\nis 3. Height and depth are different properties\nand height and depth of a node may or may not be same. We often confuse between the two. Based on properties, trees are classified\ninto various categories. There are different kinds of trees that are\nused in different scenarios. Simplest and most common kind of tree is a\ntree with this property that any node can have at most 2 children. In this figure, node 2 has 3 children. I am getting rid of some nodes and now this\nis a binary tree. Binary tree is most famous and throughout\nthis series, we will mostly be talking about binary trees. The most common way of implementing tree is\ndynamically created nodes linked using pointers or references, just the way we do for linked\nlist. We can look at the tree like this. in this structure that I have drawn in right\nhere, node has 3 fields. one of the fields is to store data. Lets say middle cell is to store data. The left cell is to store the address of the\nleft child. And the right cell is to store address of\nright child. Because this is a binary tree, we cannot have\nmore than two children. We can all one of the children left child\nand another right child. Programmatically, in C or C++, we can define\na node as a structure like this. We have three fields here - one to store data,\nlets say data type is integer. I have filled in some data in these nodes. So, in each node, we have 3 fields. We have an integer variable to store the data\nand then we have 2 pointers to Node, one to store the address of the left child that will\nbe the root of the left sub-tree and another to store the address of the right child. We have kept only 2 pointers because we can\nhave at most 2 children in binary tree. This particular definition of Node can be\nused only for a binary tree. For generic trees that can have any number\nof children, we use some other structure and I'll talk about it in later lessons. In fact, we will discuss implementation in\ndetail in later lessons. This is just to give you a brief idea of how\nthings will be like in implementation. Ok, so this is cool. We understand what a tree data structure is,\nbut in the beginning we had said that storing naturally hierarchical data is not the only\napplication of tree. So, lets quickly have a look at some of the\napplications of tree in computer science. First application of course is storing naturally\nhierarchical data. For example, the file system on your disc\ndrive, the file and folder hierarchy is naturally hierarchical data. its stored in the form of tree. Next application is organizing data, organizing\ncollections for quick search, insertion and deletion. For example, binary search tree that we'll\nbe discussing a lot in next couple of lessons can give us order of log N time for searching\nan element in it. A special kind of tree called Trie is used\n, is use to store dictionary. Its really fast and efficient and is used\nfor dynamic spell checking. Tree data structure is also used in network\nrouting algorithms and this list goes on. We'll talk about different kinds of trees\nand their applications in later lessons. I'll stop here now. This is good for an introduction. In next couple of lessons, we will talk about\nbinary search trees and its implementation. This is it for this lesson. Thanks for watching ! ",
            "url": "www.youtube.com/watch?v=qH6yxkw0u78",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "oSWTXtMglKE",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:18Z",
            "title": "Data Structures: Trees",
            "description": "Learn the basics of trees, data structures. This video is a part of HackerRank's Cracking The Coding Interview Tutorial with Gayle Laakmann McDowell.",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. In this video I'm going to cover trees. A tree is best\nthought of in this sort of picture. You have a root node at the very top and it\nhas child notes and each of those child nodes, they have child nodes themselves,\nand so on and so on. Very often when we're talking about trees we talk about binary trees. A binary tree means that each node has no more than\ntwo child nodes. That is that each node has a left node and a right node. Of\ncourse one or both of those could also be null. Very often when we're talking\nabout binary trees we actually want to talk about binary search trees. A binary\nsearch tree is a binary tree which fulfills a specific ordering property. So\non any subtree the left nodes are less than the root node which is less than\nall of the right nodes. This ordering property makes finding a node very very\nfast because we have a pretty good idea of where it would be. So suppose we're\nlooking for 17 in this tree We can say okay, is 17 bigger or smaller than the\nroot node? Well it's bigger than the root node so let's go to\nthe right. Now is it bigger or smaller than that next node there? Well it's smaller than that node so it must\nbe on the left of it. And so very very quickly we can start to zoom in on where\nthat node will be because at each operation we've chopped off hopefully\nabout half of the nodes and we do that over and over again and very very\nquickly we find the node we're looking for. So it makes finds very very fast. But how do\nthose elements get in there in the first place? Well let's talk about how inserts work.\nInserts work much like finding an element works. We start with some element we want to insert like say, 19, and we say is it bigger or smaller than the route? Well its bigger so let's go to the right. Now is it bigger or smaller than that that next\nnode? It's smaller so let's go to the left. I would do this over and over again until we\nget to an empty spot or a null node and then we say ok that's where we should insert\nour new element. Now the one problem here is that if we get elements in a particular order, we could get really\nimbalanced. Suppose we have a new binary search tree and we just follow the\nproperties of insertion. So we insert one and then 2 to it's right and then 3 to it's\nright and 4 to it's right, we're going to get this data structure that looks\nless like a tree and more like a long list. And then inserts and fines will no\nlonger be so fast. There are some algorithms that can ensure that our tree\nstays balanced, that is that roughly the same number of nodes will be on the left\nside the subtree and on the right. These algorithms get pretty complicated so we're not gonna go into the details here, but it's worth knowing that they're\nbuilt into a lot of programming languages and in a lot of cases and\ninterview questions you'll just assume that you have a balanced tree. The last\noperation to talk about is traversing or walking through a tree. So there's three\ncommon ways we walk through a tree we can do an inorder traversal, a preorder traversal, or a postorder traversal. A preorder traversal means that you visit\nthe root first and then you visit its left nodes and it's right nodes. In an inorder traversal you visit the left nodes first then the current node and then you\ngo to the right nodes. In a postorder traversal, the root node comes up last so\nyou visit the left nodes and then the right nodes, then the current root node.\nTypically in binary search trees we want to do inorder traversals because\nthat actually allows the nodes to be printed in order. So for example on this\ntree here with just a 1, a 2, and a 3, the nodes in an in order traversal\nwill actually be printed out in the order one then two then three. So typically we'll see inorder traversals.\nNow that we've covered the basic operations let's take a look at the code for binary\nsearch tree. To implement a binary search tree we'll need a class node that has\npointers to the left node and the right node and then some sort of data\npresumably, and I'm going to give ourselves a constructor just to make our\nlives a little bit easier. Ok so the first method I'm going to add\nis an insert method. And this is going to take in, I'm gonna call ot value here. This\nis going to take in a node, take in a node value and look to the left and the\nright to see where we want to insert it. So first if value is less than or equal to\nthe actual data of our node then we should insert it on the left side. If\nthere is no left node yet then this becomes my new node. Otherwise then I\nasked my left to insert it and I push that down the recursion stack. And then\notherwise if value is bigger than data than myself then it should be inserted\non the right side and so if there is no right node put this as my right\nnode, otherwise ask my right to insert it. That's the basics of insert. Ok so\nlet's walk through this code on an example. So we have the simple tree and\nwe want to insert the value eight, so we call 10 dot insert of 8 and 8 is\nsmaller than 10, so we go to the left and we call it left dot insert of 8, so 5 dot insert\nof 8, 8 is bigger than 5 so we go and we don't have a right child and so we\nset 5's right child equal to 8. The next method I'll do is find. So find is\ngoing to operate recursively just like insert, in fact will be somewhat similar\nin a lot of ways. And it's going to want to return a boolean. And actually I'm gonna call\nthis contains because we're not really finding the nodes as much as checking if\nthe tree contains it. Ok, so first of all, if I'm there, return true, otherwise if\nvalue is smaller than data that it should be on the left side, if there is\nno left node then I know the answer is false. Otherwise if there is a left node\ngo ask my left node what the answer is. Ok now I do the same thing on the right.\nIf, actually I can just do an else,  if right is null or if there is no right node the\nanswer is false, otherwise go ask my right child and return its answer. Alright so that's the recursive\nimplementation of contains. So let's walk through this function and imagine we're\ntrying to find the value 8 that we just inserted. So we call 10 dot contains\nof 8, 8  is smaller than 10, so go to the left, and then we do 5 dot contains of\n8, 5 is smaller than 8, and so we go to the right, and then of course we see that\n8 in fact equals 8 and so we return true all the way up the stack. The final method that we'll implement is an inorder traversal. Specifically I'm going to print all of the nodes in the tree. So\nI just call this print in order and this is actually very simple. First if my, if I have a\nleft child then I do my in order printing first of my left child. Then I\nprint my own data and then same thing on the right. If right is not null, then I do right dot\nprint in order. So remember that inorder traversals do the left child, myself, and\nthen my right child. That's exactly what the code here does. So that's how you do an inorder printing. So let's walk through what this code does. So we're going to first\ncall 10 dot print inorder. Ten's gonna say left dot print in order\nfirst, that's the very first thing that's gonna\nhappen. Then we're going to print the root and then it's going to say right dot\nprint in order so we're going to recurse down. And 5, so we get 5 dot print in\norder. Five is going to say, ok print, but we got nothing on the left to print, so print me\nnext and then call right dot print in order where 8 will get printed. And\nthen we're going to go back up to 10 and 10 is going to get printed, and then\nwe're going to go and go down to the right in that third step and print 15. So\nthat's how an in order traversal works. If we want to do a pre or post order\ntraversal we do a very very similar things just in a slightly different order, a\npre-order traversal means that the root gets printed first. So we'd print the route,\nthen print the left subtree, then print the right. In a postorder traversal the\nroot gets printed last, so we'd print the left, then print the right, and then we\nprint the root node. So it's a pretty natural translation of the algorithmic\nconcepts. A lot of times in interviews people get kind of intimidated by the\nidea of implementing a binary search tree. They just assume it's something really challenging. But if you understand the\nconcept pretty well you can just take that and just translate it fairly\ndirectly into the code, just be really careful about the null pointer checks.\nSo now that we've gone through the basic operations why don't you try out these\nconcepts on a new problem. Good luck. ",
            "url": "www.youtube.com/watch?v=oSWTXtMglKE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "1-l_UOFi1Xw",
            "channelId": "UCxX9wt5FWQUAAz4UrysqK9A",
            "publishedAt": "2020-07-25T05:04:05Z",
            "title": "Introduction to Trees (Data Structures &amp; Algorithms #9)",
            "description": "Here is my intro to the tree data structure! And here's another interesting tree problem: https://youtu.be/7HgsS8bRvjo You can download my sample code in ...",
            "channelTitle": "CS Dojo",
            "transcript": "hey everyone in my last few videos i made a q a website for quarters and i still work on it from time to time but in this video i decided to switch topics and restart my data structures and algorithms series now in a previous video which i published a long time ago we learned the linked list data structure it looked like this one where we had a bunch of nodes that are connected to each other in a single direction and each node in the structure had a class like this it's called node and it has two attributes uh integer data and next which is also a node now a tree is a similar data structure to a linked list and the only difference is that in a linked list each node can only link to one other node but in a tree each node can link to multiple other nodes so here's one example of a tree as you can see each node here is linking to multiple nodes here each node is linking to at least three other nodes and so for this particular structure the class of each node might look like this one as you can see this one is called node again and it has four attributes uh integer data just like before sometimes this one is called value but we're calling data here and we have three children uh all of them are nose and so for example if you look at this particular node here the three children are set to these three other nodes and if you look at this node right here this one has only two children this one and this one so if you want to express that in code you can just set the two of the children to those nodes and the last child to null or none to show that it doesn't exist and if you look at this node it doesn't have any children so you can set all of these children knows to null or none depending on the language that you're using now let's take a look at another example of a tree so this one is drawn from top to bottom instead of left to right but it has the same kind of structure the more important difference is that each node has almost two children here so the class of each node might look like this one instead as you can see we have integer data just like before but now we have only two children which we're calling left and right and just like this when a tree has at most true truth it's called a binary tree now to help you understand what a tree is exactly we're going to call this little game called is this a tree basically i'm going to show you a structure and you just need to answer if it's a tree or not so let me start with this one this one uh doesn't have integers inside them instead it has strings but of course it's still a tree and what about this one well it's a linked list but it's also a tree and the way i think about it is that each node could have multiple children just like that but it just doesn't so it's kind of a boring example but technically speaking it's also a tree and what about this one well it might look like a tree but it's not because one constraint of something being a tree is that there are no two references that link to the same node and these two references violate that condition and what about this last one well again it violates the definition of being something being a tree for the same reason these two references point to the same node so it's not a tree and another way to see that this is not a tree is that it has a cycle here and whenever there's a cycle that's not a tree so you might say well what is a tree exactly then well a tree is a structure in which there are nodes that are connected to each other and there's a way to go from the root node to every other node in the structure so the root node in this particular tree is this one and there's a way for us to get to every other node from the root node in this structure and it's the same thing with this tree or this linked list there's this root node and there's a way to get to every other node from the root node but as soon as there are two references in this structure that refer to the same node for example this one then it's not a tree anymore so that's basically what a tree is and by the way the root node of a tree is a node without any parents so what that means is that whatever the root node is no other node refers to that one okay now that you hopefully have a clear idea of what a tree is let's practice using a tree with this problem you're given a tree for example this one with the root being here and this is a binary tree so the class of each node will look like this it has an integer data and it has two children left and right and the problem is writing a function which we're going to call find sum which takes the root of this tree as the input and returns the sum of all the values within the street so if you're given this particular root you want to be able to return 20 from this function because we have 2 plus 3 plus 5 plus 6 plus 4 which is 20. and try solving this problem in of and in time where n is the number of nodes in this tree okay and here's my solution and by the way if you want to try running my solution in either python or java you can find that at this url csojo.io tree like i said before we're calling this function find sum and it's taking the root of whatever tree that you're given and we're going to implement this function recursively here and the first thing we're going to do is we're going to define the base case and that's going to be when the given root is null or none which is that the given root is just an empty tree for example this empty tree right here then the sum of all the values in this empty tree is of course zero so we want to return zero in that case and otherwise uh for example if we're given this blue height right here in this recursive function then the sum of all the nodes in this tree is the sum of this current value plus the sum of all the nodes in the right subtree and the sum of all the nodes in the left subtree we can express that with this one line here we're returning the current value or root.data plus the sum of uh all the nodes in the left subtree so let's find sum of red dot left and the sum of all the nodes in the right subtree so let's find some of that right this function would only take of n in time to execute where n is the number of nodes in the given tree and let's think about why well first we need to count the number of times this function is going to be called and that's going to be the number of nodes in the given tree because for each node this function is going to be called once plus all the empty nodes or these empty trees that i didn't draw earlier in this representation of the tree and so this function is going to be called at most about 2n times or of 2n times which is the same thing as of n times and so this function is going to be called of n times and each time this function is called let's think about how how much time it takes to execute well if you look at each line uh if you look at this line it only takes a constant amount of time or of one because we're simply checking uh this simple if condition and it's the same thing as this line it only takes off one in time returning zero and this line as well we're simply adding up these three numbers so once we have the results for these two recursive calls adding up these three numbers would only take off one in time or a constant amount of time and so each time this function is called it only takes one and it's called o of n times so multiplying them together we get the total amount of time this function takes to execute or the time complexity of this function and that's going to be of n now that's it for this problem and my introduction to trees but if you need more practice using trees and there's another interesting problem that i think is much harder and it's a problem i talked about a while ago as a coding interview question so i'm gonna put a link to that video in the description below anyway thank you as always for watching my videos and i'll see you guys in the next one ",
            "url": "www.youtube.com/watch?v=1-l_UOFi1Xw",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "-LYhq4WZ04s",
            "channelId": "UC63URkuUvnugRBeTNqmToKg",
            "publishedAt": "2019-07-09T06:22:50Z",
            "title": "TREE TERMINOLOGY - DATA STRUCTURES",
            "description": "1. ROOT 2. NODE 3. EDGE 4. PARENT 5. CHILD 6. SIBLINGS 7. LEAF 8. INTERNAL NODES 9: DEGREE 10. HEIGHT 11. LEVEL 12. DEPTH 13. PATH 14.",
            "channelTitle": "Sundeep Saradhi Kanthety",
            "transcript": "[Music] hello friends welcome back to our Channel so so far we have seen the linear data structures the like arrays the Lincoln list and all these things so where the data is organized in a sequential manner so from today we will go with the nonlinear data structures so that means trace and graphs so here a tree is nothing but organizing the data in hierarchical fashion that means nonlinear it's not in a linear form nonlinear fashion that is in high lyrical fashion we will start with the things so a tree is nothing but the data which is organized in hierarchal fashion without any clothes region see for example let us take a simple example so this is called a tree this is called a tree because it is having the elements but not the total surface so if you have an edge between B and C if you have an edge between B and C then this is having a producer fence so this is not a thing right so that's why organizing the elements without any clothes or region or but without any closer to that we call it as a tree so here all the elements are represented as a nodes so similar to a legalist right so in the linked list also we are representing every element as it notes the if you consider an array we will call them as n elements if you consider a linked list we should call them as a note and similarly if you consider there is a tree we have to represent as a nodes so here also there are nodes now we will see the basic terminology of this t's and the basic technology so if you know the basic terminology of the trees then then this concept will be very easy for you for the next sessions first one node node so node means the element the element of a tea so it is an element of a tea is called a node so let us consider a tree a simple example for a tree so that with an example we can write everything okay so this is a simple tree okay this is also a simple tree right so a tree can have I mean number of elements a tree can have a number of filaments boy people should call the magic number of loads so every element so here the event of a tree is called as node so here the elements are a b c d e f g and h so all these are the nodes all these are the nodes of a take root node root node the starting node of a tree we call it as a starting element the starting node of tree is called root from where the branches occurs so here the starting node is yay so in the example yay isn't root low yeah is a root node and one more thing we'll have to remember every tree should have only one group so 3 is having 3 we have only one root role only one who put right next h edge so edge means a link or a connection between a Volvo to another floor see here we can see in different notes and all these nodes are connected by with the means of edges so here a B a and B are connected with the help of an edge yeah and C are connected with the help of an edge ba D are connected with the help of an it so H is a link or connection between two rules between two holes right it's a link or action between two rules now if our T is having yell nose our T is having n nodes then that tree cap will be having n minus 1 edges if a tree is having M nodes then it will be having n minus 1 edges right see let us consider within the example here the L is equal to number of moves is equal to 1 2 3 4 5 6 7 & 8 okay so 8 nodes are there now count the edges how the edges so according to our formula so if if it is having 8 notes it should have the 7 inches let us come so 1 2 3 4 5 6 & 7 so 7 inches right so if you need 3 is having with the N loops then number of edges for the tree will be n minus 1 right so this is called an edge parent parent node so parent nor means the Lord which is having branches that can be happened that that can be called as a parent so for example yeh node a is having two branches okay so a is having two branches so B and C B and C are the branches of a so that is why we can call a as a parent for B and C and C again B is having three branches so B is a parent say C doesn't have any branch so C we should not call C as a parent and similarly D is not having any branches so D is not called as a penned F is not having any branches so f is not a parent so G and hitch and also not a parent but he is having two branches so he's called a pair so from the top to bottom from the top to bottom if any node is having a branches then that node can be considered as a pent nor with branches some time to board our corner pins so here we can say yeah Billy e hot pellets are paid notes so we can call them as parent knows because he is having branches similarly B is having branches he is also having branches right so here a node can have a multiple branches that means a parent can have multiple chains see so these are the few terminologies node root node H period now we'll go with a cube or chain so after the parent we should call it as chain the next terminology is chain so chain means C which is having branches from bottom to top okay so Nord with edge from bottom to top from bottom to top or or branch of branches of paint we can call it as a check branches of North with the branches of parent we can call it as a chain so here see be is having a branch from bottom to top okay so this is a top to bottom so this is a top this is the bottom so be is having a branch from bottom to top so that's why we can call be as a chain see is having a branch from bottom to top so see scar the chain the EF our chains gh our chips so in this example B comma C comma D comma a comma F G and H all our chains so a node can have a number of chains a parent can have a number of chains okay siblings siblings sorry general English terminology that siblings means the children would share the same parent or a children of the same parent we call the magic siblings so change north of same parent chain notes of the same parent north we call them as siblings so in this example so be is a child of a sea state of you so B comma C are siblings similarly behavior she'll the same pattern so D comma Y comma F are siblings similarly GNH share the same pin gingka Mahesh are siblings okay hope you understood this one there's children of same parent with all the masses siblings next live live live floor leaf node means the node which is not having any chain is called a leaf node and more without chain nor without change nor the Lord without change node is called a leaf node so here you can observe the sea is not having any change D is not having any change yes is not having any tapes G and H all these nodes are not having any kind of children right similarly coming to the B B is having children d EF is having children G and H a is having children B and C right so the node which is without without any child change node that node we call it as a leaf node so in that example in our example c is in is node similarly D is a leaf node therefore the in-floor G and H are leaf nodes G and H are inference all these are done in flux right then next next one internal roots internal nodes so internal nodes means than all the rules other than leaf nodes are called as internal goes all nodes other than if notes so that means whatever the node which is having a child then that called as an internal node or we can say more with chain more with chain right nor with change nodes are called as internal goals so in this in this example we are having n number force with the children so Y is a change node sorry da is having the children so a will be the internal node similarly V is having the children B will be the internal node and E is having the children so he will be the internal node so here in this example so a B and E or a cup of notes okay a b e our internal nose next degree so degree of a node and a degree of a tip so maximum number of children the number of chain nose represents the degree of an old the numbers chain nose represents the degree of a node so for example degree of a degree of Yale so Nuria is having two children so degree of env2 similarly degree of B degree of B so B is having three children so the degree will be T and similarly the maximum the maximum degree of maximum degree among all nodes is a degree of fifty the maximum degree among all nodes is it degree of eight T so if you want to find the degree of complete tree that implies what the maximum number of degree among wall nodes so we have to find the degree for all the roles and the maximum degree where we have we get that will be the degree of a tree so here if you observe so degree of B is three so it is a maximum so in this example the degree of a tree the degree of victory will be three so simply we can say the node with a maximum number of children we can say it has a degree of a tree right so in the tree whatever the load which is having the maximum number of children that we call it as a degree of it tree right so if you count the number of Chinese rows for each node that will be the degree of control the degree of a node so this is called degree next eleven level of a tree so each step or each hierarchical in a tree will be count as a level so always the level starts from zero so every step or hierarchy in a tree is a level so level always starts from zero starts from zero and for every step every step or hierarchy every step or hierarchy level will be incremented by one see here if you observe here so this isn't level 0 this is at level 1 this is at level 2 this is okay from top to bottom the level will be zero level starts with a zero so all the children of a will be at the same level in one all the children of being see will be in the level two and all the children of de F will be at level three so we call it as a step or hand so every step or every high-ranking simply we can call it as an identity right so every hierarchy of a tree is counted as a level so level starts from zero so keep on going the hierarchy the level will be also incrementing by one so here in this example the level of the tree the level of a tree is three right because it is having three hierarchies from the roof node zero so always the hard level of a root node is zero right the level of root node zero right so from the zero we have to increment the levels from each and every hierarchy so zero one two and three so in this example the level of at a is T now someone more think is high hi so here the height means so we have to find the height for a particular load so for a particular node the height means the longest path from a leaf node to that particular node is called a head so longest path from leaf not to that node is hi-c for example if you want to find the height of B height of a B then C from the leaf node the longest path from the leaf node so leaf nodes are znh from the leaf node you have to find the path or the number of edges so here there are two edges G to E and E to be G to E and E to be two edges are there from the leaf node H there are two edges are there so that's why we can say the height of B is 2 and similarly height of EA if you hide if you can say hi Toph yay there aren't leaf nodes C is having I mean there is a leaf node C and there is a leaf node G and H from this leaf node C there is only one edge and from the leaf of G there are 1 2 3 edges so we have to consider the longest path height of phase 3 so there is a slight difference between the level and height right so here the height will be specifically specified for a particular node so that's why we have to find the longest path from a leaf node to that particular node for which we have to find the height so that is called a height right so hope you understood this one next depth depth so here also the same thing but here the depth is the longest path from root to that node so from top to bottom so here the height will be calculated from bottom to that particular node right so here the depth means we have to consider the root node to that node that particular node for which we are going to find the path so the longest path from root node to that load so depth is also for calculating the node so depth of e depth of e names finding the longest path from root node to G that means yay-yay to be B to e so here the depth is to deduct these two similarly the depth of G is root root to that node so 1 2 3 G's 3 right so hope you understood this one depth of B from root to that node root to that node so only one H so depth of bees okay so the depth is the longest path from root node to that particular node next see but but part means the sequence of notes from source to destination sequence of moves from root to leaf we can simply set from bluefruit to live or a source to destination so here see a path means the part of a to G is so A to B B to e e to G so this is called a path this is called pop a sequence of nodes from source to destination this is called pop next subtree the load with the children will always form say something like soul or with the children forms something I see here in this example we can say I will once again it right here see this is a dream and this one's another dream and this forms another so this is one pretty and this is a another subtree and this is a under circle right so hope you understood this one so every node with the chain olds on a subtree and this is also mentioned so you simply we can say this is also isn't okay so so these are the basic terminologies we have to know before going to the Tris concept so these are the all the basic terminologies so right once all these terminologies so hope you understood all these things so the root node more age-group Lord edge parent parent nor change nor siblings live Lord internal modes internal loads degree level height depth but something so all these are the basic technologies of a3 so we have seen all these things so hope you understood this basic terminologies so if you are having any doubts regarding this basic terminologies so feel free to post your doubts in the comment section so that definitely I will try to clarify all your doubts so let us stop here and in the next session we'll go with one more concept on trees so if you really understood my sessions like my sessions share my sessions with your friends and don't forget to subscribe to our channel thanks for watching thank you very much ",
            "url": "www.youtube.com/watch?v=-LYhq4WZ04s",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "vvey2QCs98o",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-10-05T14:45:41Z",
            "title": "5.2 Binary Tree and its Types | Data Structures",
            "description": "CORRECTION: at 5:42 there should be 1 at 7:30 the sum will be 15 In this video, I have discussed binary tree with its properties. I have talked about different ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "in this video we are going to talk about fine jewelry its properties and its types right in the previous video we have discussed what is that cream and you can say that introductory part of trees right some basic terminologies which are used in tree as well as how to represent a tree the logical representation of a tree right the basics we have discussed now we will discuss the binary tree see now first of all what is a binary tree see it is a tree in which each node can have maximum two children or you can say at most two children fine each node see as the name suggests binary binary means one - I mean zero and one so you can say in which a tree in which each node can have at most two children at most two means each node can have either 0 1 or 2 children but cannot have more than two children right that is the binary tree now how to represent a binary tree see if I draw something like this is this a binary tree yes see these are nodes this thing we have discussed already now this is having if this node is having two children fine and these are having zero child so that is also fine this is a binary tree now is this a binary tree yes this is also a binary tree this is having only one node that is removed having no children that is possible we can have zero child a node can have zero child right so this is also a binary tree now see what about this one is this a binary tree yes this is also a binary tree see here each node is having this node is having one child one that is also possible now see is this a binary tree this is not a binary tree because see here in this case this node is having three children that is not possible we can have at most few children so this is not a binary tree right all these are binary trees this is also a binary tree right now if I draw something like this this this this and this this is also a binary tree the only condition is what each node must have at most two children if this condition satisfies that that is a binary tree now how we are going to represent this abanda tree in memory that thing we have already discussed in the previous video see here this is the node each node is having both information plus may or may contain links that is not compulsory that it each node should contain link to another node may be if node does not have any child then it will not contain any link right so how you are going to represent this binary tree see this is a node first node is something like this three parts would be there this is what left child this is what right child you can say so here we have the data part you can say here I'm storing one this is what left this is what link to the right child so here we have one node this node is suppose having data to now see this node is having only left child so this is having only this link this link is null right so now here this is also suppose containing three ready one two and three here I have four five and six because these not a node are having some information store there three is not having any child node so there is no this link and this link would be null this is how we are going to represent this one here in this side we have four four is having both left and right child so this is left and this would be right right here we can have five and here we have five and six both five and six are having no children so the links would be null right this is how we are to represent the tree actually this is just a logical representation of a tree how we are going to store the tree in memory we are going to dynamically create these nodes we are going to set these links that thing also we will discuss the implementation of binary tree right now next thing is see now some properties of binary tree see we have discussed what is a level in the previous video this is known this is what level 0 this is what level 1 this is what level 2 now at any level see at suppose I am taking at level 1 how many maximum nodes can be possible see at level 1 only two nodes can be possible maximum nodes here we cannot have three nodes because at most two children can be there now at level 0 the maximum node possible is only one right at level 2 the maximum load possible are see the maximum node maximum node can be here I have 2 here also I have 2n 2 children of this node so this is what level 2 at level 2 we can have four children maximum we cannot have 5 6 or something like this right this thing I guess you are getting my point now suppose I am increasing one level at this level at third level the maximum number of children possible are maximum means each of this node is having maximum children and maximum children can be to only it means 1 2 3 4 5 6 7 8 right so here it can be possible here for maximum here to here we can have 0 simply same if I increase one level more then here at this level how many maximum number of modes are possible you can say each this this node at level 3 each node will have two children so here I have 8 node so 8 into 2 that is 16 can be possible so at level 4 16 maximum mode can be possible right you know how you can write this thing can I write here 2 raised to power 0 can I write 2 raised to power 1 Buddhist to power to 2 raised to power 3 and 2 raised to power so now what you can say here at each level I the maximum number of node possible in a binary tree is 2 raised to power I that is one property right the maximum number of nodes possible at any level I is 2 raised to power high right this thing I have already shown you now next point may be the maximum number of nodes possible at height H the maximum number of nodes of a binary tree right at height H C at this level suppose I have three levels only now height of this tree is what height of the root node is equal to height of the tree height of root node is what 1 2 & 3 go to the longest path find out the longest path path from the root or you can say from that node to the leaf node so now here height is 3 only right now at height 3 maximum number of nodes possible are see how to calculate you are you're supposed to add all these nodes means you are supposed to add first of all 0 plus at this level I have to plus at this level I have 4 plus at this level I have 8 it means you can say 40 number of nodes right maximum number of nodes fine now if I say height is only 2 right high it is 2 means I am removing this level means now height is 1 & 2 height of root is 2 so height of trees also 2 now if height is to maximum number of nodes possible are 1 2 3 4 5 6 7 so how to calculate maximum number of nodes if height is H simply you will add all the maximum number of nodes at each level so you can say 2 raised to power 0 at this level 2 raised to power 1 plus 2 raised to power 2 plus 2 raised to power 3 and L 2 raised to power H now this is what simply a GP series and how to find out the sum you can easily Google it out I am NOT going to tell you this thing so I am sure if this would be 2 raised to power H plus 1 minus 1 right so maximum number of nodes of height H I'm talking about this binary right so next one number of nodes can be h plus one minus one right and if I ask you the minimum number of nodes if height is H then C minimum number of nodes can be H plus one huh if height is this one 0 it means height in zero means we have only one node right you don't have this thing they have only one node it means height is zero so the minimum number of mode is 1 if height is 1 see this is height zero this is a tree binary having high to zero minimum number of node is one now if height is one I'm going to increase the height now height is one height of this tree is what one minimum number of nodes are one end to only minimum number of nodes I'm not adding this node second node right now if you increase the height one more suppose I am increasing height one more now height is 1 and 2 now height is 2 and minimum number of nodes are 1 2 & 3 if you increase one more height now height is 1 2 & 3 height is 3 minimum number of not a possible are 1 2 3 & 4 so you can say minimum number of nor possible are h plus 1 h plus 1 h plus 1 3 plus 1 is 4 if height is 1 means this one 1 height 1 2 2 number 2 nodes are possible means h plus 1 minimum number of nodes are possible right next thing is if suppose you are given maximum nor minimum nodes and you are supposed to calculate the height you can say the maximum height of the tree possible and minimum height of the tree possible then how you will see how you will calculate this thing now suppose you are given there can be n maximum nodes in the binary tree now you have to find out the possible height so maximum number of nodes are and as from this case we can say the maximum number of nodes can be of height H can be 2 raised to power H plus 1 minus 1 here you are supposed to calculate H value means higher I am calculating height of the tree now how will bullet n plus 1 is equal to 2 raised to power s plus 1 I guess you can easily solve this thing by taking log on both side log of n plus 1 and log off see base is 2 2 raised to power H plus 1 now this thing is 1 log 2 n plus 1 log 2 base 2 is this one and this one is also 2 so here simply we can write h plus 1 alright now here height you are supposed to calculate height is equal to low 2 n plus 1 minus 1 and here we are taking the ceiling function so this can be the height right but this can be the minimum height if maximum nodes are given those nodes can find out using those nodes we can find out the minimum height if minimum number of nodes are given that will give you the maximum height right now suppose minimum number of nodes are given n right n now height is what now minimum number of nodes of height H we know H plus 1 can be there now simply calculate the height is equal to n minus 1 so this can be n minus 1 can be what maximum height n minus 1 and minimum height can be this 1 log 2 n plus 1 minus 1 now we will see types of binary tree so types are full binary tree this is also known as proper or strict binary tree complete binary tree perfect binary tree degenerate tree and balanced tree also but balanced tree we will discuss when we will discuss the AVL trees right that is also that is basically known as balanced tree now what is full or strict or proper binary tree see the definition is what it is a binary tree where each node contains either 0 or 2 children or in another term you can say it is a binary tree see of obviously it is a binary tree plus one more condition is it is contain the each node is containing either 0 or 2 children or you can say each node will contain exactly to children except leaf node right now see what is a full binary tree now if I draw something like this is it a full binary tree yes because it is a first of all a binary tree plus here each node is containing either 0 see this one is containing 0 0 and 0 means these are leaf node right or to children this is containing 2 children this is having two children so this is what a full binary tree now see this is what is this a full binary tree no this is not why so because this node is having only one child but that is not possible in full binary tree now see this is what is this a full binary tree yes this is a full binary tree right now see is this a full binary tree yes it is a full binary tree is this a full binary tree no but is this a full binary tree yes each node is containing either 0 or 2 children or all the nodes are containing each node will contain exactly two children except leaf nodes except leaf nodes right now say in the property of this full binary tree is worth here number of leaf node is equal to number of internal nodes plus 1 here you can say this is a full binary tree now here number of leaf node count 1 2 3 4 5 & 6 number of leaf node are 6 right it should be equal to number of internal node plus 1 means here number of internal node node should be 5 1 2 3 4 & 5 I have discussed what is leaf node what is internal node in the previous video you can check out that video if you don't know now what about maximum node and minimum node in this tree see maximum node is same as binary tree right because here also at this level at this level at this level means at every level I there can be 2 raised to power I maximum knows and if height is it H then you need to add all the maximum of nodes at each level so this says 2 raised to power H plus 1 minus 1 this thing we already discussed right now what about minimum nodes see the minimum number of nodes height is 1 sorry height is 0 so minimum number of node can be 1 if I am increasing height 1 this has height 1 so minimum number of node can be say this is not a full binary tree we need a full binary tree so here you need one more node so 3 can be the minimum number of nodes now if you increase height one more time that is enough height is 1 and 2 height of this trees 2 but this is not a full binary tree you need to find out you need to satisfy that that condition also each node is having either 0 or 2 children so this should contain 2 children this can have 0 children because you are calculating minimum number of nodes so 1 2 3 4 5 5 right if height is 3 I am increasing one more height 1 2 & 3 here also you need two nodes so minimum number of rules can be plus 2 that is 5 plus 2 is C so now how you can write down this thing C 2 raised to power H plus 1 minimum number of nodes now how to calculate a minimum height and maximum height C the maximum nodes will give you minimum height this one minimum height so minimum height would be same as previous one as binary tree n plus 1 here ceiling minus 1 right because maximum mode are same but here the maximum height can be the minimum nodes are 2 raised to power 2 into h plus 1 so how to calculate if minimum number of nodes are given n how to calculate height 2 h plus 1 h is equal to n minus 1 divided by 2 so here you write n minus 1 divided by 2 now next is complete binary tree so now according to the definition of a complete binary tree see a binary tree is a complete binary tree if all the levels are completely filled all the levels are completely filled except possibly the last level fine plus at the last level we have one more condition see and the last level has the nodes as left as possible right we are going to fill the last level from left to right see now I'm going to take one example see here this is the last level right and this is not completely filled because these these nodes are not having any shine so that is fine in complete mandatory see we have told you I have told you except with the possibly the last level all the levels are completely filled seen on this level this level this level this is what completely filled right each node is having two child so one condition is true now second condition is completed binary trees what in the last level the nodes should be as left as possible means we are going to fill the nodes in the last level from left to right you cannot leave these nodes free these spaces free and you cannot right here then child node right so you need to delete and if I shift here then this is what a complete binary tree now is this a complete binary tree no why so obvious see the from the except the last level all the nodes are completely filled but second conditional is what here the nodes should be as left as possible we have left this node blank and we have put children to this node that is not true in complete binary tree if this is also having two child then this is fine right now is this a complete binary tree yes because here the condition is not that each node is going to have exactly two children so at the last level you can have one child but that should be filled from left to right see here if you write this thing you cannot fill the right child first of all you will have to fill the left child right so now this is also a complete binary tree right and this is also a complete binary tree now see is this a complete binary tree no this is not because now this is the last level right so at the last level you can fill the note from left only so here you should fill the left child you cannot feel first of all the right child is this the complete manual oh yes this is a complete mind you drink right somewhere it is also written as it is nearly complete binary tree fine now in this case also same what about maximum node at minimum nodes maximum node obviously this is a binary tree so maximum no that same that is 2 raised to power h plus 1 minus 1 maximum node in a complete binary tree of height H right now what about a minimum number of nodes here the minimum number of nodes are 2 raised to power H this thing you need to find out how the number of minimum number of nodes are 2 raised to power H I am NOT going to trace out this thing now minimum height and maximum height obviously minimum height would be same as the previous one because maximum nodes are same in all the three binary trees right now what is maximum height maximum height means minimum nodes will return you the maximum height so how you will calculate I am going to write down this thing you need to calculate this thing right so the minimum the sorry the maximum height in a complete manual tree is log n this thing you need to calculate how this is 2 raised to power H and how this is log n right so this is what a complete binary tree now perfect binary tree see a tree can be a perfect binary tree if all the internal nodes are having two children and all the levels sorry all the leaves all the leaf nodes are at same level right these two condition fine now see I am drawing one tree all the internal nodes should contain exactly two children so here these are leaf nodes but all the internal nodes are containing how many two children right but second condition is what all the leaf node all the leaves should be at same but here see this is what level 0 1 2 and this is what 3 so 2 leaf node are at level 2 2 leaf node are at level 3 so this is not a perfect binary tree all the leaf nodes should be at level 3 so now how to do this thing now see these are leaf node and all the leaf node are at level 3 and all the internal nodes are having two children so this is now a perfect binary tree now see this is also a complete binary tree can we say it is a full binary tree yes it is also a full mandatory so every perfect binary tree can be complete binary tree and full binary tree but why size not true see if a tree is complete binary tree then it is not necessary that it is perfect binary tree if a tree is full binary tree then it is not necessary that it should be perfect binary tree right now see what is degenerate binary tree here in this case all the nodes all the internal nodes are having only one child that is known as degenerate tree so see this if you draw this thing here this is leaf node and 1 2 3 3 are internal node and each internal node is having only one child so this is what a degenerate tree and you can say this is what a left skewed binary tree left skew binary tree means if the nodes the internal node is containing only the left child then it is known as also known as left skewed binary tree see now this tree this is what this is also degenerate tree because each internal node is having only one child that is a right child so it is also known as right skewed binary tree right now taking example of this is this a degenerate tree yes we can see each internal node is having only one child this is having right child this is having left child right so this is also a degenerate tree we cannot say that it is a left or right skewed it is mixture of both fine so I guess this is a about binary tree plus properties of binary tree we have discussed and I've so binary tree right now in detail how to implement a binary tree that thing we are going to discuss in next video so I'll see you in the next video till then bye bye take it ",
            "url": "www.youtube.com/watch?v=vvey2QCs98o",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "BHB0B1jFKQc",
            "channelId": "UCmJz2DV1a3yfgrR7GqRtUUA",
            "publishedAt": "2019-02-02T19:47:06Z",
            "title": "Binary Tree Bootcamp: Full, Complete, &amp; Perfect Trees. Preorder, Inorder, &amp; Postorder Traversal.",
            "description": "Full Binary Tree: Every node (besides children) has exactly 2 children (the maximum children a node can have in a binary tree). Complete Binary Tree: Every ...",
            "channelTitle": "Back To Back SWE",
            "transcript": "all right we are back all right so today what we're going to do is we're going to go over our binary tree fundamentals and yes I know maybe you're already familiar with this but my goal is to make this channel one of the world's largest resources for software engineering interviews and this kind of preparation so the key is we have to go through our fundamentals and get them very solid before we can build on top of them and do other topics so if you haven't subscribed to the channel subscribe to the channel and like this video what we're going to do today is we're going to talk about our fundamental traversals of binary structures binary tree structures and we're going to talk about the types of trees we're just going to go over our very basic concepts so that we have them very sound so let's go over three of the key kinds of trees or three terms we can use to describe a tree if we have a tree where leaf nodes have no children or a node has two children it is a full tree notice this is a leaf it has no children this is a leaf it has no children this is a leaf it has no children and that is the leaf it has no children but the nodes that do have children have two children they cannot have one chip child they have to have two children so this tree is full every time we decide to have a descendant we have to have two descendants we can't just have one so this node decided I'm going to have descendants I need to have to this node said I'll have no descendants it has no descendants no children that is a full tree and you can tell by what it looks like so this is a complete binary tree complete binary trees are our binary heaps we make binary heaps complete trees so what does complete mean all it means simply is when we fill out the nodes we go top to bottom we go left to right do you see how we go and fill it out like this do you see how we go top to bottom and do you see how we go from left to right and if I just put a node right here just out of the blue I stuck a note in there this tree is no longer complete because because I just missed putting a note there so this is a complete by an area and then finally we have our perfect binary tree so a perfect binary tree is where all the leaves are on the same level and all of the nodes that decide to have descendants have exactly two children a perfect binary tree is both complete and it is also full you see how the notes that decided to have children decided to have descendants they only can have two children they can't just have one child but the ones that did not decide have no children and notice how all of the ones that did not decide what we call leaves are all on the same level this is a perfect binary tree so now that we understand our terminology very soundly what we need to do is let's look at the traversals and yes these are going to be the rock reversals you can do on a tree but it's very key to understand these traversals so we can adapt them to other problems if we were very flexible with traversing a binary structure it becomes much easier to solve problems recursively or iteratively with a stack so let's look at our traversal now okay so what we're going to do is we're going to do a traversal of this tree and there are three fundamental ways to traverse a binary tree you can do it other ways but these are the three key ways there's your pre-order traversal your inorder traversal and your post order traversal and I don't want you to worry about the part in the word where it says order I only want you to notice the first part of the word notice how it says pre notice how it says in notice how it says post that prefix the prefix to the name of the traversal tells us when we visit the node we're sitting at so what I want you to see is in a pre order traversal in a pre order traversal we visit the node we visit the left subtree we visit the right subtree do you see how it's called pre order do you see how the N is the first visited you see how it's pre before the left and right so for inorder think of it as in so left subtree visit the node and then visit the right subtree so it's you see how it's in do you see how it's in the that's how you remember in order traversal and then we have our post order traversal we go left sub-tree we go right subtree we visit the node so do you see how it's post it's after the left and right so the left and right stay in sequence left and rights and sequence but the the prefix tells us when we visit the node before the sub trees the sub trees will be left to right but when do we visit the node that's what the prefix tells us so what we're gonna do is we'll do a pre-order we'll do an inorder and then we'll do a post order traversal here so this is what I want you to think about when we're traversing a tree I'm going to write something that's going to help you so I want you to think of recursion think of recursion as a certain policy we have to execute at each node think of the recursion as the tasks we need to do at a node and the state this state stays on the call stack this is the key with recursion so do you see how I just put node left to right this is our pre-order we're doing pre-order right now and what we want to do is we want to execute the policy at each node so what we do is we start at the 10 I see I have to do a node visit I have to do a left subtree visit I have to do a right subtree visit so what I'm gonna do is I'm gonna do the node visit I'm gonna just output 10 and what I'm gonna do is I'm gonna erase the end so I'm just familiarizing you with the example that we're walking through and notice we don't just have to print a node we can do any form of work the whole point is visitation we want to get our fundamentals down for visiting a node right now so what we're going to do is we're going to execute our policy at this stack frame we're going to say I need to visit my left so this stack frame says I need to visit the left subtree so we're going to circle the left okay so now we recurse and now we just circled the left and now we're gonna come down and we'll come to the 7 what is the policy at 7 7 says ok what do I need to do here in my stack frame so what we see is we see that 7 has 2 we see that 7 has to do we see that 7 has to do a node visitation so what we're going to do is we're going to visit seven and notice the next step in sevens policy in this stack frame is to visit the left subtree so let's do it so we visit the left subtree and now what we need to do is we need to do this policy at this stack frame so do you see how recursion is we're executing the same policy at each node but it's going to give us the behavior we desire because of the way we're ordering the visitations right so what we're going to do is we'll visit the six and then we're going to recurse and then we're going to come to the one we're going to visit the one and then one says I need a visit my left subtree we hit a base case nothing we come back one says okay I finished my left so I can erase that I'm done and then what is one's policy what is the policy at this stack frame what is left for this recursion in this stack frame to finish and we see all that's left is visit the right subtree let's visit the right subtree and then we see that there's nothing so we come back and now one has nothing to do so now we return to our call and now 6 says okay thank you left subtree you're finished now what is next in sixes stack frame and like again I say stack frames but the thing is we don't have to use the call stack we could make our own stack we can make our own stack and then we could execute the traversal that way so it just depends on the traversal and what implementation you want to do so this says I need to visit my right so the six visits is right there's nothing there so six comes back so now six has nothing to do it returns to its caller seven in sevens stack frame in its policy its stack frame it says I visited my left and now all seven has to do is visit its right subtree there's stuff to do over here so let's do that so now eight says what do I need to do what does eight need to do it needs to visit itself it needs to visit its its own node and then it needs to go left we see there's no left and then eight says okay I need to go right now so we recurse on the right subtree and now we're at nine what is nines policy what is nines job and I want you to drill this in your brain because this is how we really understand recursion this is how we really see that recursion expresses our decisions at each node it's different for each node each node has a different state do you see how states differs this is recursion fundamental I want you to internalize so we see nine so what we need to do is we need to print nine we see it has to print itself and so nine needs to visit its left nothing nine needs to visit its right nothing so it has nothing left if we return to the eighth the eighth finished its right subtree nothing left it has nothing to do left and now we come back to seven seven was just visiting its right subtree seven says okay unfinished seven is finished and now we return to ten and do you see how this all was the left subtree of ten do you see how our next task is to explore the right subtree of ten so all the traversals do is they change how we traverse this tree they change when we visit nose what we do is we check the right subtree and then what we need to do is we need to print 11 because 11 has that task to do and so 11 has to visit its left there's nothing here so we come back to 11 and so 11 has to visit its right and so 11 visits its right and now 20 comes to itself and 20 says what do I need to do here I need to print myself go left and right so 20 will print itself so 20 now needs to go left so it comes to 1440 needs to print itself and now 14 will go to the left so 14 finds nothing it'll go to the right as well it'll find nothing and now back to 20 what was 20 just doing it was looking to its left so what we're going to do is we're going to finish that what is the next state in 20 stack frame well we need to go to the right we come to the right and we see 22 so we see 22 and 22 s job and well it hasn't printed itself it hasn't gone left hasn't gone right it needs to do its job so we're going to print 22 and then it will go left there's nothing and then we'll go right there's nothing 22 is finished it returns to 20 and then 20 has explored it's right LLL finish 20 has nothing left to do LLL return to 11 11 has finished this right so 11 has nothing to do it's going to return to 10 10 has finished it's right and 10 stack frame the top level stack frame that drove us into the recursion is finished we're going to return to our caller whatever we returned whether it's the count of the nodes or something and that is finished that is the traversal of the tree this is what the pre-order traversal looks like the key is you don't really need to memorize these traversals you literally get the hint of what they are from the name anyway I think you get the idea now let's go through the in order and post-order and see how those work out they're basically the same thing so now what we're going to do is we're going to do an inorder traversal and all that changes is we're going to do a different policy at each node so let's define that policy okay so now all we did was define a different policy so we're going to go left we're going to visit the node we're sitting at and then we're going to go right that is all that we're going to do different so what we're going to do is we're going to start at the 10 the 10 will be called by an external caller and we're going to kick off our recursion what we're going to do is we're going to execute the policy at 10 and when you really do internalize this that recursion at each frame every frame has a different state although every frame has the same policy every frame will have a different state at different points in the recursion so we're going to go left in 10 and then we come to 7 what does 7 need to do 7 needs to go left what will 6 do 6 needs to go left what will one do one needs to go left and one is going to go left there's nothing there it comes back and so what does one need to do one needs to print itself so one printed itself and after a prints itself it needs to go right there's nothing there and now what we need to do is come back we come back to 6 because 1 is finished we come back to 6 so 6 just finished up going left so now 6 needs to print itself so now 6 needs to go right we see that there is nothing - 6 is right so what we're going to do is we're going to just return to 7 we have nothing else to do at 6 so 7 just finished going left so 7 its next job in its stack frame is to print itself so now 7 needs to go right and now 8 needs to go left we see in its stack frame that's his first job and then it goes left it finds nothing and then 8 needs to print itself and then 18 needs to go right and then it goes right and then we see 9 needs to go left there's nothing there 9 needs to print itself and then 9 needs to go right there's nothing there 9 has nothing to do it returns to 8 and 8 has finished its right subtree a has nothing to do left so eight returns to seven seven is finished is right sub-tree so seven returns to ten ten has finished its left subtree all that work we were doing was on the left subtree so now ten needs to print itself and now ten needs to go to its right and now eleven needs to go to its left there's nothing to eleventh left it needs to come back to itself and now eleven needs to visit itself and then eleven goes to the right twenty what does it need to do it needs to go to the left fourteen needs to go to the left there's nothing there fourteen needs to visit itself and then we see fourteen needs to go right there's nothing there so fourteen returns to whoever called in which was twenty twenty is done going left twenty needs to visit itself nest and then twenty needs to go to the right and then we reach twenty-two twenty-two needs to go left to visit itself and go right so it goes left there's nothing comes back it needs to print itself and now twenty-two needs to go right there's nothing there we return to 20 20 is finished twenty returns to its caller its caller has finished its right subtree 11 returns to its caller ten ten has finished its right subtree and we are finished printing it and I wouldn't even notice there's something special about this what we just did there's something special right here because do you notice how these are in increasing order this tree is a special kind of tree called a binary search tree so the nature of the way these notes are oriented is this node is in the middle of all of these guys and all of these guys so if we go to the left we go lesser in value we go less than ten everything in the left subtree is less than ten everything in the right subtree is greater than ten so this is a special kind of tree again a binary search tree you're probably already familiar with this if you are watching this but anyway so now I think you really get the idea but just to drill it in let's do the post order traversal okay so now we're going to do the post order traversal and nothing changes nothing changes except our policy at each node the way we visit the nodes so let's just go straight through this and you should be pretty rapid with this now so what we're going to do is we're going to go to the left first for Ted we'll go left first and then seven we'll go left six we'll go left this is starting to look like the in order traversal but let's continue so one go to the left we go to the left and we see that we don't find anything so we come back and this is the way this differs from our in order traversal instead of visiting ourselves next the next task is to visit our right subtree remember this is a post order traversal we visit ourselves a post last right so what we're going to do is visit our right there's nothing there and then we'll visit ourselves and what we're going to do is Prince ourselves there's nothing left to do it one so what we'll do is return to our collar six so six needs to go to the right there's nothing there so we come back and so six needs to visit itself so we print six six is finished so six returns to its collar we see its collar was seven seven just finished up its left subtree so now seven goes to the right seven goes to the right and we come to eight what does eight need to do it needs to go to the left to the right and to itself so we go left there's nothing here so we come back to eight so eight now needs to explore it's right and so now eight is exploring is right we come to the nine so nine needs to explore its left there's nothing there so now ninety needs to explore its right there's nothing there so now nine only needs to print itself nine returns to its caller eight eight realizes it's finished its right subtree and now eight needs to print itself it has nothing left to do it returns to seven seven all it needs to do is prints itself seven has nothing left to do it returns to its caller ten ten finished its left subtree all it has to do is go right and now we come to eleven eleven needs to go to the left eleven does not have anything on its left so 11 goes right we come to twenty twenty needs to go left to right and visit itself we go to the left we come to fourteen we go to the left there's nothing we go to the right there's nothing we visit the node fourteen that's the last task in our stack frame we visit 14 we come back to 20 20 is exhausted its left subtree so twenties next task is to go to the right so now we're going to go to the right we see 22 22 s job is not to print itself it's to go left to go right and then print itself so now 22 is going left so there's no from there it needs to go right there's nothing there it needs to print itself now we come back to our caller 20 it's finished exploring its right subtree now 20 needs to print itself 20 is finished with its tasks so it comes back to 11 again Levin realizes I'm done with my right subtree 11 needs to print itself now and now 11 has nothing to do we return to our caller and now we have 10 10 realizes I'm done with my right subtree and now finally 10 prints itself 10 realizes it has nothing left to do and we've completed our traversal that is our post order traversal that is basically how you do it see the thing is you don't always have to do this recursively but what we're going to do is there's a certain way we need to visit these nodes and however we structure our recursion how every structure our are stacked what items we push and in what order is going to change how we visit these nodes it's not that scary to deal with binary structures binary tree structures because as long as we know our fundamentals as long as we know how to visit nodes we can be very flexible in how we deal with these structures I haven't even gotten into breadth-first traversal we can do a zigzag traversal we would use a queue for that but that's for another video but I just want to introduce this concept you're probably already familiar with this if we are thinking about complexities if we think about any of these traversals where we're touching all of the nodes if n is the number of nodes then the upper bound we can set on the time we're taking is going to be linear time we're going to scale in a linear fashion as our tree gets bigger if we're touching all of the nodes anyway we're going to get more familiar with tree complexities and all that it gets fairly straightforward as you do more problems but that is all for this video if you liked this video hit the like button subscribe to the channel this was a very basic fundamental one of course we have a table of contents so you could skip through this I would do not expect anyone to watch all of this but that is all for this video and what I'm gonna do and [Music] ",
            "url": "www.youtube.com/watch?v=BHB0B1jFKQc",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "GzJoqJO1zdI",
            "channelId": "UCRLEADhMcb8WUdnQ5_Alk7g",
            "publishedAt": "2020-10-22T15:30:03Z",
            "title": "Binary Trees - Data Structures Explained",
            "description": "#data #structures #trees.",
            "channelTitle": "Aaron Jack",
            "transcript": "how's it going everyone this is a free video from the coding interview course that i released earlier this year interview espresso this one's about binary trees i hope you enjoy it and if you want to check out my course there's a ton more videos like this one [Music] welcome to the next overview video in this one we're saying goodbye to the linked list and hello to the binary tree we can think of a linked list as the shallow end of data structures when there's a whole ocean out there in fact both the linked list and the binary tree are part of a family of node-based data structures by now we're quite familiar with creating list nodes with a value property and setting their next pointer you might be surprised to hear this but a ton of data structures have these very same components that is a node containing a value property and one or more pointers so think of nodes as the bricks that we're using to build different quite literally structures so within the broad category of node-based data structures we have everything from graphs which can represent cities and the paths between them and taking this a step further we can think of getting from point a to b in any navigation service as following a pointer from node a to node b and then we also have trees which are different because they're hierarchical that means nodes branch out in one direction with multiple pointers going from top to bottom most trees look more like a pyramid than a tree but if you squint you can see the tree if you flip it upside down let's get more precise trees expand in one direction so that means no cycles they're also made up of parents and children these are relative terms for nodes and describe where they're located in relation to each other and relative here means every parent can also be a child just think of a family tree so here the node with value 1 would be a child of node 3 and a parent of nodes 2 and 5. the one hard rule for trees is that every node can only have one parent but it can have many children so just think parent to children one to many even within trees there's so many different types you've got heaps which keep things in order as you add to them you've got tries which you can store words in to look them up easily and the html on any page can be represented as a tree and in fact you can store anything in a tree with a hierarchical nature that is parents and children now the title of this video is binary trees and we've chosen to focus on them because they are a simple type of tree that probably has the most interview algorithms associated with it now each type of tree has a specific set of rules and the main rule for a binary tree is that each node can have maximum two children or two pointers more specifically every node can have either zero one or two children and these children are represented in the interface of our node with the properties left and right that is to say left and right pointers comparing this to the linked list where we have a single dimension dot next dot next dot next here we have two dimensions left and right okay time for a bit of vocabulary so we can talk about trees in more detail nodes and trees are still called nodes but we'll refer to them as tree nodes or binary tree nodes instead of list nodes we call the node at the top equivalent to the head of our list the root of the tree remember trees upside down so the roots are at the top instead of the bottom as you can probably imagine having multiple paths to go down makes traversal an interesting challenge on one hand we could set an on pointer like we've been doing and choose to follow one path all the way to the end when we reach the end or a node with no children well this note is called a leaf if we take our leaf node and our root node and all the nodes in between that we went through to get here well this is called a branch so you might hear variations of following an entire branch following a path to the end things like that when we talk about traversing through trees more often than following one complete branch though we'll want to look at every node in our tree whether we're searching for something modifying the values pulling them out or just doing any number of different things so the important question becomes what order do we look at our nodes in the best answer is it depends and this question is actually at the core of a lot of binary tree problems so as you can imagine if we're processing every note in the tree in some way whether that's as simple as just printing out each node's value or something a bit more complex we could choose to do this traversal iteratively with a while loop and an on pointer or recursively using the call stack so with the tree and i know you love recursion we're gonna start seeing something called branching recursion which means since every node can have more than one child we can have more than one recursive call per stack frame what our call stack ends up doing is branching out like this but when you look at all the function calls after they return the call stack is actually in the same shape as our tree which makes sense because we're calling the function whatever it is for each node one time i'm intentionally staying generic here but we're gonna get into what the implications of this are and what exactly this looks like in code in the upcoming videos before we wrap this video up i have to mention one more even specific type of tree that we're going to talk about in a few problems this type of tree is a binary search tree note the binary search in binary search tree the reason why it's called that is because like the binary search algorithm that uses a list or array binary search trees if they are balanced also give us a log n search operation now as far as what exactly balance means well we've got a whole video dedicated to that coming up soon so in addition to the rule of binary trees where you can have maximum two children left and right binary search trees have to follow one additional specific rule and that rule is this every node's value must be more than its left child's value and less than its right child's value so in this tree three is more than one and less than five so we can call this a valid binary search tree not only that simple rule but this greater on the right less on the left principle has to be true for the entire tree let me explain if i put a node with value two as five's left child our sub tree with five and two passes but unfortunately we are breaking it within the crater context of the tree because it's down our right path and we can't have anything less than three down our right branch and checking whether this condition is true for the whole tree is called validating the tree and we have another whole video dedicated to that coming up soon now if we know we do have a valid bst the way we find something is by simply traversing towards the value we want so if i wanted to see if the value 8 was in our tree then i'd set an on pointer and look at the value on each step which would tell me where to go next so in this example well 8 is greater than our roots value 3 so i know i'm going to want to search down the right path i can keep doing this simple check over and over until i hit null in this case i attempt to go from 5 right again but five has no right child so we can safely say that eight is not in our tree and this is assuming that our bst is valid so just to recap there are a ton of different node and pointer-based data structures a very common one of those is trees and within trees we have binary trees binary trees are very common in algorithms and they're actually not that different than a linked list they both have a value property but instead of a next property a binary tree node has two pointers left and right which represent the left and right children the note at the top that we're often passed in is referred to as the root then we can follow a root down a branch all the way to its leaf a node with no children now the order we traverse this tree in is a whole topic of its own that we're going to discuss in all the upcoming problems finally there's a special type of binary tree called the binary search tree which gives us certain guarantees if things are kept in a certain order i'm gonna leave it at that for now but we will again talk about that a lot in a upcoming video so this should cover your bare bones basics for binary trees which are certainly a must-know data structure when you're going into interviews nothing to be afraid of though they're just a linked list with a additional pointer all that said let's get into our tree algorithms starting right now ",
            "url": "www.youtube.com/watch?v=GzJoqJO1zdI",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "URRNruf2yVk",
            "channelId": "UCRIWTSgd7hGtZhx4RYoASEg",
            "publishedAt": "2020-06-01T15:30:06Z",
            "title": "What is a Tree? | Introduction to Tree Data Structure (diagram) | Important Tree Terms &amp; Properties",
            "description": "Support Simple Snippets by Donations - Google Pay UPI ID - tanmaysakpal11@okicici PayPal - paypal.me/tanmaysakpal11 ...",
            "channelTitle": "Simple Snippets",
            "transcript": "yo what's going on guys than my ear for simple snippets and welcome back to another video tutorial on data structures and algorithms and today finally we are starting off with our very first nonlinear data structure which is three data structure so this is just an introduction and it's a very very important video because this is where we start off with the nonlinear type of data structures and don't worry we'll take our differentiation between linear and nonlinear data structures in a separate video but this is just an introduction to the tree data structure which is a nonlinear data structure this video is very important ties and the topics that we are gonna cover in this video is as shown on the screen first we will start off with what is a tree data structure we will try to understand how a tree data structure looks by taking a real world example and then comparing it with our data structure example we will also see what is a binary tree we will also understand some important three terms and some important properties those are absolute important those are fundamentals which you need to know we will see the logical diagram in the terms of implementation of how it would look like when we actually implement a tree data structure programmatically and then at the end we will simply list down some of the types of trees some of the variations as well as the applications of tree data structure please make sure you watch this video till the end this is a very very important data structure it has a wide range of applications many variations and it is one of the most widely used data structure in real world applications also so with that being said let's get started if you new to my channel my name is thon my sock pal and I do a lot of computer science and information technology video tutorials like computer programming development technology talks and a lot more on this channel so if that's something you are interested into then definitely subscribe and turn on the notifications to get the latest updates and never miss out on such important topics now before we jump to the pre definition and understand the tree data structure a quick recap you can skip this but we've already seen this in this DSA course in this DAC playlist and we know what is a data structure right if you've seen this DAC course we already know what is data structure data structure is simply a way of storing and organizing data in the memory in such a way that access management and modification becomes efficient so it's nothing but how you store the data right now why am I taking a recap it is because which data structure to use depends upon many different criterias some of them have listed as follows which is what type of data needs to be stored the next is the cost of operations like read write update depending upon which is more efficient so for some applications may be a queue data structure is much more efficient then compared to a stack or a link list is much more efficient compared to an array we've already seen our differentiation between array and link lists in the previous tutorial and we've seen which one is better in what scenarios so same on those lines another criteria is memory usage and efficiency then we have ease of implementation and lastly we have maintainability and of course there are many other criterias but the point being said over here is every data structure has its own pros and cons with its own unique properties and some drawbacks so it depends upon the application depends upon the condition on which we decide which data structure is supposed to be used so I just wanted to give you this recap so now that you've understood what is the data structure which you already had but this was just a recap so far in this entire tutorial course as I mentioned we've covered quite a lot of linear data structures and to give you a basic explanation of what is linear and non-linear in a linear data structure data is arranged in a sequential manner so we have a logical start we have a logical end and every element has a next element and a previous element so if you see on the screen I have denoted the four basic linear data structures which we've already covered arrays stack queue and linked list if you observe array you can see data is arranged in a sequence in a proper sequential order in a linear order in a queue also you can see we have data coming in from one end and going out from the other so we have a rear and a friend that is a logical start and end in a stack also data is pushed in this direction and popped out from the same end but it is still arranged in a linear way in a sequential way and linked list again you can see we have every node arranged one of each other so all of these data structures are linear in a sense that the data is arranged in a sequential manner so now that you've got a brief idea about linear data structures let's see what is a tree data structure so the definition of a tree data structure is a tree is a nonlinear data structure that simulates a hierarchical tree structure with the root value and sub trees of children with parent node represented as a set of linked nodes okay so before we understand the technical aspect let's take a real world example of what is a hierarchical tree so let's take an example of a typical College hierarchy you know so in a College we have a chairman you would have a director so a director is under the chairman then under the director we have multiple attorneys that is head of departments so let's say in a college we have multiple departments so we have the science we have Commerce and we have Arts Department so we have their individual HIDs they all report to the director under the h.o.t we have senior faculty one and two over here we have only one senior faculty and over here we have three seniors faculties and the hierarchy would go on we would have some junior faculties and other senior faculties and so on so this is a real world example of what a hierarchical tree would look like there are many other examples in fact you have your own family tree you have a hierarchy in a company in organization and you have many different types of hierarchical data in real world so tree data structure is a data structure that simulates this behavior okay so in data structures now coming into the data structure side our data structure is gonna try to simulate this same hierarchical behavior when I say that it would mean that the data is gonna be organized in a hierarchical tree kind of scenario so let's see how that looks and then we will again go through this definition okay so on the right hand side this is where a logical tree diagram would look like for a nonlinear data structure of a tree so again let's go through the definition now so a tree is a nonlinear data structure and the reason why it is nonlinear is because data is not organized in a linear way you can see over your you have multiple links starting from one node so these blue circles are what is called as nodes okay and we'll talk about that as we move on but you can clearly see that it is not linear so this tree is a non linear data section that simulates a hierarchical tree structure so this looks pretty much like this with a root value so the top node is gonna be called as the root node so this is root which is at the top if you see in the real world example the chairman would be the root then we have ant subtrees of children so this root node is pointing to two child nodes that is two nodes below it let's name these nodes I'm going to say one two three four five six seven eight nine ten and eleven so I've just named them randomly okay this is not like there is a way to name them this is just for our reference for now and you can see root node is root node number one after that it has two nodes right billard which is node 2 and node 3 so these can be individually considered as sub trees of children so for one the children's our node two and three so if you only see everything below - it can be also called as a tree only right so it is a subtree similarly this is also a tree data structure itself so these are sub trees with a parent node parent node being root node over here and it is represented as a set of linked nodes so these yellow arrows are nothing but links or they are also called as edges okay so they are linked in a way that they look like a tree diagram now remember in a linked list also we had nodes but they were linked in a sequential way over here in a tree we would have nodes but the linking would be done in a way that they represent a hierarchical tree okay all right so now that a little bit of basics is covered a little bit of definition is understood let's try to get into more details about some important terms of tree data structure okay so on the left hand side we have some important three terms let's go one by one if you're making nodes you can take a screenshot you can note them down but don't worry I am gonna be sure all this theory along with the diagrams on our official website so you can just copy paste it and prepare your notes for your exams there's a link in the video description to our official website for this article just go there and you can refer these notes later on but now let's go one by one through all these different three terms so point number one root the root is a special node in a tree and the entire tree is referenced through it and it does not have a parent so that would be the top node which is node number one and it is called as a root node so it's a special node because there is only one root node and the entire tree is referenced through it so you can go to any node starting from the root node also it does not have anything above it so there is no parent of this root node so obviously the next question is what is a parent node so that is point number two and parent node is a node which is an immediate predecessor of a node three Desa sir means the node that comes before it so for node 2 and 3 which node comes before it immediately it is a root node which is node 1 so for node 2 and node 3 1 is their parent which basically makes 2 and 3 as child of node 1 so that is point number 3 shine load shine node is all immediate successors of a node are its children so after node 1 node 1 is directly linking to node 3 and node 2 and 2 and 3 can be considered as children of node 1 I hope I'm making sense over your please do note these points do note these terms these are absolutely important in further tutorials in further videos we will constantly refer to these terms directly and I'm going to assume that you already know so hence please pay attention now moving on we have the concept and the term of siblings nodes with the same parent are called siblings so over here if you see node 2 and 3 have the same parent as nor one so they can be considered as siblings if you see below let's go one level down node 2 is the parent of node 4 node 5 and node 6 because it is immediately predecessor of the node that is no.2 is directly linked to more 4 node 5 node 6 so this makes more 4 & 5 & 5 & 6 & 4 & 6 all of these 3 as siblings as well as all of them as child node off node 2 okay if you go one level below again node 9 and 10 are siblings because their immediate predecessor is notify which is their parent which makes 9 and 10s children of fire make sense all right so siblings is done let's move down we have point number five which is leaf so leaf is the last node in the tree and there is no node after this mode so at the bottom is where we will find the leaf nodes so over here that would be node 9 node 10 no 11 and also at this level we have node 8 because all these nodes do not have any node below 8 so is 9 link or is 9 pointing to any other node no is 10 pointing to any other node no his 11 pointing to any node no and it is also not pointing to any node which makes them leaf nodes all right okay let's see point number 6 point number 6 is edge edge is the connection between one node to another it is the line between two nodes or a node and a leaf so this yellow line is what I am trying to say is a edge it is also known as a link so it can be linked and edge please remember both these two terms it is just the line that is connecting between the two nodes now do note that these lines are not bi-directional they only go in one direction which means that you can go from node 1 to 3 but you cannot come back this is not valid so when you actually implement a tree data structure the traversal of nodes will only start from root node and it will go to the child nodes and it will go below only and not in the reverse order okay so hence the arrow is also in one direction it is not like this so keep in mind that the edges and the links are not bi-directional they are only in one direction and that is the downward direction the next term is the path so path is a number of successive edges from source node to the destination node so if the destination node is seven and I just mentioned that we will start from the root mode only the path would be this edge and then this edge right so this is going to be our path another example if this is the destination where we want to reach we will have to traverse from one to two we will have to traverse from two to five and then we will have to traverse from five to ten so three edges come between root node one and the destination node which is a leaf node of ten and that is the path the eighth remover your is the degree of the node so what is degree of the node set degree of a node is equal to the number of children's a node have so if you try to calculate the degree of the root node you simply count the direct children it has so we have node 2 and node 3 as children of node 1 so degree will be equal to 2 is simply the number of children one particular node has so if you go and calculate the degree of node 2 2 has 3 children which is 4 5 & 6 so here the degree is going to be 3 also degree of the tree is also 1 term which is the maximum number of children one particular node has and in this logical tree diagram the maximum children any node has is 3 which is node n 2 or node 2 which has the maximum number of children which is 3 so the degree of the tree you can say is also 3 okay okay so these were some important three terms I hope they were easy to understand let's see a few properties of tree data structure okay so property number one says that a tree can be termed as a recursive data structure so what does this mean now I am assuming you already know what is recursive behavior or recursion or recursive function recursion basically means that repetition of same entity or same activity over and over again till a particular condition is met okay so a tree can be considered as a recursive data structure so what does this mean so if you see if you start from root node 1 this whole data structure is a tree now if you go to its child nodes and divide it into two sub trees that is this is sub tree one and this has sub tree two you can safely say that even these two are three data structures now again again further divide these sub trees into smaller sub trees and you can keep on going till you ultimately reach a single node so this is the recursive behavior of this tree data structure which means that you can divide up entire tree data structure into smaller sub trees over and over repetitively till you reach a single unit that is the more of the tree okay hence this tree can be termed as a recursive data structure so this recursive property is something that we will use in the implementation side also and as I mentioned recursive in this context simply means that our tree data structure can be divided into smaller sub tree data structures recursively till you reach a single entity that is the null okay okay let's move forward point number two so in a valid 3 for n nodes you have n minus 1 edges that is links so if you calculate the number of nodes over here we have 11 nodes let's calculate the number of links 1 2 3 4 5 6 7 8 9 and 10 you can see we have 11 nodes so 11 minus 1 is 10 so that is the number of links so if n is equal to 11 the number of edges is gonna be 11 minus 1 which is equal to 10 so this is always going to be true for a valid T when I say valid tree it means that it is a proper pre data structure and not something other than the tree data structure this property only applies to a valid tree data structure so if you simply have one more edge - one more node let's say this is node 12 so this would be as number 11 and node will become 2 it so number of nodes again will become 12 and edges will become 11 so again the same property is followed okay all right now let's see three important properties or you can see these are important attributes of a tree the first one is depth of node so depth of node represents a number of edges from the trees root node to that particular node so whenever you want to calculate depth of any node you calculate the number of edges from the root node to that node so if I were to calculate depth for this node 6 I simply have to calculate the number of edges from this root node so this is the root node till this node 6 so we have this one first link which goes from 1 to 2 then we have this second link which goes to our nord 6 so the depth for node 6 is equal to these 2 edges so that is true ok let's calculate depth for this node so depth for node 9 is going to be equal to this first edge then we will go from 2 to 5 this is the second edge and then we will go from 5 to 9 which is our destination so this is the third edge the depth over here is 3 ok basic enough one thing to note that is the depth of root node is always going to be 0 because there is no node above root node so the depth of root node is always going to be 0 ok keep that in mind it can be asked in your exams or as a trick question moving forward what is height of the node so height of a node is the number of edges again it is number of edges only but it is different than depth of node so height of node is the number of edges on the longest path between that node and a leaf so when you calculate depth you start from root to the particular node but when you calculate height you start from that node and take the longest part till you reach a leaf ok so let's see what that means let's calculate the height of node 3 so let me write it over here height of node 3 is equal to the number of edges on the longest path between that node and a leaf so far north three if you go from three to eight this eight is also a leaf we have one edge but for three we can go in this direction also we will go from three to seven which is one edge and then we can go from seven to eleven which is second edge and this is also a leaf node so we have two options of leaf nodes starting from node three we have to select the longest path which is the longest path obviously we will go from three to seven and seven to eleven because there are two edges so two is greater than one so height is going to be two okay so height of node 3 is going to be 2 let's calculate the height of node 2 which is this node so we have first path going from node 2 to 4 and 4 is also a leaf node we have one path going from 2 to 5 and 5 to 9 so one edge and second edge again we can also go from 2 to 5 and 5 to 10 again one edge and second edge and both 9 and 10 are leaf nodes and last direction which we can go is from 2 to 6 6 is also a leaf node so this is 1 so obviously the longest path is comprising of 2 edges so height of node 2 is 2 lastly height of root node can be considered as this path that is 1 to 2 2 to 5 and 5 to 10 you can also go from 1 to 3 3 to 7 and 7 to 11 in both ways we have height of root node which is 1 is going to be equal to 3 it is going to be the longest path so I hope you have got how to calculate height of node and depth of node a lot of times students get confused between depth and height it can be different so please note these points down and how to calculate them very properly and last point last property is height of tree and the height of tree is always equal to the height of root node so height of 1 which is this root node is equal to 3 which is also equal to height of tree ok all right so these were some important three terms and properties and now let's move forward so so far what we've understood is what is the tree data structure we saw the we saw the comparison of a real-world tree hierarchy and also our logical tree but so far what we've seen is a very general tree when I say general it is not a variation or a special type of tree now we will see what is a special type of tree which is called as a binary tree and as the name suggests a binary tree is nothing but a tree where each node or where every node can have maximum of two childs okay so that is the only specific definition for a binary tree compared to a general tree that is in a binary tree every node can have only maximum of two children so over here you can see node two has three children so that is not a valid in a binary tree so let's remove out one node and let's see how a binary tree would look like okay so now if you can see we have removed one child of node two and now every node in the binary tree has maximum of two children so you can see this is the root node it has two children which is 2 & 3 2 also has 2 children 4 & 6 3 as maximum 2 children 7 & 8 & 7 has one child which is also valid in a binary tree the rule is that you cannot have more than two child 4 parent okay now the reason why we are trying to understand what is the binary tree is because majority of the future tutorials are gonna involve some form of binary tea of course we will take a look at different types other than binary tree as well but lot of work is gonna be done on binary tree hence this is the initial introduction toward what is a binary tree and now that you've understood what is a binary tree in a very general way let's take the same binary tree in the form of an implementation diagram in the form of a little bit of programmatic way how would it look like when you actually implement this tree data structure this binary tree data structure in the form of code so on the left hand side you can see binary tree diagram in the implementation view that is when you write some line of code to create these individual nodes and to try to link them so over your each of this circular node programmatically would look something like this now if you've seen the video tutorials on link list this would be a little similar a node typically would comprise of a left pointer and a right pointer when I say pointer a pointer is nothing but or entity in a node that points to the child node okay for c and c++ there would be actual pointers but if you're using some other general-purpose programming language it would be some reference or some other mechanism which would point to the next node the center part would be the data part where the actual value would be stored so this same binary tree is converted into implementation view so the first node n1 this is the name of the node n1 is the root node this hash 10 is the actual address where the mode would be created in the memory when you write a program so this is nothing but the address of course it is a fictitious address it is not a real address a real addresses look different we have just taken this for a representation okay so n1 would be a node created in the address of hash then in the memory let's say it has some value of you know let's say it is 50 so this 50 is an integer value so this data would be of type int of course it can be anything but for simplicity purpose we've taken int then we have n2 and n3 created at address locations hash 23 and hash 27 now in a binary tree we have a left child and a right child so the child which is left of the tree obviously is known as the left child and the one that we have on the right side is known as the right child this is pretty basic now n1 would point to both left child I will represent it as LC and right child as RC so n3 is address hash 27 should be stored in the right pointer so you can see star left and star right means these are pointers of type node itself so they would point to n3 for the right child and hash 23 is the address of n2 for the left child let's say they have some individual values of 7 and 1 similarly n2 for the left child would have the address of n4 n 4 is created at address location hash 73 so 73 store or let's say it has the value of 2 for n for being the leaf node which means that it does not have any node below it the address stored would be null right for the left child and right share initially whenever you add another node under it that address will be stored over here but since it is a leaf node the addresses inside the leaf nodes left and right pointers would be none for n 3 n 3 is pointing to n 6 as left child so hash 13 store hash 71 is the address of n 7 which is as the right child RC and this is left child let's say it has the value of 11 and 21 n 6 has only a left child which is n 8 let's say it as the value of 8 and it is at the address hash 55 hence 55 is stored in the left pointer of n 6 which is the parent of n it and n Phi has left and right as blank let's say it as the value of 5 okay all right so this is how the implementation view would look like when you actually create the node I will show the node class on the right you can see on the screen so this is a C++ code where you create a class node inside which you will have two pointers of the same type of node to node star left and node star right and then we have a data type which is of type int in this case that can be anything it can be a complex array type also it can be fluid it can be double it can be character or whatnot so the center value can be anything it can be alphabet ABC something like that it can be a another class it can be a user-defined class you can create a person class and store those data's over here also so that is completely upon the application also your node can have a unique identifier as P also so one more value of key can be added over your that's what we did in the linked list where key was supposed to be unique to every node so if you want a binary tree to have duplicate data you can keep extra entity as key which is supposed to be unique so that you can uniquely identify every node but that's something that you can do yourself according to you neccessity but in general this is how a binary tree would look like in the implementation side and I hope you've got a little bit of understanding of both the logical view as well as the implementation view okay so now that you've understood in depth about tree data structure at least at the theoretical side a lot of terms a lot of properties the visual diagrams let's come to the last part where we try to list down some types as well as the applications starting with types we have many types of trees we have general tree which we just saw we also saw a binary tree then we have another variant in binary tree which is binary search tree we have AVL tree spanning 3b 3b plus tree heap here is also of type of tree and we have some more examples also and this is the reason why tree data structure has so many variations and so many applications and real world scenarios because for every different type of application there is some type of tree which is suitable for it and that is the reason why tree data structure is absolutely important and right now we've just listed the types of trees but as we progress in this tutorials course we will try to understand each of these types individually in detail but right now I've just listed them so moving on to the application tree data structure can store hierarchical data we just saw that in the very beginning because a tree data structure pretty much simulates a hierarchical tree so it is best suited to store hierarchical data like folder structure organization structure any real world scenario where there is some kind of hierarchical data then point number 2 says binary search tree which is a variation of binary tree is a tree that allows fast search fast insertion fast deletion on sorted data so this is where it is more efficient or heap is a tree data structure which is implemented using arrays and it is used to implement priority queues then we have V and V Plus trees that I used to implement indexing in databases so lot of indexing in databases that happens is using these data structures trees are also used to store router tables in routers routing data and whatnot then trees are also used by compilers to build a syntax tree trees are used to implement expression parsers and expression solvers so there are some technical terms but there are many more applications which I could listed you can simply google them out and you'll realize that three data structure is pretty much used in most of those real world applications especially when there is a lot of complication involved and hence it is very important that we understand three data structure in detail okay so I'm going to conclude this video over here I know it got a little lengthy and pretty theoretical but this was very important to get started with data structures to understand the basics to understand the fundamentals as we move forward as I mentioned we will see the different types we will see some implementation we will see the tree traversal we'll also see some comparisons and whatnot so I hope this video was understandable I hope you've understood what is tree data structures at least a theoretical level and diagrammatic and implementation view if you like this video please give it a thumbs up let me know in the comments how this video was buu share it with your friends and I'll see you guys in the next video where we will talk more about three data structures thanks for watching see you in the next one peace [Music] ",
            "url": "www.youtube.com/watch?v=URRNruf2yVk",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "stacks data structures": [
        {
            "videoId": "A3ZUpyrnCbM",
            "channelId": "UCxX9wt5FWQUAAz4UrysqK9A",
            "publishedAt": "2020-10-16T01:59:50Z",
            "title": "Introduction to Stacks and Queues (Data Structures &amp; Algorithms #12)",
            "description": "Here's my introduction to stacks, queues, and deques (double-ended queues)! You can check out the problem I mentioned at the end of the video here: ...",
            "channelTitle": "CS Dojo",
            "transcript": "hey everyone sorry about the delay but in this video i'm gonna give you a quick ish introduction to stacks queues and decks or double ended queues so let's get started first of all what's a stack well personally i like to think of a stack like a bunch of pancakes so just imagine for a second that these circles represent pancakes with different numbers written on them we could have any type of data here but we're using numbers or integers as an example here and one feature of pancakes the real world pancakes is that you can stack them on top of one another so just imagine that this line here represents a plate and once you have a plate you can have pancakes stacked on top of one another so you could have minus one at the bottom and then you can put three on top of it and then let's say this one nine this pancake right here and then at the top you can put this one and then you might say okay what if i wanna retrieve this pancake right here with the number three written on it then what you would need to do is you would need to take out this one first at the top and then this next one the nine pancake and then finally you can take out this one uh so that's how you know pancakes in a real world work and it's the same thing with the stack data structure so a stack is a collection of data in which you can only add a piece of data at the top of the structure or retrieve a piece of data from the top of the structure so you aren't really able to retrieve data from any position just like you could for example in array so another way to describe the same thing is that whatever piece of data you put in last will need to come out first so in the current structure of these three pieces of data the last piece of data that we put in is nine so that needs to come out first and that's sometimes referred to as last in first out okay so that's how a stack works but how can we implement it well one way to implement it is uh by using an array so we have an array of eight elements here and we're going to try to represent this stack right here to do that the first thing we'll need to do is we'll need to have a pointer or just an integer variable that's going to point to the last element that we put in in this data structure and let's say for now that the stack is empty then there is no last element 2.2 so we can initialize this variable to -1 or the index that would be here but that doesn't exist and this shows that this stack is empty and now what if we want to start putting in some pieces of data here for example -1 here then what we can do is move the pointer here again this is going to always point to the last element that we put in in this data structure and then put -1 here and what if we want to put in a 3 on top of -1 then we can move the pointer again again pointing to the last element that we put in and then put 3 here and then we can keep doing that if we want to put 9 here oh you can move uh the pointer here or increment pointer by one and then put nine here and what if you want to remove uh this number right here nine and to do that all you need to do is you need to move the pointer back by one or decrement this variable by one now you could do something with this number right here you know either erase it or change it to something else but it doesn't really matter because in this data structure we always know that the pointer always points to the number that's at the top of this structure so the numbers following this pointer are not relevant so we can keep going like this if you want to put in 2 here you can move the pointer back here and then update this number right here with two and then if you want to put nine again here you can move the pointer by one and then put nine here and throughout this explanation we saw a few key operations here one is delete sometimes it's called pop that's deleting or removing a number from this data structure and another one is add and that's adding a number on top of this data structure and with this particular implementation you can implement both of them in one or in a constant amount of time and that's assuming that the number of elements that we put in in this data structure doesn't exceed the length of the array and if it does you will need to either zero an error or make a new array that's longer than the original array and transfer all the elements from the first array to the second array and that would take some extra time anyway that's it for a stack let's now take a look at a queue the analogy i use to understand a queue is a bunch of people lining up in a line or in a queue so let's say we have these people with some numbers assigned to them just for convenience and they want to line up to do something for example to see this octopus for whatever reason and this octopus is busy so they need to line up and with a cube i think you already know how it works but you can put people in the queue or in this line and when the octopus is free uh the person that's at the front of the queue you can see the octopus and then go away and then you can add more people in the queue or more numbers in the queue and then the person or the number that's in front of the queue you can see the octopus and then go away so that's the idea of the queue data structure and i think you can see that uh whatever number or whatever person that came in first will go out first too out of this data structure and that's sometimes referred as uh first in first out okay and how can we implement this data structure one way to implement it is with an array again and this time we're going to have two pointers the first one is going to point to whatever is at the front of the queue or in this particular example this number or this person right here and we're going to put this one right here at zero for now and the second pointer is going to point to the space that's right after the last person or the last number in the queue and for now i'm going to put this at the same position as the first pointer at zero and let's say that the queue is empty right now then we're gonna make these pointers uh be initialized to both zero right here and we're gonna implement this data structure so that whenever these two pointers point at the same thing this q is empty okay now let's think about how we can represent a line of people with this particular implementation so let's say that this person comes uh in the line first then we can put number one here and then move the second pointer right here and if there's another person uh right after that let's say 42 then we can put 42 here and then move the pointer here again the first pointer will always be pointing at the first person in the queue or the front of the queue and the second pointer will always be pointing at the space right after the last person or the last number in the queue so let's keep going with this if 13 comes in a line we can put 13 here and then move the pointer move the second pointer right here and what if the octopus is free now and this person one sees the octopus and goes away then uh we can just move the first pointer over here and we don't really have to do anything with this number right here one because in this implementation we'll know that the q is only between these two pointers so we can just keep going like that and just to show you more examples if -4 comes after that we can put -4 here and then move the second pointer over here if zero comes after that we can put zero here and move the second pointer over here or increment the second pointer by one and if 42 goes away we can move the first pointer over here let me just keep going like this and what if you have a situation like this now where you have three people in the queue 0 1 and 42 and you want to add another person minus 4 here to do that we can put minus 4 here and then you would try to move the second pointer over here but that's out of bound to fix that you can just move this pointer back here at zero instead so you can actually visualize uh this array like a circular array where if you try to go out of bound you just go back to zero so let's just keep going like that uh if we want to put 13 after that you can put 13 here and then move the second pointer by one over here and it would work the same way for the first pointer too i've if the first pointer keeps going to the right and if it's about to go out of bound instead of having it go out of bound we can just bring it back to zero right here and another thing to note about this particular implementation is that you're only able to store almost n minus one elements in this data structure assuming that the length of the array is n to explain that let's consider this situation where we have the second pointer right here and we have some elements here here and here if you try to add one more element right here you would need to move the second pointer right here to the same position as the first pointer but we've already said that in this particular implementation uh if these two pointers point to the same thing this q is empty but clearly it's not empty and that's why we would need to stop here and that's why we're only able to store n minus 1 elements where the length of the array is n if you want to store more elements you will need to either throw an error or create a new array that's longer than the original array and then transfer all the elements to the new array anyway in this implementation we saw two key operations one is removing an element or a person or a piece of data from the cube and another one is adding a piece of data to the queue sometimes it's called dq and q and with this particular implementation assuming that the number of elements doesn't exceed n minus 1 we can implement both of those things in o 1 or in constant time and that's it for a queue but let's quickly discuss another data structure and that's a deck or double ndq it's a more generalized version of the queue data structure that we saw and in this data structure deck you're able to put data and remove data from either end of this queue so you can remove this person right here or you can remove this person right here and you can add a person at the front of the queue or at the left side of the queue or add this piece of data at the right side of the queue and one way to implement this is similar to the implementation of the queue that we saw so you can use a circular array still and have the same kind of structure but in this new structure we're able to remove data from either end and add data to either n2 so you would basically have functions that are called something like add lift remove left add right and remove right sometimes they're called top left pop right or other names but you get the idea you should be able to implement all of those operations in one as well okay so that's my introduction to these three data structures but if you want to practice using these concepts one of the resources i recommend is one of my business affiliates algoexpert.io this is my referral link and this is my discount code cs dojo and there's actually an interesting problem that i found on this website for which you can use one of these concepts so i want to give you a quick introduction to that problem in this problem you're given a string of different types of brackets regular brackets square brackets and curly brackets and you want to write a function that takes a string like this and returns true if the brackets are balanced and false if they're not so what does it mean for these brackets to be balanced to explain that i think the best way to do that would be to give you a bunch of examples this one is balanced because there are square brackets inside and regular brackets outside this is not balanced obviously this is not balanced either because you're trying to close before you open this one's not balanced and this one is not balanced either because these two types of brackets are overlapping anyway you should be able to solve this problem in of and in time where n is the length of the string and of n in space as well anyway uh sorry about the delay again uh i'll try to be you know a little bit faster in my video production in the future but thank you so much for sticking with my video and you know my channel okay thank you as always for watching my videos and i'll see you guys in the next one ",
            "url": "www.youtube.com/watch?v=A3ZUpyrnCbM",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "77GDiGd1_UU",
            "channelId": "UCZUyPT9DkJWmS_DzdOi7RIA",
            "publishedAt": "2020-06-11T17:26:24Z",
            "title": "Introduction to Stacks - Data Structures and Algorithms",
            "description": "~~~~~~~~~~~~~~~ CONNECT ~~~~~~~~~~~~~~~ \u2709\ufe0f Newsletter - https://calcur.tech/newsletter Instagram - https://www.instagram.com/CalebCurry Twitter ...",
            "channelTitle": "Caleb Curry",
            "transcript": "hey you might grab me that SQL book sure see where is it SQL there we go yeah yeah that's not how stacks work hey everyone welcome as you can see I've been working on my tan how does it look now I'm just playing I just haven't fixed the settings yet let's try to get these looking a little bit more normal there we go so what are we gonna be talking about today we're gonna be talking about the stack data structure and yeah I just like looked because I couldn't remember so I have my notes over there so we're gonna be talking about stacks so these are often taught with another data structure known as queues they're very similar but it helps to understand stacks first and then picking up the queue is actually a piece of cake and no I don't mean a literal piece of cake I just mean it's gonna be easier to learn the queue after you learn the stack so the way a stack works is first we're going to approach it more like a conceptual way and then we're going to look at some of the operations of a stack so in the example of let's say books if you have a stack of books and I literally just made a stack of books nothing technical or fancy here well if you wanted to add a book to this stack the most logical place to put it is on the top and that is how a stack of data structure works as well we're going to represent data in such a way that we put stuff on top like so and then when we need to get data back out we actually take it off of the top so this one's going to come off of the top and we will have it over here and then it will no longer be on our stack so conceptually that is how a stack data structure works just like a normal stack of anything in real life now if we wanted to describe the capabilities of a stack data structure we could break it down to two key essential very important operations how to have as many adjectives as possible there so these operations are pop and push and these are functions or actually usually these are going to be methods on an object in our code so you might have something like data dot pop and data dot push where data is some collection some variable now what is the data type of this data variable well it's going to be some collection and by collection I mean it's probably going to be a dynamic array or a linked list so those are the two common ways of doing it you can do it with a dynamic array heck you could even do it with a static array too it's just going to be a little bit different but most of the time it's going to be a dynamic array or a linked list and heck this is interesting because there's actually different ways of creating a stack and because of that because there's different ways of doing it the stack is known as an abstract data type so you know when you study like abstract art it's just people like splash paint up on something and they say something like hey you can interpret it however you will you can bring it into existence and I'm not an artist okay but similar thing here where we define behaviors a little bit more abstractly by just saying hey it has to have a pop method and it has to have a push method the actual implementation can vary it could be a dynamic array it could be a linked list it's up to you guys to decide how you want to actually create a stack data structure so the stack is less about a physical thing and more about a set of behaviors the ability to push something on the stack and the ability to pop something off of the stack crazy so let's start from the beginning and build this stack right here I'm gonna erase it and we're gonna go from scratch so the very first thing is we put our very first element and to do this we invoke the push method so here is going to be the the actual method calls so we'll say data dot push and instead of using the concept of books let's just go with some other type of data like integers let's say we push Z number 5 well we're going to see how you could visualize this over here so we're going to have the value 5 at the bottom of a stack then inside of our array it's going to look like so one element five now let's say we want to put another piece of data on top of the stack the way we do that is we would say data dot push and this time let's pass in 10 so 10 visually is going to be on top of this 5 and is going to be represented in the array just with another element so the length of the array is now 2 now let's add one more element in here so we'll say data dot push and let's pass in negative 7 just to switch it up alright so this is going to go up here and we're going to have another element in our array like so all right let's do one more element and then we'll talk about pop so let's say data dot push and what number you guys want to put you want to do positive 7 all right yeah I like that all right so that's gonna go there and that's gonna go right there in our array so now let's talk about the pop operation so the pop operation modifies the stack it changes the data of the stack what it does is it will remove this element here will remove it here and return it so what that means is we can assign it to a variable so the call to this would look like so we would create some variable and then we would invoke data dot pop we don't pass anything in it's always going to grab that top element and now this variable element contains the value 7 so that is how a stack works so if we wanted to get this element here here's what we're going to do we're just going to say data dot pop again data dot pop so the first one will get rid of that number the next one will get rid of that number and then we do it one more time and we can assign this one to a variable let me think of some creative variable name and this is going to be assigned data dot pop now if you don't actually need to use that data later for example in this case the negative 7 and the 10 you can just invoke pop without actually storing that anywhere but if you need to use it later then you can assign it to a variable now our array is going to be empty but we're going to have two variables available to us element which is going to contain what was it 7 and then we're going to have this other variable my var which is going to contain the value 5 so cool the Sun is so unenthusiastic so the push method and the pop method are methods that describe the operations but if you are working inside of a programming language it's going to depend on whatever structure you were using so if you were using a list inside of Python these methods are going to be different if you are in an ArrayList inside of Java or C sharp these again are going to be different so the actual method names change but the functionality stays the same the way to describe this without using these names is basically the ability to add an element to the end of the collection and the ability to remove it and return it so those are the two general behaviors of a stack now let's talk about an example with Python to create a stack in a Python we first create a list variable so that's gonna look like so we would say data and we'll just assign it an empty list next up is the push capability and with a list inside of Python this method is known as append so we would say data dot append and we would pass in some data such as 5 now for the pop operation Python actually kept that name so we could say something like element or literally any variable name is data dot pop and that is a method call and then what we can do is if you wanted you could say print and pass in element so that is how you would do this inside a Python but I'm sure figuring this out and in any of the major programming languages is going to be fairly simple now again because a stack is an abstract data type all it really cares about is that there's a push operation and a pop operation it doesn't necessarily mean there can't be other things so oftentimes there will be some variation of a peek method and what this will do is it'll actually look at that top element without actually popping it off of the stack because if you have a stack you might want to check to see what this number is right here without actually removing it so that's sometimes called peek if we're just talking about the abstract data type you would say peek but different languages are going to have different names so a very universal way to do a peek would basically be to grab the element at the last index so in this case what we do is we would say data and then we would use array notation or just square brackets and inside of here we're going to say the length of data minus 1 and that's how you would get that last element you could assign that to a variable just like we did here but it's not actually going to remove it from that list so the list stays unchanged so we talked about stacks and we understand them conceptually when would you actually want to do something like this well there's various ways that this is used already so for example a call stack basically anytime you invoke a function in your code that gets added to a stack so when that function finishes and returns we basically pop that function off of the stack and return to where we were so there's a portion of memory known as a stack and this is actually like an upside down stack so we add elements this way grows this way and this is just a portion of memory that is used for various things so if you want to know more about that just look up stack memory or something like that and you'll be able to find information on that another common use of the stack data structure is to do something known as backtracking so if you imagine you had like a maze I'm gonna try not to draw a swastika here and here you are well if you want an algorithmic way to describe how you would solve this you basically go down a path let's just say you always go to the rightmost path first so you go right and then you go what would that be yeah they'll be right again and oh you hit a wall that doesn't work so if you put those right operations in a stack and you basically had a list like so right right and then you've hit a wall then you're just backtrack you pop those off the stack and say hey we need to back up and then we need to back up again and go this way now it looks like we might go left and keep going left until we go right so now the stacks going to look like this left and then right mmm that's not working out either so you pop those off the stack and backtrack to where you were anyways this is getting like really ugly but basically the backtracking is an approach to solve various paths in code I actually did a video on solving mazes in Java inside of my 30 days of Java series if you're interested we build out a maze structure using ASCII characters and we basically tell the computer to start at a position and end at a position and it will basically follow these different paths it's something you can build recursively or iteratively and we're going to get into the differences there in the future but basically it's a really cool way to make the computer try all possibilities and if it knows a direction doesn't work then it's going to back it up and try a different path so that's your introduction to the stack data structure next up you probably want to understand the queue data structure so stay tuned for the next video I think that's what we're going to be talking about and if it's not in the next video we'll be talking about it soon if you've enjoyed this content please be sure to subscribe and I'll see you in the next one you you ",
            "url": "www.youtube.com/watch?v=77GDiGd1_UU",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "wjI1WNcIntg",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:25Z",
            "title": "Data Structures: Stacks and Queues",
            "description": "Learn the difference between linear data structures stacks and queues. This video is a part of HackerRank's Cracking The Coding Interview Tutorial with Gayle ...",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. Today I'm going to talk about stacks and queues. Stacks and\nqueues have a lot of things in common. They are both linear data structures in\nthat you have one element and another element and then another element. They\nare both flexible with their sizes so you don't have to allocate initially\nthem to have a size like 50, you can just add elements as you go and then also\nshrink it down. The main difference comes in how elements are removed from the\nstack or from the queue. A stack is what would be called a LIFO data structure,\nlast in first out. It's much like an actual stack of plates.\nThe last plate you put on top of that stack, that's going to be the first one\nyou remove, its LIFO, last in first out. A queue though, is FIFO, first in first out. So think about a queue or line of people waiting to get into a movie theater. When\nthe movie theater doors open they don't first serve the person who\njust hopped into line five seconds ago. They serve the person who got in line at the\nvery very beginning an hour or two ago, and then the next person and then the next person. The\nvery first person in is the very first person removed. That's what FIFO means,\nfirst in first out. Now let's look at the code for these data structures. Here's\nthe framework for what our queue class needs. We need this inner class which is a node,\nand it just keeps a pointer or variable that represents the data, and then also\neach node needs a pointer to the next node and we gave ourselves a little\nconstructor here. Now when we implement a queue or when you use a queue we're going to\nadd things here to the tail and remove from the head. Because you want to add from one side\nand remove from the other. Okay. And then we need these methods so let's walk through and\nactually start implementing these methods. So is empty is very simple just\nreturn if head is null. If head is null then the queues empty otherwise it's not. Okay.\nAnd then peek. Well what peek is going to do is just return head dot data.\nNow this will throw an exception when head is null, if you want you can go explicitly check\nfor that exception. Ok so the add and remove are the sort\nof interesting ones. So with add what we want to do here is add to the tail. So\nfirst thing we need to do is actually go and create this node, then if tail is not\nnull, let tails next pointer point over this node, and then update the tail. Then what we\nwant to do is we want to make sure that even, there could be a case for the array\nwith the queue is completely empty in which case head is null, and so if the head is null, then this value should head, should also be this node. Alright. So that's all add\nhas to do. Alright now for remove we want to remove from the head of the\nlinked list so first what I'm going to do is actually get this head data then what we want\nto do is simply move the head. So I set head equals to head dot next and that\nbasically removes it from the queue and then we need to say okay if head is now\nnull make sure you set the tail to null too, and then go and return that data.\nSo that's the basics of how we implement queue. It follows pretty logically from the\nactual design and the algorithms behind it. Now let's look at the stack\nimplementation. Much like with the queue, we have this inner class that is a node\nclass, has a pointer to the next node. Here though we're going to want to add\nand remove from the top. So we just need a top, we don't\nneed a head and a tail anymore. And then these are the methods were going to want\nto implement. The implementation for is empty is pretty straightforward, just if top\nis null, return true, essentially. And then for peek I'm gonna ignore know pointer\nchecks just to keep my code really really simplistic for you all. All peek needs to do is return top dot\ndata. Ok so push is the first interesting\nmethod. So first we need to actually create this new node, so node, so new node\ndata then this new node is going to become the top. So node dot next is going to point\nover to the old top and then the top points over to node. That's all push\nneeds to do. Now for pop. Well pop is going to, first going to need to, we're going to want to return the old heads data, so first we need to actually just get that data. So head dot\ndata, sorry top dot data. Then top just should move, be moved and pointed over to\nthe new top or the next element down, and then we just need to return that data.\nPretty straightforward. Now again I ignored null pointer checks but if you really want to be complete you'd probably want to do some sort of\ncheck that says hey if top is null throw an exception, if something like. That's\nthe basics of how stacks and queues are implemented.  They're not too tricky to\nimplement just a little bit of, you know, pointers and making sure to\nupdate those things correctly. Now that you've seen both stacks and queues and\nimplementation of them why don't you try these out on a new\nstack or queue problem. Good luck. ",
            "url": "www.youtube.com/watch?v=wjI1WNcIntg",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "F1F2imiOJfk",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2013-10-01T10:24:32Z",
            "title": "Data structures: Introduction to stack",
            "description": "In this lesson, we have described stack data structure as abstract data type. Lesson on Dynamic memory allocation: ...",
            "channelTitle": "mycodeschool",
            "transcript": "In this lesson we're going to introduce\nyou to stack data structure. Data structures, as we know, are ways to\nstore and organize data in computers. So far, in the series we have discussed\nsome of the data structures. We have talked about arrays and linked\nlists. Now in this lesson we are going to\ntalk about stacks and we are going to talk about stack as abstract data type or ADT. When we talk about a data structure\nas abstract data type, we talk only about\nthe features or operations available with the data\nstructure. We do not go into implementation details.\nSo basically we define the data structured only as a mathematical or\nlogical model. We'll go into implementation of stack in\nlater lessons. In this lesson, we're going to talk only\nabout stack ADT. So we are only going to have a look at\nthe logical view of stack. Stack as a data structure in\ncomputer science is not very different from stack as a way of organizing objects, in real world. Here are some examples of\nstack from real world: First figure is of a stack of dinner\nplates. Second figure is of a mathematical\npuzzle, called tower of hanoi, where we have three rods or\nthree pegs and multiple disks and the game is about moving a stack of\ndiscs, from one peg to another with this\nconstraint that, a disc can not go on top of a smaller\ndisc. Third figure is of a pack of Tennis balls. Stack basically is a collection with\nthis property, that an item in the stack must be inserted\nor removed, from the same end that we call the top\nof stack. In fact this is not just a property, this\nis a constraint or restriction. Only the top of a stack is accessible and\nany item has to be inserted or removed from the top. A stack is\nalso called 'last in first out' collection. Most recently added item in a stack has to go\nout first. In the first example, you will always\npick up a dinner plate from top of the stack and\nif you will have to put a plate back into the stack, you will\nalways put it back on top of the stack. You can argue, that I\ncan slip out a plate from in between without actually\nremoving the plates on the top. So the constraint that I should take\nout a plate always from the top is not strictly enforced. For the sake of\nargument, this is fine. You can say this. In other\ntwo examples where we have discs in a pag, and tennis balls in this box that can open only from one side,\nthere is no way you can take out an item from in between. Any insertion of removal has to happen\nfrom top. You can not slip out an item from in\nbetween. You can take out an item, but for that you will have to remove all\nthe items on top of that item. Let's now formally define stack as an\nabstract data tape. A stack is a list or collection with the\nrestriction that insertion and deletion can be performed only from\none end, that we call the top of stack. Let's\nnow define the interface or operations available with stack ADT. There are two fundamental\noperations available with a stack. An insertion is called a 'push' operation. 'push' operation can insert or push some\nitem 'X' onto the stack. Another operation,\nsecond operation is called 'pop'. 'pop' is removing the most recent item from the stack,\nmost recent element from the stack. 'push' and 'pop' are the fundamental\noperations and there can be few more. Typically there is\none operation called 'top', that simply returns the element at\ntop of the stack. And there can be an operation to check\nwheather a stack is empty or not. So this\noperation will return true if the stack is empty, false\notherwise. So 'push' is inserting an element on top\nof stack and 'pop' is removing an element from\ntop of stack. We can 'push' or 'pop' only one element at a\ntime. All these operations that have written\nhere can be performed in constant time, or in other words their\ntime complexity is O(1). Remember an element that is pushed or\ninserted last on to a stack, is popped or removed first. So stack is\ncalled 'last in first out' structure, what goes in\nlast comes out first. 'last in first out', in short is called\n'LIFO'. Logically a stack is represented\nsomething like this: As a three sided figure, as a container open from one side. This is representation\nof an empty stack. Let's name this stack 's'.\nLet's say this figure is representing a stack of integers. Right now the stack is empty. I will\nperform push and pop operations to insert and remove integers from the\nstack. I will first write down the operations here and\nthen show you what will happen in the logical\nrepresentation. Let's first perform a 'push'. I want to 'push' number 2 on to\nthe stack. The stack is empty right now, so we\ncan not 'pop' anything. After the 'push', stack will look\nsomething like this: There is only one integer in the stack, so\nof course its on 'top'. Let's 'push' another integer. This time, I want to 'push' number 10. And now lets say we want to perform a 'pop'. The integer at 'top' right now is 10. With a 'pop', it will be removed from\nthe stack. Let's do few more 'push'. I just pushed\n7 and 5 onto the stack. At this stage, if I will call 'top'\noperation, it will return me number 5. 'IsEmpty' will return me false. At this stage, a 'pop' will remove 5 from the stack. As you can see the element, the\ninteger which is coming last, is going out first, That's why we call\nstack 'last in first out' data structure. We can 'pop' till the stack gets empty. One more 'pop', and stack will be empty. So this pretty much is stack data\nstructure. Now one obvious question can be what are the real scenarios where stack helps us. Let's list down some of the\napplications of stack. Stack data structure is used for\nexecution of function calls in a program. We have talked about this quite a bit in\nour lessons on dynamic memory allocation and linked lists. We can also say that stack is used for\nrecursion, because recursion is also a chain of function\ncalls. It's just that, all the calls are to the same function.\nTo know more about this application, you can check the description of this video,\nfor a link to 'MyCodeSchool' lesson on dynamic memory allocation. Another application of stack is we can\nuse it to implement undo operation, in an editor. We can perform undo\noperation in any text editor or image editor. Right now,\nI'm pressing 'Ctrl Z', and as you can see some of the text\nthat I have written, is getting cleared. You can implement this using a stack. Stack is used in a number of important\nalgorithms, like for example a compiler verifies\nwhether parentheses in a source code are\nbalanced or not using Stack data structure. Corresponding\nto each opening curly brace or opening\nparentheses in a source code, there must be a closing parentheses at appropriate\nposition. And if parentheses in a source code are\nnot put properly, if they're not balanced, compiler should throw error and this check can be\nperformed using a stack. We will discuss some of these problems\nin detail in coming lessons. This much is good for an introduction. In\nour next lesson we will discuss implementation of stack. This is it for\nthis lesson. Thanks for watching!! ",
            "url": "www.youtube.com/watch?v=F1F2imiOJfk",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "bxRVz8zklWM",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-09-07T14:26:36Z",
            "title": "3.1 Stack in data structure | Introduction to stack | data structures",
            "description": "In this lecture, I have described stack as abstract data type, introduction to stack and various operations performed on stack with example. See Complete ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "Yeah right we have discussed few data structures like array and Ling lists how data is stored in array what are the different operations on array what is linked list or what are the different operations on linked list how data is stored in linked list right and now we will see what is the stack data structure so you can see it is a linear data structure fine and seen array what is their random access as possible you can directly access any data in a constant time in linked list what only sequential access is possible right what about stuck in stack only you can say limited access is possible right or you can say it is a ordered list what is that it is an ordered list or you can say it is a collection or you can say it is a container which is going to follow a rule for insertion and deletion of the data right and what is that rule or what is that restriction you can say or what is that principle right which that stack data structure follow so that rule is insertion and deletion is possible only from one end right this is applied on both insertion and deletion insertion and deletion is possible from only one end like you can take a real life example suppose you have a CD stand right like this you are going to put CDs here first CD then second third fourth fifth obviously like this you are going to put suppose you want to insert another CD in that case you have only one way to insert CD from the top only you cannot insert CD here from the bottom you cannot insert from the left or right the only way is from the top only you can insert that CD right second K says if you want to take out a CD from this series stand then what you will do only one option you can take out from the top right suppose you want to take out in this city the first CD right so you don't have any option the only option is first of all you will have to take out all the CDs which are placed above this CD after that only you can take out this CD right that is the restrictions on insertion and deletion in stock fine so in this video we will see how logically you are going to represent a stack what are the introduction introductory part of stack some basic operations on stack what what are the meaning of those operations as well as some applications of stack in next video we will see how to implement a stack right using arrays as well as using link inst so now like this if you map this real-life stack obviously this is what a stack only or you can say a stack of plates right one plate is you have put one plate here if you want to play a place another plate then you will put on this plate then third and fourth and fifth like this you are going to place if you want to remove a plate then first plate you will take out first right so the principle is what last in first out you can say right this is the last plate or you can say this is the last CD you have put in the CD stand and the last CD would be the first one that you can take out so last in first out leaf oh so the rule on which this stack data structure works is what leave for last in first out or you can say first in last out this CD was first in but if you want to take out this CD then this would be the last one you can take out because for for taking out this CD outside of the series 10 you how to take out all the above CDs first of all right so first any last out and if you will map this real-life example of stack in this with this stack then you can say the logical represent datian of the stack is what we represent stack something like this like this this is what a stack you will represent this it is a container which has only one open end you can insert data from here you can delete a data from here right there is no other way this is what a stack logical representation of stuff this is not actual representation of stack right that we will discuss in later we use right and in stab insertion operation when you will insert some data understand that operation is known as push right and deletion operation is known as pop so two fundamental operations are there on the stack one is push one is pop push means inserting or putting a data into the strap pop means taking out or deleting the topmost data from the stack right two fundamental operations many more operations are also there that if you are we will also discuss now see this is the only and from where you are going to push and pop the data right so this is known as top top of the step right you can insert a data and you can delete data from top of the stack that end is known as top from where you can insert you can push and pop data right so now we will see some operations that are performed on star data structure see first is push and in bracket you will write down that a data you want to insert into stack C stack is what it is a collection of similar data type only it's not like that this is stack and here the first data is suppose integer and after that I'm inserting a character after that again I am inserting to know you can only insert the data of similar data type either in teaser all the data should be integer or character or float something like this right see push second operation is pop operation right here they don't pass any argument here why so because pop means always the topmost element would be popped out from the step right so no need to pass anything in this function these are two fundamental operation third operation may be peak operation or somewhere it is also known as top operation it means what it is going to return the topmost element of the stack without removing that element from the stack see Bob will return the topmost element from the stack as well as it will remove that element from the stack see suppose this is what I have stack and in this I have data type 1 I have data 1 2 & 3 if you write down pop it means it will remove 3 from the stack now this is the step right and if on this stack you will perform peak operation or top operation it means it will return 3 but it will not remove this from the step this is the difference right fourth operation may be is empty means it will true if the stack is empty there is known data in the list just in the stack right otherwise it will return false sake another may be is full so this function will return true if this stack is full otherwise it will return false see these are not the only operation you can perform there are many more operation you can perform on stack like you cannot perform search operation reverse operation you can find out that minimum element from the stack maximum value element from the stack right bad thing also we will discuss in a later videos right these are some fundamental operations you can perform one stack fine now we will see the logical representation of stack as well as we are going to perform these operations right so this is how we logically represent the step right not actually in the memory this is just a logical representation right for your understanding purpose now obviously you want do you want to push some data in the stack right so you need to know the capacity of the stack or you can say the size of the stack so you need to allocate some memory to the stack right and how to fix that size how you will get to know the size of the stack you can allocate the memory either using static memory allocation or dynamic memory allocation there are two ways to implement stack static memory allocation and dynamically you can implement step static means using arrays you can implement stack write dynamic means using linked lists you can implement stack so these implementations we will see in the next video with the proper with the help of an example plus code right so now suppose I have taken the size of the stack as 5 means the stack can store only five elements either using by static memory location or dynamic memory allocation right that thing in detail we will discuss in next video see suppose the capacity is here 5 so you can insert here 5 elements only fine at starting at starting top is what top is equal to minus 1 fine 5 means you can say you can insert 5 elements the index would be 0 first of all then 1 then 2 then 3 then 4 from 0 to 4 right so here 5 elements I can store this is the capacity of the stack at starting top is minus 1 right minus 1 means somewhere here minus 1 hypothetically we assume that here we have minus 1 index right now suppose in the empty stack you call this pop operation what would happen pop means the topmost element would be removed but here we don't have anything stack is empty in this case it is what under flow condition it will return what the stack is empty so this is what an under flow condition you can say right and now suppose I'm calling push to write actually implementation or loose also we will see how to write down the code for push and pop right here I am just giving you the brief introduction push 2 mins here from the top one you will insert this 2 right we have only one end so first of all what would happen top is -1 so we will increment this top first of all top plus plus it means top becomes 0 now now here we have top and now you will insert this to write again if you will call push 3 again first of all top plus plus right now table becomes this one top is pointing to this one 1 and now you will insert 3 here in the stack fine if you call pop no need to pass any argument here why so because only the topmost element would be removed from the stack you cannot write here pop 2 means if you want to remove this 2 you cannot see pop 2 and this 2 would be removed no always this element would be removed right so pop 3 pop means the 3 would be removed from the stack and now see right now we will do top minus minus means now again top is 0 Oh second again if you do pop in that case again though would be removed from the list or simply you can do top minus minus means top is now minus 1 right and if you will not remove this if you will not take out this from the stack that is also fine because this is now a garbage we do not care what garbage value is there in the stack because after that if you will again call push for then first of all top plus plus means now top becomes 0 minus 1 to 0 here we will this too would be overwritten and herefor would be stored right this thing also will discuss how to code push and pop operation fine now suppose I am going to push four times one five six and seven one five six and seven again I am calling push eight now the stack is full Vegas capacity is only five right so now it should return what it is what an overflow condition we have discussed what is under flow condition now here this is what overflow condition if this dope is pointing to this maximum size minus one the index is for maximum size is five in that case it would return overflow condition you cannot insert any data in the stack because stack is full so this is what overflow condition and now here if you will call is full function means it will return true if the stack is full and now the condition is status full so it would return at this time is full function would return true right and when there is nothing in the stack suppose we have popped out all the data and after that we call is empty in that case it would return true because stack is empty how you are going to code these function we will see what so now what are the applications of stack see the very basic application is if you want to reverse a string or in reverse a word then we will use stack that is very simple suppose I want to reverse I have a string ABC and D so I want to reverse this I want to print a DC B and a so simply what I can do I can push this into stack first of all ABC and D and then pop out first of all D would be popped out then C then B then e this is what we have reversed to the string second application is for undo mechanism in text editor I guess everybody have used this undo mechanism suppose you have written something I have written ABCDE right in the text editor in text editor and you press ctrl-z the shortcut key for undo then you would be deleted then D would be deleted then C then B then a this mechanism is performed using step in your text editors right third application maybe you can use it in recursion or you can say in function call when you are going to call a function then obviously something would be returned some value would be return like and recursion means it is you can say a chain or function call a function is calling itself again and again right so whenever that function would return something then that values would be stored in stack how actually recursion will work that also we will discuss when we will discuss recursion fourth may be to check the balance of the parentheses parentheses means like this the compiler use stab for verifying the balance of the parentheses means for each opening parenthesis there is proper closing parenthesis at right place right suppose here is opening again here I have opened again here I hope open so it means there should be three closing brackets right so this balance would be checked using step this thing also we will discuss in detail right fourth application may be in fix to postfix or prefix conversion when you are going to convert these expressions from infix to postfix or in fix to prefix in that case also starting to be used that thing also will discuss entity right and as well as in many algorithm stack data structure is used you can say in topological sorting in DFS we are using staff in Tower of Hanoi problem also we are going to use staff in tray traverser also we will use step right so there are many applications of staff and sixth you can say for the evaluation of postfix expression we will use step right that is also we'll discuss all the application we will discuss in detail this is just an introductory video of this tag to get you familiar with stack the logical representation of star how actually we are going to implement stack how we are actually going to code these operations we will discuss in next you fine so I'll see in the next video till then bye-bye take ",
            "url": "www.youtube.com/watch?v=bxRVz8zklWM",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "FNZ5o9S9prU",
            "channelId": "UCcDGsN3JxMavDkM9INRLGFA",
            "publishedAt": "2013-01-15T00:17:38Z",
            "title": "What is a Stack Data Structure - An Introduction to Stacks",
            "description": "This tutorial covers the basic concepts and functions of a stack data structure. Want to learn C++? I highly recommend this book http://amzn.to/1PftaSt Donate ...",
            "channelTitle": "Paul Programming",
            "transcript": "hey everybody this is Paul in this tutorial I'm going to be explaining the basic concept of a stack data structure so what is a stack well a stack is basically a way that we can store information and I went ahead and drew a diagram here of what a stack looks like and basically what we have here is we have five different items and you can think of these as five different nodes and each node contains some data in it and they're just kind of stacked on top of one another and at the very top of the stack the top item is being pointed to by a pointer that we call the stack pointer so basically what we have with a stack is we have two main functions to manipulate it we have the push function which adds an item or some data to the top of the stack or we have the pop function which removes the item from the top so these are the two functions that we use to manipulate our stack and notice that they're both doing something to the top of the stack so if we ever add anything to a stack we are always adding it to the top if we ever remove something from the stack we are always removing it from the top so adding an item to the stack is called pushing it in removing an item from the stack is called popping the item so because of these two functions and because they always have to manipulate the top of the stack we call the stack a last in first out data structure because the last item that was placed on the top of the stack is always going to be the first item removed from the stack because they both manipulate the top so now that I have covered all the basic concepts of a stack data structure let's just go ahead and write some pseudocode to build our own stack and just kind of show you how something like this would work so let's say that we've already written our push in our pot functions and let's just say that we want to push on the value one onto a stack so this is just going to be pseudocode this isn't any particular language that I'm doing here I'm just doing this for illustrative purposes so my push function is going to basically take the value one and place it on a stack now for now we don't really have anything we don't have any type of stack at this point so we'll just say that this is our stack pointer and he's pointing to let's just go ahead and do it down here let's just say our stack pointer is down here and he's just pointing to null right now to begin with so he's pointing to nothing and then I go ahead and implement this part of my code and it's going to push the number one on the top of the stack so what's going to happen when I do push one is it's basically just going to create a node and then place the item or the data one inside that node so then if I wanted to push three what would happen is my stack pointer would move up to the next location so would create some sort of new node here and then our stack pointer would point to that location and then we would place the value three into the new node that we created and now this is the top of the stack if we wanted to do another push we could do push five if we wanted to so basically that's just going to create some sort of new node here move our stack pointer to the next part and place the value five in it so what happens if we use the pop command if we did pop we wouldn't put anything in the parenthesis here we wouldn't be placing any argument in we would basically be returning a value and so if we were to just do pop at this point what it would do is it would go find the stack pointer it would remove the number five and put it somewhere depending on how we wrote our function and then once that's done it would just delete the top node and move the stack pointer to the new top to the element below it so one more pop would basically remove three send it to some part of our program depending on how we wrote our pop function it would put three in a certain location and then we would just go ahead and move our stack pointer back down to the location below the top and now this is the new top so anyway that's the basic concept of the stack data structure we're always adding and removing from the top of the stack and because of that it is a last in first out data structure and the two things that you normally do with the stack are the push and the pop a push adds an item to the top of the of the stack and a pop removes an item from the top of the stack and we keep track of the top of the stack by a stack pointer so anyway hopefully this was educational for you and soon once I get everything working correctly on my computer as far as screen capturing and audio I'm going to be making some programming tutorials where you can actually see me code this stuff so stay tuned for that and thank you guys for watching have an excellent day and if you haven't already don't forget to subscribe ",
            "url": "www.youtube.com/watch?v=FNZ5o9S9prU",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "sFVxsglODoo",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2013-10-08T02:52:32Z",
            "title": "Data structures: Array implementation of stacks",
            "description": "In this lesson, we have discussed array based implementation of stack data structure. Source Code: C code: https://gist.github.com/mycodeschool/6878252 C++ ...",
            "channelTitle": "mycodeschool",
            "transcript": "In our previous lesson we introduced\nyou to stack data structure. We talked about stack as abstract data type or ADT has been often we define \ndata structure as abstract data type. We define it as a mathematical or\nlogical model. We define only the features or\noperations available with the data structure and do not bother about implementation.\nNow in this lesson we will see how we can implement stack data structure. We will\nfirst discuss possible implementations of\nstack and then we will go ahead and write some code.\nOkay so let's get started as we had seen a stack is a list or collection with this restriction, with\nthis constraint that insertion and deletion that we call push and pop operations in a stack must\nbe performed one element at a time and only from\none end, that we call the top of stack.So if\nyou see if we can add only this one extra\nproperty only this one extra constraint to any implementation\nof a list that insertion and deletion must be\nperformed only from one end then we can get\na stack. There are two popular ways of creating\nlists we have talked about them alot in our\nprevious lessons we can use any of them to create a stack.We can implement stacks using a) arrays and b) linked lists both these\nimplementations are pretty intuitive. Let's first discuss array based\nimplementation. Let's say I want to create a stack of\nintegers, so what I can do is I can first create\nan array of integers. I am creating an array of 10 integers here,\ni'm naming this array 'A'. Now I'm going to use this array to\nstore a stack, what I'm going to say is\nthat at any point some part of this array starting index 'zero' till an index marked as 'top' will be my stack. We can create a variable named 'top' to store the index\nof top of stack. For an empty stack top is set as -1, right now in this figure top is pointing to an imaginary -1\nindex in the array. An insertion or push operation will be something like this. I will write\na function named 'Push' that will take an integer 'x' as\nargument. In 'Push' function we will first\nincrement top and then we can fill in integer 'x' at top index. Here we are assuming that 'A' and 'top' will be accessible to 'Push'\nfunction even when they're not passed as\narguments. In 'C' we can declare them as global variables or in an object-oriented implementation\nall these entities can be members of a class. I'm only\nwriting pseudo code to explain the implementation logic. Okay, so for this example array that I'm\nshowing here, right now top is set as -1 so my stack is empty. Let's insert\nsomething onto the stack. I will have to make call to 'Push'\nfunction. Let's say I want to insert number 'two' onto the stack, in a call to 'Push' first 'top' will be\nincremented and then the integer passed as argument\nwill be written at top index, so two will be written at index\n'zero'. Let's push one more number, let's say i want to push number 'ten' this time. Once\nagain 'top' will be incremented 'ten' will now go at index 'one', with each\npush the stack will expand towards higher indices in the array. To\npop an element from the stack, i am writing a function here for pop\noperation. All I need to do is decrement 'top' by 'one' with a call to 'pop'. Let's say i am making a call to\n'pop' function here, top will simply be decremented. Whatever cells are in yellow in this\nfigure are part of my stack. We do not need to reset this value\nbefore popping, if a cell is not part of stack\nanymore we do not care what garbage lies there. Next time when we will push we will\nmodify it anyway. So let's say after this pop operation I want\nto perform a push, i want to insert number seven\nonto the stack. So top once again will be incremented\nand value at index 'two' will be overwritten, the new value will be 7. These two functions 'push' and 'pop' that\ni have written here will take constant time. we have simple\noperation in these two functions and execution time will not depend upon\nsize of stack. While defining stack ADT we had said that\nall the operations must take constant time or in other words\nthe time complexity should be O(1) . In our implementation here both push\nand pop operations are O(1). One important thing here we can push onto the stack only till array is not exhausted, only till some\nspace is left in the array. We can have a situation where stack\nwould consume the whole array so top will be equal to highest index in the array.A further push will not be\npossible because it will result in an overflow. This is\none limitation with array based implementation. To avoid an overflow we can always\ncreate a large enough array, for that we will have to be reasonably sure\nthat stack will not grow beyond a certain limit. In most practical\ncases large enough array works but irrespective\nof that we must handle overflow in our\nimplementation. There are couple of things that we can do in\ncase of an overflow, 'push' function can check whether array is\nexhausted or not and it can throw an error in case of an\noverflow. So push operation will not succeed, this\nwill not be a really good behavior. We can do another thing, we can use the\nconcept of dynamic array. We have talked about\ndynamic array in initial lessons in this series. What we can do is in case of an\noverflow we can create a new larger array. We can copy the content of stack from\nolder filled up array into new array if possible we can delete this\nsmaller array. The cost of copy will be O(n) or in simple words time taken to copy\nelements from smaller array to larger array will be\nproportional to number of elements in stack or\nthe size of the smaller array because anyway stack will occupy the\nwhole array. There must be some strategy to decide\nthe size of larger array. Optimal strategy is that we should\ncreate an array twice the size of smaller\narray. There can be two scenarios in a push\noperation. In a normal push we will take\nconstant time, in case of an overflow we will first create\na larger array twice the size of smaller array. Copy all elements in time proportional\nto size of the smaller array and then we will take constant time to insert\nthe new element. The time complexity of push with this\nstrategy will be O(1) in best-case and O(n) in worst case, in case of an\noverflow time complexity will be O(n) but we will still be O(1)\nin average case. If we will calculate the\ntime taken for n pushes then it will be proportional to\nn, remember n is the number of elements in\nstack. O(n) is basically saying that time taken will be very close to some constant times n, in simple words\ntime taken will be proportional to n. If we are taking c into n time for\nn pushes, to find out average we will divide by n.\nAverage time taken for each push will be a constant hence O(1) in average case. I will not go in to all the\nmathematics of why it's O(n) for n pushes, to know about it you\ncan check the description of this video for some resources. Okay so this pretty\nmuch is core of our implementation. We have talked about two more operations\nin definition of stack ADT, top operation simply returns the element at top of stack so 'top'\nfunction will look something like this. We will simply return the element\nat top index. To verify whether stack is empty or not\nthis is another operation that we have defined. We can simply check the value of top if\nit is equal to -1, we can say the stack is empty we can\nreturn true else we can return false. Sometimes pop and top operations are combined together\nin that case pop will not just remove an element from top of stack it\nwill also return that element. Language libraries in a lot of programming\nlanguages give us implementation of stack. Signature of\nfunctions in these implementations can vary slightly. Okay now I will quickly show\nyou a basic implementation of stack in C. In my C code here I'm going to write\na simple array based implementation to create a\nstack of integers. The first thing that I'm going\nto do is I'm going to create an array of integers as global variable and the size of this\narray is 'MAX_SIZE' where 'MAX_SIZE' is defined by this macro as 101. I will declare another global\nvariable named top and set it as -1 initially, remember top equals -1 means an empty\nstack. When a variable is not declared inside\nany function it's a global variable, it can be accessed anywhere so you do not have to pass it as\nargument to functions and now I will write all\nthe operations. This is my 'push' function, I'm first\nincrementing top and then setting the value at top as x. x is the integer to be inserted passed\nas argument. Instead of writing these two statements i can write one statement like this and I will be good. I am using pre\nincrement operators so increment will happen before assignment. I\nalso want to handle overflow. We will have an overflow when top\nindex will be equal to MAX_SIZE-1, highest index available in the array. In case of an overflow I simply want to print an\nerror message something like this and return. So in this implementation I'm not using\na dynamic array, in case of overflow push will not\nsucceed. Okay now this is my 'Pop' function i am simply decrementing top. Here also we\nmust handle one error condition if stack is already\nempty we cannot pop, so I'm writing these\nstatements here if top is equal to -1 we cannot pop. I will print this error message that\nthere is no element to pop and simply return. Now let's write top operation, top operation will simply return the integer at top index. So now\nmy basic operations are all written here. I have already written\nPush pop and top. In main function i will make\nsome calls to 'push' and 'pop' and I want to write one more function\nnamed print and this is something that I'm going to write only\nto verify that 'push' and 'pop' are happening properly. I will simply print all the elements in\nthe stack in my main function after each push\nor pop operation i will make a call to print. I am writing\nmultiple function calls, two function calls on same line here because I'm short of\nspace. Remember print function is not a typical\noperation available with stack, i am writing it only to test my\nimplementation. So this pretty much is my code, let's now\nrun this program and see what happens. This is what I'm getting as output we are\npushing three integers 2,5 and 10 and then we are\nperforming a pop so 10 gets removed from the\nstack and then we are pushing 12. So this is a basic implementation of stack in C. This is not an ideal implementation, an\nideal implementation should be something like we should have a datatype called\nstack and we should be able to create instances\nof it. We can easily do it in an\nobject-oriented implementation, we can do it in 'C' also using\nstructures. Check the description of this video\nfor link to source code of this implementation as\nwell as of an object-oriented implementation. In\nour next lesson we will discuss linked list implementation of stack this\nis it for this lesson. Thanks for watching. ",
            "url": "www.youtube.com/watch?v=sFVxsglODoo",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "r7P9sy5Rar8",
            "channelId": "UCRIWTSgd7hGtZhx4RYoASEg",
            "publishedAt": "2019-03-15T15:00:06Z",
            "title": "What is Stack Data Structure ? | Data Structure and Algorithms (DSA) | Part - 1",
            "description": "Support Simple Snippets by Donations - Google Pay UPI ID - tanmaysakpal11@okicici PayPal - paypal.me/tanmaysakpal11 ...",
            "channelTitle": "Simple Snippets",
            "transcript": "yo what's going on guys done by our four simple snippets and welcome back to another video tutorial on data structures and algorithms so in this video tutorial we are going to be taking a look at our very first data structure that is the stag data structure so I'm going to be dividing this topic into parts that is the first part is going to be all about understanding what exactly stag need a structure is so we will take a theoretical look at what is stack how is the working of stack and the different operations and we also take a look at the application and in the second part we will also implement the stack data structure using C++ programming so the second video will be right after this one wherein we will actually implement the stack data structure but if you are a beginner it is very important that you understand what happens behind the scenes so not only we are we going to take a look at the presentation but we will also use the digital black board to see how the stack operations work behind the scenes so make sure you watch this video till the end if you are a beginner it is really important and then the next part as I mentioned would be the implementation part so with that being said let's start off and let's take a little bit of theory on what exactly is a stack data structure so a short Theory over your what is stack data structure so a stack is a linear data structure which operates in leaf oh that is last in first out or filo that is first in last out pattern now do note these two points before in filo we will talk in detail about them as we move on when we see the working right now just keep this in mind this is just the basic standard definition but the reason why we call this data structure as a stack data structure is because it behaves like a real world stack so the word stack itself means some objects which are piled on top of each other for example you can see in the image a pile of books you know it's a stack of books which are kept on top of each other so if you want to get the last book you have to first remove off first view of the book slide or for example the stack of cards so that's why it's called a stack data structure because it behaves like a stack okay now again it's a abstract data type and we've talked about abstract data type in the previous video I'll link that video in the description but basically it's a logical entity because we will be creating the functions that are basically operations of this Jesuits abstract data type which has a bounded capacity so a stack data structure has a bounded capacity which means it can store limited number of data elements ultimately data structures are gonna store data right but every data is accessed stores this data differently so the stack data structure stores the data in the form of a stack and of course we are going to see the working as we move on so it's a very simple data structure that allows adding and removing elements in a particular order now the order may be needful and fellow so we'll talk more about what exactly different fellow means when we actually take the working so one keyword that you also need to remember is this data structure is a linear data set share so there are two different types of data structure for example we have linear and nonlinear so when it comes to linear the data is accessed and stored in a linear way or in a sequential way in a particular order and when it comes to nonlinear the data is not stored in that fashion so you'll understand more when we go in detail and when we discuss the other data structures also right now just keep that in mind okay so this was just a little bit of theory and explanation of what exactly is a stack data structure in the theoretical form and we also took a real-world example like stack of books stack of cards stack of CDs you know but now let's try to understand what exactly a stack would look like when it comes to a digital example that is how it looks like in the digital world or how it looks like in the computer system in the memory okay and we'll also try to understand the different operations okay so as you can see on the digital blackboard what we have here is a computer memory so I have just drawn a basic diagram and this is just visualize this or imagine this as your memory computer RAM or whatever storage system you have and you know that memory has memory blocks right so each rectangle here is a memory block with some address let's see this is 1000 and this is 1000 2 or whatever in sequence you know so every memory block has its address right so in this computer memory we are creating this stack data structure right so this orange rectangular box basically represents our stack ok you can see this right so we have 1 2 3 4 & 5 memory elements so we have 5 memory blocks which mean that this data structure this stack has a size of five which means it can store fire elements okay so I have a separate representation over your so in memory this is how the stack would look like so we have five positions we will start from the bottom actually so this is one two three four five okay now coming to our two key words that is leave for that is last in first out or first in last out okay so stagnate a scepter operates in leaf o or filo manner or baton so we just discussed that so what exactly does this mean so when I say last in first out so when we store data in a stack so let's assume that all of these five blocks are blank right now you know and let's say our stack is storing integer datatype so whenever a new data is going to be entered so it will be at entered at the bottom of the stack okay so just assume that this is a container okay and this is the top of the container so this is top and this is bottom okay so whenever a data is entered so let's say we enter five okay so we are storing the number five over here so it will be entered at the bottom okay now let's say you store one more value let's say you want to store 2 so you can see that the numbers are piling up like a stack red so we have 1 we have 50 we have minus 3 and so on and so forth so right now since our stack size is full that is we can only store fine numbers a stack is basically full so whenever you enter something that is when it will add some values it goes in this fashion from top to bottom and it is stored at the bottom of the stack right and it gets filled up in this order from bottom to top so when it comes to the removal since our stack is something like this you know so there is only one way of entry and one way of exit ok because this is basically closed just imagine that this is a container and one end is closed so everything can be entered in this way so first in and last out which means that whatever value goes first so we know that we store number 5 forced right and then 2 then 1 then 50 and then - the so whatever value were entered first so this is a position number one two three four and five will be removed last so that's why first in last out or another way to look at it is last in first out so we first entered Phi then we entered two then one then 50 and then minus 3 so minus three was the last value which was entered and after that our stag got full right so this is the value which will come out first so that's why last in first out so the last value that was inserted in the stack will be the first one to come out so always remember that there is only one way entry in the stack and it has to be removed in the same way okay so this is how visually you can kind of imagine how stag basically operates in the memory how stack data structure actually operates now let's actually try to understand a few standard operations that you can perform on stag data structure okay so these are the eight different standard stack operations so the number one is push so when you say push and the reason why I have added round basis is because when you actually implement this tag data structure in in the form of a programming language these are all functions okay so whenever it comes to operations or behavior we implement them in the form of functions and you'll see that in the next video but right now just understand that this round brackets basically terms that this is a function okay so the first operation is push so what pulse does is place an item on to the stack if there is no place for new item stack is in overflow State okay so right now let's understand that again this is our stack okay let me use another color okay blue seems pretty good so this is our stack right we have one two three four and five positions so if you perform one push operation so let's say you want to push a number five again our stack is of size five okay and it is an integer data type stack okay which means that it is just going to store integer values for now let's assume that so let's say you push a value as 50 okay so 50 is gonna go like this and since all of them are empty the 50 is gonna be store at the first location at the very bottom okay so let's assume that fill out the and complete stack I'm just gonna fill out random values okay and now when you perform one more push operation after the five push operations you have to check whether the stack is full or not and right now you can see it is full so in the stack is full it is called a stack overflow ours overflow speed so this is the push operation basically push operation is just pushing in values inside the stack in this order the second operation is pop so the pop operation is return the item at the top of the stack and then remove it okay which means that you have to remove the topmost item of the stack and it is it okay so when I say pop this value is gone if I say pop again now I'm going to remove 6 and after I raise it from the stack now if you do pop 5 times all of these values will be erased right removed from the stack and after that if you try to pop one more time it will be an underflow state because the stack is empty okay so these are two different states stack overflow state and stack and the fluo state so just remember that then there are some other functions or operations you can say is empty so SMD is else if the stack is empty or not now how do you do this in terms of programming we will keep a count of the number of elements inserted okay so you'll understand this when we actually see the program but these are the functions so is empty tells if the stack is empty or not basic enough we have is full which means that it tells if the stack is full or not again you just have to keep a count of how many values are there and equated with the size okay so if the number of elements in the stack is equal to the size of the stack our stack is full right so that's how you basically implement the logic then we have peak peak is when you want to access the item at high position now you can see that each of this stack has position values 1 2 3 4 5 so when I say peak of 4 I am trying to see what exactly is over here ok peak of 4 means this value pick off one would be this pick off 2 would be this now remember right now I am starting the positions from 1 to 5 when it comes to implementation and if you use array the index position would be used and it would start from 0 ok so don't confuse yourself right now since we are just using the theory to represent the since we are starting from one otherwise when it comes to arrays you know that the index position starts from zero then we have one then we have two three and four okay so that's how it goes next thing is count which means this operation gets the number of items in the stack so let's say we have three forty-one and seventy-one so we have three items right the stack size is five but these two positions are empty which means that the count of items in the stack is basically three so we should get the output as three the next function or operation that a stack operation is change so again as the name suggests change the item at high position so if I say change of one to eleven and you know the positions are one two three four and five what I am trying to do is I'm trying to access this value 71 and I'm changing it to value 11 okay so this is what this operation would do and last is the display operation which is basically display all the items in the stack so you can print all the stack items in any order you know any order you want or you can be like get more creative and say one that is the position one and the value at position 1 11 to value at position 2 is 41 3 value at position 3 is 3 something like that you know you can do this printing thing in the programming part anyhow you want so these were the basic stack operations and these are the things that we are basically going to be implementing in C++ programming language in the next video so I just thought that you should go through this and I hope you have a very basic idea about how these operations work and what exactly is stack and how you can visualize it in the memory now one last thing that is left out is the applications of stack so let's go ahead with that so obviously when we are studying any kind of data structure the question arises that where exactly is that particular data structure used so some applications of stack data structure is balancing of symbols now to understand this let's take a programming example let's say we are programming in C++ so whenever we have opening curly braces we always have a closing curly braces right so when it comes to balancing this stack can be used for balancing for example whenever there is a opening curly brace you push that curly brace into a stack and whenever the closing curly brace is used again you pop that out which means that the net value in the stack is always going to be zero right so similar to that at the end of the program if there is any kind of extra value left out in the stack it means that there is some symbol left out that is some curly braces missed out and there is a syntax error so this was just a very basic example then we have infix to postfix conversion which is another concept we have redo and undo feature that many places like and it does in Photoshop so remember the last thing that you have done sometimes you misplace something and you are like okay what was the last thing that I did I want to undo it so that last feature or last action that you took is stored in a stack kind of way because remember stack operates as last in and forced out so the last operation will be the first that you come back when you click undo right so that's how redo and undo features are also implemented we have forward and backward features also in web browsers which work in kind of a stack way and then there are many other algorithms also so you can't read through them one more example would be your cache memory right sometimes the last thing that you've loaded into a web browser loads much faster it because it is just accessible immediately and it works in a kind of stack oriented way which means that it is easily accessible which comes out very first so that's how some memory systems also work okay so this was a complete theoretical aspect of stack data structure I hope you've got understanding of what exactly is a standard data structure how does it look what are the different operations in stack data structure and some of the applications in the next video we will try to implement the stack data structure in C++ and if you like this video do give it a thumbs up share it with your friends make sure you subscribe and don't forget to turn on the notifications because in the next video as I mentioned will implement the stack data structure in C++ programming so thanks for watching guys see you guys in the next one peace ",
            "url": "www.youtube.com/watch?v=r7P9sy5Rar8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "BrVZZZkkGGI",
            "channelId": "UC4o8Fdpv3g_AjgShAeivqpA",
            "publishedAt": "2016-09-23T21:18:50Z",
            "title": "Stack in Data Structure | Data Structure Tutorial | Mr. Srinivas",
            "description": "Stack in Data Structure | Data Structure Tutorial | Mr. Srinivas ** For Online Training Registration: https://goo.gl/r6kJbB \u25bb Call: +91-8179191999 Also Watch C ...",
            "channelTitle": "Naresh i Technologies",
            "transcript": "hi everyone welcome to nourish technologies this is cinemas so in this session we are going to discuss about a stack data structure what is a stock means this is an algorithm right so nothing but this is one abstract data type or set of rules so what is the use of stack means just to store the information in some of the situations if you follow the rules of a stack so we can access the information effectively so what are the applications and where we are using stack exactly so that we will see later so first here now we will discuss so what is the stack and how to implement a stack and finally we will discuss applications of a stack okay so first one so what is a stack means a simple and algorithm that works based on a rule called last in first out we can call it as a leaf oh so based on a last in first out rule a stack works so what you inserted last into the memory that will come out first it is a simple rule so one best example where we are placing the series sadist and so we are inserting right the seed is right so then the CD will move like this and here it is this is a CD and this is a next CD and this is a third state see you inserted first second third so this is inserting so if you want to pick out one CD from the CD stand then the third one will come first it will come first so this is just deleting or collecting the information and this is inserting the information so a stack algorithm so we'll run a based on the rule last in first out right how the insertions and how the deletions right every data structure right or right every stack should have a particular amount of memory block initially so we can call it as a capacity of stack so what is the capacities and how we will decide right so either using dynamic memory allocation we can decide or we can use a static memory allocation also so first we will see a static memory allocation is nothing but a constant memory allocation so what we will use in a static memory allocation simply we are using the concept of array we are using the concept of array so how see for example how we are declaring an array means in a our are the size is a 5 5 so whenever we declare variable like this it gets a memory allocation a block to store five elements at some location suppose two zero four six two zero four eight five zero five two and five four so this is memory allocation so now I want to implement a stack and of course write a stack implementation also with the help of arrays only arrays concept just rotate this memory allocation so by minus 90 degrees minus 90 observe integer type elements we are storing write the name is a stack and of course it is array only but the approach is different stacked here it is the capacity capacity suppose initial capacity we are giving like this the same memory allocation we are writing in different ways so this is now one two three four five this is a base address to zero four six two zero four eight two zero five zero two zero five two two zero five four here base address of the block who will hold the array variable ARR holds the base address of the block to collect the information of the memory block in the same way a stack variable is an array variable is holding the base address of the block 2 0 4 6 2 0 4 6 this is what we called static memory allocation how we can allocate the memory right to a stack is a fixed memory fixed memory so for example if you want to implement a stack dynamically then we should use the concept of we should use the concept of write a malloc function Cal log function real log function and free function we already discussed the dynamic memory allocation concept in a C language right so now here it is for arrays so what are the functions we are using in a steady Li B dot H means a catalog function and next one real log function so what is the use of a catalog function we can allocate the memory dynamically of course but with a fixed size we cannot change if you want to increase or decrease the size of array or size of memory block we should go for a real log function we should go for real log function very simple how to allocate the memory observe so how to allocate the memory dynamically to stack so first we are declaring integer pointer variable but the variable name is a stack stack in a static memory allocation we are using array with of exercise but now here it is a pointer so only a stack get memory allocation at some location at some location now it is ready to accept one integer array nothing but a memory block address it is ready to hold how we are allocating the memory to this one how so that is using a catalog function so what is the size nothing but what is the capacity capacity we have to pass see for example the capacity is a 5 capacity equals to 5 capacity we are passing and next one what is the size of each element that we are going to store in the stack sizeof integer so that we are collecting what catalog function will do a capacity into sizeof integer capacity is a 5 sizeof integer is a 2 is nothing but 10 bytes memory it will allocate a block 10 bytes memory it will allocate and the base address suppose 2 0 4 6 we should collect into stacks so that it start pointing to this 1 here it is a stack we are collecting that information into variable stack but stack is of type 1 is an integer pointer type but catalog function return type is a wide pointer we know that catalog function returns wide pointer this is what we called generic pointer this is already we discussed clearly what is the prototype of a catalog function right why it is returning wide pointer how to typecast a pointer all these things already we discussed in a dynamic memory allocation con except of a C language right so once go through that how memory will be allocated using a catalog function this is just allocating a memory to this stack with a fixed size here initial capacity is a 5 so if I want to store the sixth element then what will happen then we should go for a real log function for that we have to write the logic how to write the logic and all we'll see okay so for simply this is memory allocation dynamically to the stack right so we can implement a stack data structure algorithm in two ways either by using a static memory allocation concept or by using dynamic memory allocation concept static memory allocation concept means we are using arrays dynamic memory allocation concept means we are using write the CL log function and real log function of course with the help of a pointers concept okay so this is just only creation answer what are the operations we can perform right on a stack so once a stack is ready once stack has been created so what are the operations we can perform on a stack data what are the stack operations what are the stack operations so first one first one so creation of a stack creation either dynamically or with the static memory allocation second one we can push the elements into the stack right we can push the elements right so what is that pushing the element a right nothing but insertion of elements according to that algorithm so right as some of the words a terminology we should understand but here it is whenever we are calling push function so whatever the element you want to insert that we are passing suppose a stack is an integer stack that element we should pass what element you want to push and next one third one pop third one is popper but here whenever we are calling a pop function no need to pass anything any argument so why what is the reason because right in this from the stack if you want to pop any element it is always try to access a last element right so what you insert at the element last so that will come out first the last element what is the top of the stack that will be collected that will be collected and next one fourth one Traverse function so what is a Traverse function just displaying all the elements of the stack displaying all the elements of the stack is nothing but Traverse function so these are the main functions we are using in the implementation of a stack so some more functions these are optional and anyway we are implementing at the time of a stack implementation is empty or not if stack is empty or it contains elements or not and next one sixth one is full or not is full and next sixth one sohow seventh one how many elements are there so what is the length of the stack I think but simply we can call it as a size also more clearly so what is the size of the stack how many elements are present how many elements are present in the stack so these many things so we are implementing these many types right so implementation of all these functions just writing logic for all these functions is nothing but a stack implementation once you implement all these things then a stack is ready with the help of that stack then we can store the information effectively into every program into every programming application so that we can process the information effectively so first for example so we are creating the stack with a size 5 we are creating the stack creating either if you want to push the elements or if you want to pop the elements that is possible only from the top of the stack any operation you can perform with the help of element top element only from the top only either we are inserting or deleting the elements nothing but we will push or we will pop so first of all for example here so we are calling push of element 10 so then the stack will be like this right it will go like this from the top it will stay here and next if you want to push 20 20 then this is the stack 10 next element here 20 and remaining nothing and next for example here so we just want to pop pop means so which element will be popular the last in first out is a 20 will be deleted so then in the stack only 10 will be present 20 will pop willpower next for example here it is we are pushing 30 just push 40 push 50 50 then a stack will be like this 10 30 40 50 and next for example if you want to perform a pop operation so then then here it is at ten thirty forty here it is fifty will come out it will pop so what you inserted last so that will come out first so if you insert a five elements we cannot insert the sixth element right in a static memory allocation of course in a dynamic memory allocations we will increase with the help of real log function and we are inserting anyway so these are just operations on a stack how we are inserting the elements how we are deleting the elements just we are performing push operations and pop operations all these operations we can perform with the help of a variable called top because we should perform all the operations on the stack from the top only either you want to push or you want to pop the elements okay so implementation how to write the logic of all these things all these functions right so we will see in the next session right so for more videos so please log in to nourish idea channel thank you ",
            "url": "www.youtube.com/watch?v=BrVZZZkkGGI",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "wtynhUwS5hI",
            "channelId": "UC29ju8bIPH5as8OGnQzwJyA",
            "publishedAt": "2020-05-29T14:57:52Z",
            "title": "Stack Data Structure | JavaScript",
            "description": "In this video, we will look at the stack data structure using JavaScript. This is part of an ongoing data structure playlist Code: ...",
            "channelTitle": "Traversy Media",
            "transcript": "[Music] hey what's going on guys so I've had a bunch of requests to do some videos on data structures and that's something that I've been wanting to do data structures algorithms things that really gets the gears going and gets you thinking like a programmer thinking in you know logical terms and it's good to know this stuff sometimes they'll ask you about this kind of thing on on interviews and if you start to get into like data intensive applications and algorithms you'll need to know this stuff so I figured it's a it's a good little playlist to start I already did a video on linked lists a few months ago and I'll add that to the playlist as well so today we're gonna look at stacks which are pretty simple it's a really simple concept I have a diagram here and you can think of the elements in the stack as kind of like a stack of books and you can only add and remove from the top so it's what's known as a last in first out data structure so the last item that's put in is the first item that's put out and the way that we do this is with a method called push and a method called pop now if you've been developing with JavaScript for any amount of time you probably know that arrays actually have prototype methods push and pop that do the same thing so what we're gonna do is create a class to create a stack and we're going to create our own push and pop methods instead of using the built-in array methods all right and I just have a diagram here of how push works very simple so we're just adding a data here just a1 adding it to the stack the next one is gonna get added on top of that on top of that and so on and then pop will take the top element off okay so five comes off four comes off and so on so it's pretty simple to wrap your head around so let's go ahead and and create this with a class okay and we're gonna have some other methods as well like I want to be able to to see if it's empty to see the size of the stack print out the values and the stack things like that so let's create our class I'm just gonna close that up so have a class class called stack and basically what I want to be able to do is initialize a variable to our class so create a stack object and then we'll have methods like push so we'll be able to push on some data I'm just gonna use numbers so 100 200 300 and that should add on to the stack now we're gonna need a constructor here because we need some properties so a constructor is a method that runs once we instantiate an object from this class and we need a place to store data I'll just call this items and then also I'm going to have a count to tell where we are basically the position of the element because I'm not going to use the length property in JavaScript I want this to be as low level as possible so the first method will create is push I'm just going to put a comment here we'll say add elements to our store to top of stack and let's say push this is gonna take in an element which as you can see below we're just passing in numbers and I'm not gonna use push like I could say I could take the items which is our data and I could call push because it's a JavaScript array method but I'm not going to do that I'm gonna take the items and then the index that I want is gonna be the count right and then I want to set that to the element that's passed in so if I call this it's gonna go ahead and add 100 to it right now for the next one if I just leave it like this it's going to replace the 100 I don't want it to do that I wanted to add on so we need to increment the count so let's say this dot count and plus equals 1 or plus plus whatever you want to use and then as far as what I want a return I want to return the the position that this is being added to now this dot count got incremented so the position of this is going to be 0 however count will be one after this runs so I'm going to return count minus 1 so that it returns in this in this case 0 because that's the position and what else is what the other thing I'm going to do is some console logs within each of these just so we can see what's going on so we get a response within our console whether or not terminal so let's put some back ticks here and we'll just put the element I will say element added to and then the count however we want to move this up because we want to move this up because we want to call it before the count gets incremented so let's save this and if we run this file I'm going to use node so you need nodejs installed and we'll run the file and you can see 100 was added to the zero position 200 to 1 and 300 to 2 now in terms of using pop we should be able to just call stack pop and that should remove the topmost item which in this case is going to be whatever the last item in the stack so 300 so the last that we add is gonna be the top right it gets added to the top when we push so let's go up here and let's say return return and remove top element in stack and then also I want to return undefined if stack is empty so let's say pop this doesn't need to take anything in because remember it's just popping it off the top there's there's no specific element that we're targeting here and like I said I wanted to return undefined if it's empty so to see if it's empty we can just say if the count is equal to 0 then we want to return undefined and if you want to pause the video at any time and try this yourself that's fine I'm gonna every time I create a method I'll you know put a comment here and tell you what it does although the rest of them are pretty easy now we want to return and remove the top element in the stack so what I'll do is create a variable called delete delete item or whatever you want really and then set that to this dot items and then I want the count however the count is going to give me one more than I need for the position one hundred is in the zero position this is the tube I'm sorry one position this is the two position but the count is going to be one two three so we don't want we don't want three because there is no three position we want the two position in this case so we want to subtract one from it okay hopefully that makes sense because our stack is zero based like most data structures so that'll put it in the variable now we also need to decrease the count because we're taking one off right so we want to say this count - equals one that'll decrease it by one and then we need to return the delete item and then I'm just gonna put a console log in here just to tell us what's going on and we'll put the delete I'll say delete item removed so now if I save this after knowing what a stack is and how it works you should know what what's gonna happen here right so let's go ahead and run it and what happened was we added one two and three hundred and then when we called pop it removed 300 because that's on the top of the stack if we call pop again it's pretty easy to figure out what's gonna happen it's gonna remove 200 okay if we call it again we get 100 removed and if we call it again we just get nothing cuz it's actually like a well we'll do is console.log because it's not gonna it's not gonna print out what's returned unless we console.log so this should give me undefined because it's empty okay so we get undefined and if I want to console.log this remember we're logging the position right I'm sorry we're not logging the position here logging the position on push this will return the actual item which is 100 if I console.log the push this should give me 0 so let's try that and you can see we get the zero position all right so let's just clear that up and I'm just gonna leave we'll leave two pops in there so the next thing I want to do is peek so peek is is used to just see what's on top it's not gonna actually remove it so let's say check check top element in stack and this is really simple after we do this you should know exactly how to do this we just need to return this right here whoops so we want to return that that's the top-level item or element and then I'm just gonna console.log here and let's just let's say top element is and we'll put in that all right so now if we peek let's actually put the peek right here before we push on the 300 so we'll say stack dot peek and that should give us 200 so let's run that and right here we get top element is 200 because we had we haven't pushed on the 300 yet okay and then 300 to added to 2 then 300 was removed then 200 was removed so now I want to be able to check if the stack is empty so it's a is empty which is also pretty simple we just need to check if the count is equal to zero we could put an if statement but a much cleaner way to do that would be just to return this dot count equal to zero which will give us true or false and then for a console log I'll say this dot count equal to zero and I'll just use a ternary and we'll say let's just say stack is empty if it's equal to zero else so we use a colon for else will say stack is not empty and then let's put the is empty up here at the top where we know it is and then let's put it I don't know down here and we'll run that so at the top we get stack is empty and then down here we get stack is not empty another thing I want to do is check the size so we'll say check size stack which is gonna be really easy we just need the count right we just need to return this dot count and let's go here and just put some back ticks in there because we want to grab the count and then we'll say elements in stack so we'll check the size let's check the size after we pop off those two items so stack dot size so right here one elements in stack because we we popped off 300 and then 200 so I'd also like to print out everything print out all the data in the stack at any given time so let's say print print elements in stack and if you again if you want to pause the video and try this yourself you can there's this there's a lot of different ways to do a lot of different things but what I'm going to do is just initialize a string because I want to print this out as a string and then I'll do a for loop and we'll say let's let the index equal 0 and then say as long as I is less than the count then we want to increment by 1 and then in here we'll take that string that we initialized and we want to append to it so plus equals we don't want to replace it through each iteration we want to append this dot items and we'll just out of space like that and then return the string now I'm not doing any console logs in the print so we do have to console.log down here and let's print out we'll go after 300 and say stacks prints actually we have to console.log and let's also do it after we pop this stuff off alright so we'll run this so let's see something is not right here 100 why is it printing out so many times oh I added the the entire thing here we just want the current index there we go so right here it's printing out one two three hundred then we removed two three and two hundred and then it prints out one hundred so that's working correctly now the last thing I want to do is just clear everything so it's a clear stack so we'll set this items to just empty and then this stock count to zero and then as far as what we want to return will return the stock items and let's just do a console log here and say stack cleared all right so we'll go down here and where should we put this so we have 100 we'll go right under right before we print out and let's say stack clear so this should print out nothing so let's clear this up and run and right here the stack got cleared we try to print it out there's nothing there zero elements in the stack when we call size and the stack is empty all right so everything is functioning as it should and I think a good idea for another video would be to maybe write a test to really test this out without having to do all these console logs let me know if that's something you guys would be interesting it interested in but that's it I just wanted to do a quick video I will be doing other data structures as well we'll probably do a queue next which is pretty similar it you just take it off the take it off the the end instead of the top so we might do that next and we'll get into some other ones as well and if you have any requests or anything like that you can leave that and leave those in the comments but that's it thanks for watching guys I appreciate it and I'll see you next time ",
            "url": "www.youtube.com/watch?v=wtynhUwS5hI",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "queues data structures": [
        {
            "videoId": "zp6pBNbUB2U",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-09-13T05:52:45Z",
            "title": "4.1 Queue in data structure | Introduction to queues | data structures",
            "description": "In this lecture, I have described queue data structure as abstract data type. Discussed introduction to queue with its operations. See Complete Playlists: ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "in this video we are going to talk about queues in data structure see what is the data structure it is a way of storing and organizing the data right we have discussed few data structures like arrays linked lists and stacks in this video we will see what is U so Q is what it is a linear data structure you can see or you can say Q is an abstract data type in this video we will discuss Q as an abstract data type ADT means when I say edit E it means we are going to define we are going to see the features or operations of Q we will not go in detail implementation right see we can implement Q's using arrays linked lists as well as using stack that implementation we will discuss in next video in this video we will see what is Q and what are different operations performed on Q fundamental operations fine as well as we will see some applications of Q's so let us understand this concept with a real-life scenario first of all right let us suppose there is a ticket counter fine that's a movie ticket counter you can consider right and now there is no one there in the queue or in the line fine first of all suppose you go and you stand there and after that second third fourth fifth five persons are there so obviously you if you are the first then you will get the ticket first then you will go after that second person then third and fourth and then fifth and suppose before you there are five persons and after that you reach there so you have you will have to stand at sixth position right and you will get ticket after be after you know these five persons fine so here the simple funda is what first-in first-out or you can say first come first so the person who is first in the row will get the ticket first right so now in the queue this funda is known as first in first out FIFO so Q is basically what it is a structure it is an ordered list as stack we have discussed staff is an ordered list that follow the principle of Li for last in first out queue is an collection or queue is an ordered list which follow what principle first-in first-out right now what is that principle see you can say Q is a structure that is going to follow some restrictions on insertion and deletion operation fine or that is going to follow a rule that is going to follow a principle and what is that rule insertion and deletion in case of queue insertion would be performed from one end right and the name of that and that end is known as rear or till right and deletion would be performed from another end and that end is known as head or you can say friend right in queue if you say more technically then we will use a rear end front not head and pain and rather than insertion insertion means adding a data in the queue fine so the technical name in the for in in this in the context of queue it is known as in queue right and deletion is known as DQ by and in stab this insertion and deletion is not known as push and pop fine so NQ operation should be performed from one end and DQ operation would be performed from another end right so we will see the logical representation of queue if you logically represent the queue it means it will have two ends to open it right in stab we have only one end one opponent like and queue would be represented something like this it is having two and one is this one is this right suppose I am taking this end is rear right and this is what friend obviously when you are going to implement this cue you will have to take front and rear two variables like that is must so insertion or you can see NQ operation would be performed from rear from here we can insert data in the cube and if you want to delete data from the queue it means from the front we can DQ we can delete data right so this is what a logical representation of a queue fine suppose and queue I have right now two elements two and three at some point of time right so at that time this front variable would be pointing to here and the rear variable would be pointing to here right and the index is suppose zero and one at some point of time we are suppose we are implementing the skew using array and at some point of point of time p.m. only two elements in that queue and index is zero and one so front is zero and rear is one now in this case if you want to insert third element from where we can insert from this end only so what you need to do if suppose the size of this do we have taken five we can insert five element the capacity is five right so now first of all you will increment this rear right so now rear plus plus that is real would be pointing to this node and now you can insert another it suppose I have inserted five right and if you want to delete then from here only you can delete right so first in first out firstly we have inserted two and that is the first element you can delete if suppose you want to later this five you cannot directly delete this five first of all you will have to delete this two from the queue then three from that you after that only you can delete this 5 right so it is that is why it is no it is known as it will follow FIFO principal love first-in first-out or you can say last in last out last in last out somewhere it is also written like this that the same thing last integer that is in queued in this 2 is 5 and that would be the last element you can remove so last in last out this is Q so now we will see some operation that can be performed on a Q so you can define Q as it is a ordered list or you can say it is a collection in which insertion can be performed from one end that is from rear end and a deletion can be performed from another end that is from front end of the queue fine and it is going to follow it is a structure you can say that is going to follow the FIFO rules that is first-in first-out right so now we will see some operation that can be performed on Q so two operation we have discussed that is first is n 2 and that is the second is DQ right these are two fundamental operations and Q and D Q n 2 means inserting or adding a data in the q DQ ms deleting a data from the queue see here in NQ I'm passing to as an argument because I want to suppose I want to insert 2 in the queue then I can pass this in the NQ in DQ no need to pass anything because always the element would be DQ'd from the front so the element which is at the front index of the queue that would be deleted right so no need to pass anything third may be friend or you can say peek in stack it was top it means the motto of this operator operation is what it is going to tell you what does the element at the front of the queue right we will see what is the element at the front of the queue without removing that from the queue or without deterring that element from the queue right now is queue full you can check by is full function it is it will return true if the queue is full it will otherwise it will return phones is empty same we have discussed in stack if the queue is empty then it could return true otherwise it will return false right now see the logical representation of you so this is the logical representation of queue fine any end you can take front or rear but you have to take care of that thing deletion from front and insertion from rear right so here I am taking this is what front and this is what rear I will insert always from here delete from here you can take front this side rear this side as you wish but insertion and deletion would be according to the rule only fine now if you want to insert some data here obviously you need to specify the size of this queue suppose the capacity of queue is fine you can say size I am taking is 5 how will take the size 5 Huggle implement this through that thing we will discuss in next video so it means I can insert 5 element in this queue right here I have 3 this end and index is 0 1 2 3 & 4 so initially there is nothing in the queue right in that case what we will do both friend front end this rear would point to minus 1 hypothetically we assume that there is a minus 1 index and these are pointing to minus 1 it means queue is empty right that is the signal if this is minus 1 it means Q is impeding now I want to include 2 now what would happen see friend is minus 1 rear is also minus 1 obviously we will increase front and rear both so front plus plus and rear plus plus also right so now front is also pointing to here and at this point of time rear is also pointing to here at the zero and now we can insert here too right now suppose again I want to NQ three I have hold again function and Q and suppose ten I want to insert in that case what will happen see friend will always point to this node the front one the front element we will not move this front for inserting the data inserting would be always from the rear part so the real variable we are going to move so first of all you will increase the rear rear plus plus means now rear is pointing to here and now here I can insert ten again suppose I am calling NQ minus 1 again what we will not touch this front we will move this rear insertion from drear only that thing you have to take care rear plus plus means rear would point here and now here I can insert minus 1 say at this point of time front is 0 and rear is now - right now suppose I am calling DQ function no need to pass anything because always the data would be deleted from front now when you can touch this front now we will not touch this rear in DQ we will touch this friend right so now suppose you want to print the data you have DQ'd so you can write down printf the data you have DQ'd is from the queue you can print this value and after that what you will do you will do front plus plus right so now front is pointing to here front is one rear is two or in DQ simply you will write front plus plus that is also fine because now this is not a part of queue the part of queue is only two elements whatever between front and rear that is part of you this is now a garbage value and we don't care what the garbage value lies here in future if you will access this selling and usually if you will write here something that this value would be overwritten that is fine fine now suppose I am calling NQ function 3 times so now NQ 0 means from rerai I will know touch this front from rear I'm where only I can insert a year plus plus a year would be pointing to here and here I can insert a 0 into one rear plus plus here I can insert one into five then rear plus plus but what we have the size till here only so if rear is what rear is equal to four it means rear is equal to this maximum size minus one index is 4 now maximum size is five in that case you will print we cannot insert any data you means you can say all flow condition this is all flow condition right so this will print what overflow condition this is an hour of overflow condition right and what is under flow condition suppose you want to DQ and there is nothing in this list right both front and rear are minus one in that case what that is done under flow condition that is to is empathy right now suppose before calling this DQ function I am calling peak function after this NQ but you can say front so it will return what front value is now n because C Q is between from front to rear that is here to here this is what garbage value so I rub this one this is garbage value right so now this will return 10 after that suppose you are calling DQ function continuously three times what would happen first of all DQ it means front plus plus front foot point here again DQ front plus plus AG + DQ front plus plus right means front and rear both are pointing to here now this is what a garbage value this is not a cure suppose I am removing these value from here from these cell because you can have override these values right now as you can see both front and rear are pointing to hair both are at same index so in de you can write down one condition you can check that condition also if front and rear is different is equal to is equal to read in that case what it means only one element is there in the queue so what you can do after removing this what will what would happen friend and driller is equal to minus one you can set front and rear is equal to minus one because this is the we have set for em ptq right or if we will not do this thing then simply same processor front plus plus right front plus plus means front foot point to here that is five friend becomes five so another condition of checking the in particular is what if front is greater than this rear because rear is still four front is five right in that case it means Q is empathy friend plus plus means we have deleted this Q right so delete this element from the queue so it means Q is empathy so when friend becomes greater than we are then also it is empathy so we are going to see how to write down these condition in next video fine now suppose if you talk about the time complexity then in that case these operations would take order of one only because we are not going to write any loops or anything for performing these operations so it would take order of one only right constraint time now suppose at some point of time both friend and Bria are pointing to this node it means Q is having only one data this this this this these four cells are empty right and now if you call NQ in that case it would return what Q is full that is the drawback why it will return Q is full because see see here near is what pointing to for or ear is for that is maximum size minus one and that is condition of what or flow condition means the Q is full now it will show you Q is full right but see these spaces are free but we cannot insert here this is what wastage of the space so this is a drawback of this Q we have a solution of this cube that is the circular queue that also I will discuss later fine so but this is now a drawback you have space but you cannot insert here data right now we will see some applications of Q so the most common application of this queue data structure is what it is used where you want to you know serve the request on a single shared resource suppose you have a single resource and that is shared let us take you you can take an example of printer suppose you have one printer and that is shareable fine so what would happen it's not like that suppose there are five pcs and these five pieces are sharing one printer it's not like that it will give command and this will print and at the same time it will print it will give command and it will print right what this printer will do suppose this this has given some command to print a date and now the printer is printing now at the same time computer this tree it has given command to this printer then what would happen the printer is busy 'no so what printer will do it will obviously it will have a program so that request would be stored in queue after that suppose this printer would give the request so it would store here after that this this would store here so it will in the memory in the printer memory it will what make a queue of all the requests right first of all it will print whatever the request it has even then it will fulfill requests of three then two like this right and queues are also used in real life scenario like you can take an example of a new oil in customer care then sometimes they tell you that they tell you to hold on for a few minutes because their representative is not free so what they do they use queues to put the people on hold right until their representative are free fine next you can take an example of processor see you have only one processor CPU you can see right so the processes would be placed in queue in operating system I guess we have discussed many times when we were discussing the concept of operating system then you can check out in the playlist there are ready queue there are waiting queue fine so the processes would be put in the queue and as soon as processor gets free it will take from the queue it will take the processes from the queue one by one right so all the processes are also put in the queue right because processor is what it is a shareable resource any process all the processes can share this processor but obviously we cannot execute all the processes at the same time so you have to put those processes and waiting or you can say those processes are put in queues right so these are some example these are some applications of queue data structure and there are many more applications of youth' we will discuss all these one-by-one in later videos so in next video basically we will discuss how to implement queue using arrays and then using linked lists and then using stacks fine so I'll send the next video till then bye bye take care ",
            "url": "www.youtube.com/watch?v=zp6pBNbUB2U",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "XuCbpw6Bj1U",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2013-11-01T13:30:16Z",
            "title": "Data structures: Introduction to Queues",
            "description": "In this lesson, we have described queue data structure as abstract data type. See source code in C++ here: https://gist.github.com/mycodeschool/7331785 For ...",
            "channelTitle": "mycodeschool",
            "transcript": "Hello everyone ! We have been talking about\ndata structures for some time now. As we know, data structures are ways to store\nand organize data in computers. So far in this series, we have discussed some\nof the data structures like arrays, linked lists and in last couple of lessons, we have\ntalked about stack. In this lesson, we are going to introduce\nyou to Queues. We are going to talk about Queue ADT. Just the way we did it for stack, first we\nare going to talk about queue as abstract data type or ADT. As we know, when we talk about a data structure\nas abstract data type, we define only the features or operations available with the\ndata structure and do not go into implementation details. We will see possible implementations in later\nlessons. In this lesson, we are only going to discuss\nlogical view of queue data structure. Ok ! so let's get started. Queue data structure is exactly what we mean\nwhen we say queue in real world. A queue is a structure in which whatever goes\nin first, comes out first. In short, we call Queue a FIFO structure. Earlier, we had seen stack which is a last-in-first-out\nstructure which is called a last in first out structure or in short LIFO. A stack is a collection in which both insertion\nand removal happen from the same end that we call the top of stack. In queue however, an insertion must happen\nfrom one end that we call rear or tail of the queue and any removal must happen from\nthe other end that we can call front or head of the queue. If i have to define queue formally, as an\nabstract data type, then a queue is a list or collection with the restriction or the\nconstraint that insertion can be and must be performed at one end that we call the rear\nof queue or the tail of queue and deletion can be performed at other end that we can\ncall the front of queue or head of queue. Lets now define the interface or operations\navailable with queue. Just like stack, we have two fundamental operations\nhere. An insertion is called Enqueue operation. Some people also like to name this operation\npush. Enqueue operation should insert an element\nat tail or rear end of queue. Deletion is called Dequeue operation. In some implementation, people call this operation\npop also. Push and pop are more famous in context of\nstack. Enqueue and Dequeue are more famous in context\nof Queues. While implementing, you can choose any of\nthese names in your interface. Dequeue should remove an element from front\nor head of the queue. And Dequeue typically also returns this element\nthat it removes from the head. The signatures of Enqueue and Dequeue for\na queue of integers can be something like this. Enqueue is returning void here while Dequeue\nis returning an integer. This integer should be the removed element\nfrom the queue. You can design Dequeue also to return void. Typically a third operation front or Peek\nis kept just to look at the element at the head. Just like the top operation that we had kept\nin stack. This operation should just return the element\nat front and should not delete anything. Ok, we can have few more operations. We can have one operation to check whether\nqueue is empty or not. If queue has a limited size, then we can have\none operation to check whether queue is full or not. Why I am calling out these alternate names\nfor operations is also because most of the time, we do not write our own implementation\nof a data structure. We use in-built implementations available\nwith language libraries. Interface can be different in different libraries. For example, if you would use the in-built\nqueue in C++, the function to insert in push which in C# its Enqueue. So, we should not confuse. I'll just keep more famous names here. OK ! so these are the operations that i have\ndefined with queue ADT - Enqueue, Dequeue, Front and IsEmpty. We can insert or remove one element at a time\nfrom the queue using Enqueue and Dequeue. front() is only to look at the element at\nhead. InEmpty is only to verify whether Queue is\nempty or not. All these operations that i have written here\nmust take constant time or in other words, their time complexity should be big-oh of\none. Logically, a queue can be shown as a figure\nor container open from two sides. So, an element can be inserted or Enqueued\nfrom one side and and an element can be removed or de-queued from other side. If you remember stack, we show a stack as\na container open from one side. So, an insertion or what we call push in context\nof stack and removal or pop, both must happen from the same side. In queue, insertion and removal should happen\nfrom different sides. Let's say I want to create a queue of integers,\nlets say initially we have an empty queue. I will first write down one of the operations\nand then show you the simulation in logical view. Lets say i first want to enqueue number 2. This figure that I'm showing here right now,\nis an empty queue of integers and I am saying that I'm performing and Enqueue operation\nhere. In a program, I would be calling an Enqueue\nfunction passing it number 2 as argument. After this Enqueue, we have one element in\nthe queue, we have one integer in the queue. Because we have only one element in the queue\nright now, front and rear of the queue are same. Lets Enqueue one more integer. Now, i want to insert number 5. 5 will be inserted at rear or tail of the\nqueue. Let's Enqueue one more. And now, I want to call Dequeue operation. So, we will pick 2 from head of the queue\nand it will go out. If Dequeue is supposed to return this removed\ninteger, then we will get integer 2 as return. Enqueue and Dequeue are the fundamental operations\navailable with Queue. In our design, we can have some more for our\nconvenience. Like we have front and IsEmpty here. A call to front at this stage will get us\nnumber 5, integer 5 as return. No integer will be removed from the queue. Calling IsEmpty at this stage can return us\na boolean false or a zero fro false and 1 for true. So, this pretty much is Queue works. Now, one obvious question can be, what are\nthe real scenarios where we can use Queue, what are the use cases of Queue data structure. Queue is most often used in a scenario where\nthere is a shared resource that's supposed to serve some request, but the resource can\nhandle only one request at a time. It can serve only one request at a time. In such a scenario, it makes most sense to\nQueue up the requests. The request that comes first, gets served\nfirst. Lets say we have a printer shared in a network. Any machine in the network can send a print\nrequest to this printer. Printer can serve only one request at a time,\nit can print only one document at a time. So, if a request comes when its busy, it can't\nbe like - I'm busy, request later. That will be really rude of the printer. What really happens is that the program that\nreally manages the printer, puts the print request in a queue. As long as there is something in the Queue,\nprinter keeps picking up a request from the front of the queue and serves it. Processor on your computer is also a shared\nresource. A lot of running programs or processes need\ntime of the processor and the processor can attend to only one process at a time. Processor is the guy who has to execute all\nthe instructions , who has to perform all the arithmetic and logical operations. So, the processes are put in a queue. Queue in general can be used to simulate wait\nin a number of scenarios. We will discuss some of these applications\nof queue in detail while solving some problems in later lessons. This is good for an introduction. In next lesson, we will see how we can implement\nQueue. This is it for this lesson. Thanks for watching ! ",
            "url": "www.youtube.com/watch?v=XuCbpw6Bj1U",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "A3ZUpyrnCbM",
            "channelId": "UCxX9wt5FWQUAAz4UrysqK9A",
            "publishedAt": "2020-10-16T01:59:50Z",
            "title": "Introduction to Stacks and Queues (Data Structures &amp; Algorithms #12)",
            "description": "Here's my introduction to stacks, queues, and deques (double-ended queues)! You can check out the problem I mentioned at the end of the video here: ...",
            "channelTitle": "CS Dojo",
            "transcript": "hey everyone sorry about the delay but in this video i'm gonna give you a quick ish introduction to stacks queues and decks or double ended queues so let's get started first of all what's a stack well personally i like to think of a stack like a bunch of pancakes so just imagine for a second that these circles represent pancakes with different numbers written on them we could have any type of data here but we're using numbers or integers as an example here and one feature of pancakes the real world pancakes is that you can stack them on top of one another so just imagine that this line here represents a plate and once you have a plate you can have pancakes stacked on top of one another so you could have minus one at the bottom and then you can put three on top of it and then let's say this one nine this pancake right here and then at the top you can put this one and then you might say okay what if i wanna retrieve this pancake right here with the number three written on it then what you would need to do is you would need to take out this one first at the top and then this next one the nine pancake and then finally you can take out this one uh so that's how you know pancakes in a real world work and it's the same thing with the stack data structure so a stack is a collection of data in which you can only add a piece of data at the top of the structure or retrieve a piece of data from the top of the structure so you aren't really able to retrieve data from any position just like you could for example in array so another way to describe the same thing is that whatever piece of data you put in last will need to come out first so in the current structure of these three pieces of data the last piece of data that we put in is nine so that needs to come out first and that's sometimes referred to as last in first out okay so that's how a stack works but how can we implement it well one way to implement it is uh by using an array so we have an array of eight elements here and we're going to try to represent this stack right here to do that the first thing we'll need to do is we'll need to have a pointer or just an integer variable that's going to point to the last element that we put in in this data structure and let's say for now that the stack is empty then there is no last element 2.2 so we can initialize this variable to -1 or the index that would be here but that doesn't exist and this shows that this stack is empty and now what if we want to start putting in some pieces of data here for example -1 here then what we can do is move the pointer here again this is going to always point to the last element that we put in in this data structure and then put -1 here and what if we want to put in a 3 on top of -1 then we can move the pointer again again pointing to the last element that we put in and then put 3 here and then we can keep doing that if we want to put 9 here oh you can move uh the pointer here or increment pointer by one and then put nine here and what if you want to remove uh this number right here nine and to do that all you need to do is you need to move the pointer back by one or decrement this variable by one now you could do something with this number right here you know either erase it or change it to something else but it doesn't really matter because in this data structure we always know that the pointer always points to the number that's at the top of this structure so the numbers following this pointer are not relevant so we can keep going like this if you want to put in 2 here you can move the pointer back here and then update this number right here with two and then if you want to put nine again here you can move the pointer by one and then put nine here and throughout this explanation we saw a few key operations here one is delete sometimes it's called pop that's deleting or removing a number from this data structure and another one is add and that's adding a number on top of this data structure and with this particular implementation you can implement both of them in one or in a constant amount of time and that's assuming that the number of elements that we put in in this data structure doesn't exceed the length of the array and if it does you will need to either zero an error or make a new array that's longer than the original array and transfer all the elements from the first array to the second array and that would take some extra time anyway that's it for a stack let's now take a look at a queue the analogy i use to understand a queue is a bunch of people lining up in a line or in a queue so let's say we have these people with some numbers assigned to them just for convenience and they want to line up to do something for example to see this octopus for whatever reason and this octopus is busy so they need to line up and with a cube i think you already know how it works but you can put people in the queue or in this line and when the octopus is free uh the person that's at the front of the queue you can see the octopus and then go away and then you can add more people in the queue or more numbers in the queue and then the person or the number that's in front of the queue you can see the octopus and then go away so that's the idea of the queue data structure and i think you can see that uh whatever number or whatever person that came in first will go out first too out of this data structure and that's sometimes referred as uh first in first out okay and how can we implement this data structure one way to implement it is with an array again and this time we're going to have two pointers the first one is going to point to whatever is at the front of the queue or in this particular example this number or this person right here and we're going to put this one right here at zero for now and the second pointer is going to point to the space that's right after the last person or the last number in the queue and for now i'm going to put this at the same position as the first pointer at zero and let's say that the queue is empty right now then we're gonna make these pointers uh be initialized to both zero right here and we're gonna implement this data structure so that whenever these two pointers point at the same thing this q is empty okay now let's think about how we can represent a line of people with this particular implementation so let's say that this person comes uh in the line first then we can put number one here and then move the second pointer right here and if there's another person uh right after that let's say 42 then we can put 42 here and then move the pointer here again the first pointer will always be pointing at the first person in the queue or the front of the queue and the second pointer will always be pointing at the space right after the last person or the last number in the queue so let's keep going with this if 13 comes in a line we can put 13 here and then move the pointer move the second pointer right here and what if the octopus is free now and this person one sees the octopus and goes away then uh we can just move the first pointer over here and we don't really have to do anything with this number right here one because in this implementation we'll know that the q is only between these two pointers so we can just keep going like that and just to show you more examples if -4 comes after that we can put -4 here and then move the second pointer over here if zero comes after that we can put zero here and move the second pointer over here or increment the second pointer by one and if 42 goes away we can move the first pointer over here let me just keep going like this and what if you have a situation like this now where you have three people in the queue 0 1 and 42 and you want to add another person minus 4 here to do that we can put minus 4 here and then you would try to move the second pointer over here but that's out of bound to fix that you can just move this pointer back here at zero instead so you can actually visualize uh this array like a circular array where if you try to go out of bound you just go back to zero so let's just keep going like that uh if we want to put 13 after that you can put 13 here and then move the second pointer by one over here and it would work the same way for the first pointer too i've if the first pointer keeps going to the right and if it's about to go out of bound instead of having it go out of bound we can just bring it back to zero right here and another thing to note about this particular implementation is that you're only able to store almost n minus one elements in this data structure assuming that the length of the array is n to explain that let's consider this situation where we have the second pointer right here and we have some elements here here and here if you try to add one more element right here you would need to move the second pointer right here to the same position as the first pointer but we've already said that in this particular implementation uh if these two pointers point to the same thing this q is empty but clearly it's not empty and that's why we would need to stop here and that's why we're only able to store n minus 1 elements where the length of the array is n if you want to store more elements you will need to either throw an error or create a new array that's longer than the original array and then transfer all the elements to the new array anyway in this implementation we saw two key operations one is removing an element or a person or a piece of data from the cube and another one is adding a piece of data to the queue sometimes it's called dq and q and with this particular implementation assuming that the number of elements doesn't exceed n minus 1 we can implement both of those things in o 1 or in constant time and that's it for a queue but let's quickly discuss another data structure and that's a deck or double ndq it's a more generalized version of the queue data structure that we saw and in this data structure deck you're able to put data and remove data from either end of this queue so you can remove this person right here or you can remove this person right here and you can add a person at the front of the queue or at the left side of the queue or add this piece of data at the right side of the queue and one way to implement this is similar to the implementation of the queue that we saw so you can use a circular array still and have the same kind of structure but in this new structure we're able to remove data from either end and add data to either n2 so you would basically have functions that are called something like add lift remove left add right and remove right sometimes they're called top left pop right or other names but you get the idea you should be able to implement all of those operations in one as well okay so that's my introduction to these three data structures but if you want to practice using these concepts one of the resources i recommend is one of my business affiliates algoexpert.io this is my referral link and this is my discount code cs dojo and there's actually an interesting problem that i found on this website for which you can use one of these concepts so i want to give you a quick introduction to that problem in this problem you're given a string of different types of brackets regular brackets square brackets and curly brackets and you want to write a function that takes a string like this and returns true if the brackets are balanced and false if they're not so what does it mean for these brackets to be balanced to explain that i think the best way to do that would be to give you a bunch of examples this one is balanced because there are square brackets inside and regular brackets outside this is not balanced obviously this is not balanced either because you're trying to close before you open this one's not balanced and this one is not balanced either because these two types of brackets are overlapping anyway you should be able to solve this problem in of and in time where n is the length of the string and of n in space as well anyway uh sorry about the delay again uh i'll try to be you know a little bit faster in my video production in the future but thank you so much for sticking with my video and you know my channel okay thank you as always for watching my videos and i'll see you guys in the next one ",
            "url": "www.youtube.com/watch?v=A3ZUpyrnCbM",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "wjI1WNcIntg",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:25Z",
            "title": "Data Structures: Stacks and Queues",
            "description": "Learn the difference between linear data structures stacks and queues. This video is a part of HackerRank's Cracking The Coding Interview Tutorial with Gayle ...",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. Today I'm going to talk about stacks and queues. Stacks and\nqueues have a lot of things in common. They are both linear data structures in\nthat you have one element and another element and then another element. They\nare both flexible with their sizes so you don't have to allocate initially\nthem to have a size like 50, you can just add elements as you go and then also\nshrink it down. The main difference comes in how elements are removed from the\nstack or from the queue. A stack is what would be called a LIFO data structure,\nlast in first out. It's much like an actual stack of plates.\nThe last plate you put on top of that stack, that's going to be the first one\nyou remove, its LIFO, last in first out. A queue though, is FIFO, first in first out. So think about a queue or line of people waiting to get into a movie theater. When\nthe movie theater doors open they don't first serve the person who\njust hopped into line five seconds ago. They serve the person who got in line at the\nvery very beginning an hour or two ago, and then the next person and then the next person. The\nvery first person in is the very first person removed. That's what FIFO means,\nfirst in first out. Now let's look at the code for these data structures. Here's\nthe framework for what our queue class needs. We need this inner class which is a node,\nand it just keeps a pointer or variable that represents the data, and then also\neach node needs a pointer to the next node and we gave ourselves a little\nconstructor here. Now when we implement a queue or when you use a queue we're going to\nadd things here to the tail and remove from the head. Because you want to add from one side\nand remove from the other. Okay. And then we need these methods so let's walk through and\nactually start implementing these methods. So is empty is very simple just\nreturn if head is null. If head is null then the queues empty otherwise it's not. Okay.\nAnd then peek. Well what peek is going to do is just return head dot data.\nNow this will throw an exception when head is null, if you want you can go explicitly check\nfor that exception. Ok so the add and remove are the sort\nof interesting ones. So with add what we want to do here is add to the tail. So\nfirst thing we need to do is actually go and create this node, then if tail is not\nnull, let tails next pointer point over this node, and then update the tail. Then what we\nwant to do is we want to make sure that even, there could be a case for the array\nwith the queue is completely empty in which case head is null, and so if the head is null, then this value should head, should also be this node. Alright. So that's all add\nhas to do. Alright now for remove we want to remove from the head of the\nlinked list so first what I'm going to do is actually get this head data then what we want\nto do is simply move the head. So I set head equals to head dot next and that\nbasically removes it from the queue and then we need to say okay if head is now\nnull make sure you set the tail to null too, and then go and return that data.\nSo that's the basics of how we implement queue. It follows pretty logically from the\nactual design and the algorithms behind it. Now let's look at the stack\nimplementation. Much like with the queue, we have this inner class that is a node\nclass, has a pointer to the next node. Here though we're going to want to add\nand remove from the top. So we just need a top, we don't\nneed a head and a tail anymore. And then these are the methods were going to want\nto implement. The implementation for is empty is pretty straightforward, just if top\nis null, return true, essentially. And then for peek I'm gonna ignore know pointer\nchecks just to keep my code really really simplistic for you all. All peek needs to do is return top dot\ndata. Ok so push is the first interesting\nmethod. So first we need to actually create this new node, so node, so new node\ndata then this new node is going to become the top. So node dot next is going to point\nover to the old top and then the top points over to node. That's all push\nneeds to do. Now for pop. Well pop is going to, first going to need to, we're going to want to return the old heads data, so first we need to actually just get that data. So head dot\ndata, sorry top dot data. Then top just should move, be moved and pointed over to\nthe new top or the next element down, and then we just need to return that data.\nPretty straightforward. Now again I ignored null pointer checks but if you really want to be complete you'd probably want to do some sort of\ncheck that says hey if top is null throw an exception, if something like. That's\nthe basics of how stacks and queues are implemented.  They're not too tricky to\nimplement just a little bit of, you know, pointers and making sure to\nupdate those things correctly. Now that you've seen both stacks and queues and\nimplementation of them why don't you try these out on a new\nstack or queue problem. Good luck. ",
            "url": "www.youtube.com/watch?v=wjI1WNcIntg",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "okr-XE8yTO8",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2013-11-06T06:34:08Z",
            "title": "Data structures: Array implementation of Queue",
            "description": "In this lesson, we have described array based implementation of queue data structure. Source Code in C++: https://gist.github.com/mycodeschool/7331785 For ...",
            "channelTitle": "mycodeschool",
            "transcript": "In our previous lesson, we introduced you\nto Queue data structure. We talked about Queue\nas Abstract Data Type or ADT. As we know when we talk about\ndata structure as Abstract Data Type, we define it as a mathematical or\nlogical model. We define only the features or\noperations available with the data structure, and do not go into implementation\ndetails. In this lesson, we are going to discuss\npossible implementation of a Queue. I will do a quick recap of what we have\ndiscussed so far. A Queue is a list of collection with\nthis restriction with this constraint, that\ninsertion can be performed at one end, that we call rear of Queue or tail of Queue and Deletion can be performed at other end that we\ncall the front of Queue or the head of Queue. An insertion \nin Queue  is called enqueue operation. A deletion is called dequeue operation. I have defined Queue ADT\nwith these Four operations that have written here, in an actual implementation all these\noperations will be functions,  front operation should simply return the\nelement at front of Queue should not remove any element from the\nQueue, Isempty should simply check whether Queue is\nempty or not and all these operations must take constant\ntime. Enqueue, dequeue or looking at element at front, the time taken for any of these\noperations must not depend upon a variable like number of elements\nin Queue or in other words, and complexity of all\nthese operations must be O(1). Okay! So let's get started, we are saying\nthat a Queue is a special kind of list, in\nwhich elements can be inserted or removed one\nat a time and insertion and removal happen at different ends of the Queue. We can insert\nan element at  one end and we can remove an element\nfrom the other end, just the way we did it for stack. We can\nadd these constraints or extra properties of Queue to some implementation of a list and\ncreate a Queue. They're two popular\nimplementations of Queue, we can have an array based\nimplementation and we can have linked list based implementation. Let's first discuss array-based\nimplementation. Let's say we want to create a Queue of\nintegers. What we can do is we can first create an array of integers. I have created an array\nof 10 integers here.  I have named this array A, now what\nI'm going to do is, I'm going to use this array to store my Queue, what I'm going to\nsay is that at any point, some part after array\nstarting an index marked as front, till an index marked as rear will be my Queue. In this array I'm showing front of the\nQueue toward left and the rear towards right.\nIn earlier examples I was showing front towards right and rear towards left. Doesn't really matter, any side can be\nfront and any side can be rear, it's just that an element must\nalways be added from rear side and must always\nbe removed from front. So if at any stage a segment of the array from an index\nmarked as front till an index marked as rear is my Queue and rest of the positions in the \narray are free space, that can be used to expand the Queue. To insert an element to enqueue, we can\nincrement rear, so we will add a new cell in the Queue\ntowards rear end and in this cell, we can write\nthe new value element to be inserted can come to this\nposition. I fill in some values here at these\npositions. So we have these integers in the Queue and let's say we want to insert number 5. To\ninsert we will increment rear ofcourse there should be an available\ncell in the right, an available empty cell in the right and\nnow we can write value 5 here. After insertion new rear index\nis  7, and value at index 7 is 5. Now dequeue means we must remove an\nelement from front of Queue. In this example, here a dequeue operation\nshould remove number 2 from the Queue to dequeue, we can simply increment front because at any point only the cells\nstarting front till rear are part of my Queue.\nBy incrementing front I have discarded index 2 from the Queue and we do not\ncare what value lies in a cell, that is not part of the Queue, when\nwe will include cell in the Queue we will overwrite\nthe value in that cell anyway. So just incrementing front is\ngood enough for dequeue operation. Let's quickly write\npseudocode for whatever we have discussed so far. In my\ncode I will have 2 variables named front and rear, and\ninitially I'll set them both as -1. Let's say for and empty Queue both front and rear will be -1. To check whether Queue is empty\nor not we can simply check the value of front\nand rear and if they're both -1 we can say that\n Queue is empty. I just wrote isempty function here. -1\nis not a valid index. For an empty Queue there\nwill be no front and rear. In our implementation we are saying that\nwe will represent empty state of Queue by setting both front and rear as -1. Now let's write the enqueue function.\nEnqueue will take integer x as argument, there will be a\ncouple of conditions in enqueue. If rear is already equal to maximum\nindex available in array A, We cannot insert\nor enqueue an element in such scenario we can return and exit. I would rather use a function named \nisfull to determine whether Queue is full or not.\nIf Queue is already full, we can't do much we should simply exit, else if Queue is empty we can add cell to the Queue, we can add cell at index 0 in the Queue, and now the\nwe can set value at index rear as x. In all other cases,\nwe can first increment rear, and then we can fill-in value X at index rear. I can get a statement a[rear] = X\noutside these two conditional statements because it's common to them, so this is\nmy enqueue function. In the example array that I'm showing\nhere let's enqueue some integers. I'll make calls to enqueue function and\nshow you the simulation. In the figure here, let's say first I\nwant to insert number 2 in the Queue, I'm making a call to\nenqueue function passing number 2 as argument. The Queue is empty, so we will set both front and rear as 0. Now we will come to this statement, we\nwill write value 2 at index 0. So this is Queue after one enqueue\noperation, front and rear of the Queue is same. Let's make\nanother call to enqueue, this time I want to insert number 5.\nthis time Queue is not empty, so rear will be incremented. We have\nadded a cell to the Queue by incrementing\nrear and now we will write the value 5 at the new rear index. Let's enqueue 1 more number. I have \nenqueued 7. Let's not write dequeue operation. There will be\ncouple of cases in dequeue. If the Queue is already empty, we cannot\nremove an element In this case we can simply print or throw\nan error, and return or exit. There will be one more\nspecial case, if the Queue has only one element. \nIn this case, front and rear will not be -1 but they\nwill both be equal, because we are already checking\nfor -1 case in isempty function in the previous if. In\nthis else if we can simply check whether front is equal to rear\nor not, if this is the case a dequeue will make the Queue empty, and to mark to\n Queue as empty, we need to set both front\nand rear as -1. This is what we had said, that we\nwill would represent and empty Queue by\nmarking both front and rear as -1. In default or\nnormal scenario, we will simply increment front, we\nshould really be careful about corner cases in any implementation, that's fair most of the Bugs come. Okay,\nso this finally is my dequeue function. In this example here at this stage, let's\nsay be want to perform a dequeue, Queue is not empty and we do not have\nonly one element in the Queue. So people simply increment front,\nbefore incrementing we could set the value in this cell at index 0 as something, but the\nvalue in a cell that is not part of Queue anymore doesn't really matter. At this stage it\ndoesn't really matter what we have at index 0 or index 3 or any other index apart the\nsegment between front and rear. When we will add a cell in the Queue, we will\noverwrite the value in that cell anyway. Let's now perform some more enqueues\nand dequeues. I'm enqueuing 3 and then I'm enqueuing 1, with each enqueue we are\nincrementing rear. I just performed some more enqueue here. Now\nlet's the perform a dequeue. If I'll perform one more enqueue here, rear will be equal to the maximum index available\nin the array. Let's enqueue one more now at this stage, we cannot enqueue an element anymore because we cannot\nincrement rear. Enqueue operation will fail now. \nThere are two unused cells right now but with whatever\nlogic we have written, we cannot use these two cells that are\nin the left of front in fact this is a real problem. As we\nwill dequeue more and more, all the cells left of front index will\nnever be used again they will simply be wasted. Can we do something to use these cells? Well, we can use the concept of a Circular\narray. Circlular array is an idea that we use in a lot of scenarios. The idea is very simple, as we\ntraverse an array we can imagine that there is no end in\nthe array, from 0 we can go to 1, from 1, we can go to 2, and finally then we will reach the\nlast index in the array. Like in this example, when we are at index 9 the next index for me is index 0. We\ncan imagine this array something like this, remember this is\nonly a logical way of looking at the array. An circular interpretation of array, if I'm\npointing to a position and my current position is i then the next position or next index\nwill not simply be i + 1, it will be i + 1 Modulo the\nnumber of elements in array or the size of array.\nLet's say, N is the number of elements in array,\nthen the next position will be i + 1 Modulo N. The modulo\noperation will get us the remainder upon dividing by N for any i other than N - 1. This modulo\noperational will not have any effect, but for i = N - 1 next position will\nbe N module N which will be equal to 0.\nWhen you divide the number by itself, the remainder is 0. Previous\nposition in circular interpretation of array, will be I + (N - 1) modulo N. We could simply say I-1 modulo N,\njust to make sure this expression inside the parenthesis is always positive, I'm adding N here. Give this some thought.\nYou should be able to get why it should be (i + (N - 1)) modulo N. Now\nwith this interpretation of array, we can increment rear in an enqueue operation as long as there is any unused cell in\nthe array. I'm going to modify functions in my\npseudo code now. Isempty will remain the same we are\nstill saying that, for an empty Queue front and rear will be -1. Let's scroll down and come to enqueue. Now, in\ncircular interpretation I will call my Queue full, when the position next to\nrear in circular interpretation that we will\ncalculate as (rear + 1) modulo N, will be equal\nto front, so we will have a situation like this.\nRight now, the next position to rear in circular\ninterpretation is front. So there is no unused cell.\nThe complete array is exhausted. Nothing will change in\nthis condition. If Queue is empty, we can simply set\nfront and rear as 0. In the last else condition, we will\nincrement rear like this, we will say \nrear = (rear+1) modulo N where N is number of elements in the array.\nWith this much change, my enqueue function is good. Now let's make a call to enqueue and insert\nsomething in this array here, I want to insert\nnumber 15. We will come to this last else condition,\nRear right now is 9, so this expression will be (9 + 1) modular N, N is 10\nhere the size of this array A is 10 here. This will evaluate to 0, now my new rear is 0. I'll write number 15 here. Let's now see what we need to do in dequeue\nfunction. Nothing will change in the first two\nconditions, if Queue is already empty or if there is only one element in the\nQueue, we will handle these cases in same manner in the final else when we are\nincrementing front, we need to increment it in a circular\nmanner so we will say  fornt = (front + 1) modulo N where N is the number of elements in the array, \ntotal number of elements in the array, or size of array. Now let's perform a dequeue, we will come to\nthis condition front right now is 2 so this will be (2 + 1)\nmodulo 10, one more cell is available to us now. This much is the core of our\nimplementation. Front operation will be really straightforward, we simply need to\nreturn the element at front index. Here also, we first need to check whether the\nQueue is empty or not, we should return a[front] only\nwhen front is not equal to -1. All these\noperations all these functions that have written here will take constant time, there complexity will be O(1). We\nare performing simple arithmetic and assignments in the functions, and not doing anything costly like\nrunning the loop, so time taken will  not depend upon size\nof Queue or some other variable. I leave this here it should not be very\ndifficult converting this pseudo code to a running program in a language of your\nchoice, If you want to see my code you can check the description of this\nvideo for a link. Thanks for watching. ",
            "url": "www.youtube.com/watch?v=okr-XE8yTO8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "gnYM_G1ILm0",
            "channelId": "UC4o8Fdpv3g_AjgShAeivqpA",
            "publishedAt": "2016-10-04T16:42:23Z",
            "title": "Queue | Data Structures Tutorial | Mr.Srinivas",
            "description": "Queue | Data Structures Tutorial | Mr.Srinivas ** For Online Training Registration: https://goo.gl/r6kJbB \u25bb Call: +91-8179191999 Also Watch C Language ...",
            "channelTitle": "Naresh i Technologies",
            "transcript": "hi everyone welcome to nourish technologies this is inverse so today we are going to discuss about queue data structure so what is the Q so Q is an algorithm Q is an algorithm and simply this is a data structure first one it is algorithm second one it is data structure to arrange the data in a particular format and third one it is a linear data structure nothing but arrangement of elements in a linear form one after another and next one next one it follows a rule nothing but the complete inflammation of a queue based on a simple rule that is first in first out FIFO first in first out right here it is how we can implement the queue right to implement the queue we can use either static arrays or a dynamic arrays we can implement using static arrays or we can use a dynamic arrays a static arrays means what is a fixed in size fix it in size and here it is the size varies automatically the size varies depends on the number of elements storing the size will increase and if you want to delete some of the elements the size will decrease automatically okay so this is Q implementation with the help of a static arrays we can implement and with the help of a dynamic arrays we can implement so how the Q structure will be and so what all the operations we can perform on the q see for example so this is the Q structure this is the Q here here we can store the elements this is simply so we can call it as a cue right so how ask you will be created for example a static declaration simply in teaser here it is a cue and the size we have given five so five locations will be created five locations and here it is so what all the operations we can perform on the cue first one we can insert element second one we can delete element and next one we can display all the elements in the queue display elements in the queue and all these operations we can perform how means what insertion operations deletion operations how we can insert an element into the queue and how can we delete an element from the queue simple insertions from where from rail here it is we can insert the elements and how can we delete the elements deletion from the front so these variables are mandatory these variables are mandatory whenever we are performing operations right in a queue implementation of a queue in that program we must use a front variable and rare variable to perform all the operations on the queue okay so how to insert the element and how to delete the element observe friend always should point into the first location we cannot move the front value front always pointing to the first location that is a fixed memory location and next one where initially rare is also pointing to the fore locations are wiser because no elements in this queue no elements so front is pointing to zero and the rare is also pointing to zero friend value zero and rare value is also zero suppose if you want to insert an element we need to insert in the rare position only what is a rare position zero right if you want to insert use the rare variable if you want to delete use the front variable so here rare variable I am using I am storing the element supposed 10 nothing but we are inserting like this and it will travel and it will stay here next after insertion now rare position will change rare position shift to hear nothing but rare value is a one rare value is a one next one next whenever you insert the element here it is a 20 20 after insertion of 20 now rare stop pointing to second one rare is pointing to the next location rare value is a two next we are inserting like this 30 we are inserting it stop pointing it will become three and it pointing to this one next we are inserting 40 it stop pointing rare value become 4 it is pointing to this one next we are inserting 50 then it stop pointing rare is pointing to the outside location where value 5 rare value 5 so now whenever we are trying to insert a new element into the queue right it will give 1 error message what is that q is already full q is already full because here it is a all the five elements inserted into a queue the size is a 5 so sixth element you cannot store then what operation we have to perform means either you go for display or you can go for delay an operation right here it is the friend if you want to delete it then we should delete this one delete generally the people saying after deletion of a first element front we should move to this next location that is completely wrong suppose if you move the front location directly to next next next finally it will reach that end that is not possible think generally for example in your cue line here it is a ticket counter is there just consider ticket counter so first person got the ticket and the person come out of the queue line then remaining people will move in the same way or remaining all the elements we should shift that is the process deletion of a front element is nothing but we need to shift all the elements in the queue line right we need to shift then automatically the rail also right here it is 20 come to here 30 come to here 40 here 50 here now now the rail is pointing and of course 50 will be here only next the rear is pointing to 4 red is pointing to 4 is now pointing to this one because we have to decrease the rare value because we are deleting one element from the queue so automatically a location will become empty there you can store the new value we already know that it is impossible to delete the data which is inside the memory location what we can do only we can overwrite the information so that is why here it is these elements are overridden but still in this location 50 is there then what we should do next suppose if you want to insert another element that we are inserting in the rare position by the time 50 will be replaced with to some other value 60 that is replacing the information you can't delete the information which is in inside the queue not only inside the queue inside the memory location in any programming language we know that basics right here it is now the rare is always again pointing to that next node like that so like that suppose if you are deleting continuously 20 we are deleting then we're become 430 we are deleting we're become 340 we are deleting rare become 250 we are deleting we're become 160 we are deleting we're become zero rare becomes zero nothing but all the elements we inserted all the elements we deleted now front value is zero and rare value is zero what is the meaning whenever front and rear both are equals two zeros that is what we called queue is empty no elements in the beginning also whenever you created the node by that time no elements were inserted so by the time also initially front is pointing to the first location rare is pointing to the first location whenever both the values are same that we can call it as it clearly right front and rear equals zero means queue is empty queue is empty so this is how we are inserting the elements and how we are deleting the elements how we are checking queue is full or not how we are checking queue is empty or not right all these things okay so this is all about a theoretical concept of a queue implementation okay in the next session we will see how to implement programmatically this queue thank you for watching for more videos please subscribe to narration 80 channel you ",
            "url": "www.youtube.com/watch?v=gnYM_G1ILm0",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "O3y6A7WLlao",
            "channelId": "UC63URkuUvnugRBeTNqmToKg",
            "publishedAt": "2019-06-08T08:15:30Z",
            "title": "QUEUE IMPLEMENTATION USING ARRAYS - DATA STRUCTURES",
            "description": "STACKS IMPLEMENTATION USING ARRAYS - FOLLOWS FIFO MECHANISM - LINEAR DATA STRUCTURE - ENQUEUE OPERATION (INSERTION) ...",
            "channelTitle": "Sundeep Saradhi Kanthety",
            "transcript": "[Music] hello friends welcome back to our channel so in the previous session we have seen the implementation of a stack which is a linear data structure and the implementation of a stack can be done in two ways one is by using the air is another one by using the link list so in the previous session we have seen the implementation of the stack using arrays now in this session we'll go with the another linear data structure that is called Q's Q so this is also a linear data structure similar to the stack with a little bit difference and here also there are two operations to be verified that is insertion and deletion so in the stack we have seen the insertion is called as push and the deletion is called as pop here the insertion will be called as NQ and deletion will be called as DQ and see this is also a linear data structure similar to the stack so it is a linear data structure the first point right so that means all the elements will be arranged in sequential manner so it remains in sequential manner this is third point so in the stack it follows the lastin first-out mechanism that means the recently added element or recently inserted element will be removed first so here the Q is it follows the FIFO mechanism so it follows fearful if I fo that means first in first out so that means whatever the element inserted first that can be removed first right so best example for this cue is standing on a line for ticket reservation this is the best example for this cue okay standing on line for ticket resolution so the person who comes first if you will get the ticket first it first come for sir similar to the first come first serve so here all in the stack there will be a top position and both the insertion and deletion will be done at the top position right so here the insertion and deletion will be performed on different positions see here two operations will be there first one and Q and Q and did you so thank you is inserting an element into the Q DQ means deleting an element from the queue so and Q is inserting an element DQ is deleting energy and also there are two conditions to be checked while implementing these enqueue and dequeue operations to two conditions a water flow condition under flow condition more for a laminar flow say these two we have seen in stack implementation so the definition is same so our view means insertion into you which is full which is full enough amines deletion from and big queue so that is called a waterphone this is called enough room so overflow condition must be checked in MQ operation and under flow condition to be checked in and take your operation right then so in the stack we have seen another thing that is called a top tup which is at top of this tab so go to him in I mean the push operation is top operation will be performed on the same thing that is from here the mq will be performed on one position and think you will be performed on another position right let us go with that and then we will directly go with the implementation here there will be two ends friend ray find points to starting in with whereas arrange points to mastiff and here also we need to specify the size okay so that we will see later so friend end grain so mq operation NQ increments in session we'll be done at rare and rare similarly DQ will be done at friend there's only difference and now the representation representation of the Curie's in this way so this is the friend this one will be the rain right so okay Frank Andrea here we will perform beat you here will be perform thank you so if you want to insert an element into the queue that will be inserted here if you want to delete an element from the queue it must be deleted from here because the first element entering into the queue which will be the first element to be removed right so this way we have to represent a queue so this is a queue this is a queue Frank and Ray okay so if you are right so initially the front end rail will be initialized to minus one initially friend is equal to where is equal to minus one so if you want to insert an element first we need to build the rail and then we have to insert an element if you want to delete an element first we want to reduce the tellement which we want to remove and we need to update the friend right hope you understood this one right now like we'll go with the implementation paths implementation how the queue can be implemented here also queue can be implemented in two ways so first one by using Alice another one by using linked list in two ways we can implement this true now in this session we'll go with implementation of queue by using as in the later video we will see the implementation of Q using lincoln\u00eds right Q using ants implementation of queue using Alice no see initially the front end rail will be minus one and if you are inserting an element that first aware should be abraded right so let us see this first one we need to fix the size of an area because it is a static allocation before starting the queue itself we need to specify the size fix the size so later we can't update the addresses there is a main project of implementing the queues using arrays the same car back we have seen in stacks also so that's why we will move on to the linked list now let us take the size as some 10 right next friend is equal to red is equal to minus 1 so both are equal front and drain both are equal and both are initialized to minus 1 now after every enqueue operation we need to update this 1f after every dequeue operation we need to have data friend now let us go with them so I also declare a stack I mean Q and Q are a with a size n now we will go with the enqueue function and Q function so in the n cube first we are supposed to check whether the stack is full of not if the stack is full then the insertion operation needs not be done right so we can't insert the element out of the size so we have to check the cheerful so if there is equal to is equal to size minus 1 so after every enqueue operation we are updating the mayor right so rare points the last statement of the queue so which we have discussed just now so that's why if R is equal to zero size minus one so here the size is 10 so the size of the queue is from 0 to 9 that will size minus one so if rain is pointing to the size minus 1 automatically that is a queue is full so we can't inside the add elementary to the queue so that's why if RL is equal to is equal to size minus 1 simply read f war flow condition Oh similarly can bring the queue is full yes so if it is not size minus 1 then we can insert an element into the queue so fast rear element scanf % HD ampersand in here again we need to check one more condition that if rent is also minus 1 so because we have to update the front also so initially this is a queue this is the queue so friend and then minus 1 so if you insert an element here let it be 10 rain will be updated so rail will be pointing here but still the front is equal to minus 1 so Fred should point at the top element I mean first element so if we have to check that condition if friend is equal to is equal to minus 1 what we have to do just SNe to 0 then friend is equal to 0 right so if it is minus 1 is equal to 0 then after completion of this condition before inserting what we have to do see so here an element temp is taken from the keyboard and now friend is equal to equal to also friend is equal to zero so this is the zero position one two three and four now fans day is pointing to here Frank is pointing towards here this position right yes is now rate is equal to minus one so in order to insert an element we need to update that name right so open the place through the breeze so just to avoid the confusion here we we need to update the rave so where is updated so rave minus one so where we were updated so the rail value will be here so that means pointing towards zero so at the zero we have to insert arrangement so Q of L is equal to n so now the N will be here now the 10 will be here that's all close close one section if you call this enqueue operation see this is equal to size minus one now ray is pointing towards zero zero is equal to nine funds it comes here it reads the element if it reads the twenty then if friend is equal to minus one that is not equal to minus 1 because friend is already initialized to zero that we see is pointing towards the first element that is why it wishin is passed this is simple if condition right then recklessness zero now array will be pointing to one right then q o3 r where q of Ray is equal to Q of 0 so 33 of 1 is equal to 20 so party will be inserted here so this is a great position and again if you again you want to insert another element then again you call the NQ operation so rate is equal to size minus 1 is equal to is equal to size minus one so condition false yes condition it reads another element so 30 so friend is equal to minus one threat is our but is not equal to minus 1 so condition fails and out from the conditional statement read plus plus now then will be pointing towards to Q of red is equal to element so here the 30 will be printing similarly for me in the next all right in the next one the party will forget until this condition becomes false sorry this condition becomes true if it is true we can't insert an element into the Q so this is how we can insert an element into the cube so insertion always done after a rain okay that's we should remember so here there will be two positions front and rain and all the instructions will be done at the very end so first we have to update the rain and we need to insert the element into the rain now let us move with dequeue operation that is how to delete an element from the queue so this insertion operation so very simple thing DQ so this sort of function let us write the function itself right so DQ means deleting an element from the queue so we we have to do it from where we have to delete so that all the elements will be deleted from the fronton right friend thing so before deletion we need to check the condition that is under flow condition if rain is equal to is equal to minus 1 if rain is equal to is equal to minus 1 simply that implies our queue is an empty cube because if you want to insert an element first compass re we have to increment this rare so if rain is equal to is equal to minus 1 that implies our queue is empty that means lower elements available in the work you so simply we can write pre them on the flow or simply we can write empty queue empty queue yes so if it is not an empty queue then what you have to do it the first element should be deleted so element is equal to Q of friend so M will be assigned to element so we can write the printer percentage D is delete table percentage is what is the person density anybody then we need to obtain the friend because we have deleted M so 20 is the first statement so we have deleted the 10 so deletion means just we are pointing towards another one right so the memory will be same we are not freeing the memory right so 20 is now the first element of the queue is 20 so we need to build a friend so friend plus plus friend plushness so friend will be moved to here right ok then close hope your muscle every time the mentor is deleted from the front end and we are incrementing the friend and here we can also check the condition there is equal to zero to minus one or friend is greater than 3 this is also one condition so friend if friend is greater than red so deleting one by one element the find will be pointing towards here so 4 is greater than 3 that means no more elements are there in evening in queue so that is why we can take this condition also friend greater than array Frank go to them so if anyone's condition is true automatically that indicates this is under flow that will secure is empty so this is how we can delete an element from the queue see range is equal to minus 1 false so initially let us let us see here under so else element is equal to your friend so 10 will be removed and fine plus this now friend will be pointing towards 20 again if you again apply this DQ operation array is equal to minus 1 pulse so 1 is greater than 4 false so total false yes what will be executed so if it is equal to your friend so 20 will be deleted and find restless so friend will be now here itself right there is equal to minus 1 false finding better than 2 greater than 3 false so element is equal to cure friend that it will be deleted in here and friend plus place now friend is pointing towards the same thing rate is equal to minus 1 false try to greater than 3 so 3 rather than 3 Fox so under flow again false so the else part will be executed that 40 will be deleted and fretless place so no friend is pointing towards 4 now again if you again if your applying this I mean if you are deleting this DTO operation you are applying this dequeue operation and that is equal to minus one Falls and finds greater than they so for greater than three condition is true so under flow that means our Q is and D so this is how we can apply the deletion operation on Q's right so hope you understood this insertion and deletion and Q and EQ now we'll go with the third one that is a display how to display the elements of a cube that's also very simple T so this is the Ray this is the friend right now display operation so we need to display all the elements of a cube first let us check whether it is an empty cure so for that we need to check if Ray is equal to is equal to minus 1 or friend rather than Ray so this is also condition if any one of these condition is true automatically we can say it is in empty queue empty queue right yes so if it is false then we need to pray all the elements from front to where so we need to use the introduced segments for I is equal to friend simple for me I less than or equal to V I plus plus here we can print percentage D Q of I simple display function all right so is equal to friend so I is equal to 0 0 less than or equal to 3 so Q of I so Q of 0 that means my repeated next I will be limited to 1 so 1 less than or equal to 3 so Q of 1 and this 20 next is increment K so I is equal to 2 2 less than or equal to 3 so again to 0 of 2 is equal to 30 so I is equal to 3 the third next condition next increment so 3 sorry 3 less than or equal to 3 condition 2 Q of 3 is equal to 40 so I is equal to 4 so 4 less than or equal to 3 things so it comes out from the loop it comes out from the loop and the display function will be stopped here so these are the elements which are presented in the queue so 10 20 30 and 40 which are here so hope you understood this one display function write a very simple logic while implementing these cues using headings so here we draw a case we need to specify the size of the queue before starting the operations itself so later we can't change the size of the queue right so that's a worried or back in this queue implementing the implementation of queue using arrays so here the mq & DQ are the operations for insertion and deletion and Q will be done at rain DQ will be done at front end so in this session we have seen the NQ operation the king of Christmas display how to display the elements of vacuum and right so hope you understood this session so let us stop here if you are having any doubts regarding this session so feel free to post your notes in the comment section so that definitely clarify all your don'ts and if you really understood my sessions like my sessions shave my sessions with your friends and don't forget to subscribe to our channel keep following thanks for listening thank you ",
            "url": "www.youtube.com/watch?v=O3y6A7WLlao",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "binary search trees data structures": [
        {
            "videoId": "pYT9F8_LFTM",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2014-01-25T04:55:55Z",
            "title": "Data structures: Binary Search Tree",
            "description": "In this lesson, we have discussed binary search tree data structure. Binary search is an efficient data structure in which we can store data to get search, insertion ...",
            "channelTitle": "mycodeschool",
            "transcript": "In our previous lesson, we talked about binary\ntrees in general. Now, in this lesson we are going to talk about\nbinary search tree, a special kind of binary tree which is an efficient structure to organize\ndata for quick search as well as quick update. But before I start talking about binary search\ntree, I want you to think of a problem. What data structure will you use to store\na modifiable collection? So, lets say you have a collection and it\ncan be a collection of any data type, records in the collection can be of any type. Now, you want to store this collection in\ncomputers memory in some structure and then you want to be able to quickly search for\na record in the collection and you also want to be able to modify the collection. You want to be able to insert an element in\nthe collection or remove an element from the collection. So, what data structure will you use? Well, you can use an array or a linked list. These are two well known data structure in\nwhich we can store a collection. Now, what will be running time of these operations\n- search, insertion or removal, If we will use an array or a linked list. Lets first talk about arrays and for sale\nof simplicity, lets say we want to store integers. To store a modifiable list or collection of\nintegers, we can create a large enough array and we can store the records in some part\nof the array. We can keep the end of the list marked. In this array that I am showing here, we have\nintegers from 0 till 3. We have records from 0 till 3 and rest of\nthe array is available space. Now to search some X in the collection, we\nwill have to scan the array from index 0 till end and in worst case, we may have to look\nat all the elements in the list. If n is the number of elements in the list,\ntime taken will be proportional to n or in other words, we can say that time complexity\nwill be big-oh of n. Ok, now what will be the cost of insertion. Lets say we want to insert number 5 in this\nlist. So, if there is some available space, all\nthe cells in yellow are available, we can add one more cell by incrementing this marker\n'end' and fill in the integer to be added. Time taken for this operation will be constant. Running time will not depend upon number of\nelements in the collection. So, we can say that time complexity will be\nbig-oh of 1. Ok, now what about removal. Lets say we want to remove 1 from the collection. What we'll have to do is, we'll have to shift\nall records to the right of one by one position to the left and then we can decrement end. The cost of removal once again will be big-oh\nof n. In worst case, we will have to shift n-1 elements. Here, the cost of insertion will be big-oh\nof 1, if the array will have some available space. So, the array has to be large enough. If the array gets filled, what we can do is,\nwe can create a new larger array, typically we create an array twice the size of the filled\nup array. So, we can create a new larger array and then\nwe can copy the content of the filled up array into this new larger array. The copy operation will cost us big-oh of\nn. We have discussed this idea of dynamic array\nquite a bit in our previous lessons. So, insertion will be big-oh of 1 if array\nis not filled up and it will be big-oh of n if array is filled up. For now, lets just assume that the array will\nalways be large enough. Lets now discuss the cost of these operations\nif we will use a linked list. If we would use a linked list, I have drawn\na linked list of integers here, data type can be anything, the cost of search operation\nonce again will be big-oh of n where n is number of records in the collection or number\nof nodes in the linked list. To search, in worst case, we will have to\ntraverse the whole list. We will have to look at all the nodes. The cost of insertion in a linked list is\nbig-oh of 1 at head and its big-oh of n at tail. We can choose to insert at head to keep the\ncost low. So, running time of insertion, we can say\nis big-oh of 1 or in other words, we will take constant time. Removal once again will be big-oh of n. We will first have to traverse the linked\nlist and search the record and in worst case, we may have to look at all the nodes. Ok, so this is the cost of operations if we\nare going to use array or linked list. Insertion definitely is fast. But, how good is big-oh of n for an operation\nlike search. What do you think? if we are searching for\na record X, then in the worst case, we will have to compare this record X with all the\nn records in the collection. Lets say, our machine can perform a million\ncomparisons in one second. So, we can say that machine can perform 10\nthe power 6 comparisons in one second. So, cost of one comparison will be 10 to the\npower -6 second. Machines in today's world deal with really\nlarge data. Its very much possible for real world data\nto have 100 million records or billion records. A lot of countries in this world have population\nmore than 100 million. 2 countries have more than a billion people\nliving in them. If we will have data about all the people\nliving in a country, then it can easily be 100 million records. Ok, so if we are saying that the cost of 1\ncomparison is 10 the power -6 second. If n will be 100 million, time taken will\nbe 100 seconds. 100 seconds for a search is not reasonable\nand search may be a frequently performed operation. Can we do something better? Can we do better than big-oh of n. Well, in an array, we can perform binary search\nif its sorted and the running time of binary search is big-oh of log n which is the best\nrunning time to have. I have drawn this array of integers here. Records in the array are sorted. Here the data type is integer. For some other data type, for some complex\ndata type, we should be able to sort the collection based on some property or some key of the\nrecords. We should be able to compare the keys of records\nand the comparison logic will be different for different data types. For a collection of strings, for example,\nwe may want to have the records sorted in dictionary or lexicographical order. So, we will compare and see which string will\ncome first in dictionary order. Now this is the requirement that we have for\nbinary search. The data structure should be an array and\nthe records must be sorted. Ok, so the cost of search operation can be\nminimized if we will use a sorted array. But, in insertion or removal, we will have\nto make sure that the array is sorted afterwards. In this array, if I want to insert number\n5 at this stage, i can't simply put 5 at index 6. what I'll have to do is, I'll first have to\nfind the position at which I can insert 5 in the sorted list. We can find the position in order of log n\ntime using binary search. We can perform a binary search to find the\nfirst integer greater than 5 in the list. So, we can find the position quickly. In this case, its index 2. But then, we will have to shift all the records\nstarting this position one position to the right. And now, I can insert 5. So, even though we can find the position at\nwhich a record should be inserted quickly in big-oh of log n, this shifting in worst\ncase will cost us big-oh of n. So, the running time overall for an insertion\nwill be big-oh of n and similarly, the cost of removal will also be big-oh of n. We will have to shift some records. Ok, so when we are using sorted array, cost\nof search operation is minimized. In binary search for n records, we will have\nat max log n to the base 2 comparisons. So, if we can perform million comparisons\nin a second, then for n equal 2 to the power 31 which is greater than 2 billion, we are\ngoing to take only 31 micro-seconds. log of 2 to the power 31 to base 2 will be\n31. Ok, we are fine with search now. we will be good for any practical value of\nn. But what about insertion and removal. They are still big-oh of n. Can we do something better here? Well, if we will use this data structure called\nbinary search tree, I am writing it in short - BST for binary search tree, then the cost\nof all these 3 operations can be big-oh of log n in average case. The cost of all the operations will be big-oh\nof n in worst case. But we can avoid the worst case by making\nsure that the tree is always balanced. We had talked about balanced binary tree in\nour previous lesson. Binary search tree is only a special kind\nof binary tree. To make sure that the cost of these operations\nis always big-oh of log n, we should keep the binary search tree balanced. We'll talk about this in detail later. Let's first see what a binary search tree\nis and how cost of these operations is minimized when we use a binary search tree. Binary search tree is a binary tree in which\nfor each node, value of all the nodes in left sub-tree is lesser and value of all the nodes\nin right sub-tree is greater. I have drawn binary tree as a recursive structure\nhere. As we know, in a binary tree, each node can\nhave at most 2 children. We can call one of the children left child. If we will look at the tree as recursive structure,\nleft child will be the root of left sub-tree and similarly, right child will be the root\nof right sub-tree. Now, for a binary tree to be called binary\nsearch tree, value of all the nodes in left sub-tree must be lesser or we can say lesser\nor equal to handle duplicates and the value of all the nodes in right sub-tree must be\ngreater and this must be true for all the nodes. So, in this recursive structure here, both\nleft and right sub-trees must also be binary search trees. I'll draw a binary search tree of integers. Now, I have drawn a binary search tree of\nintegers here. Lets see whether this property that for each\nnode value of all the nodes in left subtree is lesser or equal and the value of all the\nnodes in right sub-tree must be greater is true or not. Lets first look at the root node. Nodes in the left subtree have values 10,\n8 and 12. So, they are all lesser than15 and in right\nsubtree, we have 17, 20 and 25, they are all greater than 15. So, we are good for the root node. Now, lets look at this node with value 10. In left, we have 8 which is lesser. In right, we have 12 which is greater. So, we are good. We are good for this node too having value\n20 and we don't need to bother about leave nodes because they do not have children. So, this is a binary search tree. Now, what if I change this value 12 to 16. Now, is this still a binary search tree. Well, for node with value 10, we are good. The node with value 16 is in its right. So, not a problem. But for the root node, we have a node in left\nsub-tree with higher value now. So, this tree is not a binary search tree. I'll revert back and make the value 12 again. Now, as we were saying we can search, insert\nor delete in a binary search tree in big-oh of log n time in average case. How is it really possible? Lets first talk about search. If these integers that I have here in the\ntree were in a sorted array, we could have performed binary search and what do we do\nin binary search. Lets say we want to search number 10 in this\narray. What we do in binary search is, we first define\nthe complete list as our search space. The number can exist only within the search\nspace. I'll mark search space using these two pointers\n- start and end. Now, we compare the number to be searched\nor the element to be searched with mid element of the search space or the median. And if the record being searched, if the element\nbeing searched is lesser, we go searching in the left half, else we go searching in\nthe right half. In case of equality, we have found the element. In this case, 10 is lesser than 15. So, we will go searching towards left. Our search space is reduced now to half. Once again, we will compare to the mid-element\nand bingo, this time, we have got a match. In binary search, we start with n elements\nin search space and then if mid element is not the element that we are looking for, we\nreduce the search space to n/2 and we go on reducing the search space to half, till we\neither find the record that we are looking for or we get to only one element in search\nspace and be done. In this whole reduction, if we will go from\nn to n/2 to n/4 to n/8 and so on, we will have log n to the base 2 steps. If we are taking k steps, then n upon 2 to\nthe power k will be equal to 1 which will imply 2 to the power k will be equal to n\nand k will be equal to log n to the base 2. So, this is why running time of binary search\nis big-oh of log n. Now, if we will use this binary search tree\nto store the integers, search operation will be very similar. Lets say, we want to search for number 12. What we'll do is, we start at root and then\nwe will compare the value to be searched, the integer to be searched with value of the\nroot. if its equal, we are done with the search, if its lesser, we know that we need to go\nto the left sub-tree because in a binary search tree, all the elements in left sub-tree are\nlesser and all the elements in right sub-tree are greater. Now, we will go and look at the left child\nof node with value 15. We know that number 12 that we are looking\nfor can exist in this sub-tree only and anything apart from the sub-tree is discarded. So, we have reduced the search space to only\nthese 3 nodes having value 10, 8 and 12. Now, once again, we will compare 12 with 10. We are not equal. 12 is greater, so we know that we need to\ngo looking in right sub-tree of this node with value 10. So, now our search space is reduced to just\none node. Once again, we will compare the value here\nat this node and we have a match. So, searching an element in binary search\ntree is basically this traversal in which at each step, we will go either towards left\nor right and hence at each step, we will discard one of the sub-trees. if the tree is balanced, we call a tree balanced\nif for all nodes, the difference between the heights of left and right sub-trees is not\ngreater than 1. So, if the tree is balanced, we will start\nwith a search space of n nodes and when we will discard one of the sub-trees, we will\ndiscard n/2 nodes. So, our search space will be reduced to n/2\nand then in next step, we will reduce the search space to n/4. We will go on reducing like this till we find\nthe element or till our search space is reduced to only one node when we will be done. So, the search here is also a binary search. And that's why the name - Binary Search Tree. This tree that I am showing here is balanced. In fact this is a perfect binary tree. But with same records, we can have an unbalanced\ntree like this. This tree has got the same integer values\nas we had in the previous structure and this is also a binary search tree, but this is\nunbalanced. This is as good as a linked list. In this tree there is no right sub-tree for\nany of the nodes. Search space will be reduced by only one.at\neach step. From n nodes in search space, we will go to\nn-1 nodes and then to n-2 nodes, all the way till 1 will be n steps. In binary search tree, in average case, cost\nof search, insertion or deletion is big-oh of log n and in worst case, this is the worst\ncase arrangement that I am showing you. The running time will be big-oh of n. We always try to avoid the worst case by trying\nto keep the binary search tree balanced. With same records in the tree, there can be\nmultiple possible arrangements. For these integers in this tree, another arrangement\nis this. For all the nodes, we have nothing to discard\nin left sub-tree in a search. This is another arrangement. This is still balanced because for all the\nnodes, the difference between the heights of left and right sub-tree is not greater\nthan 1. But this is the best arrangement when we have\na perfect binary tree. At each step, we will have exactly n/2 nodes\nto discard. Ok, now to insert some records in binary search\ntree, we will first have to find the position at which we can insert and we can find the\nposition in big-oh of log n time. Lets say we want to insert 19 in this tree,\nwhat we will do is start at the root. If the value to be inserted is lesser or equal,\nif there is no child, insert as left child or go left. If the value is greater and there is no right\nchild, insert as right child or go right. In this case, 19 is greater, so we will go\nright. Now, we are at 20. 19 is lesser and left sub-tree is not empty. We have a left child. So, we will go left. Now, we are at 17, 19 is greater than 17. So, it should go in right of 17. There is no right child of 17. So, we will create a node with value 19 and\nlink it to this node with value 17 as right child. Because we are using pointers or references\nhere just like linked list, no shifting is needed like an array. Creating a link will take constant time. So, overall insertion will also cost us like\nsearch. To delete also, we will first have to search\nthe node. Search once again will be big-oh of log n\nand deleting the node will only mean adjusting some links. So, removal also is going to be like search\n- big-oh of log n in average case. Binary search tree gets unbalanced during\ninsertion and deletion. So, often during insertion and deletion, we\nrestore the balancing. There are ways to do it and we will talk about\nall of this in detail in later lessons. In next lesson, we will discuss implementation\nof binary search tree in detail. This is it for this lesson. Thanks for watching. ",
            "url": "www.youtube.com/watch?v=pYT9F8_LFTM",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "9Jry5-82I68",
            "channelId": "UCEBb1b_L6zDS3xTUrIALZOw",
            "publishedAt": "2013-01-14T20:26:48Z",
            "title": "5. Binary Search Trees, BST Sort",
            "description": "MIT 6.006 Introduction to Algorithms, Fall 2011 View the complete course: http://ocw.mit.edu/6-006F11 Instructor: Srini Devadas License: Creative Commons ...",
            "channelTitle": "MIT OpenCourseWare",
            "transcript": "The following\ncontent is provided under a Creative\nCommons license. Your support will help MIT\nOpenCourseWare continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Today's lecture\nis about a brand new data structure that you've\nprobably seen before, and we've mentioned\nearlier in double 06, called a binary search tree. We've talked about\nbinary search. It's a fundamental divide\nand conquer paradigm. There's a data structure\nassociated with it, called the BST, a\nbinary search tree. And what I want to do is\nmotivate this data structure using a problem. It's a bit of a toy problem,\nbut certainly a problem that you could imagine\nexists in all sorts of scheduling problems. It's a part of a runway\nreservation system that you can imagine building. And what I'll do is\ndefine this problem and talk about how we could\npossibly solve it with the data structures you've already seen--\nso lists and arrays, heaps as well as, which\nwe saw last time-- and hopefully motivate you into\nthe reason behind the existence of binary search\ntrees, because they are kind of the\nperfect data structure for this particular problem. So let's dive into what the\nrunway reservation system looks like. And it's your basic\nscheduling problem. We'll assume an airport\nwith a single runway. Now Logan has six runways. But the moment there's any sort\nof weather you're down to one. And of course, there's lots of\nairports with a single runway. And we can imagine that\nthis runway is pretty busy. There's obviously safety issues\nassociated with landing planes, and planes taking off. And so there are\nconstraints associated with the system, that\nhave to be obeyed. And you have to build these\nconstraints in-- and the checks for these constraints--\ninto your data structure. That's sort of the\nsummary of the context. So reservations\nfor future landings is really what this\nsystem is built for. There's a notion of time. We'll assume that\ntime is continuous. So it could be represented\nby a real variable, or a real quantity. And what we'd like to do is\nreserve requests for landings. And these are going to\nspecify landing time. Each of them is going to\nspecify a landing time. We call it t. And in particular,\nwe're going to add t to the set R of landing times if\nno other landings are scheduled within k minutes. And k is a parameter\nthat could vary. I mean, it could be statically\nset to 3 minutes, or maybe 4. You can imagine it\nvarying it dynamically depending on weather\nconditions, things like that. For the most of the examples\nwe'll talk about today, we'll assume k is 3 minutes,\nor something like that. So this is about adding\nto the data structure. And so an insert\noperation, if you will, that has a constraint associated\nwith it that you need to check. And so you wouldn't insert if\nthe constraint was violated. You would if the\nconstraint was satisfied. And time, as I\nsaid, is something that is part of the system. It needs to be modeled. You have the current\nnotion of time. And every time you have a\nplane that's already landed, which means that\nyou can essentially take this particular\nlanding time away from the set R. So this\nremoval, or delete-- we remove from set R, which is\nthe set of landing times after the plane lands. So every once in awhile,\nas time increments, you're going to be checking\nthe data structure. And you can do this, maybe,\nevery minute, every 30 seconds. That isn't really important. But you have to be able\nto remove from this data structure. So fairly straightforward\ndata structure. It's a set, R. We don't quite\nknow how to implement it yet. But we'd like to do all of these\noperations in order log n time, where n is the size of the set. All right? So any questions about that? Any questions about\nthe definition of the problem\nbefore we move on? Are we good on? OK. So let's look at a real\nstraightforward example, and put this up here so you\nget a better sense of this. Let's say that, right\nnow, we are at time 37. And the set R has\n41.2, 49, and 53 in it. And that's time. Now you may get a request\nfor landing time 53. And-- I'm sorry. I want to call this\n56.3-- 41.2, 49, and 56.3. You may get a request\nfor landing time 53. And right now the time is 37. It's in the future, and\nyou say OK because you've done the check. And let's assume\nthat k equals 3. And 53 is four ahead of 49, and\n3.3 before 56.3, so you're OK. 44 is not allowed. It's too close to 41.2. And 20, just for\ncompleteness, is not allowed because it's passed. Can't schedule in the past. I mean, it could\nbe the next day. But then you\nwouldn't call it 20. Let's assume that time is\na monotonically increasing function. You have a 64-bit number. It can go to the end\nof the world, or 2012, or wherever you want. So you can keep the\nnumber a bit smaller, and do a little constant\nfactor optimization, I guess. So that's sort of the set up. And hopefully you get a sense\nof what the requirements. And you guys know about a bunch\nof data structures already. And what I want to do is\nlist each one of them, and essentially shoot\nthem down with respect to not being able to make\nthis efficiency requirement. And I'd like you guys to\nhelp me shoot them down. So let's talk about\nan easy one first. Let's say you have an unsorted\nlist or an array corresponding to R. That's all you have. What's wrong with\nthis data structure from an efficiency standpoint? Yeah. AUDIENCE: Pretty much everything\nyou want to do to it is linear. PROFESSOR: That's exactly right. Pretty much everything you\nwant to do to it is linear. And so you want to check\nthe k minute check. You can certainly insert\ninto it, and just add to it. So that part is not linear,\nthat's constant time. But certainly,\nanything where you want to go check against\nother elements of the array, it's unsorted. You have no idea of where\nto find these elements. You have to scan\nthrough the entire array to check to see whether\nthere's a landing time that's within k of the current time\nt that you're asking for. And that's going to\ntake order n time. So you can insert in\norder 1 without a check. But sadly, the check\ntakes order n time. All right? Let's do something that is\na little more plausible. Let's talk about a sorted array. So this is a little\nmore subtle question. Let's talk about a sorted array. What happens with\na sorted array? Someone? What can you do\nwith a sorted array? Yeah. AUDIENCE: Do a binary search\nto find the [INAUDIBLE]. PROFESSOR: Binary search\nwould find a bad insert. OK, good. So that's good. So if you have a sorted array,\nand just for argument's sake, it looks like 4, 20, 32, 37, 45. And it's increasing order. And if you get a particular time\nt, you can use binary search. And let's say, in particular,\nthe time is, for example, 34. Then what you do is you go\nto the midpoint of the array, and maybe you just look at that. And you say oh, 34\nis greater than 32. So I'm going to go\ncheck and figure out if I need to move to\nthe left or the right. And since it's greater I'm\ngoing to move to the right. And within logarithmic\ntime, you'll find what we call the insertion\npoint of the sorted array, where this 34 is\nsupposed to sit. And you don't necessarily\nget to insert there. You need to look, once you've\nfound the insertion point, to your left and to your right. And do the k minute check. So finish up the\nanswer to the question, tell me how long it's going to\ntake me to find the insertion point, how long it's going\nto take me to do the check, and how long it's going\nto take me to actually do the insertion. AUDIENCE: Log n in the search-- PROFESSOR: Log n for the\nsearch, to find the point. AUDIENCE: Constant\nfor the comparison? PROFESSOR: Constant\nto the comparison. And then the last step? AUDIENCE: Do the\nresearch [INAUDIBLE]. PROFESSOR: Sorry, little louder. Sorry. AUDIENCE: The\ninsertion is constant. PROFESSOR: Insertion\nis constant? Is that right? Do you people agree with him,\nthat insertion is constant? AUDIENCE: You've got a\nmaximum size up there, right? There must be a maximum. [INAUDIBLE] PROFESSOR: No, the indices--\nso right now the array has indices i. And if you start with 1, it's\n1, 2, 3, 4, 5, et cetera. So what do you\nmean by insertion? Someone explain to me\nwhat-- yeah, go ahead. AUDIENCE: When you\nput something in you have to shift\nevery element over. PROFESSOR: That's exactly right. That's exactly right. Ok, good, that's great. I guess I should give\nyou half a cushion. But I'll do the full one, right? And you get one, too. So the point here is\nthis is pretty close. It's almost what we want. It's almost what we want. There's a little bit\nof a glitch here. We know about binary search. The binary search is\ngoing to allow us, if there's n elements\nhere, to find the place-- it's going to be able\nto find-- and I'm going to precise here-- the\nsmallest i such that R of i is greater than or equal\nto t in order log n time. It's going to be\nable to do that. You're going to be able to\ncompare R of i and R of i minus 1-- so the left\nand the right-- against t in order 1 time. But sadly, the actual insertion\nis going to require shifting. And that could take order n\ntime, because it's an array. So that's the problem. Now you could imagine that\nyou had a sorted list. And you could say, hey\nif I have a sorted list, then the list looks\nlike this, and it's got a bunch of pointers in it. And if I've found\nthe insertion point, then-- the list is nice,\nbecause you can insert something by moving pointers\nin constant time once you've found\nthe insertion point. But what's the\nproblem with the list? Yeah. AUDIENCE: You can't do\nbinary search [INAUDIBLE]. PROFESSOR: Well you can't\ndo binary search on a list. There's no notion of\ngoing to the n by 2 index and doing random access on\na conventional list, right? So the list does\none thing right, but doesn't do the\nother thing right. The array does a\ncouple things right, but doesn't do the\nshifting right. And so you see why we've\nconstructed this toy problem. It's to motivate the\nbinary search tree data structure, obviously. But you're close,\nbut not quite there. What about heaps? We talked about heaps last time. What's the basic problem with\nthe heap for this problem? The heaps are data\narrays, but you can visualize them as trees. And obviously if we're talking\nabout min heaps and max heaps. So in particular, what goes\nwrong with a min heap or a max heap for this problem? What takes a long time? Yeah. AUDIENCE: You have to scan every\nelement, which [INAUDIBLE]. PROFESSOR: That's right. I mean, sadly, you know when\nwe talk about min heaps or max heaps, they actually have\na fairly weak invariant. It turns out that-- I'm\npreviewing a bit here-- binary search\ntrees are obviously similar to heaps in the\nsense that you visualize an array as a tree,\nin the case of a heap. And binary search\ntrees are trees. But the invariant in a\nmin heap or a max heap, is this kind of\na week invariant. It essentially says,\nlook at the min element. And the min element\nhas to be the root, so you can do that one\noperation pretty quickly. But if you want to look\nfor a k minute check, you want to see if there's\nan element in the heap that is less than or equal to k,\nor greater than or equal to k from t, this is going\nto take order n time. OK? Good. And finally, we haven't\ntalked about dictionaries, but we will next week. Eric will talk about hash\ntables and dictionaries. And they have the same problem. So it's not like dictionaries\nare going to solve the problem, for those of you who know about\nhash tables and dictionaries. But you'll hear about\nthem in some detail. They're very good\nat other things. So I don't want to say much more\nabout that, because you're not supposed to know\nabout dictionaries. Or at least we\ndon't want to assume you do, though we\nhave talked about them and alluded to\ndictionaries earlier. And so that's a story here. Yeah, back there, question. AUDIENCE: Yeah, can you explain\nwhy it's [INAUDIBLE] time? PROFESSOR: So what\nis a heap, right? A heap essentially-- a\nmin heap, for example, or we talked about\nmax heaps last time, has the property that\nyou have an element k, and you're going to look\nat, let's say it's 21. Let's do min heaps, so this\nhas to be less than what's here, 23, and what\nthere, maybe it's 30, and so on and so forth. And you have a\nrecursive definition. And when you insert into a min\nheap, typically what happens is suppose you wanted to\ninsert, for argument's sake, I want to insert 25. I want to insert 25 into this. The insertion algorithm\nfor a min heap typically adds to the\nend of the min heap. So what you do is you\nwould add 25 to this. And let's say that you\nhad something out here. So you'd add to it. And you'd start flipping things. And you could work with\njust this part of the array to insert 25 in here. And you'd be able to satisfy\nthe invariant of the min heap. And you'd get a\nlegitimate min heap. But you'd never check the\nleft part of it, which is 23. So it's quite possible--\nand this is a good example-- that your basic insertion\nalgorithm, which is essentially a version of max heap\nof i, or min heap of i, would simply insert\nat the end, and keep flipping until you get\nthe min heap property, would be unable to check\nfor the k minute check during the insertion. But what you'd have to do\nis to go look elsewhere. That min heap of i\nwe'd never look at-- or the insert algorithm we'd\nnever look at-- and that would require order n time. All right? AUDIENCE: Thank you. PROFESSOR: So that's the\nstory for the min heap. Thanks for the question. And it's similar for\ndictionaries, as I said. And so we're stuck. We have no data structure yet\nthat can do all of the things that I put up on the board to\nthe left, in order log n time. And as you can see, the\nsorted array got pretty close. And so if you could\njust solve this problem, if you could do fast insertion--\nand by fast I mean order log n time-- into a sorted\narray, we'd be in business. So that's what we'd like to\ndo with binary search trees. Binary search trees\nare, as you can imagine, enable binary search. But the sorted arrays\ndon't allow fast insertion, but BSTs do. So let me introduce BSTs. As with any data\nstructure, there's a nice invariant\nassociated with BSTs. The invariant is stronger\nthan the heap invariant. And actually, that makes them\na different data structure, not necessarily a better\ndata structure. And I'll say why, but different. For this problem they're better. So one example of a binary\nsearch tree looks like this. And as a binary tree you have\na node, and we call it x. Each of the nodes\nhas a key of x. So 30 is the key for this node,\n17 for that one, et cetera. Unlike in a heap,\nyour data structure is a little more complicated. The heap is simply\nan array, and you happen to visualize\nit as a tree. The binary search\ntree is actually a tree that has\npointers, unlike a heap. So it's a more complicated\ndata structure. You need a few more bytes for\nevery node of the binary search tree, as opposed\nto the heap, which is simply an array element. And the pointers\nare parent of x. I haven't bothered\nshowing the arrows here, because you could be going\nupwards or backwards. And you could imagine\nthat you actually have a parent pointer\nthat goes up this way, and you have a child\npointer that goes this way. So there's really,\npotentially, three pointers for each node, the\nparent, the left child, and the right child. So pretty straightforward. That's the data\nstructure in terms of what it needs to have\nso you can operate on it. And there's an\ninvariant for a BST. What makes a BST\nis that you have an ordering of the\nkey values that satisfy the invariant that\nfor all nodes x if y is in the left subtree\nof x, we have-- if it's in the left\nsubtree then key of y is less than or\nequal to key of x. And if y is in the\nright subtree we have key of y is greater\nthan or equal to key of x. So if we're talking\nabout trees here, subtrees here,\neverything underneath-- and that's the stronger part\nof the invariant in the BST, versus in the heap we were just\ntalking about the children. And so you look at\nthis BST, it is a BST because if I look to\nthe right, from the root I only see values that\nare greater than 30. And if I look to the left,\nin the entire subtree, all the way down I only see\nvalues that are less than 30. And that has to be true for any\nintermediate node in the tree. And the only other\nnontrivial node here is 17. And you see that 14 is less than\n17, and 20 is greater than 17. OK? So that's the BST. That's the data structure. This is the invariant. So let's look at why BSTs\nare a possibility for solving our runway reservation problem. And what I'll do is\nI'll do the insert. So let's start with the\nnil set of elements, or null set of elements, R.\nAnd let's start inserting. So I insert 49. And all I do is make a node\nthat has a key value of 49. This one is easy. Next insert, 79. And what happens here\nis I have to look at 49, and I compare 79 to 49. And because 79 is greater\nthan 49 I go to the right and I attach 79 to\nthe right child of 49. Then I want to insert 46. And when I want to\ninsert 46 I look at this, I compare 49 and 46. 46 is less, so I go to the left\nside and I put 46 in there. Next, let's say I\nwant to insert 41. So far I haven't really talked\nabout the k minute checks. And you could imagine\nthat they're being done. I'll show you exactly, or\ntalk about exactly how they're done in a second. It's not that hard. But let me go ahead\nand do one more. For 41, 41 is less\nthan 49, so I go left. 41 is less than 46, so\nI go left and attach it to the left child. All right? So that's what I have right now. Now let's talk about\nthe k minute check. It's good to talk about\nthe K minute check when there's\nactually a violation. And let's assume\nthe k equals 3 here. And so, same thing here. You're essentially doing\nbinary search here. And you're doing the checks as\nyou're doing the binary search. So what you're\ngoing to be doing is you're going to check that--\nyou're going to compare 42 with 49, with the\nk minute check. And you realize they're 7 apart. So that's OK. And 42 is less than\n49, so you go left. And then you compare 42 with 46. And again, it's less than 46,\nbut it's k away, more than 3 away from 46. So that's cool. And you go left. And then you get to 41. And you compare 42 with 41. In this case is greater. But it's not k more than it. And so that means that if\nyou didn't have the check, you would be putting 42 in here. But because you have\nthe check, you fail. And you say, look,\nI mean this violates the safety property, violates\nthe check I need to do. And therefore I'm\nnot going to insert-- I'm not going to reserve\na request for you. All right? So what's happened here is\nit's basically a sorted array, except that you added\na bunch of pointers associated with the tree. And so it's somewhere between a\nsorted list and a sorted array. And it does exactly\nthe right thing with respect to\nbeing able to insert. Once you've found\nthe place to insert, it's merely attaching\nthis particular new node with it's appropriate\nkey to the pointer. All right? So what's happened\nhere is that if h is the height of the\ntree then insertion with or without the check\nis done in order h time. And that's what\nBSTs are good for. People buy that? Any questions about how they\nk minute check proceeded? Yeah, question. AUDIENCE: So, what's it called? The what check? PROFESSOR: The k minute check. Sorry, the k was 3 minutes k. I had this thing over\nhere, add t to the set R if no other landings are\nscheduled within k minutes. So k was just a number. I want it to be a\nparameter because it doesn't matter what k is. As long as you know what it is\nwhen you do the binary search, you can add that in to an\nargument to your insert, and do the check. AUDIENCE: OK. PROFESSOR: So in this case,\nI set k to be 3 out here. And I was doing a check\nto see that the invariant, any elements in the BST\nalready, on any nodes that had keys that were\nwithin 3 minutes-- because I fixed k to be\n3-- to the actual time that I was trying to insert. All right? AUDIENCE: So there's\nno way [INAUDIBLE]. PROFESSOR: I'm sorry,\nthere's no way? AUDIENCE: There's\nno way you could insert the 42 into\nthe tree then? PROFESSOR: Well, if\nthe basic insertion method into a binary search tree\ndoesn't have any constraints. But you can certainly\naugment the insertion method without changing the efficiency\nof the insertion method. So let's say that\nall you wanted to do was insert into a\nbinary search tree, and it had nothing to do\nwith the runway reservation. Then you would just insert\nthe way I described to you. The beauty of the\nbinary search tree is that while you're\nfinding the place to insert, you can do these checks--\nthe k minute checks. Yeah, question back there. AUDIENCE: What about 45? PROFESSOR: What about 45? So this is after-- we\nhaven't inserted 42 because it violated the check. So when you do 45,\nthen what happens is you see that\n45 is less than 49 and you pass, because you're\nmore than 3 minutes away. We'll stick with that example. And then you get\nhere and then you see that 45 is less than 46,\nand you'd fail right here. You would fail right here\nif you were doing the check, because 45 is not\n3 away from 46. All right? So that's the story. And so if you have h being\nthe height of the tree, as you can see you're\njust following a path. And depending on\nwhat the height is you're going to do\nthat many operations, times some constant factor. And so you can say that\nthis is order h time. All right? Any other questions? Yeah, question back there. AUDIENCE: In a normal\narray [INAUDIBLE]. PROFESSOR: Well, it's up to you. In a conventional binary search\ntree, or the vanilla binary search tree, typically\nwhat you're doing is you're doing\neither find or insert. And so what that means\nis that you would just return the pointer\nassociated with that element. So if you're looking for find\n46, for example, on the tree that I have out there, typically\n46 is just the key value. And there may be a record\nassociated with it. And you would get a\npointer to that record because it's already in there. At that point you can\nsay I want to override. Or if you want, you could\nhave duplicate values. You could have this,\nwhat's called a multiset. A multiset is a set that\nhas duplicate elements. In that case, you would need\na little more sophistication to differentiate between\ntwo elements that have the same key values. So you'd have to\ncall it 46a and 46b. And you'd have to have some\nway of differentiating. Any other questions? Yeah. AUDIENCE: Wouldn't\nit be a problem if the tree's not balanced? PROFESSOR: Ah, great question. Yes, stay tuned. So I was careful, right? I guess I kind of\nalluded to the fact that we'd solved the\nrunway reservation system. Did I actually say that\nwe'd solved the problem? Did I say we had\nsolved the problem? OK, so I did not lie. I did not lie. I said that the height\nof the tree was h. And I said that this was\naccomplished in order h time, right? Which is not quite what I want,\nwhich is really your question. So we'll get to that. So we're not quite done yet. But before we do\nthat, it turns out that today's lecture is\nreally part one of two. You'll get a really good\nsense of BST operations in today's lecture. But there's going to be a few\nthings that-- we can't cover all of double 6 in\nthe lecture, right? We'd like to, and let you\noff for the entire fall, but that's not the way\nit works, all right? So it's a great question. I'll answer it towards the end. I just wanted you\nto say a little bit about other operations. There's many operations that\nyou can do on a binary search tree, that can be\ndone in order h time, and some even in constant time. And I'll put these in the notes. Some of these are\nfairly straightforward. Find min can be done\nin heap, in a min heap. If you want to find the minimum\nvalue, it's constant time. You just return the root. In the case of a binary search\ntree, how do you find the min? Someone? Worth a cushion. Yep. AUDIENCE: Keep\ngoing to the left? PROFESSOR: Keep\ngoing to the left. And how do you find the max? AUDIENCE: [INAUDIBLE]. PROFESSOR: Keep\ngoing to the right. All right great, thank you. And finally, what\ncomplexity is that? I sort gave it away, but I\nwant to hear it from you. AUDIENCE: [INAUDIBLE]. PROFESSOR: Hm? AUDIENCE: It's the height PROFESSOR: It's the\nheight, order h. All right, it's\norder h complexity. Go to the left until\nyou hit a leaf, and until leaf\norder h complexity. Same thing for max. And then you can do\na bunch of things. I'll put these in the notes. You can find things\nlike next larger x, which is the next\nlargest value beyond x. And you look at the key for\nx and you say, for example, if you put 46 in there, what's\nthe next thing that's larger and that? In this tree here, it's 49. But that's something which was\ntrivially done in this example. But in general you can do\nthis in order h time as well. And you can see the pseudocode. And we'll probably cover\nthat in section tomorrow. What I want to do today, for the\nrest of the time I have left, is actually talk about augmented\nbinary search trees, which are things that can do more\nand have more data in them than just these pointers. And that's actually\nsomething which should give you a sense of the\nrichness of the binary search tree structure, this\nnotion of augmentation. And those of you, again,\nwho have taken double 05, you know about\ndesign amendments. And so specifications\nnever stay the same. I mean, you're\nworking for someone, and they never really\ntell you what they want. They might, but they\nchange their mind. So in this case, we're\ngoing to change our mind. And so we've done\nthis to the extent that we can cover all of\nthese in order h time. And let's say that now\nthe problem specification changed on us. There's an additional\nrequirement that we're asked to solve. And so you sort of\ncommitted to BST structures. But now we have an\nadditional requirement. And the new requirement is that\nwe be able to compute rank t. And rank t is how\nmany planes are scheduled to land at times\nless than or equal to t. So perfectly\nreasonable question. It wasn't part of\nthe original spec. You now have built your\nBST data structure, you thought you were done. Sorry, you aren't. You've got to do\nthis extra stuff. So that's the notion\nof augmentation, which we're going to use this\nis an example of how we're going to augment\nthe BST structure. And oh, by the way,\nI don't want you to change the\ncomplexity from order h. And we eventually will\nget to order log n, but don't go change something\nthat was logarithmic to linear. That would be bad. So let's talk about\nhow you do this. And I don't think we\nneed this anymore. So the first thing we need to\ndo is add a little bit more information to the\nnode structure. And what we're going to do\nis augment the BST structure. And we're going to add one\nlittle number associated with each node, that looks at\nthe number of nodes below it. So in particular,\nlet's say that I have 49, 46, let's just\nsay 49, 46 for now. And over here I\nhave 79, 64, and 83. I'm going to modify--\nI'm going to have an extra number associated\nwith each of these nodes. And I'm just going\nto write that number on the outside of the node. And you can just imagine\nthat now the key value has two numbers associated\nwith it-- the thing that I write inside the node,\nand what I write outside of it. So in particular, when\nI do insert or delete I'm going to be\nmodifying these numbers. And these are size numbers. And what do I mean by that? Well these numbers\ncorrespond to subtree sizes. So the subtree size\nhere is 1, 1, 1. So as I'm building\nthis tree up I'm going to create an\naugmented BST structure, and I've modified\ninsert and delete so they do some extra work. So let's say, for\nargument's sake, that I've added this in\nsort of a bottom up fashion. And what I have are these\nparticular subtree sizes. All of these should make sense. This has just a single\nnode, same thing here. So this subtree sizes associated\nwith these nodes are all 1. The subtree size\nassociated with 79 is 3, because you're\ncounting 79 and 64 and 83. And the subtree size\nassociated with 49 is 5, because you're counting\neverything underneath it. How did we get these numbers? Well you want to\nthink about this as you started\nwith an empty set, and you kept inserting into it. And you were doing a sequence\nof insert and delete operations. And if I explain to you how\nan insert operation modifies these numbers, that is\npretty much all you need. And of course, analogously,\nfor a delete operation. So what would happen for, let's\nsay you wanted to insert 43? You would insert\n43 at this point. And what you'd do is you\nfollow the insertion path just like you did before. But when you're\nfollowing that path you're going to increment the\nnodes that you're seeing by 1. So you're going\nto add 43 to this. And you'd add 5 plus\n1, because you see 49. And then you would go\ndown and you'd see 46. And so you'd add 1 to that. And then finally,\nyou add 43 and you assign-- since\nit's a leaf-- you'd assign to value corresponding\nto the subtree size of this new node that you\nput in there, to be 1. It guess a little, teensy\nbit more complicated when you want to do\nthe k minute check. But from a complexity\nstandpoint, if you're not worried\nabout constant factors, you can just say, you know what? I'm going to first run\nthe regular insert, ignoring the subtree sizes. And if it fails, I'm done. Because I'm not going to\nmodify the BST, and I'm done. I'm not going to have to\nmodify the subtree sizes. If it succeeds, then\nI'm going to go in, and I know now that I can\nincrement each of these nodes, because I know I'm\ngoing to be successful. So that's sort of a trivial\nway of solving this problem, that from an asymptotic\ncomplexity standpoint gives you your order\nh augmented insert. That make sense? Now you could do something\nbetter than that. I mean, I would urge you,\nif you had wrote something that-- we asked you to\nwrite something like this, to create a single procedure\nthat essentially uses a recursion appropriately to\ndo the right thing in one pass through the BST. And we'll talk about\nthings like that as we go along in sections,\nand possibly in lectures. So that's the subtree\ninsert delete. Everyone buy that? Yeah, question back there. AUDIENCE: If I wanted to delete\na number, like let's say 79-- PROFESSOR: Yep? AUDIENCE: --would we\nhave to take it out and then rewrite the entire BST? PROFESSOR: What you'd have to\ndo is a bubble up pointers. So you'd have to actually\nhave 64 connected to-- what will happen is 83\nwould actually come up, and you would essentially\nhave some thing-- this is not quite how it works--\nbut 83 would move up and you'd have 64 to the left. That's what would happened\nfor delete in this case. So you would have to move\npointers in the case of delete. And we're not done with\nbinary search tree operations from a standpoint of\nteaching you about them. We'll talk about them not\njust in today's lecture, but later as well. So there's one\nthing missing here, though, which is I haven't\nquite figured out-- I've told you how these\nsubtree sizes work. But it's not\ncompletely clear, this is the last thing we have\nto do, is how are you going to compute rank t\nfrom the subtree sizes? So everyone understand\nsubtree sizes? It's just the number of nodes\nthat are underneath you. And you remember to count\nyourself, all right? Now what is rank t? Rank t is how many\nplanes are scheduled to land at times less\nthan or equal to t. So now I have a BST structure\nthat looks like the one and I just ended up with. So I've added this 43. And so let me draw\nthat out here, and see if we can\nanswer this question. This is a subtle question. So I got 49, and that\nsubtree size is 6. I got 46, subtree size is 2. 43, 79, 64. and 83. So what I want is\nwhat lands before t? And how do I do that? Give me an algorithm\nthat would allow me to compute in order h time. I want to do this\nin order h time. What lands before t? Someone? Yeah. AUDIENCE: So first\nyou would have to find where to insert\nit, like we did before. PROFESSOR: Right, right. AUDIENCE: And then because we\nhave the order of whatever it was before-- not\nthe order, the-- PROFESSOR: The sizes? The sizes? Yeah. AUDIENCE: And then we can\nlook what's more than it on the right, we can\nsubtract it and we get-- PROFESSOR: What is more\nthan it on the right. Do you want to say-- AUDIENCE: Because, like-- PROFESSOR: OK. AUDIENCE: --on the right-- PROFESSOR: Right. AUDIENCE: --and then we\ncan take this minus this and we get what's left. PROFESSOR: That's\ngreat, that's excellent. Excellent. So I'm going to do it a little\nbit differently from what you described. I'm going to\nactually do it in a, sort of, a more positive\nway, no offense intended. What we're going to\ndo is we're going to add up the things\nthat we want to add up. And what you have\nto do is walk-- your first step was right on. I mean, your answer is correct. I'm just going to do it\na little bit differently. You walk down the tree\nto find the desired time. This is just your search. We know how to do that. As you walk down you\nadd in the nodes that is the subtree sizes-- you're\njust adding in the notes here. So if you see-- depending\non the number of nodes that you see as you're\ngoing deeper in, you want to add in the nodes. And you're going to add\none to that, corresponding to the nodes that are smaller. And we're going to add in the\nsubtree sizes to the left, as opposed to subtracting. That may not make\na lot of sense. But I guarantee you it\nwill once we do an example. So what's going on here? I want to find a\nplace to insert. I'm not actually going\nto do the insert. Think of it is doing a lookup. And along the way,\nI need to figure out the less than operator. I want to find all\nof the things that are less than this\nvalue I'm searching for. And so I have to do\na bit of arithmetic. So let's say that I'm\nlooking for what's less than or equal to 79. So t equals 79. So I'm going to look at 49. I'm going to walk down,\nI'm going to look at 49. And because I say I'm\nlooking at 49-- and 49 is clearly less than 79. So I'm going to add 1. And that's this check over here. I move on and what I need to\ndo now is move to the right, because 79 is greater than 49. That's how my search would work. But because I've\nmoved to the right, I'm going to add the subtree\nsizes that were to the left. Because I know that all\nof the things to the left are clearly less than 79. So I'm going to add 2,\ncorresponding to a subtree 46. So I'm not actually\nlooking there. But I'm going to add\nall of that stuff in. I'm going to move to the right,\nand now I'm going to see 79. At this point 79 is less\nthan or equal to 79. So I'm going to see 79\nand I'm going to add 1. And because I've added 79,\njust like I did with 49, I have to add the subtree\nsize to the left of 79. So the final addition\nis I add 1 corresponding to the subtree 64. And at this point\nI've discovered where I have to insert, I've\nessentially found the location, it matches 79. And there was no modification\nrequired in this algorithm. So if that was 78 you'd\nessentially do the same things. But you're done because you\nfound the value, or the place that you want to insert. And you've done a\nbunch of additions. And you go look at add 1, add\n2, add 1, add 1, and you have 5. And that's the\ncorrect answer, as you can see from this example. So what's the bad news? The bad news was what\nthis lady said up front, which was we haven't\nquite solved the problem. Because sadly, I could\neasily set things up such that the height h is\norder n, h could be order n. And if, for example, I\ngave you a sorted list, and I said insert into\nbinary search tree that's originally null 43,\nand you put 43 in there. Then I say insert 46. And then I say instead of 48. And then I say\ninsert 49, et cetera. And, you know, these\ncould be any numbers. Then you see that what\ndoes this look like? Does it look like a tree? It looks like a list. That's the bad news. And I'll let Eric give\nyou good news next week. We need to have this notion of\nbalanced binary search trees. So everything I've said is true. I did not lie. But the one extra\nthing is we need to make sure these trees are\nbalanced so h is order log n. And then everything\nI said works. All right? See you next time. ",
            "url": "www.youtube.com/watch?v=9Jry5-82I68",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "ovWqEgYYAEQ",
            "channelId": "UCNsGQ_oLlH89HoKd5uyoAEQ",
            "publishedAt": "2019-04-02T19:41:50Z",
            "title": "Binary Search Tree",
            "description": "Video 64 of a series explaining the basic concepts of Data Structures and Algorithms. This video introduces the concept of binary search tree. This video is ...",
            "channelTitle": "Lalitha Natraj",
            "transcript": "binary search tree a binary search tree is a binary tree in which for every node the left child of that node is going to be less than the node and the right child of that node is going to be greater than that node so to properly understand this let's take an example of a binary search tree so this is going to be an example of a binary search tree as you can see for every node let's take a node 3 the left child 1 is less than 3 and the right child 5 is going to be greater than 3 let's take another node 1 the left child 0 is less than 1 and the right child 1 is greater than 1 for the node 5 the left child 4 is less than 5 and the right child 6 is going to be greater than 5 so if this property holds for every node in the binary tree it's known as a binary search tree so what is so special about a binary search tree its speciality lies in the fact that the inorder traversal of this binary tree is going to result in the sorted order of these elements so the inorder traversal is going to result in the sorted list of elements let's look at this and see how it works so what is the inorder traversal state first we must see the left subtree or we must traverse the left subtree then we must traverse the root and finally we must traverse the right subtree so this is going to be the order of in order traversal so let's start traversing this tree so I have a root 3 I have a left subtree and a right subtree I first go to the left subtree I have a root 1 I have a left subtree and right subtree so i go to the left subtree and print it out because it's a leaf node and there are no left or right subtrees to a leaf node so I've printed out the left subtree of 1 now I print 1 which is the root of this left subtree then I print out the right subtree of 1 which is going to be 2 now the left subtree of tree of 3 has been completely traversed so now I can print out 3 the 3 now that I have printed out the left sub three of three the root three itself and now I have to go to the right subtree of three so I have this subtree I'll go to the left subtree again I will print it out because it's a leaf element then I will print out the root which is five then I will print out the right subtree of five which is 6 now that I have printed out the left subtree of three three itself and the right subtree of three i can say that this tree which is rooted at element 3 is going to be completely traversed as you see the inorder traversal is going to return the sorted order of these elements another important property of a binary search tree is that it is easy to search for elements in a binary search tree suppose I want to search for element 2 I start at the root will I search for 2 in the left subtree of 3 or the right subtree of 3 definitely I will search for 2 somewhere in the left subtree of 3 because it is going to be less than 3 so in this way we can keep minimizing our range of search using a binary search tree in this topic of binary search trees we are going to take a look at three algorithms we will take a look at the searching algorithm then we will see how to insert elements into a binary search tree we will also see how we are going to delete elements from this binary search tree so in the following videos we will learn these three algorithms and see how they work and with that we will get a comprehensive understanding of what a binary search tree is and how it works ",
            "url": "www.youtube.com/watch?v=ovWqEgYYAEQ",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "H5JubkIy_p8",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2014-01-18T06:08:28Z",
            "title": "Data structures: Binary Tree",
            "description": "In this lesson, we have discussed binary tree in detail. We have talked about different types of binary tree like \"complete binary tree\", \"perfect binary tree\" and ...",
            "channelTitle": "mycodeschool",
            "transcript": "In our previous lesson, we introduced you\nto tree data structure. We discussed tree as a logical model and talked\nbriefly about some of the applications of tree. Now, in this lesson we will talk a little\nbit more about binary trees. As we had seen in our previous lesson, binary\ntree is a tree with this property that each node in the tree can have at most 2 children. We will fist talk about some general properties\nof binary tree and then we can discuss some special kind of binary trees like binary search\ntree which is a really efficient structure for storing ordered data. In a binary tree as we were saying, each node\ncan have at most 2 children. In this tree that I have drawn here, nodes\nhave either 0 or 2 children. We could have a node with just one child. I have added one more node here and now we\nhave a node with just one child. Because each node in a binary tree can have\nat most 2 children, we call one of the children left child and another right child. For the root node, this particular node is\nleft child and this one is right child. A node may have both left and right child. These 4 nodes have both left and right child\nor a node can have either of left and right child. This one has got a left child, but has not\ngot right child. I'll add one more node here. Now this node has a right child, but does\nnot have a left child. In a program, we would set the reference or\npointer to left child as NULL. So, we can say that for this node left child\nis NULL and similarly for this node, we can say that the right child is NULL. For all the other nodes that do not have children,\nthat are leaf nodes, a node with 0 child is called leaf node. For all these nodes, we can say that both\nleft and right child are NULL. Based on properties, we classify binary trees\ninto different types. I'll draw some more binary trees here. If a tree has just one node, then also its\na binary tree. This structure is also a binary tree. This is also a binary tree. Remember, the only condition is that a node\ncannot have more than 2 children. A binary tree is called strict binary tree\nor proper binary tree if each node can have either 2 or 0 children. This tree that I am showing here is not a\nstrict binary tree because we have 2 nodes that have one child. I'll get rid of 2 nodes and now this is a\nstrict binary tree. We call a binary tree complete binary tree\nif all levels except possibly the last level are completely filled and all nodes are as\nfar left as possible. All levels except possibly the last level\nwill anyway be filled. So, the nodes at the last level, if its not\nfilled completely must be as far left as possible. Right now this tree is not a complete binary\ntree. Nodes at same depth can be called nodes at\nsame level. Root node in a tree has depth 0. Depth of a node is defined as length of path\nfrom root to that nodes. In this figure lets say nodes at depth 0 are\nnodes at level 0. I can simply say L-0 for level 0. Now, these two nodes are at level 1, these\n4 nodes are at level 2 and finally these 2 nodes are at level 3. The maximum depth of any node in the tree\nis 3. Maximum depth of a tree is also equal to height\nof the tree. if we will go numbering all the levels in\nthe tree like L-0, L-1, L-2 and so on, then the maximum number of nodes that we can have\nat some level i, will be equal to 2 to the power i. At level 0, we can have 1 node, 2 to the power\n0 is 1. Then at level 1, we can have at max 2 nodes. At level 2 , we can have 2 to the power 2\nnodes at max which is 4. So, in general at any level i, we can have\nat max 2 to the power i nodes. You should be able to see this very clearly. Because each node can have 2 children, so\nif we have x nodes at a level, then each of these x nodes can have 2 children. So, at next level, we can have at most 2x\nchildren. Here in this binary tree, we have 4 nodes\nat level 2 which is the maximum for level 2. Now, each of these nodes can possibly have\n2 children. I am just drawing the arrows here. So, at level 3, we can have max 2 times 4\ni.e 8 nodes. Now, for a complete binary tree, all the levels\nhave to be completely filled. We can give exception to the last level or\ndeepest level. It doesn't have to be full. But the nodes have to be as left as possible. This particular tree that I am showing here\nis not a complete binary tree because we have 2 vacant node positions in left here. I'll do slight change in this structure. Now this is a complete binary tree. We can have more nodes at level 3, but there\nshould not be a vacant position left. I have added one more node here and this still\nis a complete binary tree. if all the levels are completely filled, such\na binary tree can also be called perfect binary tree. In a perfect binary tree, all levels will\nbe completely filled. If h is the height of a perfect binary tree,\nremember height of a binary tree is length of longest path between root to any of the\nleaf nodes or i should say number of edges in longest path from root to any of the leaf\nnodes. Height of a binary tree will also be equal\nto max depth, Here, for this binary tree, max depth is 3. Maximum number of nodes in a tree with height\nh will be equal to, we will have 2 to the power 0 nodes at level 0, 2 to the power 1\nnodes at level 1 and we'll go on summing for height h, we will go till 2 to the power h. At deepest level, we will have 2 to the power\nh nodes. Now this will be equal to 2 to the power h\nplus 1 minus 1. h+1 is number of levels here. We can say that 2 to the power number of levels\nminus 1. In this tree, number of levels is 4. We have L0 till L3. So, number of nodes, maximum number of nodes\nwill be 2 to the power 4 minus 1 which is 15. So, a perfect binary tree will have maximum\nnumber of nodes possible for a height because all levels will be completely filled. Well, I should say maximum number of nodes\nin a binary tree with height h. Ok, I can ask you this also. What will be height of a perfect binary tree\nwith N nodes. Lets say N is number of nodes in a perfect\nbinary tree. To find out height, we'll have to solve this\nequation n = 2^h+1 - 1 because if height is h, number of nodes will be 2 to the power\n(h+1) minus 1. We can solve this equation and the result\nwill be this. Remember n is number of nodes here. I'll leave the maths for you to understand. Height will be equal to log (n+1) to the base\n2 minus 1. In this perfect binary tree that I am showing\nhere, number of nodes is 15. So, n is 15. (n+1) will be 16. So, h will be log 16 to the base 2 minus 1. log 16 to the base 2 will be 4. So, the final value will be 4-1 equal 3. In general, for a complete binary tree, we\ncan also calculate height as floor of log n to the base 2. So, we need to take integral part of log n\nto the base 2. Perfect binary tree is also a complete binary\ntree. Here n is 15. log of 15 to base 2 is 3.906891. if we'll\ntake the integral part, then this will be 3. I'll not go into proof of how height of complete\nbinary tree will be log n to the base 2. We'll try to see that later. All this maths will be really helpful when\nwe will analyze cost of various operations on binary tree. Cost of a lot of operations on tree in terms\nof time depends upon the height of tree. For example, in binary search tree which is\na special kind of binary tree, the cost of searching, inserting or removing an element\nin terms of time is proportional to the height of tree. So, in such case we would want the height\nof the tree to be less. Height of a tree will be less if the tree\nwill be dense, If the tree will be close to a perfect binary tree or a complete binary\ntree. Minimum height of a tree with n nodes can\nbe log n to the base 2 when the tree will be a complete binary tree. if we will have an arrangement like this,\nthen the tree will have maximum height. With n nodes, minimum height possible is floor\nof or integral part of log n to the base 2 and maximum height possible with n nodes in\nn-1 when we will have a sparse tree like this which is as good as a linked list. Now, think about this. If I'm saying that time taken for an operation\nis proportional to height of the tree or in other words I can say that if time complexity\nof an operation is big-oh of h where h is height of the binary tree, then for a complete\nor perfect binary tree, my time complexity will be big-oh of log n to the base 2 and\nin worst case for this sparse tree, my time complexity will be big-oh of n. Order of log n is almost best running time\npossible. For n as high as 2 to the power 100, log n\nto the base 2 is just 100. With order of n running time, if n will be\n2 to the power 100, we won't be able to finish our computation in years even with most powerful\nmachines ever made. So, here is the thing. Quite often, we want to keep the height of\na binary tree minimum possible or most commonly, we say that we try to keep a binary tree balanced. We call a binary tree balanced binary tree,\nif for each node, the difference between height of left and right sub-tree is not more than\nsome number k. Mostly k would be 1. So, we can say that for each node, difference\nbetween height of left and right sub-tree should not be more than 1. There is something that I want to talk about\nheight of a tree. We had defined height earlier as number of\nedges in longest path from root to a leaf. Height of a tree with just one node where\nthe node itself will be a leaf node will be 0. We can define an empty tree as a tree with\nno node and we can say that height of an empty tree is -1. So, height of tree with just one node is 0\nand height of an empty tree is -1. Quite often, people calculate height as number\nof nodes in longest path from root to a leaf. In this figure, I have drawn one of the longest\npaths from root to a leaf. We have 3 edges in this path. So, the height is 3. If we will count number of nodes in the path,\nheight will be 4. This looks very intuitive and I have seen\nthis definition of height at lot of places. if we will count the nodes, height of tree\nwith just one node will be equal to 1 and then we can say that height of an empty tree\nwill be 0, but this is not the correct definition and we are not going to use this assumption. We are going to say that height of an empty\ntree is -1 and height of tree with one node is 0. The difference between heights of left and\nright sub-trees of a node can be calculated as absolute value of height of left subtree\nminus height of right subtree and in this calculation, height of a sub-tree can be -1\nalso. For this leaf node here in this figure, both\nleft and right sub-trees are empty, so both hleft or height of left sub-tree and hright\nor height of right sub-tree will be -1, but the difference overall will be 0. For all nodes in a perfect tree, difference\nwill be 0. I have got rid of some nodes in this tree\nand now by the side of each node, I have written the value of diff. This is still a balanced binary tree because\nthe maximum diff for any node is 1. Lets get rid of some more nodes in this tree\nand now this is not balanced because one of the nodes has diff 2. For this particular node, height of left sub-tree\nis 1 and height of right sub-tree is -1 because right sub-tree is empty. So, the absolute value of difference is 2. We try to keep a tree balanced to make sure\nits dense and its height is minimized. If height is minimized, cost of various operations\nthat depend upon height are minimized. Ok, the next thing that I want to talk about\nvery briefly is how we can store binary trees in memory. One of the ways that we had seen in our previous\nlesson which is most commonly used is dynamically created nodes linked to each other using pointers\nor references. For a binary tree of integers, in C or C++,\nwe can define node like this - data type here is integer, so we have a field to store data\nand we have two pointer variables, one to store address of left child and another to\nstore address of right child. This of course is the most common way. Nodes dynamically created at random locations\nin memory linked together through pointers, but in some special cases, we use arrays also. Arrays are typically used for complete binary\ntrees. I have drawn a perfect binary tree here. Lets say this is a tree of integers. What we can do is, we can number these nodes\nfrom 0 starting at root and going level by level from left to right. So, we will go like 0, 1 , 2 , 3 , 4, 5 and\n6. Now, I can create an array of 7 integers and\nthese numbers can used as indices for these nodes. So, at 0th position, I'll fill 2, at 1th position\nI'll fill 4, at 2th position, we will have 1 and I'll go on like this. We have filled in all the data in the array,\nbut how will we store that information about the links. How will we know that the left child of root\nhas value 4 and the right child of root has value 1? Well, in case of complete binary tree, if\nwe will number the nodes like this that for a node at index i, the index of left child\nwill be 2*i+1 and the index of right child will be 2i+2 and remember this is true only\nfor a complete binary tree. For 0, left child is - 2i+1 for i = 0 will\nbe 1 and 2i+2 will be 2. Now, for 1, left child is at index 3, right\nchild is at index 4. For i =2, 2i+1 will be 5 and 2i+2 will be\n6. We will discuss array implementation in detail\nwhen we will talk about a special kind of binary tree called heap. Arrays are used to implement heaps. I'll stop here now. In our next lesson, we will talk about binary\nsearch tree which is also a special kind of binary tree that gives us a really efficient\nstoring structure in which we can search something quickly as well as update it quickly. This is it for this lesson. Thanks for watching !! ",
            "url": "www.youtube.com/watch?v=H5JubkIy_p8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "i_Q0v_Ct5lY",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:18Z",
            "title": "Data Structures: Binary Search Tree",
            "description": "Learn how to detect if a tree is a valid binary search tree. This video is a part of HackerRank's Cracking The Coding Interview Tutorial with Gayle Laakmann ...",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. Today we're going to talk about detecting if a tree is\nactually valid binary search tree. A binary search tree, as you may recall, is a\nbinary tree so it has a left on right node, but it's one where all the nodes on the\nleft, for any given node, all the nodes on its left are smaller than it and all the\nnodes on the right are bigger than it. So we want to check to make sure the binary\ntree is actually a binary search tree, and so that means checking to make sure that\nordering property is true. So one approach that a lot of people take that is\nactually mistaken is they think okay I'll just walk through my tree and check to\nmake sure for any given node, compare it to the left node and compare it to the right node\nand see if it's in the right order. So is the left node smaller than the\ncurrent node and smaller than right? And the problem with that is that even if\nthat's true it may not be a valid binary search tree because there could be\nsomething else underneath it that's bigger than the parent. So for any\ngiven route, maybe it's grandchild is actually bigger\nthan it and maybe its left grandchild is actually bigger than it. So that won't actually\nwork. Another approach that is correct but slow\nis, we can say okay, all the nodes on the left must be smaller than all of the nodes on the right, so take each node, get the biggest node on left, compare it to this node,\nget the smallest node on the right, compare it to that node. That'll work but is pretty inefficient.\nThese get min and get max operations require walking through that whole\ntree so that's going to actually get very very slow. A faster way is we can flip\naround this logic. We can say okay, in the very beginning our route is valid, the root can be anything in the entire world. But when we go to the left we're going to walk through all its\nchildren and we'll go to the left everything on the left has to be between\nthe integer minimum and the root value. And everything on the right has to be between\nthe root value and the integer maximum. Ok so now let's go to the left. Well that, you know, we'll check to make sure, hey, is that node on the left, is that within those values? Great it is, ok\nkeep going. Now we're going to go to the right side of\nthat. All those values must be between that left node's value and that\nroot node's value. So we're going to pass around these ranges of min and\nmax and say, at any given point are you within that min and max\nrange. So that's how we tackle this problem. Okay so what we need for this method actually is \nwe need check BST to take in a min and max value, and this initial node is going\nto just take in and pass an integer dot min. So initially the root can be any value\nat all actually. Now I'm going to make sure, I'm going to specify\nhere, that these are inclusive ranges. Ok so in the very beginning first I want to do, so I want to check to make\nsure my route is in the right value. So if it's smaller than my min or if its bigger\nthan my max return false. I also want to be careful of, I need a\nbase case here, so if root is null then return true. Otherwise go left or right.\nSo check my left and right. Route dot left. And I'm gonna come back to what\nthese ranges are in a second. So check the left and check the right. If both are valid and then its valid. Ok that's the\nbasic logic. Now initially, so my route can be inbetween min and max. If I\ngo to the left of my route anything down there can still be a small as the min, but it\ncannot be any bigger than the route. And in fact it can't even be equal\nto the route because we actually do not have duplicates in this tree, and so the\nbiggest, so my values on the left of my root can be anywhere between min at the\nsmallest and one smaller than the route. When I go to the right, things can be at\nleast, or they have to be at least as big as route, actually 1 bigger, and they can be up to that max value. Now let's run this and see what happens. Perfect. It worked so we can do a, throw in more test cases if we want. But\nlet's remember, let's walk through what this does. So this basically flips around our initial\nlogic. What we're going to do is pass these ever-shrinking min and max values, so the\nlogic is basically route had to be somewhere between min and max. If we go to the left we've now shrunk the biggest those\nvalues can be. They can be between that old minimum and route. If we go to the right\nthen they can be still as big as that max, but they can't, but they have to be at\nleast as big as route. Now you want to be very careful on any recursive\nproblems to pay extra close attention there to the base cases because that's\na really really easy thing to mix up. One thing I always check for in a recursive\nproblem is if I'm returning a boolean, I definitely want to make sure that I have\nsome sort of return true and some sort of return false statement somewhere,\nbecause it's obviously if I only have a return false statement how would I ever get anything other than\nfalse. So that's just a quick little sanity check to do. So, that's that's how we\ntackle this problem. The efficiency of this problem, this solution is actually really nice. We\nactually have a a linear-time solution, and we know since\nwe have to touch every single node in the tree we can't do any better than\nthat. So this is pretty close to as\noptimal as we can get. And the space complexity by the way of this problem is\ngoing to be if its a balanced tree, it's going to be log n because of that\nrecursive complexity. So now that you've seen this problem, why don't you\ntry this again on your own or check out some new binary search tree problems. Good luck. ",
            "url": "www.youtube.com/watch?v=i_Q0v_Ct5lY",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "oSWTXtMglKE",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:18Z",
            "title": "Data Structures: Trees",
            "description": "Learn the basics of trees, data structures. This video is a part of HackerRank's Cracking The Coding Interview Tutorial with Gayle Laakmann McDowell.",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. In this video I'm going to cover trees. A tree is best\nthought of in this sort of picture. You have a root node at the very top and it\nhas child notes and each of those child nodes, they have child nodes themselves,\nand so on and so on. Very often when we're talking about trees we talk about binary trees. A binary tree means that each node has no more than\ntwo child nodes. That is that each node has a left node and a right node. Of\ncourse one or both of those could also be null. Very often when we're talking\nabout binary trees we actually want to talk about binary search trees. A binary\nsearch tree is a binary tree which fulfills a specific ordering property. So\non any subtree the left nodes are less than the root node which is less than\nall of the right nodes. This ordering property makes finding a node very very\nfast because we have a pretty good idea of where it would be. So suppose we're\nlooking for 17 in this tree We can say okay, is 17 bigger or smaller than the\nroot node? Well it's bigger than the root node so let's go to\nthe right. Now is it bigger or smaller than that next node there? Well it's smaller than that node so it must\nbe on the left of it. And so very very quickly we can start to zoom in on where\nthat node will be because at each operation we've chopped off hopefully\nabout half of the nodes and we do that over and over again and very very\nquickly we find the node we're looking for. So it makes finds very very fast. But how do\nthose elements get in there in the first place? Well let's talk about how inserts work.\nInserts work much like finding an element works. We start with some element we want to insert like say, 19, and we say is it bigger or smaller than the route? Well its bigger so let's go to the right. Now is it bigger or smaller than that that next\nnode? It's smaller so let's go to the left. I would do this over and over again until we\nget to an empty spot or a null node and then we say ok that's where we should insert\nour new element. Now the one problem here is that if we get elements in a particular order, we could get really\nimbalanced. Suppose we have a new binary search tree and we just follow the\nproperties of insertion. So we insert one and then 2 to it's right and then 3 to it's\nright and 4 to it's right, we're going to get this data structure that looks\nless like a tree and more like a long list. And then inserts and fines will no\nlonger be so fast. There are some algorithms that can ensure that our tree\nstays balanced, that is that roughly the same number of nodes will be on the left\nside the subtree and on the right. These algorithms get pretty complicated so we're not gonna go into the details here, but it's worth knowing that they're\nbuilt into a lot of programming languages and in a lot of cases and\ninterview questions you'll just assume that you have a balanced tree. The last\noperation to talk about is traversing or walking through a tree. So there's three\ncommon ways we walk through a tree we can do an inorder traversal, a preorder traversal, or a postorder traversal. A preorder traversal means that you visit\nthe root first and then you visit its left nodes and it's right nodes. In an inorder traversal you visit the left nodes first then the current node and then you\ngo to the right nodes. In a postorder traversal, the root node comes up last so\nyou visit the left nodes and then the right nodes, then the current root node.\nTypically in binary search trees we want to do inorder traversals because\nthat actually allows the nodes to be printed in order. So for example on this\ntree here with just a 1, a 2, and a 3, the nodes in an in order traversal\nwill actually be printed out in the order one then two then three. So typically we'll see inorder traversals.\nNow that we've covered the basic operations let's take a look at the code for binary\nsearch tree. To implement a binary search tree we'll need a class node that has\npointers to the left node and the right node and then some sort of data\npresumably, and I'm going to give ourselves a constructor just to make our\nlives a little bit easier. Ok so the first method I'm going to add\nis an insert method. And this is going to take in, I'm gonna call ot value here. This\nis going to take in a node, take in a node value and look to the left and the\nright to see where we want to insert it. So first if value is less than or equal to\nthe actual data of our node then we should insert it on the left side. If\nthere is no left node yet then this becomes my new node. Otherwise then I\nasked my left to insert it and I push that down the recursion stack. And then\notherwise if value is bigger than data than myself then it should be inserted\non the right side and so if there is no right node put this as my right\nnode, otherwise ask my right to insert it. That's the basics of insert. Ok so\nlet's walk through this code on an example. So we have the simple tree and\nwe want to insert the value eight, so we call 10 dot insert of 8 and 8 is\nsmaller than 10, so we go to the left and we call it left dot insert of 8, so 5 dot insert\nof 8, 8 is bigger than 5 so we go and we don't have a right child and so we\nset 5's right child equal to 8. The next method I'll do is find. So find is\ngoing to operate recursively just like insert, in fact will be somewhat similar\nin a lot of ways. And it's going to want to return a boolean. And actually I'm gonna call\nthis contains because we're not really finding the nodes as much as checking if\nthe tree contains it. Ok, so first of all, if I'm there, return true, otherwise if\nvalue is smaller than data that it should be on the left side, if there is\nno left node then I know the answer is false. Otherwise if there is a left node\ngo ask my left node what the answer is. Ok now I do the same thing on the right.\nIf, actually I can just do an else,  if right is null or if there is no right node the\nanswer is false, otherwise go ask my right child and return its answer. Alright so that's the recursive\nimplementation of contains. So let's walk through this function and imagine we're\ntrying to find the value 8 that we just inserted. So we call 10 dot contains\nof 8, 8  is smaller than 10, so go to the left, and then we do 5 dot contains of\n8, 5 is smaller than 8, and so we go to the right, and then of course we see that\n8 in fact equals 8 and so we return true all the way up the stack. The final method that we'll implement is an inorder traversal. Specifically I'm going to print all of the nodes in the tree. So\nI just call this print in order and this is actually very simple. First if my, if I have a\nleft child then I do my in order printing first of my left child. Then I\nprint my own data and then same thing on the right. If right is not null, then I do right dot\nprint in order. So remember that inorder traversals do the left child, myself, and\nthen my right child. That's exactly what the code here does. So that's how you do an inorder printing. So let's walk through what this code does. So we're going to first\ncall 10 dot print inorder. Ten's gonna say left dot print in order\nfirst, that's the very first thing that's gonna\nhappen. Then we're going to print the root and then it's going to say right dot\nprint in order so we're going to recurse down. And 5, so we get 5 dot print in\norder. Five is going to say, ok print, but we got nothing on the left to print, so print me\nnext and then call right dot print in order where 8 will get printed. And\nthen we're going to go back up to 10 and 10 is going to get printed, and then\nwe're going to go and go down to the right in that third step and print 15. So\nthat's how an in order traversal works. If we want to do a pre or post order\ntraversal we do a very very similar things just in a slightly different order, a\npre-order traversal means that the root gets printed first. So we'd print the route,\nthen print the left subtree, then print the right. In a postorder traversal the\nroot gets printed last, so we'd print the left, then print the right, and then we\nprint the root node. So it's a pretty natural translation of the algorithmic\nconcepts. A lot of times in interviews people get kind of intimidated by the\nidea of implementing a binary search tree. They just assume it's something really challenging. But if you understand the\nconcept pretty well you can just take that and just translate it fairly\ndirectly into the code, just be really careful about the null pointer checks.\nSo now that we've gone through the basic operations why don't you try out these\nconcepts on a new problem. Good luck. ",
            "url": "www.youtube.com/watch?v=oSWTXtMglKE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "GzJoqJO1zdI",
            "channelId": "UCRLEADhMcb8WUdnQ5_Alk7g",
            "publishedAt": "2020-10-22T15:30:03Z",
            "title": "Binary Trees - Data Structures Explained",
            "description": "#data #structures #trees.",
            "channelTitle": "Aaron Jack",
            "transcript": "how's it going everyone this is a free video from the coding interview course that i released earlier this year interview espresso this one's about binary trees i hope you enjoy it and if you want to check out my course there's a ton more videos like this one [Music] welcome to the next overview video in this one we're saying goodbye to the linked list and hello to the binary tree we can think of a linked list as the shallow end of data structures when there's a whole ocean out there in fact both the linked list and the binary tree are part of a family of node-based data structures by now we're quite familiar with creating list nodes with a value property and setting their next pointer you might be surprised to hear this but a ton of data structures have these very same components that is a node containing a value property and one or more pointers so think of nodes as the bricks that we're using to build different quite literally structures so within the broad category of node-based data structures we have everything from graphs which can represent cities and the paths between them and taking this a step further we can think of getting from point a to b in any navigation service as following a pointer from node a to node b and then we also have trees which are different because they're hierarchical that means nodes branch out in one direction with multiple pointers going from top to bottom most trees look more like a pyramid than a tree but if you squint you can see the tree if you flip it upside down let's get more precise trees expand in one direction so that means no cycles they're also made up of parents and children these are relative terms for nodes and describe where they're located in relation to each other and relative here means every parent can also be a child just think of a family tree so here the node with value 1 would be a child of node 3 and a parent of nodes 2 and 5. the one hard rule for trees is that every node can only have one parent but it can have many children so just think parent to children one to many even within trees there's so many different types you've got heaps which keep things in order as you add to them you've got tries which you can store words in to look them up easily and the html on any page can be represented as a tree and in fact you can store anything in a tree with a hierarchical nature that is parents and children now the title of this video is binary trees and we've chosen to focus on them because they are a simple type of tree that probably has the most interview algorithms associated with it now each type of tree has a specific set of rules and the main rule for a binary tree is that each node can have maximum two children or two pointers more specifically every node can have either zero one or two children and these children are represented in the interface of our node with the properties left and right that is to say left and right pointers comparing this to the linked list where we have a single dimension dot next dot next dot next here we have two dimensions left and right okay time for a bit of vocabulary so we can talk about trees in more detail nodes and trees are still called nodes but we'll refer to them as tree nodes or binary tree nodes instead of list nodes we call the node at the top equivalent to the head of our list the root of the tree remember trees upside down so the roots are at the top instead of the bottom as you can probably imagine having multiple paths to go down makes traversal an interesting challenge on one hand we could set an on pointer like we've been doing and choose to follow one path all the way to the end when we reach the end or a node with no children well this note is called a leaf if we take our leaf node and our root node and all the nodes in between that we went through to get here well this is called a branch so you might hear variations of following an entire branch following a path to the end things like that when we talk about traversing through trees more often than following one complete branch though we'll want to look at every node in our tree whether we're searching for something modifying the values pulling them out or just doing any number of different things so the important question becomes what order do we look at our nodes in the best answer is it depends and this question is actually at the core of a lot of binary tree problems so as you can imagine if we're processing every note in the tree in some way whether that's as simple as just printing out each node's value or something a bit more complex we could choose to do this traversal iteratively with a while loop and an on pointer or recursively using the call stack so with the tree and i know you love recursion we're gonna start seeing something called branching recursion which means since every node can have more than one child we can have more than one recursive call per stack frame what our call stack ends up doing is branching out like this but when you look at all the function calls after they return the call stack is actually in the same shape as our tree which makes sense because we're calling the function whatever it is for each node one time i'm intentionally staying generic here but we're gonna get into what the implications of this are and what exactly this looks like in code in the upcoming videos before we wrap this video up i have to mention one more even specific type of tree that we're going to talk about in a few problems this type of tree is a binary search tree note the binary search in binary search tree the reason why it's called that is because like the binary search algorithm that uses a list or array binary search trees if they are balanced also give us a log n search operation now as far as what exactly balance means well we've got a whole video dedicated to that coming up soon so in addition to the rule of binary trees where you can have maximum two children left and right binary search trees have to follow one additional specific rule and that rule is this every node's value must be more than its left child's value and less than its right child's value so in this tree three is more than one and less than five so we can call this a valid binary search tree not only that simple rule but this greater on the right less on the left principle has to be true for the entire tree let me explain if i put a node with value two as five's left child our sub tree with five and two passes but unfortunately we are breaking it within the crater context of the tree because it's down our right path and we can't have anything less than three down our right branch and checking whether this condition is true for the whole tree is called validating the tree and we have another whole video dedicated to that coming up soon now if we know we do have a valid bst the way we find something is by simply traversing towards the value we want so if i wanted to see if the value 8 was in our tree then i'd set an on pointer and look at the value on each step which would tell me where to go next so in this example well 8 is greater than our roots value 3 so i know i'm going to want to search down the right path i can keep doing this simple check over and over until i hit null in this case i attempt to go from 5 right again but five has no right child so we can safely say that eight is not in our tree and this is assuming that our bst is valid so just to recap there are a ton of different node and pointer-based data structures a very common one of those is trees and within trees we have binary trees binary trees are very common in algorithms and they're actually not that different than a linked list they both have a value property but instead of a next property a binary tree node has two pointers left and right which represent the left and right children the note at the top that we're often passed in is referred to as the root then we can follow a root down a branch all the way to its leaf a node with no children now the order we traverse this tree in is a whole topic of its own that we're going to discuss in all the upcoming problems finally there's a special type of binary tree called the binary search tree which gives us certain guarantees if things are kept in a certain order i'm gonna leave it at that for now but we will again talk about that a lot in a upcoming video so this should cover your bare bones basics for binary trees which are certainly a must-know data structure when you're going into interviews nothing to be afraid of though they're just a linked list with a additional pointer all that said let's get into our tree algorithms starting right now ",
            "url": "www.youtube.com/watch?v=GzJoqJO1zdI",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "jBDc4Uuif28",
            "channelId": "UC4o8Fdpv3g_AjgShAeivqpA",
            "publishedAt": "2016-10-19T21:31:59Z",
            "title": "Binary Search Tree | Data Structures Tutorial | Mr.Srinivas",
            "description": "Binary Search Tree | Data Structures Tutorial | Mr.Srinivas ** For Online Training Registration: https://goo.gl/r6kJbB \u25bb Call: +91-8179191999 Also Watch C ...",
            "channelTitle": "Naresh i Technologies",
            "transcript": "hi everyone welcome to nourish technologies this is cinemas in this session so we are going to discuss about a binary search tree algorithm and its implementation in a data structures and algorithms concept here the discussion is about binary search tree in all our previous sessions so we discussed about a linear data structures but now a binary search tree so nothing but a tree is a nonlinear data structure tree is a non-linear data structure algorithm non-linear data structure algorithm is nothing but one node is connected to n number of nodes so what is a node so we know already so good at a single linkedlist and double linkedlist operations okay here it is a this is node based data structure node based data structure sir how can we represent sir in a binary search tree a node is a minimum having minimum having three fields so one is a data field second one is a left child third one is a right child right here it is at most having three nodes mean three fields this is a node data structure so why the reason in binary search tree so a node is always connected to at most two nodes maximum it will be connected to two nodes two pointers will be present two pointers okay so minimum some of the situation's node is not connected to any other node that is connection with the zero nodes or in some of the cases only left is present right will not be present or a right will be present left will not be present such type of nodes we will create nothing but we will construct the binary search tree in such a way okay so this is a nonlinear data structure and a node based we know how to create a node so very simple struck with the help of struttin data type user-defined data type sir what is the name you can give BST binary search tree node or simply I am writing node node so as usual is having three fields so one is a data field and two more fields are there so one is a node type struct node struct node pointer type one is a left child and the second one struct node it is also pointer type it is a right child left child and a right shape this is the node structure to create nodes in the binary search tree so this is the user-defined data type we are using okay and how the stree structure will be see for example so some of the nodes I am connecting for example 30 is one node we are representing like this a node and next one suppose if you want to connect write a value is it 20 20 is connected to left side reason 20 is comparing with this existing node if the newly connected node value is greater than the root value is connected to right side if it is a lesser value is connected to left side suppose here it is a 20 and next one if you want to connect 40 suppose it will be connected like this 40 if you want connected 10 first it will compare with the 30 n is lesser than 30 so move it to left side it will compare with 20 n is lesser to 20 so it is connected to left side suppose if you want to store a 50 when compared with the 30 is greater value right side and here it is a greater value right side 5050 for example if you want to store 25 here it is so 30 is connected to right left side because 25 is lesser than 30 X when compared with the 20 25 is a greater than 20 is connected to this one 25 next suppose 35 30 is greater than 40 is less than so 35 will be connected here for define so this is so generally we are representing a binary search tree and for example so I want to connect to 37 37 when compared with 30 is a greater value when compared with the 40 is lesser value when compared to 35 is a greater value so 37 will be connected here this is structure observe and here how many nodes are present ok 1 2 3 4 5 6 7 8 nodes some of the nodes is not having any child here it is this node is connected to 0 chills connected to 0 chills no children look at this node is connected to one child right child is present left child is not present so this is is connected to single node connected to single node an x1 look at this node is connected to how many chains left child and as well as a right child so this is connected to two nodes connected to two nodes so in a binary search tree a node is always connected to at most two other nodes right here it is a two nodes but zero nodes or one node so these are the chances okay and one more thing for example a binary search tree is having n nodes contains n plus 1 null nodes n plus 1 null nodes so this n plus 1 I will show you see for example so now I am writing so this tree right so directly with the help of nodes clear structures actually how the data will be connected in the program exactly I am writing for example I am taking one node this is data data is just considered 30 and here it is a two nodes we are writing here it is one node here it is one node suppose data is a 40 data is a 20 next two nodes we are writing this is one node and this is one node and this is one node and this is one node node so data is at ten twenty five is a 35 and is a 50 connections how so generally whenever you create node using Emma log function to a structure if you allocate the memory dynamically node will be created at some location address suppose addresses we are taking thousand node address 2000 3000 4000 5000 6000 7000 some random values we are taking mm will be stored here so that a connection to this node 3000 will be stored here so connection to this node 4000 will be stored here so connection to this node 5000 here so connection to this node 6000 here connection 7000 here connection sir what about this so not connected to any other node so all these are null nodes null null null all these are null nodes if there is no connection the node is pointing to null so total how many nodes are there in this tree one two three four five six seven nodes are there if it tree is having seven nodes n nodes which contains seven plus one eight null nodes look at this one two three four five six seven eight so total eight null nodes are present because seven nodes are there seven nodes are there and eight null nodes are there this is one important question interview question they will ask okay if a binary search tree is having n nodes it is having how many null nodes this is the answer okay and what all the operations we can perform on a binary search tree C so what all the operations operations on binary search tree operations on binary search tree so we can insert a node into a binary search tree we can insert next one we can delete a node from binary search tree a third one is it traverse traverse is nothing but a displaying but in how many ways we can traverse how many ways here it is a three base v1 is a inorder traversal second one is a pre-order traversal third one is a post order traversal so mostly these are the operations we will perform on a binary search tree insertion a deletion and a traversal nothing but displaying the elements okay so about all these things and code implementation so we will discuss inner coming sessions okay for more videos please subscribe to nourish IT channel thank you thank you all ",
            "url": "www.youtube.com/watch?v=jBDc4Uuif28",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "vvey2QCs98o",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-10-05T14:45:41Z",
            "title": "5.2 Binary Tree and its Types | Data Structures",
            "description": "CORRECTION: at 5:42 there should be 1 at 7:30 the sum will be 15 In this video, I have discussed binary tree with its properties. I have talked about different ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "in this video we are going to talk about fine jewelry its properties and its types right in the previous video we have discussed what is that cream and you can say that introductory part of trees right some basic terminologies which are used in tree as well as how to represent a tree the logical representation of a tree right the basics we have discussed now we will discuss the binary tree see now first of all what is a binary tree see it is a tree in which each node can have maximum two children or you can say at most two children fine each node see as the name suggests binary binary means one - I mean zero and one so you can say in which a tree in which each node can have at most two children at most two means each node can have either 0 1 or 2 children but cannot have more than two children right that is the binary tree now how to represent a binary tree see if I draw something like this is this a binary tree yes see these are nodes this thing we have discussed already now this is having if this node is having two children fine and these are having zero child so that is also fine this is a binary tree now is this a binary tree yes this is also a binary tree this is having only one node that is removed having no children that is possible we can have zero child a node can have zero child right so this is also a binary tree now see what about this one is this a binary tree yes this is also a binary tree see here each node is having this node is having one child one that is also possible now see is this a binary tree this is not a binary tree because see here in this case this node is having three children that is not possible we can have at most few children so this is not a binary tree right all these are binary trees this is also a binary tree right now if I draw something like this this this this and this this is also a binary tree the only condition is what each node must have at most two children if this condition satisfies that that is a binary tree now how we are going to represent this abanda tree in memory that thing we have already discussed in the previous video see here this is the node each node is having both information plus may or may contain links that is not compulsory that it each node should contain link to another node may be if node does not have any child then it will not contain any link right so how you are going to represent this binary tree see this is a node first node is something like this three parts would be there this is what left child this is what right child you can say so here we have the data part you can say here I'm storing one this is what left this is what link to the right child so here we have one node this node is suppose having data to now see this node is having only left child so this is having only this link this link is null right so now here this is also suppose containing three ready one two and three here I have four five and six because these not a node are having some information store there three is not having any child node so there is no this link and this link would be null this is how we are going to represent this one here in this side we have four four is having both left and right child so this is left and this would be right right here we can have five and here we have five and six both five and six are having no children so the links would be null right this is how we are to represent the tree actually this is just a logical representation of a tree how we are going to store the tree in memory we are going to dynamically create these nodes we are going to set these links that thing also we will discuss the implementation of binary tree right now next thing is see now some properties of binary tree see we have discussed what is a level in the previous video this is known this is what level 0 this is what level 1 this is what level 2 now at any level see at suppose I am taking at level 1 how many maximum nodes can be possible see at level 1 only two nodes can be possible maximum nodes here we cannot have three nodes because at most two children can be there now at level 0 the maximum node possible is only one right at level 2 the maximum load possible are see the maximum node maximum node can be here I have 2 here also I have 2n 2 children of this node so this is what level 2 at level 2 we can have four children maximum we cannot have 5 6 or something like this right this thing I guess you are getting my point now suppose I am increasing one level at this level at third level the maximum number of children possible are maximum means each of this node is having maximum children and maximum children can be to only it means 1 2 3 4 5 6 7 8 right so here it can be possible here for maximum here to here we can have 0 simply same if I increase one level more then here at this level how many maximum number of modes are possible you can say each this this node at level 3 each node will have two children so here I have 8 node so 8 into 2 that is 16 can be possible so at level 4 16 maximum mode can be possible right you know how you can write this thing can I write here 2 raised to power 0 can I write 2 raised to power 1 Buddhist to power to 2 raised to power 3 and 2 raised to power so now what you can say here at each level I the maximum number of node possible in a binary tree is 2 raised to power I that is one property right the maximum number of nodes possible at any level I is 2 raised to power high right this thing I have already shown you now next point may be the maximum number of nodes possible at height H the maximum number of nodes of a binary tree right at height H C at this level suppose I have three levels only now height of this tree is what height of the root node is equal to height of the tree height of root node is what 1 2 & 3 go to the longest path find out the longest path path from the root or you can say from that node to the leaf node so now here height is 3 only right now at height 3 maximum number of nodes possible are see how to calculate you are you're supposed to add all these nodes means you are supposed to add first of all 0 plus at this level I have to plus at this level I have 4 plus at this level I have 8 it means you can say 40 number of nodes right maximum number of nodes fine now if I say height is only 2 right high it is 2 means I am removing this level means now height is 1 & 2 height of root is 2 so height of trees also 2 now if height is to maximum number of nodes possible are 1 2 3 4 5 6 7 so how to calculate maximum number of nodes if height is H simply you will add all the maximum number of nodes at each level so you can say 2 raised to power 0 at this level 2 raised to power 1 plus 2 raised to power 2 plus 2 raised to power 3 and L 2 raised to power H now this is what simply a GP series and how to find out the sum you can easily Google it out I am NOT going to tell you this thing so I am sure if this would be 2 raised to power H plus 1 minus 1 right so maximum number of nodes of height H I'm talking about this binary right so next one number of nodes can be h plus one minus one right and if I ask you the minimum number of nodes if height is H then C minimum number of nodes can be H plus one huh if height is this one 0 it means height in zero means we have only one node right you don't have this thing they have only one node it means height is zero so the minimum number of mode is 1 if height is 1 see this is height zero this is a tree binary having high to zero minimum number of node is one now if height is one I'm going to increase the height now height is one height of this tree is what one minimum number of nodes are one end to only minimum number of nodes I'm not adding this node second node right now if you increase the height one more suppose I am increasing height one more now height is 1 and 2 now height is 2 and minimum number of nodes are 1 2 & 3 if you increase one more height now height is 1 2 & 3 height is 3 minimum number of not a possible are 1 2 3 & 4 so you can say minimum number of nor possible are h plus 1 h plus 1 h plus 1 3 plus 1 is 4 if height is 1 means this one 1 height 1 2 2 number 2 nodes are possible means h plus 1 minimum number of nodes are possible right next thing is if suppose you are given maximum nor minimum nodes and you are supposed to calculate the height you can say the maximum height of the tree possible and minimum height of the tree possible then how you will see how you will calculate this thing now suppose you are given there can be n maximum nodes in the binary tree now you have to find out the possible height so maximum number of nodes are and as from this case we can say the maximum number of nodes can be of height H can be 2 raised to power H plus 1 minus 1 here you are supposed to calculate H value means higher I am calculating height of the tree now how will bullet n plus 1 is equal to 2 raised to power s plus 1 I guess you can easily solve this thing by taking log on both side log of n plus 1 and log off see base is 2 2 raised to power H plus 1 now this thing is 1 log 2 n plus 1 log 2 base 2 is this one and this one is also 2 so here simply we can write h plus 1 alright now here height you are supposed to calculate height is equal to low 2 n plus 1 minus 1 and here we are taking the ceiling function so this can be the height right but this can be the minimum height if maximum nodes are given those nodes can find out using those nodes we can find out the minimum height if minimum number of nodes are given that will give you the maximum height right now suppose minimum number of nodes are given n right n now height is what now minimum number of nodes of height H we know H plus 1 can be there now simply calculate the height is equal to n minus 1 so this can be n minus 1 can be what maximum height n minus 1 and minimum height can be this 1 log 2 n plus 1 minus 1 now we will see types of binary tree so types are full binary tree this is also known as proper or strict binary tree complete binary tree perfect binary tree degenerate tree and balanced tree also but balanced tree we will discuss when we will discuss the AVL trees right that is also that is basically known as balanced tree now what is full or strict or proper binary tree see the definition is what it is a binary tree where each node contains either 0 or 2 children or in another term you can say it is a binary tree see of obviously it is a binary tree plus one more condition is it is contain the each node is containing either 0 or 2 children or you can say each node will contain exactly to children except leaf node right now see what is a full binary tree now if I draw something like this is it a full binary tree yes because it is a first of all a binary tree plus here each node is containing either 0 see this one is containing 0 0 and 0 means these are leaf node right or to children this is containing 2 children this is having two children so this is what a full binary tree now see this is what is this a full binary tree no this is not why so because this node is having only one child but that is not possible in full binary tree now see this is what is this a full binary tree yes this is a full binary tree right now see is this a full binary tree yes it is a full binary tree is this a full binary tree no but is this a full binary tree yes each node is containing either 0 or 2 children or all the nodes are containing each node will contain exactly two children except leaf nodes except leaf nodes right now say in the property of this full binary tree is worth here number of leaf node is equal to number of internal nodes plus 1 here you can say this is a full binary tree now here number of leaf node count 1 2 3 4 5 & 6 number of leaf node are 6 right it should be equal to number of internal node plus 1 means here number of internal node node should be 5 1 2 3 4 & 5 I have discussed what is leaf node what is internal node in the previous video you can check out that video if you don't know now what about maximum node and minimum node in this tree see maximum node is same as binary tree right because here also at this level at this level at this level means at every level I there can be 2 raised to power I maximum knows and if height is it H then you need to add all the maximum of nodes at each level so this says 2 raised to power H plus 1 minus 1 this thing we already discussed right now what about minimum nodes see the minimum number of nodes height is 1 sorry height is 0 so minimum number of node can be 1 if I am increasing height 1 this has height 1 so minimum number of node can be say this is not a full binary tree we need a full binary tree so here you need one more node so 3 can be the minimum number of nodes now if you increase height one more time that is enough height is 1 and 2 height of this trees 2 but this is not a full binary tree you need to find out you need to satisfy that that condition also each node is having either 0 or 2 children so this should contain 2 children this can have 0 children because you are calculating minimum number of nodes so 1 2 3 4 5 5 right if height is 3 I am increasing one more height 1 2 & 3 here also you need two nodes so minimum number of rules can be plus 2 that is 5 plus 2 is C so now how you can write down this thing C 2 raised to power H plus 1 minimum number of nodes now how to calculate a minimum height and maximum height C the maximum nodes will give you minimum height this one minimum height so minimum height would be same as previous one as binary tree n plus 1 here ceiling minus 1 right because maximum mode are same but here the maximum height can be the minimum nodes are 2 raised to power 2 into h plus 1 so how to calculate if minimum number of nodes are given n how to calculate height 2 h plus 1 h is equal to n minus 1 divided by 2 so here you write n minus 1 divided by 2 now next is complete binary tree so now according to the definition of a complete binary tree see a binary tree is a complete binary tree if all the levels are completely filled all the levels are completely filled except possibly the last level fine plus at the last level we have one more condition see and the last level has the nodes as left as possible right we are going to fill the last level from left to right see now I'm going to take one example see here this is the last level right and this is not completely filled because these these nodes are not having any shine so that is fine in complete mandatory see we have told you I have told you except with the possibly the last level all the levels are completely filled seen on this level this level this level this is what completely filled right each node is having two child so one condition is true now second condition is completed binary trees what in the last level the nodes should be as left as possible means we are going to fill the nodes in the last level from left to right you cannot leave these nodes free these spaces free and you cannot right here then child node right so you need to delete and if I shift here then this is what a complete binary tree now is this a complete binary tree no why so obvious see the from the except the last level all the nodes are completely filled but second conditional is what here the nodes should be as left as possible we have left this node blank and we have put children to this node that is not true in complete binary tree if this is also having two child then this is fine right now is this a complete binary tree yes because here the condition is not that each node is going to have exactly two children so at the last level you can have one child but that should be filled from left to right see here if you write this thing you cannot fill the right child first of all you will have to fill the left child right so now this is also a complete binary tree right and this is also a complete binary tree now see is this a complete binary tree no this is not because now this is the last level right so at the last level you can fill the note from left only so here you should fill the left child you cannot feel first of all the right child is this the complete manual oh yes this is a complete mind you drink right somewhere it is also written as it is nearly complete binary tree fine now in this case also same what about maximum node at minimum nodes maximum node obviously this is a binary tree so maximum no that same that is 2 raised to power h plus 1 minus 1 maximum node in a complete binary tree of height H right now what about a minimum number of nodes here the minimum number of nodes are 2 raised to power H this thing you need to find out how the number of minimum number of nodes are 2 raised to power H I am NOT going to trace out this thing now minimum height and maximum height obviously minimum height would be same as the previous one because maximum nodes are same in all the three binary trees right now what is maximum height maximum height means minimum nodes will return you the maximum height so how you will calculate I am going to write down this thing you need to calculate this thing right so the minimum the sorry the maximum height in a complete manual tree is log n this thing you need to calculate how this is 2 raised to power H and how this is log n right so this is what a complete binary tree now perfect binary tree see a tree can be a perfect binary tree if all the internal nodes are having two children and all the levels sorry all the leaves all the leaf nodes are at same level right these two condition fine now see I am drawing one tree all the internal nodes should contain exactly two children so here these are leaf nodes but all the internal nodes are containing how many two children right but second condition is what all the leaf node all the leaves should be at same but here see this is what level 0 1 2 and this is what 3 so 2 leaf node are at level 2 2 leaf node are at level 3 so this is not a perfect binary tree all the leaf nodes should be at level 3 so now how to do this thing now see these are leaf node and all the leaf node are at level 3 and all the internal nodes are having two children so this is now a perfect binary tree now see this is also a complete binary tree can we say it is a full binary tree yes it is also a full mandatory so every perfect binary tree can be complete binary tree and full binary tree but why size not true see if a tree is complete binary tree then it is not necessary that it is perfect binary tree if a tree is full binary tree then it is not necessary that it should be perfect binary tree right now see what is degenerate binary tree here in this case all the nodes all the internal nodes are having only one child that is known as degenerate tree so see this if you draw this thing here this is leaf node and 1 2 3 3 are internal node and each internal node is having only one child so this is what a degenerate tree and you can say this is what a left skewed binary tree left skew binary tree means if the nodes the internal node is containing only the left child then it is known as also known as left skewed binary tree see now this tree this is what this is also degenerate tree because each internal node is having only one child that is a right child so it is also known as right skewed binary tree right now taking example of this is this a degenerate tree yes we can see each internal node is having only one child this is having right child this is having left child right so this is also a degenerate tree we cannot say that it is a left or right skewed it is mixture of both fine so I guess this is a about binary tree plus properties of binary tree we have discussed and I've so binary tree right now in detail how to implement a binary tree that thing we are going to discuss in next video so I'll see you in the next video till then bye bye take it ",
            "url": "www.youtube.com/watch?v=vvey2QCs98o",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "avl tree data structures": [
        {
            "videoId": "jDM6_TnYIqE",
            "channelId": "UCZCFT11CWBi3MHNlGf019nw",
            "publishedAt": "2018-03-16T16:24:28Z",
            "title": "10.1 AVL Tree - Insertion and Rotations",
            "description": "AVL Trees ----------------- Binary Search Trees Drawbacks of Binary Search Tree What are AVL Trees Rotations in AVL Trees Creating AVL Trees PATREON ...",
            "channelTitle": "Abdul Bari",
            "transcript": "topic is AVL trees and these are the things I am going to discuss in this one that is what is binary search tree drawbacks of binary search tree how binary search tree can be improved what is an AVL tree how the rotations are performed in AVL tree and how to generate a VLT or create an AVL tree from given set of keys let us start with the binary search tree this is a binary search tree here the keys are arranged such that for any node all the elements on the left hand side are smaller than that node the elements on the right hand side are greater than that node means for any node the elements in the left subtree are smaller than that key element and in the elements in the right subtree will be greater than that element so 30 is greater in 2010 is less than 220 so in this way the elements are arranged reason it is useful for searching how suppose I want to search for a key element say 30 then I will start my search from room and check with the root element is it 30 no 30 is smaller than that key element so go on the left hand side now is it the 30 no this is not 30 30 is greater than this key element so go on the right hand side now right hand side yes this is the key element found so total three comparisons we got the element let us take one more if I am searching for the key element 60 then is it 60 no 60 is greater than this one so go on the right hand side is it 60 no 60 is greater than 50 so go on the right hand side yes I got the element so only in three comparison I got this element let us take one more key suppose I want to search for a key element 32 let us search for it start from here this is not 32 32 is less than this one so go on the left hand side this is not 32 so 32 is greater than this one so go on the right hand side this is not 32 32 is greater than this one to try to go on the right-hand side but there is nothing so now search fails so for this we cannot find the element so the point here is that when you are searching for a key element possibilities either it can be found or it will not be found so search may be successful also search may be unsuccessful also but when the search for unsuccessful how many comparisons I made one two three so total three comparisons so maximum number of comparisons required for searching any element in a tree depends on the height so the time taken for searching in a binary search tree depends on the height usually we mention height starting from zero onwards but I will take from 1 onwards 1 2 3 so let us say height of this binary search tree is a 3 so the time taken is dependent on the height for binary search tree so this is one of the property of a binary search tree that is useful for searching purpose the elements are organized smaller on left side greater on right side and the time taken for searching is depending on the height now the question is what is the height of a binary tree like binary search tree is nothing but a binary tree only what is the height of a binary tree height of a binary tree can be minimum login and maximum and so it depends for same set of keys we can form different binary search trees it may extend its height upto n also or it may reduce its height to logon also so it means the minimum time taken for searching in a binary search tree may be log n maximum time may be n so let us observe the next thing what is the problem with binary search tree let us see you how to create a binary search tree I have set of keys here and the same keys I have taken here also in the different order something I want to show you by creating a binary search tree let us first create a binary search tree for these keys what is the method of creating a binary search tree so we have to insert one element at a time so first key and that is 30 so there is nothing I have taken 30 here now inserting 40 40 is greater than root that is 30 so insert 40 on the right hand side then 10 is a smaller than root that is less than 30 so insert it on left hand side then 50 check from root for every element we should check from rule 50 is greater than 30 and it is greater than 40 so insert it here then d20 smaller than 30 come this side left side and 20 is greater than 10 so insert it on the right hand side the next is 5 5 is smaller than 30 come to left side it is less than 10 smaller than 10 also so insert it on the left hand side 35 is greater than 30 go to right side less than 40 so insert it on the left hand side she supposing if I am inserting again 50 then starts from here 50 is greater than 30 50 is greater than 40 50 it's already 50 50 is already present here so don't insert it so he don't insert duplicates in a binary search tree now this is the binary search tree I got based on these key elements what's the height of a binary search tree this is minimum height that is log n what will be the time taken for searching any key element and this one it will be log and that depends on the height of a binary search tree so height is log n so for the set of keys when I have created a binary search tree I got this height now same keys I have taken them here also see 50 is there 40 is there 35 all the keys are as it is so but the order is different now let me create a binary search tree for that start from the first key element 50 next is 40 40 is less than 50 so it will come as a left hand side then 35 is less than 50 and also less than 40 so it comes from left hand side 30 less than this less than this as well as less than this so it will come on this side then 20 is smaller than smaller than smaller than it comes this side and then come on this side and five comes on this side so this is the height height is what n height of a binary search tree is n see the keys are given such that the binary search tree when I am creating it is becoming height and so this is the problem with binary search team the method of creationists we insert one element at a time the method I have shown you but what will be the final height that is a not inert over control the height may be login also the height may be order of and also it depends how the key elements are inserted if the height is log and then the time taken for searching is login and if the height is n then the time taken for searching is n and it is similar to linear search then if I have to search in this binary search tree that is similar to linear search like see if I want to search for five then I should start from here five is smaller than this and smaller than this and small and so finally how many comparisons I have to make all seven comparisons so this is the problem with binary search tree that height is not under control it all depends on how keys are inserted so this is the drawback of binary search tree next can we improve binary search tree is there any chance let us look at this I have three keys here let us create our binary search tree using those keys see these keys if I insert them and created by the research tree then the tree that I will get is 30 then 20 is smaller than that 20 comes from this side and 10 is smaller than that it comes from this side so what is the order in which I have inserted I have first inserted 13 and 20 and then time can I insert the same keys in a different order yes there are many orders possible for the same of key so if I am getting the keys like this then this is the tree what I am getting is the order is different let us say it is 30 then 10 and 20 then how a tree looks like so 30 10 is a smaller than this so it comes to this side 20 smaller than 30 but greater than 10 so it comes on this side so this is the shape of a tree I am getting and can we take a different order yes I'll try a different order that is 10 30 and 20 so this is 10 and 30 is greater so he's come this side and 20 is greater than 10 but less than 30 so it comes this side the another shape I am getting if I take 10 20 and 30 then this is 10 20 is greater and 30 is greater than that so for different orders I am getting different shapes so for 3 keys how many orders are possible 3 factorial orders are possible that is 6 orders are possible so for already have taken so I will take 2 more 2 more or possible that a 6 are possible so 2 more I will take that is 10 D 10 and 30 or 20 30 and then 10 let us create 20 it comes here 10 is a smaller than this so 10 comes this side 30 is greater than this so it comes this side and for the next order also 21st that 30 comes from the right side 10 comes on the left-hand side so I am getting a tree like this so it means that for the same set of keys if I insert them in different order I am getting different shape of binary search trees if you look at these trees the height of these trees is 1 2 3 all these trees are having high 2 3 4 just three keys height is 3 so these are with a maximum height but this tree is of height 2 so this is of minimum height so this means that if you have some set of you can form a very long binary search tree also or a short hide binary search tree also so what we prefer is a minimum height by binary search tree so that the search time can be reduced this is the objective so the drawback of binary search tree is that for same keys we can get different shaped binary trees that can be of maximum height or even off minimum height what we prefer is we want minimum height binary search tree so now let us see whether by the research tree can be improved or not see for the same set of keys if I am getting in these orders I am getting this shade binary search trees but I want this one is there any way to convert this so there is no way just we say that just remove it and take this one if you're getting any other shape just take this one but there should be some method which we should define some procedure for converting that one into this one so for that we define rotations we say that we rotate this tree around this node that is will pull this 30 on this side so 20 will move up and then we'll move at this place so we say we will perform rotation around this node and we will change the shape of this node like this and similarly we will rotate this a tree around this node and we will change the shape so 10 will come down 20 will come this side and 30 will come this side it's just like you imagine that is a male fixed here and around that does the thread and you're pulling a thread so if you pull that thread here 10 will come this side 20 will move up and 30 will move up so he say that we will perform rotations and convert this larger height binary search trees into smaller hide binary search tree so this is how we can improve and this gives the idea of AVL tree then how about this how do you perform rotation so in one step we cannot do first we'll rotate around this 10 so 10 will come siren 20 will come up then we'll rotate around this 30 so 30 this side and 20 will move up and 10 will remain on the left-hand side so we get this shape and here also around 30 will rotate in this direction then around the stem will rotate in this direction so we will have four different type of rotations which we can convert binary search tree into a balanced binary search tree so that is the idea of AVL tree so in any shape we want this shape now you may ask one thing that just we have three nodes here what if we have many nodes in a binary search tree house rotations are done so remember rotations are done only on three nodes always whatever the size of a binary search tree may be we look for only three nodes and we try to arrange them or adjust them by performing rotation to get a tree like this and the entire tree will get balanced entire tree will be of minimum height only so this is based on three nodes only now I'm going to explain what is AVL tree then I will show the rotation then I will show how to create a AVL tree now AVL tree AVL tree is a height balanced binary search tree so for balancing the height of a binary search tree we define one factor or one property that is balanced factor we calculate balance factor for each node what is balanced factor height of left subtree - height of right subtree and ensure it can be written as balance of balance factorize height of left subtree - height of right subtree and it should be either minus one or zero or one not greater than one not less than minus one if any node is having balanced factor out of these three only then the node is balanced otherwise the node is imbalance if any node is imbalance we should do something for balancing it that is we should perform rotations for balancing that one how do you calculate the balance factors let us see one more formula I have written here that is absolute of balance factor should be less than or equal to one means minus or plus if you take it as positive only then it should be either zero or one positive one so we'll use this one now I mean here I have some binary trees there are no keys just I have taken empty nodes unlabeled nodes now let us see what are the balance factor of this one so how to calculate height of left subtree - height of right subtree for this node what is the height of left subtree so you take the longest distance in the left side one two and the longest this one on the right side 1 2 so this is 2 - 2 this is 0 same way for this node the longest distance on left side is 1 and right side there is nothing so 0 1 minus 0 is 1 and for this one left side it is 1 right side it is 0 so this is also 1 and there is nothing on left hand right so it will be 0 only so for all the nodes we got the balance factors as 0 1 1 0 0 these are within this set only so this tree is balanced because every node is balanced now let us look at this for this node 1 2 3 height is I'm counting edges ok the longest party should take don't count the nodes we are not counting the nodes we are finding the height so 1 2 3 - 1 so this is 2 this is imbalance the node is imbalance let us look at others also this is 0 left side right side is 1 2 2 so this is minus 2 so there's also imbalance this will be 1 - 0 it is 1 this is 0 only and this is 0 only let us calculate for this also left side is 1 right side is 1 2 3 so I am taking height right so this is 3 and this is minus 2 it is imbalance see I'm not counting nodes 1 2 3 4 not for height so take the longest distance now for this is the balance factor will be 0 leaf nodes will have factor 0 this is 0 minus 1 minus 1 this is 1 minus 2 1 minus 2 is minus 1 that's all these two trees are imbalanced they are having some nodes which are not hide balance but DISA tree is perfectly balanced now I learn about rotation if any node is imbalance based on a balance factor then rotations are performed for balancing that node so let us learn what are the rotations now we go for the first rotation the name of the rotation I'll right afterwards let us look at this I have a binary search tree the initial binary search tree just there are two nodes 30 and 20 let us check whether it is balanced or not the balance factor is 1 and 0 so this is 1 and this is 0 so this is balanced now industry if I insert and then they tend should be inserted 10 is a smaller than 30 it goes on the left side and it's less than 20 is goes on the left side and there is no 10 here so I can insert it 30 20 and 10 that is inserted on this side now calling the balance factor this is 0 and this is 1 and this is 1 2 and that side 0 only so this is true so this node became imbalance that node became imbalance now I have to perform rotation for balance that one but let us see why it became imbalance and this became imbalance because I have inserted on the left of left so this is left of left imbalance let us call it as left of left imbalance now I will perform rotation after rotation what type of rotation I should perform see for this node the balance factor is a 2 so it is heavy on the left hand side if it's balance factor is minus 2 then it means it's heavy on the right hand side okay I don't have to check which side it is heavy but one important thing is this note became imbalanced because we have inserted on left of left so perform this rotation on this one over the snore so over this node will perform this type of rotation so how it looks like then we will move up 20 moves up and 30 will move to the right side and 10 will take the place of 2010 now this is perfectly balanced this is balanced so because this was ll imbalance I have performed this rotation so let us call this rotation also as and then the rotation that is left left rotation so this is the first rotation this is initially 30 and 10 balance factors are this is 0 and this is 1 now I will insert 20 in this one so 20 is less than 30 it goes on left side but greater than 10 so comes on right side so 30 here 10 on the left-hand side I'm painting on the right-hand side of 10 now let us calculate balance factors this is 0 and this is minus 1 and this is 2 again this node is imbalance why it became imbalance because I have inserted on the left and then right so this is l/r imbalance and not in balance then you remember I said that whatever the binary search to you get with 3 nodes we will take a balance tree we want that one so on this we have to perform rotation so the rotations these are 2 step rotations so I will write down here 30 10 and 20 so first we'll perform rotation on this one so how it looks like 30 then 20 comes here and 10 comes here so you have perform rotation over 10 on this side by fixing a name here so who will move up 20 will move up that will not be affected so 10 is pull this side so 10 20 will move up it looks like this now perform this rotation if you perform this addition again the result is 20 will be in the root and 10 will be on the left hand side 30 on the right hand side in this way now this is the fixed point over which the rotation is done so 30 is move that side 20 moves up and 10 more so that's it so this is two-step rotation this is not 2 rotations this is double rotation we count that this also as a single one rotation only but this is having two steps inside so we call it as a double rotation now what is the name of this rotation the imbalance was left right type so let us call this rotation also and our rotation so so far we have seen two rotations that was ll rotation it was single step then LR rotation it is a double steps two steps are there now similarly we have two more rotations I will quickly cover them this is initial tree the balance factors are 0 & 1 now insert 30 in this one 30 is greater than 10 and greater than 20 so 30 comes from the right side of 20 then the balance factors are 0 and this is minus 1 and this is minus 2 so this became imbalance so which type of imbalance because you have inserted on the right of right so this is our our imbalance when are our imbalances there we will perform this type of rotation by fixing this mode will pay 20 here so 210 here 20 will move up and 30 will move up right so it looks like this again and the balance factors will be 0 0 0 what was the type of imbalance our our let us call this rotation also as our our rotation so this is the third rotation again this is a single rotation now next rotation initially the tree is 10 30 balance factors are 0 and -1 insert 20 in this one 20 will come as right side of 10 but left side of 30 balance factors are 0 & 1 and this is minus 2 so this note became imbalance hard became imbalance the insertion is done on right left so let us call this as our L imbalance now for this also two steps are required that is double rotation is required so that tree ten and thirty twenty first it is rotated around this one then ten comes here and twenty and thirty comes here then parcel rotation over this one over this mode over this node then the tray looks like this the balance is imbalances are L so the rotation is also RL rotation so that's all these are for rotations and now I will show you how to create a AVL tree by inserting keys one by one so we have seen total four rotations out of which and l and r r are similar these are single rotations and l r and r l are similar these are double rotations now i am going to show you special cases in these rotations suppose our binary search tree is like this these are the nodes ABC and it is having some left shot right child that is right child of a and there is B is also having some right child and C is having left child and right child so it means it's a very big tree don't know how many nodes are there below this one so we have just taken it as a right subtree of a so any number of nodes below that one but suppose this known became imbalance this node became imbalance because of insertion on the left of left the site the site so ll rotation how to perform this one we have to perform rotation around this mode ll rotation means imagine that assume that insertion is done on left of left of this a and a became imbalance so let us look at how rotation is done over that node and the rotation so don't look anything just look at ABC and draw this one so this is B and C and a as I said the rotations are done always within three nodes now what about others see left shine right cheering they will be as it is see left child and sees right child will be as it is then a night shared will also be in its own place then what is missing there B's right child so this is right subtree of B so it should be on the right-hand side of B only then where it should come that is the space remaining here is the space remaining so B's right child will come here B's right child will come here alright so this is you can take it like a formula or an example in a big size strain with lot of nodes beneath this one just we are looking at these three nodes out of which this node has became imbalance so this how we perform rotation I have shown you ll rotation it will be similar for our our rotation also it will be from that side this means that see if I remove everything and just take this one just take this one so imagine there is some nail fixed here and this is the thread and to a thread something is attached so there is a male and there is something attached to a thread and when you pull a thread on this side around that nail it looks like this then what about this thing that is attached it will go that side and look like this one so same thing has happened ABC and B was having write child when you pull this on this side a on this side so a there and what happens to be art it will come as a left of a removing all this if you just see this the effect is similar or if you keep a are so AR is as it is check it is just like there's a thread and a nail and you are pulling a thread on that side something is attached to a thread so after pulling that side this this thing right if it goes there the stick like thing which goes there so it looks like legs look like this this is the shape so the same shape we are getting here so that's all about ll I have shown you same thing you're gonna play on our our now let us look at lr rotation this is a binary search tree I have not taken a big size tree let us first look at just three nodes suppose this node became imbalance because of insertion on left right so we will perform an our rotation because it is a la imbalance so already have shown you how this rotation is perform first step like this then second step like this but finally what will be the result if first step is performed a B on this side see on this side and B comes here then again when this rotation is performed C goes here and B remains here and a will be on the right side it looks like this by taking two steps I'll remove this by taking two steps it looks like this now can we show it in a single step how we can show it in a single step just see this we can say that when you have to perform LR rotation out of three nodes the last node just you bring it into root C left side is B only that a you take it on right side that's all we say that we can directly always rotation is within three nodes only out of these three nodes last node you breaking into root and the root you send it on the right side because it is LR rotation in RL rotation you can bring root on the left side so LR and RL will be same so I have shown you how we can direct perform in our rotation without looking at these two steps directly we can bring this note up here and send a on that side now let us look at how it is done on a bigger sized tree if I have a tree like this a B and C on this side so a is already having its right side B is having its left side and C is having left child and C is having Rachel also and this became imbalance and imbalances alar imbalance l/r imbalance and I have to perform a la rotation now they are already having some children with them their sub trees are there then how rotation is done out of three nodes as we know that this ship moves up so C will move up B remains as it is a will come on the right side now what about the left child of B it will be as it is what about the right child of a it will be as it is now who are remaining left subtree of C a right subtree of C left of a C will go in the left sub left side only so C is here now so its left child will be on the left side only but it will become a right child of B and the right subtree will remain on the right side only but it will become a left child of a this is the method you can take it like a formula now I have shown you that when you have to perform an r and r rotation we can perform in a single step directly so that single step i have send it up so beyond this side only you have moved to the right side then the rest of the children are arranged so this is like a formula formula like you can take it and always follow this method and the last thing is I will take some keys and show you how our AVL tree is generated let us create a AVL tree of these nodes I will insert them one by one we will calculate balance factors if any node is becoming imbalance we will look at it which type of insertion is done why it became imbalance then perform corresponding rotations so let us take first key 40 is inserted this is a single node and it is balanced then insert 2020 we come on the left hand side and balance factors are this is 0 and this is 1 everything is balanced next is 10 insert 10 on this side now tell you add balance factor this is zero and this became 1 and this became 2 so height of left subtree is 1 2 so 2 right subtree is nothing is there so 2 minus 0 this is how it is becoming - so that became imbalance where the insertion is done on the left of left so ll rotation will perform ll rotation around this node so 20 here 10 this side 40 here and the balance factors are all zeros now it is balanced I'll remove this and use that one now insert next 25 25 is greater than 20 but less than 40 so it will come this side let us update balance factor 0 this is 1 and this is 1 and 2 so 1 minus 2 it is minus 1 perfect next 30 30 comes on right side of 20 left side of 40 but right side of 25 so 30 comes here update balance factors balance factors are 0 and this is minus 1 and this is 2 and this is minus 2 this is 1 minus 1 2 3 so this is minus 2 oh 2 moves became imbalance this is all same balance is also imbalance now we are learning one more thing if multiple nodes are becoming imbalance which one we should perform rotation where you have inserted here from there you go towards ancestor the first ancestor which became imbalance perform rotation over that so this is the first time so perform rotation over that one automatically that will also become balanced so according to this imbalance node insertion is done with side left right so this is a large rotation so we'll perform an hour rotation and our rotation means what instead of showing two steps we can simply take this 30 up and 40 this side so this becomes 20 on this side then here and here comes 30 25 remains here and 40 this one that's all l rotation is done the update balance factors 0 0 and this is 1 1 this is also 0 this is 0 this is 1 & 2 so this is minus 1 everything is balanced I'll remove that one now next node 22 where 22 will come right side of 20 left side of 30 and left of 25 so it will come here 22 there is update balance factors this remains 0 only this is 0 this is 1 and this is 1 2 and this is 1 so this is 2 minus 1 this is 1 only what about this this is 1 and minus 1 2 3 longest distance is 3 here so 3 is minus 2 so this became imbalance all our balanced only you see 0 0 0 1 1 and that became minus 2 so this node became imbalance now one thing to observe according to this where insertion is done right left left ah and no just take two steps are means consider only these 3 means no we inserted this one now whatever it may be wherever you insert who became imbalance this became imbalance then only two steps or three goals from that imbalance node so just three nodes you see right see even if I have not insulated 22 if I would have inserted 26 it would have came here then also insertion is on right left we say it will be right left right so will not take all steps just two steps from a imbalance node whoever we can imbalance from there just two steps so if you just take two steps perform a large rotation so as per in the rotation this 25 can be sent up 25 sent up and on this side comes 20 so what about 10 10 will be remain as a left child of 20 and this side 30 will be as it is and this is 40 what about this 22 who was left child of 25 it is still we are in a less subtree of 25 so it will come this side 22 will come this side that's how the rotation is performed like this we have performed our L rotation already I have shown you how our L is performed now last key is remaining that is 50 let us insert this 50 comes this side that is right side of 40 now if you check balance factor these are all 0 0 0 and this is 1 2 & 1 2 3 so this will be minus 1 and this will be 1 2 so this is minus 2 and this is minus 1 & 0 so this node became imbalanced perform rotation along this one so which type of imbalance are our imbalance of perform rotation so 25 and 20 10 and 22 they all remain as it is and this will be 40 and 30 50 now it's perfectly balanced binary search tree we got that is AVL tree Haida balanced ablt or my name is first in accord so this is the method of creating AVL tree now one thing to remember that don't allow any node to exceed the balance factor from minus 2 or 2 you should never get minus 3 or 3 if it is becoming imbalance then under rotation don't wait that first I will insert all the notes then afterwards I will perform all the patient's no this is not possible whenever any node is becoming imbalance just after insertion if any node is become imbalance then just perform rotation and balance the tree now I take you I will show you one more last situation then Howrah distant let us look at one last thing a baby tree I have taken here let us see whether it is balanced or not balance factor for leaves will be zeros only these are all zeros then this node 1 1 so this is 0 this is 1 2 1 2 3 so this is -1 balance only what about this 1 1 2 1 2 so this is 0 and this is also 0 this is minus 1 so all those are perfect so they are all balanced so the tree is balanced now I will insert a new node that is 42 so 42 is greater than 40 less than 50 less than 45 but greater than 41 so 42 comes here let us see what happens I'll update the balance factor this becomes 0 this becomes minus 1 this becomes 1 2 and this is 1 so this becomes 1 and this is 1 1 2 3 and this is 2 so this also becomes 1 and what about this this is 1 2 so this is 2 minus 1 2 3 4 4 and this is minus to this node became imbalance now which rotation I should perform where I have inserted right left left right right left left right don't take all steps just take first two step left right remove this one I have to perform addition by using just three nodes so what happens 45 degrees or 40 moves here what about all other nodes already have shown you the formula how they are adjusted so just you can follow that and complete rotation so that's all the height of a AVL tree is always balanced so it's a balanced height balanced binary search straight so binary search tree only but it will maintain the height and it will try to maintain always log and height it will not exceed 2 n unlike binary search tree so at most the height of a AVL tree is measured as 1 point 4 4 into log n so at most it may be 1 point 4 4 into log n but it cannot be always exactly log and it may be little then little bigger also but it will be multiples of log in only so asymptotically we say the time taken for searching in a AVL tree is log n that's all about AVL tree just like AVL tree there is one more height balanced binary search tree that is a red-black tree the idea of red black tree is also same as AVL tree but AVL tree is more strict and there may be many rotations perform in AVL tree while creating AVL tree we may be performing lot of rotations to avoid bad rotations more frequent rotations red black trees used red black tree is not having that much strict rules as compared to AVL tree but red black tree is also as efficient as AVL tree so these are to hide balanced binary search trees so we have discussed about AVL tree and that's all about this ",
            "url": "www.youtube.com/watch?v=jDM6_TnYIqE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "vRwi_UcZGjU",
            "channelId": "UCmJz2DV1a3yfgrR7GqRtUUA",
            "publishedAt": "2020-04-28T19:51:44Z",
            "title": "AVL Trees &amp; Rotations (Self-Balancing Binary Search Trees)",
            "description": "Code & Problem Statement @ https://b2bswe.co/avl-tree-rotations Subscribe To Live Tech Offers: https://offerfeed.io Join Our Coaching Service: ...",
            "channelTitle": "Back To Back SWE",
            "transcript": "so in this video we're going to be covering AVL trees if you have not subscribed to the channel hit the subscribe button and like this video or watch the video and then like it it helps us out a lot if you want to support us go to the backs of X we comm websites we are hosting a growing service and we're going to all talk about it at the end but let's get into the lesson first in this video we're going to be looking at AVL trees now we've looked at binary search trees before we know that they have the property if we look in the left subtree we're gonna have items less if we look in the right subtree we're gonna have items greater than or equal to sometimes I've seen it less than equal to and then greater well all that AVL trees add on to that is we're going to have a self-balancing property to them and they're going to balance themselves after we do inserts and outer we do deletes and why do we want to do that remember that if we have a binary search tree let's say we were inserting 3 2 & 1 that is skewed to the left we see so that's going to be linear if we were trying to search because we have three nodes and we're going to have to search all of those nodes we could go as deep as that last note the whole thing that we're trying to avoid is that skewed 'no sand if we balance our tree and define certain thresholds on the balance we have at each node we can keep these searches logarithmic and that's what we want to do so that's what we want we're going to talk about balance we're going to review what balances we're going to look at rotation where do these rotation operations we're going to look to look at left rotations right rotations left to right and right left and then we're going to be doing an implementation of insertion in the interest of time we're just going to do insertion it's going to be a good bit of code so I just realize that's not a binary search tree let me fix that going back to that property we know that our left subtree is less than and then that right subtree is greater than or equal to and what we're gonna do is we're gonna have a rebalancing threshold and we're going to look at the balance at every node in the tree if we break a certain threshold in standard AVL trees that's going to be one we're going to need to rebalance I keep talking about balance thresholds let's actually look at the idea of balance first and then we'll get into our rotations so now balanced remember we always talk about trees in a recursive manner we have this node N and this node is going have a left sub-tree and a right sub-tree they're both going to be recursively defined so every single node routes its own subtree we think about it recursively and if we were thinking in terms of a function we would have a function and then we would have that node as a parameter to the function and do something with the left and right subtrees we need to define a height what is the height of a subtree so if we have nothing if we just have a null node we're going to say that the height is minus 1 we could call it height 0 it could be either as long as we stay consistent so we have a height of minus 1 and I sometimes like to say it's underwater if we just have a null node it's like we're underneath the tree that's just kind of how I remember it I have a little fish swimming there and then if we have a single node we're going to have a height of zero so in this case if we just had a single note that's height zero and then as soon as we start adding nodes on we need to have a recursive definition for this height so we're going to say let me find the height out of this left subtree and remember this guy up here that node n wants to know the height of his subtree the way he's going to get his height is he needs to look at the left subtree he he owns and the right subtree we're gonna look at the left subtree right there we're gonna look at the right subtree right here we're gonna see between these guys who has the larger height and then we're gonna add one to that so then there we go that's going to give us the height and we're going to see more examples of this as we continue on so that is height if we have nothing it's going to be minus one if we have a single node is going to be zero if we have more than a single node we're going to need a recursive definition now what is balanced at a specific node mean balance is going to be the height of the left subtree minus the height of the right subtree that is going to give us the balance at a certain node n and so what an AVL tree does is it's going to keep this balance the absolute value of this balance within a certain threshold and here we see it can be parameterised so AVL trees are going to have a threshold of 1 we can make that threshold more but the standard threshold is going to be 1 so that's what we're going to see in our examples now let's do some examples and start calculating some balance I've kept these two things up here are balance equation and how our threshold is going to be one we're going to start at the root node what is the balance of that node 3 so we have the balance of 3 we need to look at the left subtree so do you see this tree right there that is a whole tree to itself and we need to consider what the height of that is so we see a single node at the root so that's a height of 0 as we defined before and then we have a left subtree which is just a single node we have a right subtree which is just a single node ultimately the heights of that left subtree becomes just 1 and so the height of that left subtree is 1 and now what is the height of the right subtree that's going to be this guy we see that it's a single node and since it's a single node we know that's height 0 and then once we evaluate this we're just going to get 1 so okay now this is 1 and what was our threshold our threshold is 1 we look at this threshold right there 1 is less than or equal to 1 1 is equal to 1 we know that the balance at that top node is 1 so let's just make a note of that okay so we just calculated the balance at the root node the balance is 1 and I want you to notice something this is left heavy so I want you to notice look at the equation if we have a positive balance that means that that left side of the equation that guy right there is dominating and he's going to bring us positive that means we're left heavy if we're right heavy our balance is going to be negative this guy over here is gonna dominate our equation that is something to just pay attention to that's going to be a part of our pattern matching later it'll make us it'll make it really easy to internalize our rotations later so now we can continue on we can calculate the balance for this guy right here what is the balance for him so we're going to say what is the height of his left subtree minus 1 what is the height of his right subtree minus 1 and then 1 minus 1 minus minus 1 that's just going to be 0 so the balance F 4 is 0 ok so now let's look at the 1 let's calculate the balance over there he has a left subtree single node what is a single node height 0 and then we need to find the right subtree height we need to find the subtree the height of that guy right there his high to 0 he's just a single node so 0 minus 0 is 0 so that means that the height at this one going to be zero or the balance is going to be zero and so if we continue on we're going to see that the balance of this zero here is a zero he is a minus one left two minus one writes that's just going to become zero same thing for that guy right here so we're just going to make those zero so we can see that this tree is special we have a balance of one balance of zero balance of zero balance of zero a balance of zero all of those are within our balance parameter we want to stay within a balance of one so the absolute value of any of those will be less than or equal to one this is an AVL tree it is adhered to our threshold all of the balances check out and there's nothing we need to do here this tree is balanced we're going to have logarithmic search now let's look at a tree that might not adhere to this property so let's look at this tree okay so we have a tree right here let's start at the four and let's find the balance out of four we're going to need the left subtree minus the right subtree and that's going to give us our balance the right subtree of four let's do that very quickly it's empty so just minus one so the left subtree has a height of a height of zero and then we have one and then two so then we can just eyeball this and we can see that the height is two we could do the math but we can see that we have a single node which is zero one and then that is two minus this minus one to plus one equals three we see that instantly at our root node we have broken the the the property and and this is not an AVL tree so this is not an AVL tree and this brings us to rotations rotations are how we're going to maintain we're going to maintain the binary search tree invariant at the same time as maintaining this balance threshold right here that let's look at what rotations are and specifically what are they trying to achieve when we're talking about rotations we could start out with abstract sub trees and and that can get confusing if you're not used to the notation I'm going to just start off with some pattern recognition and just get kind of build up a intuitive sense of what should we do when a tree looks a certain way although in reality you would you look at the math we'll look at implementation but I think this is a good way to step into this first and then we'll go to the concrete implementation you'll become very straightforward rotations fix imbalance in archery basically what we're doing we're trying to move notes over to the other side of the tree that needs notes if we're left heavy we want to go to the right if we're right heavy we want to move notes to the left and there's specific ways we have to do this so specifically if we're left heavy we're going to do right a right rotation or a left rotation and then a right rotation we would call it a left-to-right rotation and we're going to see exactly what these look like no worry about that if we're right heavy we're gonna throw nodes over to the left we can do a left rotation or we'll do a right rotation first and then a left and we'll see these two guys are confusing at first these are confusing until we see examples of what they look like here we see a right to rotation so this guy is a rights rotation and I want you to notice the tree on the left up here it could be left heavy and we're trying to move notes to the right sub-tree the key thing I want you to notice is there's always two nodes in a tango whenever we are doing these rotations two nodes are going to be critical and then all of the other sub trees are going to dance around and they're going to maintain that binary search tree invariants as we move these two critical notes notice those x and y's those are the nodes were going to care about and notice the special properties we're maintaining doing this right rotation and these will be clear as we do examples there's a node X and there's a node Y we know that we know that Y is less than X let's just write some things we know Y is less than X so we see this little red triangle what do we know about that red triangle we know that that red triangle is less than Y in less than X okay we're just going off base we're just going off what we know we're we're not taking any we're not doing any abstract rotations we're not making abstract sub trees we're just looking at what the tree is telling us and this is a really good way to reason about data structure problems let's look at this blue triangle this blue triangle is greater than Y greater than or equal to Y and it's going to be less than X that blue triangle fits that property this purple triangle will be greater then or equal to Y and it will be greater than or equal to X what we do here is we want to move these nodes to the right we're gonna turn Y and we're gonna push Y up to where X is and then we're gonna bring X down and move it to become the rights child of this Y which has just become the root of this new tree before ok forget about all of these sub trees forget about those sub trees down there before we do anything I just want you to notice whenever we're doing rotations just move the Y in the X so the Y's gonna move to the root the X is gonna move down now we need to know where do the sub trees fall in place so that we maintain the binary search tree invariant and we don't lose any node so you don't want to lose any nodes let's look at the properties that we had before so we see that this sub tree right here the red one less than y less than x over here this subtree right there that makes sense that's also less than Y in less than X so that holds so then let's look at this blue sub tree right here so this guy is greater than or equal to Y and less than X and yeah that makes sense we went greater than or equal to Y and then we want less than X so everything's checking out so now this purple sub tree right there we're going to go greater than or equal to Y great we did that and then greater than or equal to X so we did the same thing and guess what we just did we just performed a rotation of these two elements and we kept all of these sub trees we maintained they their positioning and their ordering so this is still a binary search tree and we have fixed the balance now that we we've seen a rotation in action let's look at all the specific rotations so that we can get a better feel for them so remember order matters when we're doing insertions on binary search trees we're going to perform these insertions every single time we perform an insertion we're going to be checking to make sure we didn't break balance at any no to break this threshold property ok so let's insert 3 ok we inserted 3 we're gonna insert 2 if we insert 2 we're gonna want to go to the left so let's insert 2 so we just inserted 2 this is still a binary search tree all of the balances check out and we could recalculate them but for the sake of time I'm just going to you can do that in your head we'll just continue with this demonstration now we're going to need to insert the one so we're gonna go to the left and then we're gonna go to the left but there's a problem and so the more of these that you do you're just going to be able to see it I don't want to do the math at every node eventually you're just going to be able to see whether there's an imbalance but in reality if you were coding this you would want to know concretely we're going to be recursively after this after this node gets inserted the call stack will return to this function call he's gonna check his balance then he returns he's gonna check his balance that's how it would actually be implemented but for the sake of just you know speed we're just not gonna trace it as the code would do it we're gonna just talk it through root is imbalanced we have the low the right is minus one and then the left is going to be depth of one so this leads to a two so this is bad we just broke the property and so what rotation can we use notice what our balance is our balance is two and remember since our balance is to the left guy the left sub-tree is dominating we are left heavy so what does that mean we can do a a right rotation get those nodes out and let the left subtree move them to the right and so there's there's a catch to this we'll see that when we get to the left right rotation which is next so remember when we do the rotation only focus on x and y only focus on two nodes we're going to move this two up we're going to move the three down we need to fix the subtrees remember there's actually three sub trees going on going on here we're going to have this sub tree we're going to have this sub tree and we're gonna have that sub tree what do we do with those so first off these guys don't even exist so they don't even there they're not even the in the picture the code would have to handle them if they were populated but this one where does that one go well we know one is less than this Y we know one is less than this X so this one is can this one can just go here this is less than y less than X so we've maintained our property so that is the right rotation come notice how we started out we just rotated these guys just worry about X&Y just rotate the nodes that matter and then adjust the subtrees we saw that this subtree gets adjusted that is the right rotation take these guys move them to the right we're rotating to the right left heavy we fix the left heavy by moving to the right so now let's look at a different situation where we're left heavy but we can't just do the right rotation so now we're at a left-to-right rotation let's do this let's insert the three then we insert the one we can eyeball this we still see that we're balanced and then we insert the two we are left heavy if we calculate the balance at the root node which is where balance is broken we're going to see that we have minus one in the right subtree and then we're gonna see we have a balance of one in the left so again we have a balance of two can we just do the right rotation we're going to try that let's just try doing the right rotation pull the one up push the three down that is the right rotation started and then the two the two is gonna have to go right there because it's greater than one in less than three it's greater than one in less than three it's greater than one in less than three but this is not balanced if we look at the root the root has a -1 - if we look at the right this has a balance of 1 this is minus 2 that this is not balanced this breaks the AVL property so we can't just do a right rotation here there's something different we have to do this is where we would do something called a left-to-right rotation we're gonna take these two guys right here these two guys we're gonna do a left rotation and then once we do a left rotation there we're gonna do a right rotation on the subsequent node so first let's do a left two rotation so we're gonna pop over the to pop over the one so we did a left rotation there and the 3 is just gonna be up here now we've performed the left rotation right there that's the left rotation and so now we need to perform the right rotation up here so we're gonna do the right rotation so now we're gonna push the 2 up and then the three down and then the one goes here so this is it this is the final tree and this is a balanced binary search tree within our threshold so that's a left-to-right both of these are left heavy restorations now that we understand how these rotations are done our least we saw initial examples we can look at how we fix write heaviness and it's the exact it's just the opposite it's the same operations so now let's insert one let's insert two and then let's insert three we see we have a problem and now we can do a left rotation so we're going to bring the two up we're going to bring the one down so remember these are our nodes we're focusing on and we're moving to the left so that one moves to the left because it's the left rotation and then this three just goes right there and then this is our finished binary search tree so choose the root left right and that is the tree so that's our left rotation and then let's look at right left so insert a 1 we're going to insert a 3 and then we're gonna insert a 2 and this is when the balance is broken but again if we just do a left rotation what happens we're going to see 3 we're gonna have a 1 there and then the 2 is just the 2 is greater than 1 less than 3 greater than 1 less than 3 then the 2 is going to go here and again this is not an AVL tree so we need to do something different we're going to first do they're the right rotation we're going to do a right rotation so it's going to become 1 2 3 and then we're gonna do a left rotation so it becomes 2 1 3 and then that is an AVL tree this might be confusing at first this might not you might not get it at first but if you do a few examples do a couple practice problems on this it's going to become very very intuitive how these rotations happen so that's all we're going to cover for this video if you want to see the full implementation you can go to back-to-backs we comm we have a growing service we're working very hard on it in the past month we have released I think for programming languages we've released Java we've released sharp we really see sharp two days ago we released Python we release JavaScript we're going to release C++ in a week we're going to be releasing Swift golang maybe Ruby soon maybe in the next month and we have a ton of great things we want to build we've put the infrastructure in place to scale right now we have about a hundred thirty or so problems we want to we want to create three hundred problems five hundred high signal problems and that's what we're going to do with our service so the best way that you can support us is to go to back to vex we calm the link is in the description so that is all ",
            "url": "www.youtube.com/watch?v=vRwi_UcZGjU",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "E9DOBLNB-aE",
            "channelId": "UCJihyK0A38SZ6SdJirEdIOw",
            "publishedAt": "2020-02-07T12:59:06Z",
            "title": "Introduction to AVL Tree in Data Structure with Examples | All Imp Points of AVL",
            "description": "AVLTree#DataStructure.",
            "channelTitle": "Gate Smashers",
            "transcript": "hello those so great smashes my aapke socket there is freedom this is Corinne grea AVL tree chimera me or a pseudonym a BLT selected sorry important point is occurring a Jo optic competitive exams even of k college or university level exams Kelly boys other beneficial hungry so guys photography video cool like her then channel go subscribe cranky with a cabin in IKEA and please press the well written sake of Kesari latest notifications military to Starcraft a subset Paulo important point a AVL tree car usage chemical of AVL tree key wire to escalate my subsequent of Koopa sahaja Tom last video memory this is here the binary search tree cavalry me to actual image of kahani a math with carnies already have a personage around tacky apathy no points you have Oh clear oh dang it so subsequently at the a binary tree kibarim a binary tree comma Club care dismay at most two children o supreme are lucky see we no takea to 0 yay one here two children Joe a bow who's obtained a carnie at a up a Kiki aku order of the data go insert chemically a binary tree key under cafe order who the name up T Sigma 3 case a data coincide perceptive one of octopus kuiba data do coiba key do without worrying up simply data core birthday Chavez Day Americana maximum two children jaibo hona chahiye a problem ki k other data go insert tourniquet I'm going order here the data search can make a time problem i giv methylammonium class key masquerade class maker students you have a proper order mein nahi battery randomly betty a obviously search curve name a problem IG IG to hunker ka up a data structure gamma clock a data for proper way she organized karateka underscore search cursor came easy that is Jovie operation maharaja tau search karna insert can I delete car memo Samba easily cursor cool to binary tree may the problem I agree to phenomenal ski bodice is chaos a binary search tree a binary search together till left side my octopus smaller element right side may root save but I only meant to home Nakia Nakia core define kia bye research recently did Cassie insert curtain delete cut they already made you maniman are you here a grab neva video nahi Jackie to make Majnu checker make Yuki description box me to link the aware whoa earthquake binary search tree said little sorry Joe a summary of come up a Papa love Jackie to have a binary search she gave I remember Kavitha rata keep buying research like a techie quarter made a low left side my chota roots a or right side me roots a butter to Yanni agama order made are wrong so obviously search Mirko a sahaja yogi search karna insert cannot delete car mechanic II a sahaja yoga resource kakeya agar Meera tree Bela's riga balanced chemical can agree proper McLaurys 3kc a guru ski proper children month a giant game so chemically mary hide yo a agar maripaz pre balance there to hide mary logger and tuk j\u00e9 log n comma clock a different number of nodes a happy hide karthik jayegi height of the tree will be log n or agree a log in the grea the bestest search karma logon insert karma logon delete karma logon lake in binary search tree may be problem a problem ki worst case Kiva's case comic love care other mary pass data is 3kc out there let's say 10 20 30 40 50 like this well of data it is 3 KCRA so what 3 keep Ajay a linked list kita Rancho Viejo behavior a comma Club 10 2010 simmer drama club right side me 3027 up right side may 40 you see what a right side me 50 is a better right side me so yeah after two three year whoa egg direction may he grow cottage a disco them right skewed is cook about their right skewed or our left side my grow he recollects in 9 8 7 6 5 4 3 that is called a left skewed other gear problem re a right skewed or left skewed key to up the algebraic Oh other number of elements Mary Ann hungry number of elements are and hungry to hide kitten yogi and who ki aur agar height and hoagie - obviously search car make a complexity Catherine yogi order of M ake element concert Carnegie worst case may M ake element could delete Carnegie of Wesley mirko endtime search karna padega - yaja page of worst case a binary search tree kheh vous crab kurta q ki normal to you a cheaper form can I make him European balance factor ki baat nahi Kathy so album Baskerville are a balance key balance Muslim hum binary search tree Kobe balance carnage re too jumpy a basket a balanced do balanced binary search tree it is known as AVL tree Muslim it is not known as AVL tree actually a theme regime sight distance you know name will be able to even higher all the balanced binary search tree mail or Bebo sorry Theresa Lake into sub Sujatha important - whoa AV l3 - Yahweh subsequently upcoming Tino cabbage me relation Pathan - binary tree after there yapping binary search tree is can the raga AVL tree whose KB interrogatories 3kc Coco Co are a key all binary search trees are binary tree yes but all binary trees are binary search tree may or may not possible all ADL rBST yes all be STR AVL may or may not possible to a relation Tino Kafka Yahoo Nagi upon basket a avian of AVL Miam cab or a balanced banana balance from Casa vanity balance actually Cuban Aria taquito height and a tricky Bulldog and say cross in a curry or another log any Reiji Haider to search time Keith Naga M origami cookie see element Co insert can I delete Cornetto time complexity log and say super giant o Heidegger login raggy the time complexity B log and he ready to balanced binary search tree may amuse Guardian Treecko of some simple operating Apiata keep my balance factor nickel thing is here so let's say I'm going a binary search tree man diagur let's email pass a binary search tree subsequently a Cohiba the a key AVL tree first of all it is a binary search tree a binary search tree Cabela's Carla Woburn Gasca avian to a sorority of retrievin REO Orozco AVL may convert karoon a binary search tree CO he a real may convert corner so he happy muir pass key a fair balance factor a balance factor on casa de Gothia ballast factor over there hi dog left subtree height of left subtree - height of right sub tree or yegorovna karaage so Esquivel uvaca get there you have to - one ho yeah zero yeah plus one half one be votes octamer lock until awareness KBJ on each eye a he have character Athena values he louder agree scale of aku your value at the a to aapke tree unbalanced or a guru unbalanced day to us Co imbalance currying it to you half a para important point out there to balance factor case an account there let's see a guru J is node cabal inspector Nick Allen Road car so they go left sub-tree what is the height of left sub-tree one two hygienic out there the roots a Mirko leaf that Johnny here leaves elena boyko route the connect to kitni edges come across Quran to Yahweh one edge to edge or what is the height of right subtree one - two - two what is it zero - zero a louder zero a louder next zero Yavapai a giri's come and check on the left subtree key hide catania one right subtree right Mako hey Nita Jiro yeni 1-0 qivana one - Calvin a louder yes one allowed to a BK I have balanced its codec oh hi it left me zero which I linear right mijito which I named the jido - zero zero he'll be allowed as he asked if I don't Corrigan left side my 0-1 to cancer I obviously will pass away - Monica which is what again allowed next is keen ecological balance factor to 0-0 Muslim zero to any Havel are trees away America's balanced tree but I go to his co-op AVL tree boots - all go because - of data a dollar a general format of Kopitar oh he choreographed Oh binary search tree Yahoo - ops binary search tree Keanu Carlo balance fact Ronnie Carlo or balance factor Michael a kebab capital a Giga rake node car every node car key a guru - 1 0 f + 1 are a 2 an Evo AVL tree had a gurney era - an Evo AVL tree nanhee so agar go AVL tree head Tomaszewski hide kitten yogi logon or a good height maximum log a noogie - search time general a Giga login so insertion deletion searching sorry operation of cacao egg a easy lake in other sk lava core value are here - 3 - 2 - 1 push me boy B or value are here other than these 3 tohe Moscow AVL may convert carranger availment convert case occurring a yam next video may taking it to you PA sorry important point UFO a meal selected important a chai in key office may a relation which I time complexity is related o Q keys typing questions now probability of exams may sub-sahara thea or even college a university level exam to be worth caring to waha baby subsidy of the question - where create can isolate the binary search tree co-create kuroh delete kuroh a AVL Koba now draw corrode delete Caracas typing questions whoever up go definitely I'm thank you ",
            "url": "www.youtube.com/watch?v=E9DOBLNB-aE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "_8qqlVH5NC0",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-02-02T16:27:18Z",
            "title": "5.14 AVL tree Insertion | with solved example | Data structures",
            "description": "Learn how to construct AVL tree from given data (example with solution). AVL tree insertion and rotations. See Complete Playlists: Placement Series: ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "hi guys welcome back in this video I'm going to discuss with you how to insert data in AVL tree or you can say how to construct our AVL tree so the question is you're supposed to construct AVL tree by inserting the following data I mean these numbers from left to right fine okay now first of all what is their first number is 14 so first insert 14 because the static maybe have empathy trees or just create a node and insert this 1414 we have inserted fine now find out the balance factor of 14 is 0 this is balanced this is the balanced tree fine next is 17 the waves 17 should be inserted see AVL tree is first of all it is BST and second is height of left subtree - ID of light right subtree would be either minus 1 0 or 1 the where 17 would be inserted 17 check karo 17 is greater than 14 to 17 would be inserted here only fine now check out the balance factor balance factor of the 17 is left - right height 0 height of left is 0 and height of 4 writers 0 - 1 that is minus 1 so no need to balance it out it is already balanced now insert this 11 fine now where this 11 would be inserted 11 is less than 14 the 11 would be inserted to the left of 14 still this tree is balanced because balance factor of 11 is zero balance factor of 17 is also zero balance factor of 40 knees height of left subtree - IRA Freid subtree that is 1 - 1 0 fine see after inserting each and every node we are supposed to check the balance factor for each node hi next is 7 now where 7 would be inserted 7 check less than 14 less than 11 those 7 would be inserted here only now find out a balance factor balance factor of 7 is zero balance factor of this 11 is 1 - 0 1 that is also fine this balance factor of 17 is 0 14 is highteeeee kic open e 1 n 2 fine 2 - 1 1 so that is also fine in order to balance it out next answered 53 53 is greater than 1453 greater than the 17 the 53 would be inserted here only fine now also this is balanced zero balance vector zero balance vector balance factory zero minus 1 that is minus 1 well inspector of this 1 is 1 minus 0 that is 1 and balance factor of 14 is 1/2 height of left is my two height of right is 2 that is 0 right 0 1 and minus 1 okay now insert the next element next is 4 now where this 4 would be inserted four is less than 14 4 is less than 11 4 is less than 7 though it would be inserted also to the left of 7 left side fine left off 7 this 4 would be inserted now check out the balance factor balance factor of this 4s 0 fine balance factor of 7 is 1 right sub-tree key height is 0 1 minus 0 that is one balance factor of 11 is what height of left subtree height of left subtree is 1 n 2 2 minus 0 that is 2 fine and this is not either minus 1 0 or 1 so this node is a you can say critical node because of this node this trees and but unbalanced so before inserting next numbers in this tree you have to balance it out first of all I know okay now how to balance out this tree see find out why this tree is unbalanced this tree is unbalanced because because of this left insertion and again left insertion fine left and again left so you can say either you can say this is left left rotation ll rotation fine and how to solve this left left rotation making out there only one right route datian right Muslim like this right rotation fine and how that right rotation would be there this 11 would be pulled down and 707 would go up or simple the shortcut is see these are we are working in on these three elements 11 7 and for the median out of these element the median element would always be the root and the remaining element would be children of that element out of 4 7 and 11 but what is the median element that is 7 only 7 would be the root ARA PA rule according a are accepted in the left left rotation though half al or L so in that case one right rotation would be there fine the tree would be 14 would be as a tease 17 would be as a tease 53 would be as a tease now what is this right rotation pull out this or you can say pull down this 11 to the right side right rotation or median of this one is 7 so 7 would be 7 would go up that would become the root find 11 and 4 that would be the children of this 7 4 would be to the left of 7 and 11 would be to the right of 7 because it is BST to greater element would be the tri in the right side and less element would be the left side fine now check out the balance vector 0 0 1 minus 1 0 0 minus 1 1 2 1 2 2 minus 2 0 this is balanced 3 now next element to be inserted is this 13 where 13 needs to be inserted 13 is less than 14 13 is greater than 7 third go to the right part in 13 a is greater than eleventh we would go again to the right part that is here threating would be inserted now find out the balance factor of each and every node balance factor of 13 is zero balance factor of 11 is 0-1 that is -1 balance factor of 4 is zero balance factor of 7 is height of left subtree is 1 - site of right subtrees 1 2 that is minus 1 0 here we have minus 1 C 14 left of a sorry height of left subtree is how much one say you can't say 1 & 2 that is the height because you are supposed to go to the leaf node Kooskia height thickening up so you have say like a 1 yeah how's he like a heart to and from the snow to the leaf node 3 1 2 & 3 3 minus 1 to 1 so obviously this tree is balanced okay now next s you have to insert this to L now where this 12 would be inserted this 2l is obviously this less than 14 and greater than 7 and greater than 11 but less than this so here the 12 will be inserted now find out the wine inspector balance factor of the balance factor of this 12 is 0 this 1 is 1 minus 0 that is 1 this one is height of left subtree is there any element to the left of 11 no so 0 minus height of right subtrees 1 & 2 that is minus 2 fine and that is not possible in AVL tree fine so we will work on this part this is our critical node or you can see the unbalanced node and with this node as unbalanced because of first of all this right insertion and then left insertion so here it is right left rotation and how to solve this right left rotation first right rotation - rotation would be there first right rotation and then left rotation okay see first right rotation how the tree would be constructed 14 here we have seven here we have 17 here we have 53 here we have four now first of all right rotation take a right rotation is Takeshi of the right rotation would be on this part because we will make it right a right rotation okay so this 13 would be pulley down and 12 will go up seven here we have 11 now here this 12 will go up and 13 would go and there only fine so now this becomes right and right are our rotation still this is unbalanced because the balance factor of 11 is minus 2 still it is unbalanced and it is having minus 1 it is having 0 now next part is first is right rotation next is left rotation to have near R&R the one left rotation would be there and the tree would be 14 17:53 here we have 7 here we have force and do this left rotation left rotation means pull down this 11 the side left side then 12 would go up 12 this side left side of 12 is 11 and right side is 13 fine so this is a balanced string or simple trick is see this is right or left rotation always you have to take care the median element of these three would be the root and remaining two elements would be the children see you can check out out of eleven twelve and thirteen which one is the middle element or the median element out of eleven twelve and thirteen or baselet well now see after two rotation right and left we got what to L is the root and eleven and thirteen would be the children so it is BST so you can easily do this here to the left of 1211 would be there and to the right of 2013 would be there yes this is the simple trick find out the median element and that would be the root okay now this is balanced tree you can check out by finding the balance factor of each and every node fine now next next you how to insert is this 8 okay now where this 8 would be inserted left over 14 it is greater than 7 go to the right part it is less than 12 or to the left part it is less than this 11 go to the left part this is 8 pi now see find out the balance vector after every insertion you're supposed to find out the balance vector balance factor of this 8 is zero balance spectro this one is 1-0 that is 1/12 Kelley a 1/2 2 minus 1 that is 1 here we have zero and here we have 1 minus 1 2 & 3 see balance factor of 7 is height of left subtree is 1 minus height of right subtree of the 7 is 1 2 & 3 right 1 minus 3 that is minus 2 so you can take a 1 and 2 you can write height 1 minus 2 you are supposed to check the longest height go to the leaf the 1 2 & 3 that is minus 2 all right so this 7 is now a critical node okay now why this minus 2 y the 7 is unbalanced find out the reason because because of this first of all this right insertion and then this left insertion because of this right and left the left this node is unbalanced so you will work on this part seven - Ln 11 fine say right and left right and left - rotation would be their first right rotation then left rotation okay we have discussed in detail with the help of this case now second the shortcut is what just find out the median element out of seven twelve and eleven what is the median element seven eleven or twelve c7 K by the eleven I can then to Eliza became BST in sorted order then what is the median element amid an element is eleven okay so eleven would be the root and seven and 12 would be children of this eleven okay now the three would be something like this see after this the tree would be 40 1753 see that part is unaffected part fine now out of this 11 is median so 11 would be to the go to the root here 11 would be there fine and 7 and to a large children of this 11th oh seven eight children off 11th and seven obviously would go to the left part because seven is less than 11 and 12 would go to the right part with us 2 L is greater than 11 now where this four would go for will go to the left part of 7c left part of 7 schedule right for now where this 13 would go 13 is to the right of 2 L say check out industry because we are creating this from this only we're balancing out the string so 13 is to the right of 2 n fine and where this 8 would go now check out 8 is to the left of 11 in this tree so basically in this tree the 8 would be to the left of 11 right now go to the 11 node having key 11 now we're to the left of 11 but you can't insert 8 at this place because here is 7 only so it would go to the right of 7 why so because 8 is greater than 7 and this is BST so you know the rule very well because the element greater than that node will go to the right of that mode fine so this is a BST now and this is balanced you can check out this by checking out the balance factor of each and every node fine ok now next inserted element is what 60 where the 60 would be inserted 60 always check out from the root greater than 14 and greater than 17 greater than 50 53 the 60 would be inserted here only fine now find out the balance vector balance factor of 60 is zero balance factor of 53 zero minus 1 that is minus 117 is zero minus 2 that is minus 2 here we have some problem because it is not minus 1 or 0 not 1 okay now and balance factor of each and every is 0 0 0 here we have 0 minus 1 minus 1 here we have 1 minus 1 0 here we have 2 minus 2 0 I know you do not find out the benefit of this one because we have this node unbalanced so you're supposed to balance it out first of all so you will work on this part and the 17 is unbalanced because first of all this right insertion again right insertion that is our our rotation a rotation make out there 1 left rotation would be there fine like this 17 would be pulled down 53 would go or you can say the median element find out the median element out of these three elements out of 1753 and 60 what is the median element or middle element 53 53 would be the root and 17 and 60 would be children of this 50 53 now then over the tree would be C will draw this tree here really fine this 14 the left subtree would be unaffected 11 7 here we have 4 here we have 8 here we have 12 here you have 13 now the middle element is 53 53 would go up that is 53 becomes the root 17 and 60 would be the children 17 is less than 53 so it would go to the left part 60s would go to the right part okay now the you can check out the balance web profusion of your node industries balanced now insert 19 where 19 would be inserted greater than 14 less than 53 greater than 17 letters here 19 would be inserted fine you can find out the balance factor of each and every node and still this tree is balanced fine okay now 16 would be inserted where 16 would be inserted 16 would be inserted to the left of 17 here 16 would be inserted still this trace is balanced you can find out the balance vector 0 0 1 minus 1 0 1 2 2 minus 1 1 balanced 0 0 0 0 2 minus 2 0 here we have 0 here we have 0 minus 1 1 here we have 1 2 3 3 minus 1 2 3 3 minus 3 is 0 ok now insert this 20/20 would be inserted here only to the right of 19 now check out the balanced vector the balanced factor of 20 is 0 balanced factor of 19 is 0 minus 1 that is minus 1 16 is 0 17 1 minus 2 that is minus sorry 1 minus 2 that is minus 1 ok and balanced factor of 53 is what balanced factor of 53 is height of left subtree C 1 2 but 3 also go to the last level after 16 C 16 is you can see it this place only 16 so height of left subtree is 1 2 and this 3 the longest hide the longest distance from that node to de you know that leaf node you are supposed to go 3 minus 1 that is minus 2 so this 53 is our critical node or you can say the unbalanced node why this tree is unbanned why this sorry node is unbalanced because of left insertion and then right insertion okay you're supposed to find out the reason though here with rotation would be there left and then right so you would work on this part only on these three in 150 37919 okay now in left/right rotation how to solve this out we are supposed to do two rotation first is left then right okay left rotation on these two elements take a left rotation means 17 would go below and 19 would go up 19 a happy I got 17 I got then it would become left and left I'll draw see 14 left part is as it is okay 7 8 12 and 13 first see we have left right then first rotation would be left rotation left rotation because you're supposed to make it these type of you know that shape to the either ll rotation or RR rotation so here we can make it ll rotation because barely have any path starting here L this coal left banana clearly we will pull this this 17 below or 19 would go up then 53:19 would go up 17 would go below 17 k left make it happen a pass 16 right Oh 53 we have 60 and to the right of this 20s to the right of 19 here we have 20 it is unbalanced still see this is having 53 is having the balance factor is - sorry 1 2 3 3 minus 1 that is 2 here we have sorry - okay now 17 this would have 0 this would have 1 this would have 1 - 2 - 1 1 now it becomes L L rotation left left ll rotation see Ln fine ll rotation gases all what the a you will do one right rotation right rotation upkeep in Tonopah Casio V you will pull up pull this 53 down and 19 would go then the tree would be 14 11 7 4 8 here we have 2 else here we have 13 now do the right rotation 53 would go down in 19min go up so 19 would become the root to the right of 19 we will have 53 and 60 would be to the right of 53 fine and 19k left make a hog aapke 17 17 key left maybe have 16 where this 20 would go check out 20 is to the right of 19 now check out right of 19 you can't answer 20 here so 20 would be inserted to the left of 53 because 20 is less than 53 ok now this would be our tree or fine simply you can use the shortcut left and right rotation you are supposed to balance out this part find out the median element of these three elements - 17 1953 a median element would be C don't check out you pirelli 53 here then 17 then 19 the median median element would be 17 oh it is BS Tina so try to write down that data in sorted order first 17 then 19 then 53 now find out the median element median element is 19 19 would become the root okay 17 and 53 would become the children of that mode how many a same thing we have done 19 is the root fine sorry 19 is the root and 70 and 53 are the children of this 90 fine here see if you don't go this long processor with this left/right means to rotation first left rotation then right rotation then simply find out the median element then median element would become the root and remaining two elements would become the the left hand right child of that note fine that is the shortcut here nineteen is median element seventeen and fifty-three are child of children of this nineteen and then find out the proper place for though for this remaining element sixteen and twenty see somewhere you're supposed to you know can you have to keep in mind that this should be a BST so like that they see twenty if you want to insert 20 then 20 is to the right of this nineteen but in the right of this 1953 is there so it's not like you can insert twenty here or maybe twenty to the right of this nineteen find out the proper place for nine didn't go to the right of nineteen and then find out the proper place is to integrate proper places to the left of fifty-three because this is less than fifty three okay so this is how the data is to be inserted in AVL tree in the next video I'll discuss with you how to delete data from a via three till then bye-bye take it ",
            "url": "www.youtube.com/watch?v=_8qqlVH5NC0",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "N9EwTeMJl5s",
            "channelId": "UC63URkuUvnugRBeTNqmToKg",
            "publishedAt": "2019-08-02T05:00:02Z",
            "title": "AVL TREE - DATA STRUCTURES",
            "description": "AVL TREES AVL tree is a self-balancing Binary Search Tree (BST) where the difference between heights of left and right subtrees cannot be more than one for ...",
            "channelTitle": "Sundeep Saradhi Kanthety",
            "transcript": "[Music] hello friends welcome back to our channel so in the previous session we have seen the different operations that can be performed on binary search tree so from today's session will start the another type of binary tree that is AV editing right so this is also a type of binary tree that means it's a type of binary tree that means it satisfies the property of a binary tree that means every node should contain a close to two children that means every node in this tree should have at least a 0 or a 1 or 2 chainz not more than 2 change right there is a property of violently or we can simply we can also say that it's a variant of binary search III my research tree so it should weigh the property of binary search tree also that makes all the elements which are on the left subtree should be less than the hoop phone and all the elements of right subtree should be less greater than than so it should go better the property of binary search tree nodes and this is a self of balancing by research self balancing my research self oberlin see by this entry which was invented by Harrison brusky and Elena's so these three persons invented the cell balancing by literally so that that's why it was named as a BLT so where is this self balancing what is it self management so self balancing means here the balancing of heights of left sub-tree and white circles so balancing heights of left and right subtrees so balancing them left and right centers so this is measured in terms of dancing factor balancing factor right so balancing factor so what is this balancing factor and how to calculate this balancing factor and if this tree obeys this binary search tree always this balancing factor then only we can call that as it EVLT so this balancing factor is nothing but hide off left subtree - hide off right sudden right so that means the difference of height of left sub-tree and right center so that is that use the balancing factor which can be either 0 1 or minus 1 it is 0 1 4 minus 1 so that means we can see every node should satisfy this balancing factor that means every node must have the well balancing factor and either 0 or 1 or minus 1 right so we hope you understand this AVL tree should satisfy the binary sensitive property along with that binary search tree property it also satisfies this balancing factor that means every node so contain the balancing factor either 0 1 or minus 1 what is the 0 1 minus 1 how to calculate this balancing factor there is a difference between the height of left subtree and the right sub right so first of all height how to calculate the height it's a 1 spot from these two from leaf node to that node so from where we are finding the height so the leaf node to that node the longest path gives the height of a node so height of a sub tree - a height of the right subtree then we'll see an example so don't get confused so it should satisfy the binary search it a property right so it should satisfy binary tree and also it should satisfy that self balancing that puts balancing factor every node should have the balancing factor at their 0 1 or minus 1 if any node is having other than these 3 values either 0 1 or minus 1 that implies that is not an AVL tree that doesn't call it as it we agree right so let us see an example and let us see how do we get a 0 1 or a minus 1 let us take an example for yeah let us take this example first see let us take this example first so if you consider if you consider this example we know that this one is the left - subtree and this one is a right sample right no balancing factor what is the balancing factor see balancing factor first binary search tree some binary search tree means all the elements which are on the left subtree are less than the root node all the elements which are on the right subtree are greater than the so excited binary search tree then coming to this balancing factor what is the balancing factor for 80 so that is nothing but kind of left subtree - height of my sudden so what is the height of left subtree - - what's a better right subtree 1 which is equal to 1 which is equal to 1 right so it is in the 0 1 1 - 1 so it satisfies the condition of aviary so this is called again right so if this we have to serve 3 is having fewer Allah means 30 and some 45 and again it is having 20 and the 30 final now what's the result so what is the left subtree of this 80 so 1 2 3 4 hi this 4 1 2 3 & 4 hi teaspoon try accepted one will get 3 which is not equal to 0 1 or minus 1 so this is not a every l3 not an AVL tree so because every Lord should have the balancing factor is a zero one or minus one which violates this condition okay so that's why this is not a ability see according to the relevancy factor so we have to calculate this balancing factor for every node every node right so if this dancing factor is a minus one if this balancing factor is a minus one this tree is called as right heavy area tree right heavy immunity or heavy light immunity or heavy height in right if it is a zero it is called balancing again it is one that we call it as heavy left area it is quite a heavy left a theater right so this is how we can consider so which type of AVL tree it is based upon the balancing factor right so we are supposed to find this balancing factor for every node of it binary search tree if it satisfies then we can call it as a where is it so let us take this example see if you find the balancing factor for this one the NC factor for this one height of left 3 that means it 2 minus 1 which is 1 so what is one heavy left on left heavy heavy left arm left leg that's the heavy tree right so heavy right now right banned city right so based upon this balancing factor value we can have whether it is a left TV or right there we or a balance it so this is we are getting the balancing factor will read one so we can call it as it left the heavy balancing T because the height of left is greater than the height of right height of left is greater than height of right so if you avoid this one if you consider this 190 in 110 C in this the balancing factor is height or I left sub-tree head of left deceptive means 1 - hi - fried circuitry - which is not equal to which is equal to minus 1 so it is within the given balancing factors so if it is a minus 1 it is called as a right heavy tree right heavy tree because here we can observe that the height of limb is less than fight of right or height of right is greater than a top left so we can get the minus 1 so we can say it has a right heavy tree or heavy right and if you have this one see 40 60 so if you consider this one this is also satisfies the binary search should be called all the elements on the left subtree then the root element of the all the elements of which are greater than the root element or 1 right subtree so it satisfies the binary search tree property and Emily this balance factor say if you observe this one so balancing factor for every road every node we can check for every node right so here the right subtree height is 2 and left subtree height is 2 which is equal to 0 which is equal to 0 that means the height of left subtree is equal to height of right subtree so if it is you know we count as a battle secretary or a balance of three a very balanced in a be empty so this is how we can find whether the given three is a binary search tree or AVL tree so every three is also one type of binary search tree with a balancing factor so that's why we can call it as a AVL tree can be called as self-balancing binary search tree and operations can be performed on this one those are insertion and deletion so operations are insertion and deletion so these two operations that can be performed on these AVL things so while after inserting on are after deleting that should not deviate this balancing factor so that means if you insert an element into this AVL tree that may disturb the property of a BLT that may disturb the balancing factor right so we have to take care while inserting an element so that the balancing factor should not change that means the property of a will eventually should not violate right so that should be taken care by inserting an element or a deleting an element from event right so we'll see these operations in the next session so hope you understood this one so AVL tree is also a variant of binary search tree that we call it as a self-balancing binary tree binary search tree that means here we have to find the balancing factor which which is nothing but the height the difference between the height of a left subtree and the right subtree so the values may be minus 1 0 or 1 so if the height of height of left subtree is a greater than height of right subtree will get a value of 1 then that will call it as it left a heavy t and if if the height of right subtree is greater than height of left subtree we get a minus 1 and we will call it as a white-headed thing and hit the height of right subtree and height of left subtree both are equal then we get a zero value and that is for a balancing or a balancing kvl thing so this is how we can find whether the given given three is a binary search tree tree or an AVL tree so hope you understood this property of AVL tree right so we have to find this balancing factor for every node in the tree so every node in the tree should satisfy this balancing factor so that means every node in the tree should have either minus 1 0 or 1 as a balancing factor right so hope you understood this one and if you are having any doubts regarding this introduction so feel free to post your talks in the comment section so that definitely I will try to clarify all your doubts and there are you if you really understood my sessions like my sessions share processions with your friends and don't forget to subscribe to our channel thanks for watching and keep following our channel thank you very much ",
            "url": "www.youtube.com/watch?v=N9EwTeMJl5s",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "FNeL18KsWPc",
            "channelId": "UCEBb1b_L6zDS3xTUrIALZOw",
            "publishedAt": "2013-01-14T20:26:48Z",
            "title": "6. AVL Trees, AVL Sort",
            "description": "MIT 6.006 Introduction to Algorithms, Fall 2011 View the complete course: http://ocw.mit.edu/6-006F11 Instructor: Erik Demaine License: Creative Commons ...",
            "channelTitle": "MIT OpenCourseWare",
            "transcript": "The following\ncontent is provided under a Creative\nCommons license. Your support will help MIT\nOpenCourseWare continue to offer high-quality\neducational resources for free. To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Continuing\nin the theme of sorting in general, but\nin particular, binary search trees, which are a\nkind of way of doing dynamic sorting,\nif you will, where the elements are\ncoming and going. And at all times, you want\nto know the sorted order of your elements by storing them\nin a nice binary search tree. Remember, in general, a\nbinary search tree is a tree. It's binary, and it has\nthe search property. Those three things. This is a rooted binary tree. It has a root. It's binary, so there's a\nleft child and a right child. Some nodes lack a\nright or left child. Some nodes lack both. Every node has a key. This is the search part. You store key in every node,\nand you have this BST property, or also called the\nsearch property, that every node-- if you\nhave a node the stores key x, everybody in the left subtree\nstores a key that's less than or equal to x, and everyone\nthat's in the right subtree stores a key that's\ngreater than or equal to x. So not just the left\nand right children, but every descendant way\ndown there is smaller than x. Every descendent way down\nthere is greater than x. So when you have a binary\nsearch tree like this, if you want to know\nthe sorted order, you do what's called\nan in-order traversal. You look at a node. You recursively\nvisit the left child. Then you print out the root. Then you recursively\nvisit the right child. So in this case, we'd\ngo left, left, print 11. Print 20. Go right. Go left. Print 26. Print 29. Go up. Print 41. Go right. Print 50. Print 65. Then check that's\nin sorted order. If you're not familiar\nwith in-order traversal, look at the textbook. It's a very simple operation. I'm not going to talk\nabout it more here, except we're going to use it. All right, we'll get to the\ntopic of today's lecture in a moment, which is balance. What we saw in last\nlecture and recitation is that these\nbasic binary search trees, where when you insert\na node you just walk down the tree to find where that item\nfits-- like if you're trying to insert 30, you go left here,\ngo right here, go right here, and say, oh 30 fits here. Let's put 30 there. If you keep doing that,\nyou can do insert. You can do delete. You can do these\nkinds of searches, which we saw, finding\nthe next larger element or finding the next\nsmaller element, also known as successor and predecessor. These are actually the typical\nnames for those operations. You can solve them\nin order h time. Anyone remember what h was? The height. Yeah, good. The height of the tree. So h is the height of the BST. What is the height of the tree? AUDIENCE: [INAUDIBLE]. PROFESSOR: Sorry? AUDIENCE: [INAUDIBLE]. PROFESSOR: Log n? Log n would be great,\nbut not always. So this is the issue\nof being balance. So in an ideal\nworld, your tree's going to look\nsomething like this. I've drawn this picture probably\nthe most in my academic career. This is a nice, perfectly\nbalanced binary search tree. The height is log n. This would be the balance case. I mean, roughly log n. Let's just put theta\nto be approximate. But as we saw at the\nend of last class, you can have a very unbalanced\ntree, which is just a path. And there the height is n. What's the definition of height? That's actually what\nI was looking for. Should be 6.042 material. Yeah? AUDIENCE: Is it the\nlength of the longest path always going down? PROFESSOR: Yeah, length of the\nlongest path always going down. So length of the longest path\nfrom the root to some leaf. That's right. OK, so this is-- I highlight this\nbecause we're going to be working a lot\nwith height today. All that's happening here, all\nof the paths are length log n. Here, there is a\npath of length n. Some of them are shorter,\nbut in fact, the average path is n over 2. It's really bad. So this is very unbalanced. I'll put \"very.\" It's not a very formal\nterm, but that's like the worst case for BSTs. This is good. This does have a\nformal definition. We call a tree balanced if\nthe height is order log n. So you're storing n keys. If your height is\nalways order log n, we get a constant factor here. Here, it's basically exactly\nlog n, 1 times log n. It's always going to\nbe at least log n, because if you're storing\nn things in a binary tree, you need to have\nheight at least log n. So in fact, it will be theta\nlog n if your tree is balanced. And today's goal is\nto always maintain that your trees are balanced. And we're going to do\nthat using the structure called AVL trees, which\nI'll define in a moment. They're the original\nway people found to keep trees balanced\nback in the '60s, but they're still\nkind of the simplest. There are lots of ways\nto keep a tree balanced, so I'll mention some other\nbalance trees later on. In particular, your textbook\ncovers two other ways to do it. It does not cover AVL\ntrees, so pay attention. One more thing I\nwanted to define. We talked about the\nheight of the tree, but I'd also like to talk about\nthe height of a node in a tree. Can anyone define this for me? Yeah? AUDIENCE: It's the level\nthat the node is at. PROFESSOR: The level\nthat the node is at. That is roughly right. I mean, that is right. It's all about, what\nis the level of a node? AUDIENCE: Like how many\nlevels of children it has. PROFESSOR: How many\nlevels of children it has. That's basically right, yeah. AUDIENCE: The distance\nfrom it to the root. PROFESSOR: Distance\nfrom it to the root. That would be the depth. So depth is counting from above. Height is-- AUDIENCE: [INAUDIBLE]. PROFESSOR: Yes, longest path\nfrom that node to the leaf. Note that's why I wrote\nthis definition actually, to give you a hint. Here I should probably\nsay down to be precise. You're not allowed to\ngo up in these paths. [INAUDIBLE] All right. Sorry. I've got to learn how to throw. All right. So for example, over here I'm\ngoing to write depths in red. If you're taking notes it's OK. Don't worry. So length off the longest\npath from it down to a leaf. Well, this is a leaf,\nso its height is 0. OK. Yeah, I'll just\nleave it at that. It takes 0 steps to get\nfrom a leaf to a leaf. This guy's not a leaf. It has a child, but it has a\npath of length one to a leaf. So it's one. This guy has a choice. You could go left and you\nget a path of length 1, or you could go right and\nget a path of length 2. We take the max, so\nthis guy has height 2. This node has height 1. This node has height 3. How do you compute\nthe height of a node? Anyone? Yeah. AUDIENCE: Max of the height\nof the children plus 1. PROFESSOR: Right. You take the max of the\nheight of the children. Here, 2 and 1. Max is 2. Add 1. You get 3. So it's going to always\nbe-- this is just a formula. The height of the\nleft child maxed with the height of the\nright child plus 1. This is obviously\nuseful for computing. And in particular, in\nlecture and recitation last time, we saw\nhow to maintain the size of every tree using\ndata structure augmentation. Data structure augmentation. And then we started with a\nregular vanilla binary search tree, and then we\nmaintained-- every time we did an operation\non the tree, we also updated the size of\nthe subtree rooted at that node, the size field. Here, I want to\nstore a height field, and because I have this nice\nlocal rule that tells me how to compute the height\nof a node using just local information-- the height\nof its left child, the height of its right child. Do a constant\namount of work here. There's a general theorem. Whenever you have a\nnice local formula like this for updating\nyour information in terms of your children,\nthen you can maintain it using constant overhead. So we can store the height\nof every node for free. Why do I care? Because AVL trees are going to\nuse the heights of the nodes. Our goal is to keep\nthe heights small. We don't want this. We want this. So a natural thing to\ndo is store the heights. When they get too big, fix it. So that's what\nwe're going to do. Maybe one more thing to mention\nover here for convenience. Leaves, for example, have\nchildren that are-- I mean, they have null pointers to\ntheir left and right children. You could draw them\nexplicitly like this. Also some nodes just\nlack a single child. I'm going to define the\ndepths of these things to be negative 1. This will be\nconvenient later on. Why negative 1? Because then this formula works. You can just think about it. Like leaves, for example,\nhave two children, which are negative 1. You take the max. You add 1. You get 0. So that just makes\nthings work out. We don't normally draw\nthese in the pictures, but it's convenient that I don't\nhave to do special cases when the left child doesn't exist and\nthe right child doesn't exist. You could either\ndo special cases or you could make\nthis definition. Up to you. OK. AVL trees. So the idea with an AVL\ntree is the following. We'd like to keep the\nheight order log n. It's a little harder to think\nabout keeping the height order log n than it is to think\nabout keeping the tree balance, meaning the left and right\nsides are more or less equal. In this case, we're\ngoing to think about them as being more or\nless equal in height. You could also think\nabout them being more or less equal\nin subtree size. That would also work. It's a different\nbalanced search tree. Height is kind of the\neasiest thing to work with. So if we have a node,\nit has a left subtree. It has a right subtree,\nwhich we traditionally draw as triangles. This subtree has a height. We'll call it HL for left. By the height of the subtree,\nI mean the height of its root. And the right subtree\nhas some height, r. I've drawn them as the\nsame, but in general they might be different. And what we would like\nis that h sub l and h sub r are more or less the same. They differ by at\nmost an additive 1. So if I look at h sub l minus\nh sub r in absolute value, this is at most\n1, for every node. So I have some node x. For every node x, I want\nthe left and right subtrees to be almost balanced. Now, I could say\ndiffer by at most 0, that the left and right have\nexactly the same heights. That's difficult,\nbecause that really forces you to have\nexactly the perfect tree. And in fact, it's not even\npossible for odd n or even n or something. Because at the very\nend you're going to have one missing child, and\nthen you're unbalanced there. So 0's just not\npossible to maintain, but 1 is almost as\ngood, hopefully. We're going to prove\nthat in a second. And it turns out to be easy\nto maintain in log n time. So let's prove some stuff. So first claim is that\nAVL trees are balanced. Balanced, remember, means\nthat the height of them is always order log n. So we're just going to assume\nfor now that we can somehow achieve this property. We want to prove that it\nimplies that the height is at most some\nconstant times log n. We know it's at\nleast log n, but also like it to be not much bigger. So what do you think\nis the worst case? Say I have n nodes. How could I make the\ntree as high as possible? Or conversely, if I have\na particular height, how could I make it have\nas few nodes as possible? That'd be like the\nsparsest, the least balanced situation for AVL trees. Yeah? AUDIENCE: You could have\none node on the last level. PROFESSOR: One node on the last\nlevel, yeah, in particular. Little more. What do the other\nlevels look like? That is correct, but I want\nto know the whole tree. It's hard to explain\nthe tree, but you can explain the core\nproperty of the tree. Yeah? AUDIENCE: [INAUDIBLE]. PROFESSOR: For every\nnode, let's make the right side have a height of\none larger than the left side. I think that's worth a cushion. See if I can throw better. Good catch. Better than hitting your eye. So I'm going to not\nprove this formally, but I think if you stare\nat this long enough it's pretty obvious. Worst case is when-- there\nare multiple worst cases, because right and\nleft are symmetric. We don't really care. But let's say that\nthe right subtree has height one more than\nthe left for every node. OK, this is a little\ntricky to draw. Not even sure I want\nto try to draw it. But you basically\ndraw it recursively. So, OK, somehow I've\nfigured out this where the height\ndifference here is 1. Then I take two copies of it. It's like a fractal. You should know all\nabout fractals by now. Problem set two. And then you just-- well,\nthat's not quite right. In fact, I need to somehow\nmake this one a little bit taller and then\nglue these together. Little tricky. Let's not even try\nto draw the tree. Let's just imagine\nthis is possible. It is possible. And instead, I'm going\nto use mathematics to understand how\nhigh that tree is. Or actually, it's\na little easier to think about-- let\nme get this right. It's so easy that I\nhave to look at my notes to remember what to write. Really, no problem. All right, so I'm\ngoing to define n sub h is the minimum number\nof nodes that's possible in an AVL\ntree of height h. This is sort of the inverse\nof what we care about, but if we can solve the\ninverse, we can solve the thing. What we really care about\nis, for n nodes, how large can the height be? We want to prove\nthat's order log n. But it'll be a lot easier to\nthink about the reverse, which is, if I fix the height to\nbe h, what's the fewest nodes that I can pack in? Because for the very unbalanced\ntree, I have a height of n, and I only need to put n nodes. That would be really bad. What I prefer is a situation\nlike this, where with height h, I have to put in\n2 to the h nodes. That would be perfect balance. Any constant to the h will do. So when you take the\ninverse, you get a log. OK, we'll get to\nthat in a moment. How should we analyze n sub h? I hear something. Yeah? AUDIENCE: [INAUDIBLE] 2 to\nthe h minus 1 [INAUDIBLE]. PROFESSOR: Maybe, but I don't\nthink that will quite work out. Any-- yeah? AUDIENCE: So you have only\n1 node in the last level, so it would be 1/2\nto the h plus 1. PROFESSOR: That turns out\nto be approximately correct, but I don't know where you\ngot 1/2 to the h plus 1. It's not exactly correct. I'll tell you that, so that\nyour analysis isn't right. It's a lot easier. You guys are worried\nabout the last level and actually what the tree looks\nlike, but in fact, all you need is this. All you need is love, yeah. AUDIENCE: [INAUDIBLE]. PROFESSOR: No, it's not a half. It's a different constant. Yeah? AUDIENCE: Start with base cases\nand write a recursive formula. PROFESSOR: Ah,\nrecursive formula. Good. You said start with base cases. I always forget that part, so\nit's good that you remember. You should start\nwith the base case, but I'm not going to\nworry about the base case because it won't matter. Because I know the base case\nis always going to be n order 1 is order 1. So for algorithms,\nthat's usually all you need for base case, but it's\ngood that you think about it. What I was looking for\nis recursive formula, aka, recurrence. So can someone tell me--\nmaybe even you-- could tell me a recurrence for n sub h,\nin terms of n sub smaller h? Yeah? AUDIENCE: 1 plus [INAUDIBLE]. PROFESSOR: 1 plus\nn sub h minus 1. Not quite. Yeah? AUDIENCE: N sub h minus\n1 plus n sub h minus 2. PROFESSOR: N plus-- do\nyou want the 1 plus? AUDIENCE: I don't think so. PROFESSOR: You do. It's a collaboration. To combine your\ntwo answers, this should be the correct formula. Let me double check. Yes, whew. Good. OK, why? Because the one thing we know is\nthat our tree looks like this. The total height here is h. That's what we're\ntrying to figure out. How many nodes are in\nthis tree of height h? Well, the height is the\nmax of the two directions. So that means that the\nlarger has height h minus 1, because the longest\npath to a leaf is going to be down this way. What's the height of this? Well, it's one less\nthan the height of this. So it's going to be h minus 2. This is where the n sub h minus\n1 plus n sub h minus 2 come in. But there's also this node. It doesn't actually make a big\ndifference in this recurrence. This is the exponential part. This is like itty bitty thing. But it matters for the\nbase case is pretty much where it matters. Back to your base case. There's one guy here, plus\nall the nodes on the left, plus all the nodes on the right. And for whatever\nreason, I put the left over here and the\nright over here. And of course, you could\nreverse this picture. It doesn't really matter. You get the same formula. That's the point. So this is the recurrence. Now we need to solve it. What we would like is\nfor it to be exponential, because that means there's a\nlot of nodes in a height h AVL tree. So any suggestions on\nhow we could figure out this recurrence? Does it look like anything\nyou've seen before? AUDIENCE: Fibonacci. PROFESSOR: Fibonacci. It's almost Fibonacci. If I hid this plus 1,\nwhich you wanted to do, then it would be\nexactly Fibonacci. Well, that's actually good,\nbecause in particular, n sub h is bigger than Fibonacci. If you add one at\nevery single level, the certainly you\nget something bigger than the base\nFibonacci sequence. Now, hopefully you know\nFibonacci is exponential. I have an exact formula. If you take the golden ratio to\nthe power h, divide by root 5, and round to the\nnearest integer, you get exactly the\nFibonacci number. Crazy stuff. We don't need to\nknow why that's true. Just take it as fact. And conveniently phi\nis bigger than 1. You don't need to\nremember what phi is, except it is bigger than 1. And so this is an\nexponential bound. This is good news. So I'll tell you\nit's about 1.618. And so we get is that--\nif we invert this, this says n sub h is bigger\nthan some phi to the h. This is our n, basically. What we really\nwant to know is how h relates to n, which is\njust inverting this formula. So we have, on the\nother hand, the phi to the h divided by\nroot 5 is less than n. So I got a log base\nphi on both sides. Seems like a good thing to do. This is actually quite annoying. I've got h minus a\ntiny little thing. It's less than\nlog base phi of n. And I will tell you that is\nabout 1.440 times log base 2 of n, because after all,\nlog base 2 is what computer scientists care about. So just to put it\ninto perspective. We want it to be\ntheta log base 2 of n. And here's the bound. The height is always less\nthan 1.44 times log n. All we care about\nis some constant, but this is a pretty\ngood constant. We'd like one. There are binary search tress\nthat achieve 1, plus very, very tiny thing, arbitrarily\ntiny, but this is pretty good. Now, if you don't know\nFibonacci numbers, I pull a rabbit out of a hat\nand I've got this phi to the h. It's kind of magical. There's a much easier way\nto analyze this recurrence. I'll just tell you because\nit's good to know but not super critical. So we have this\nrecurrence, n sub h. This is the computer scientist\nway to solve the recurrence. We don't care about\nthe constants. This is the theoretical\ncomputer scientist way to solve this recurrence. We don't care about constants. And so we say, aw, this is hard. I've got n sub h minus\n1 and n sub h minus 2. So asymmetric. Let's symmetrify. Could I make them\nboth n sub h minus 1. Or could I make them\nboth n sub h minus 2? Suggestions? AUDIENCE: [INAUDIBLE]. PROFESSOR: Minus\n2 is the right way to go because I want to know n\nsub h is greater than something in order to get a\nless than down here. By the way, I use that\nlog is monatomic here, but it is, so we're good. So this is going to\nbe greater than 1 plus 2 times n sub h minus 2. Because if I have\na larger height I'm going to have more nodes. That's an easy\nproof by induction. So I can combine\nthese into one term. It's simpler. I can get rid of this 1 because\nthat only makes things bigger. So I just have this. OK, now I need a\nbase case, but this looks like 2 the something. What's the something? H over 2. So I'll just write theta\nto avoid the base case. 2 to the h over 2. Every two steps of h, I\nget another factor of 2. So when you invert\nand do the log, this means that h is also\nless than log base 2 of n. Log base 2 because of that. Factor 2 out here\nbecause of that factor 2 when you take the log. And so the real answer is 1.44. This is the correct--\nthis is the worst case. But it's really easy to prove\nthat it's, at most, 2 log n. So keep this in\nmind in case we ask you to analyze\nvariance of AVL trees, like in problem set three. This is the easy way\nto do it and just get some constant times log n. Clear? All right, so that's AVL\ntrees, why they're balanced. And so if we can\nachieve this property, that the left and right subtrees\nhave about the same height, we'll be done. So how the heck do we\nmaintain that property? Let's go over here. Mobius trees are\nsupposed to support a whole bunch of operations,\nbut in particular, insert and delete. I'm just going to worry\nabout insert today. Delete is almost identical. And it's in the code that\ncorresponds to this lecture, so you can take a look at it. Very, very similar. Let's start with insert. Well, it's pretty\nstraightforward. Our algorithm is as follows. We do the simple BST insertion,\nwhich we already saw, which is you walk down the tree\nto find where that key fits. You search for that key. And wherever it isn't,\nyou insert a node there, insert a new leaf,\nand add it in. Now, this will not\npreserve the AVL property. So the second step is\nfix the AVL property. And there's a nice concise\ndescription of AVL insertion. Of course, how do you do step\ntwo is the interesting part. All right, maybe let's\nstart with an example. That could be fun. Hey, look, here's an example. And to match the\nnotes, I'm going to do insert 23 as\na first example. OK, I'm also going to annotate\nthis tree a little bit. So I said we store\nthe heights, but what I care about is which height is\nlarger, the left or the right. In fact, you could\njust store that, just store whether\nit's plus 1, minus 1, or 0, the difference between\nleft and right sides. So I'm going to draw that\nwith a little icon, which is a left arrow, a\ndescending left arrow if this is the bigger side. And this is a right arrow. This is even. Left and right are the same. Here, the left is heavier,\nor higher, I guess. Here it's even. Here it's left. This is AVL, because\nit's only one heavier wherever\nI have an arrow. OK, now I insert 23. 23 belongs-- it's less than 41,\ngreater than 20, less than 29, less than 26. So it belongs here. Here's 23, a brand-new node. OK, now all the heights change. And it's annoying to draw\nwhat the heights are, but I'll do it. This one changes to 1. This is 0. This changes to 2. This changes to 3. This changes to 4. Anyway, never mind\nwhat the heights are. What's bad is, well,\nthis guy's even. This guy's left heavy. This guy's now\ndoubly left heavy. Bad news. OK, let's not worry\nabout above that. Let's just start. The algorithm is going\nto walk up the tree and say, oh, when do\nI get something bad? So now I have 23,\n26, 29 in a path. I'd like to fix it. Hmm, how to fix it? I don't think we know how to\nfix it, so I will tell you how. Actually, I wasn't\nhere last week. So did we cover rotations? AUDIENCE: No. PROFESSOR: OK, good. Then you don't know. Let me tell you about rotations. Super cool. It's just a tool. That's x and y. I always get these mixed up. So this is called\nleft rotate of x. OK, so here's the thing we can\ndo with binary search trees. It's like the only\nthing you need to know. Because you've got search\nin binary search trees and you've got rotations. So when I have a tree like this,\nI've highlighted two nodes, and then there's the\nchildren hanging off of them. Some of these might be\nempty, but they're trees, so we draw them as triangles. If I just do this,\nwhich is like changing which is higher, x or y, and\nwhatever the parent of x was becomes the parent of y. And vice versa, in fact. The parent of y was x, and\nnow the parent of x is y. OK, the parent of a is still x. The parent of b changes. It used to be y. Now it's x. The parent of c was y. It's still y. So in a constant number\nof pointer changes, I can go from this to this. This is constant time. And more importantly, it\nsatisfies the BST order property. If you do an in-order\ntraversal of this, you will get a, x, b, y, c. If I do an in-order traversal\nover here, I get a, x, b, y, c. So they're the same. So it still has BST ordering. You can check more formally. b has all the nodes\nbetween x and y. Still all the nodes\nbetween x and y, and so on. You can check it at\nhome, but this works. We call it a left rotate because\nthe root moves to the left. You can go straight back\nwhere you came from. This would be a\nright rotate of y. OK, it's a reversible operation. It lets you manipulate the tree. So when we have this\npicture and we're really sad because this\nlooks like a mess, what we'd like to do is fix it. This is a path of three nodes. We'd really prefer\nit to look like this. If we could make that\ntransformation, we'd be happy. And we can. It is a right rotate of 29. So that's what\nwe're going to do. So let me quickly copy. I want to rotate 29\nto the right, which means 29 and 26-- this is x. This is y. I turn them, and so\nI get 26 here now, and 29 is the new right child. And then whatever\nwas the left child of x becomes the left\nchild of x in the picture. You can check it. So this used to\nbe the triangle a. And in this case,\nit's just the node 23. And we are happy. Except I didn't\ndraw the whole tree. Now we're happy because\nwe have an AVL tree again. Good news. So just check. This is even. This is right heavy. This is even. This is left heavy still. This is left heavy,\neven, even, even. OK, so now we have an AVL tree\nand our beauty is restored. I'll do one more example. Insert 55. We want to insert 55 here. And what changes is\nnow this is even. This is right heavy. This is doubly left heavy. We're super sad. And then we don't look\nabove that until later. This is more\nannoying, because you look at this thing,\nthis little path. It's a zigzag path, if you will. If I do a right rotation\nwhere this is x and this is y, what I'll get is\nx, y, and then this is b. This is what's in\nbetween x and y. And so it'll go here. And now it's a zag zig\npath, which is no better. The height's the same. And we're sad. I told you, though,\nthat somehow rotations are all we need to do. What can I do? How could I fix\nthis little zigzag? Just need to think\nabout those three nodes, but all I give\nyou are rotations. AUDIENCE: Perhaps rotate 50. PROFESSOR: Maybe rotate 50. That seems like a good idea. Let's try it. If you don't mind, I'm\njust going to write 41, and then there's all\nthe stuff on the left. Now we rotate 50. So 65 remains where it is. And we rotate 50 to the left. So 50 and its child. This is x. This is y. And so I get 55 and I get 50. Now, this is bad from\nan AVL perspective. This is still doubly left\nheavy, this is left heavy, and this is even. But it looks like this case. And so now I can do a\nright rotation on 65, and I will get-- so let me\norder the diagrams here. I do a right rotate on\n65, and I will get 41. And to the right I get 55. And to the right I get 65. To the left I get 50. And then I get the left subtree. And so now this is\neven, even, even. Wow. How high was left subtree? I think it's still left heavy. Cool. This is what some people\ncall double rotation, but I like to call\nit two rotations. It's whatever you prefer. It's not really a new operation. It's just doing two rotations. So that's an example. Let's do the general case. It's no harder. You might say, oh, gosh,\nwhy do you do two examples? Well, because they\nwere different. And they're are two\ncases on the algorithm. You need to know both of them. OK, so AVL insert. Here we go. Fix AVL property. I'm just going to call this\nfrom the changed node up. So the one thing that's\nmissing from these examples is that you might have to\ndo more than two rotations. What we did was look at the\nlowest violation of the AVL property and we fixed it. When we do that,\nthere's still may be violations higher up,\nbecause when you add a node, you change the height\nof this subtree, the height of this subtree,\nthe height of this subtree, and the height of this\nsubtree, potentially. What happened in these\ncases when I was done, what I did fixed one violation. They were all fixed. But in general, there might be\nseveral violations up the tree. So that's what we do. Yeah, I'll leave it at that. So suppose x is the lowest\nnode that is not AVL. The way we find that node\nis we start at the node that we changed. We check if that's OK. We update the heights as we\ngo up using our simple rule. And that's actually not our\nsimple rule, but it's erased. We update the height based on\nthe heights of its children. And you keep\nwalking up until you see, oh, the left is twice,\ntwo times-- or not two times, but plus 2 larger than\nthe left, or vice versa. Then you say, oh, that's bad. And so we fix it. Yeah, question. AUDIENCE: So here we\ncontinue to [INAUDIBLE]. PROFESSOR: Yes. AUDIENCE: [INAUDIBLE]. add n to the level\n[INAUDIBLE] than 1. So add [INAUDIBLE]. PROFESSOR: AVL property's\nnot about levels. It's about left subtrees\nand right subtrees. So the trouble is that 65--\nyou have a left subtree, which has height 2-- or sorry,\nheight 1, I guess-- because the longest path\nfrom here to a leaf is 1. The right subtree\nhas height negative 1 because it doesn't exist. So it's one versus negative 1. So that's why there's\na double arrow. Yeah, good to ask. It's weird with the negative 1s. That's also why I wanted to\ndefine those negative 1s to be there, so the AVL property\nis easier to state. Other questions? All right. Good. I think I want a\nsymmetry assumption here. I don't know why I\nwrote right of x. I guess in modern days\nwe write x dot right. Same thing. OK, I'm going to assume that\nthe right child is the heavier one like we did before. Could be the left. It's symmetric. It doesn't matter. So now there are two\ncases, like I said. I'm going to use\nthis term right heavy because it's super convenient. OK, right heavy\nis what I've been drawing by a\ndescending right arrow. Balance is what I've been\ndrawing by a horizontal line. OK, so we're just distinguishing\nbetween these two cases. This turns out to\nbe the easy case. So we have x, y, a, b, c. Why are we looking\nat the right child? Because we assumed that the\nright one is higher, so that x was right heavy. So this subtree as I've drawn\nit is higher than the left one by 2, in fact. And what we do in this\ncase is right rotate of x. And so we get x, y, a, b, c. I could have drawn this no\nmatter what case we're in, so we need to check\nthis actually works. That's the interesting part. And that's over here. OK, so I said x is right\nheavy, in fact doubly so. y is either right\nheavy or balanced. Let's start with right heavy. So when we do this rotation,\nwhat happens to the heights? Well, it's hard to tell. It's a lot easier to think about\nwhat the actual heights are than just these arrows. So let's suppose x has height k. That's pretty generic. And it's right\nheavy, so that means the y has height k minus 1. And then this is right heavy,\nso this has height k minus 2. And this is something\nsmaller then k minus 2. In fact, because this\nis AVL, we assume that x was the lowest\nthat is not AVL. So y is AVL. And so this is going\nto be k minus 3, and this is going to be k minus\n3 because these differ by 2. You can prove by a simple\ninduction you never get more than 2 out of whack\nbecause we're just adding 1, off by 1. So we got off by 2. So this is the bad situation. Now we can just update\nthe heights over here. So k minus 3 for a, k minus\n3 for b, k minus 2 for c. Those don't change because\nwe didn't touch those trees, and height is about\ngoing down, not up. And so this becomes k minus\n2, and this becomes k minus 1. And so we changed the\nheight of the root, but now you can see\nthat life is good. This is now balanced between\nk minus 3 and k minus 3. This is now balanced between\nk minus 2 and k minus 2. And now the parent of\ny may be messed up, and that's why after this\nwe go to the parent of y, see if it's messed up, but\nkeep working our way up. But it worked. And in the interest\nof time, I will not check the case\nwhere y is balanced, but it works out, too. And see the notes. So the other case is\nwhere we do two rotations. And in general, so here\nx was doubly right heavy. And the else case is\nwhen the right child of x, which I'm going to\ncall z here, is left heavy. That's the one\nremaining situation. You do the same\nthing, and you check that right rotating and\nleft rotating, which makes the nice picture,\nwhich is x, y, z, actually balances everything and\nyou restore the AVL property. So again, check\nthe notes on that. I have a couple minutes\nleft, and instead I'd like to tell you a\nlittle bit about how this fits into big-picture land. Two things I want to talk about. One is you could\nuse this, of course, to sort, which is, if you\nwant to sort n numbers, you insert them and you\ndo in-order traversal. How long does this take? In-order traversal\ntakes linear time. That's the sense in which we're\nstoring things in sorted order. Inserting n items-- well,\neach insert takes h time, but now we're guaranteed\nthat h is order log n. So all the insertions take log\nn time each, n log n total. So this is yet another way to\nsort n items in n log n time, in some ways the\nmost powerful way. We've seen heaps, and\nwe've seen merge sort. They all sort. Heaps let you do two operations,\ninsert and delete min, which a lot of times is all you\ncare about, like in p set two. But these guys,\nAVL trees, let you do insert, delete,\nand delete min. So they're the same\nin those senses, but we have the new\noperation, which is that we can do find next\nlarger and next smaller, aka successor and predecessor. So you can think about what\nwe call an abstract data type. These are the operations\nthat you support, or that you're\nsupposed to support. If you're into Java, you\ncall this an interface. But this is an\nalgorithmic specification of what your data structure\nis supposed to do. So we have operations\nlike insert and delete. We have operations\nlike find the min and things like successor\nand predecessor, or next larger, next smaller. You can take any subset of these\nand it's an abstract data type. Insert, delete, and min is\ncalled a priority queue. So if you just take\nthese first two, it's called a priority queue. And there are many\npriority queues. This is a generic thing\nthat you might want to do. And then the data\nstructure on the other side is how you actually do it. This is the analog\nof the algorithm. OK, this is the specification. You want a priority queue. One way to do it is a heap. Another way to do\nit is an AVL tree. You could do it\nwith a sorted array. You could do lots of\nsub-optimal things, too, but in particular, heaps\nget these two operations. If you want all\nthree, you basically need a balanced\nbinary search tree. There are probably a dozen\nbalanced binary search trees out there, at least a dozen\nbalanced search trees, not all binary. They all achieve log n. So it doesn't really matter. There are various practical\nissues, constant factors, things like that. The main reason you prefer a\nheap is that it's in place. It doesn't use any extra space. Here, you've got pointers\nall over the place. You lose a constant\nfactor in space. But from a theoretical\nstandpoint, if you don't care\nabout constant factors, AVL trees are really good\nbecause they get everything that we've seen\nso far and log n. And I'll stop there. ",
            "url": "www.youtube.com/watch?v=FNeL18KsWPc",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "vv0G7QgiGSQ",
            "channelId": "UCKS34cSMNaXaySe2xgXH-3A",
            "publishedAt": "2018-08-08T02:57:03Z",
            "title": "Avl tree | Introduction | Data Structures | Lec-40 | Bhanu Priya",
            "description": "avl tree in data structure introduction.",
            "channelTitle": "Education 4u",
            "transcript": "hi students welcome back coming to the next topic in the subject data structures was AVL trees so far we have discussed about the binary trees and binary search trees now let us see a VL trees actually this a Beale trees or we call it as a height balanced rebound binary trees AVL trees or called as height balanced binary trees so here we are concentrating on the height balanced B or whatever the tree that is there that you have to maintain the height balance I already explained how we are going to calculate the height so whatever the so this is a initial node or the root node okay so from root node to the leaf node you call it as a height okay this is a height of a tree so why we need this high why we need to find the height of a balanced binary tree and why we want to maintain a balanced step on every binary tree actually in the previous the main drawback of binary search trees before going to explain both AVL trees let me explain the drawback of the binary search tree in binary search tree height is not under the control it completely depends on the insertion of elements so it is the main drawback of the binary search tree so in binary search tree height is not under control okay and it completely depends upon the insertion of elements it depends on insertion of element so this is the main drawback of the binary search tree so what it means height is not under control and depends on insertion of elements so let us take whatever the nodes like me a simple example let me take a three nodes three to one so these are the three notes if you want to arrange these or else for neither if you retake this so if these notes if you want to arrange in binary search tree the condition is the left side should be less than the root node and the right side should be greater than root node so let's say it should be ready okay so now whatever the sequence they are given what are the numbers they are given it's completely depends on the insertion of elements so whether you select these thing or else if you take this to as a root load okay one becomes the left node and three is the right node again four is here right node of the three okay if you take one now surname root node and here let's take two three four means the different ways of height here if you take height here okay for this node the height is one two three okay it's height is three and here the height of the left subtree is two and the right is a one so like that the height is very ating so for each and every tree the height is varying but the sequence is the same so we are taking a set of nodes but in binary search tree you can build a tree in whatever the pattern you want you can build okay so here the main drawback is height is not under the control so for this the height is increased for this the height is decreasing and here the height is increasing it is not under the control it completely depends on the insertion of element so whenever the height is going to be increased obviously the time a time T it takes time for searching an element if you want to search an element for you need two to three searching transactions okay so first you have to come to here first you have to come here again you have to come to here means the searching time will be increasing so that is a main drawback of the binary search tree so to avoid diesel drawback and to improve this binary search the efficiency we are using the AVL trees so what is the use of the AVL tree the AVL tree is going to maintain the height balanced so whatever the height here it is thing it is going to maintain the height balance for whatever the pattern you have taken so everything will be balanced so let me explain how it is going to be maintained the height balance of each tree so for this you need to know the balance factor of a node also whatever the tree you're constructing you have to know the calculation of her balanced factor of node the formula for that is balanced factor of a node is equal to height of left subtree - height of right subtree so the balanced factor of a node is equal to height of this left subtree - height of the right subject so AVL is a balanced a tree in which let me write the definition the main use of the AVL trees or height we call AVL trees as a height balanced binary trees so a will is a binary tree in which the difference of so this is the difference the difference of height of height of right and left sub trees of any node any node is less than or equal to one so this is the main condition of the AVL tree so whatever the balance factor you are finding out so that balanced refactor should be is always less than or equal to one node is less let me write less than or equal to one that is height of left subtree - height of right subtree is equal to is in the range of minus 1 0 and 1 so this is the range whenever you maintain that node in this range then you can say that ha the height is balanced in the binary tree okay so this you have to remember that the AVL tree condition was height of left subtree - height of right subtree is in the range of minus 1 or 0 or 1 so this is a balance factor so you can also represent more balanced factor is equal to height of left subtree - height of right subtree it's less than or equal to 1 okay so let me take some examples here and take a simple example so how the height is very 8 you let me take one now so this is a tree okay let me take this as a tree this is a balanced tree so I want to find out the height of this balance tree so if you want to find out the balance factor of each node the formula is height of the left subtree - height of the right subtree okay so if you take this this is the root node and if you want to calculate the height here the height of this the balance factor of this node is the height of left subtree is 2 and the height of the right subtree is 2 2 - 2 0 ok it is in the rain this node is in the range of balance factor that is a balance factor is equal to height of left subtree - height of right subtree should be in the range of 0 sorry - 1 0 and 1 that is a condition so it is 0 this node is satisfied now coming to here we have to calculate the height of D the balanced factor is equal to height of the left subtree - and height of the right subtree is 0 that is 1 okay this is also in this range only now calculate here height of the left subtree 1 and the height of the right subtree is 0 and it is 1 okay so here 1 0 1 so then you can say this tree is balanced because every node height is in between 0 & 1 because every node whatever the node you have taken every node heipiess in between 0 1 0 minus 1 0 & 1 ok so then you can say that tree is balanced because every side is the same let me take another tree now I want to take one tree like so this is a tree now you have to find out whether the tree is balanced or not so first find the balance factor of this node the balance factor of this is right now a height of the left subtree what is the height of the left subtree 1 2 3 so 3 levels are they 3 - and this is 1 so you get 2 2 is not in this range of the AVL tree so we can say that here this is an imbalance tree this is imbalance even the work one node is not satisfied the criteria that the tree is in balanced let me check the other nodes also here the height is left subtree is 0 and right subtrees to 0-2 - - okay this is also not in the range and the leaf nodes always zero height and here one minus zero one okay so this tree is is imbalance because the height of the node is not maintaining the balance factor range so this is imbalanced this tree is in imbalanced just let me take another example I want to make you how to calculate the balance factor if you aware of this finding out the balance factor next you can easily construct the AVL trees the main concept of Favell trees is you have to maintain the it is going to maintain their height balanced balanced tree so whatever the node they are given you have to maintain the height balance so here in this video I am just explaining how what is an imbalance free okay so how this can be rectified that will be explained in the construction of this AVL tree by taking the rotations so this is the node let me take okay now check is this tree is balanced or not the height of the left subtree is 1 and the right is 1 2 3 3 levels are there 1 minus 3 height of left subtree - right subtree is the balance factor minus 2 so minus 2 is not in this range so this is also imbalanced this is imbalanced so let me calculate the other factors also so that you will know how to calculate the balance factor so height of the left subtree is 1 and the height of the right subtree is 2 1 2 so minus 1 okay this satisfied left is 0 and right is minus 1 so I will get minus 1 so even though these two nodes are in the range the here the root node is not in this range so if one node is not satisfied you can say this is imbalanced okay so if the tree is imbalanced based on the balance factor we the factor have to perform rotations to make it a balance free so the main thing is if you want to make this imbalance tree as a balance tree we have to perform rotations so that I'll explain in the next video so how we are doing rotations on the imbalance tree and how we are going to make it as constructing the AVL tree by making it as a balanced thank you ",
            "url": "www.youtube.com/watch?v=vv0G7QgiGSQ",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "5C8bLQBjcDI",
            "channelId": "UCEO__8sckBJ-AFQTjVPSIRg",
            "publishedAt": "2012-01-03T05:49:56Z",
            "title": "AVL Trees Tutorial",
            "description": "CS Learning 101 cslearning101 has temporarily disbanded due to conflicting work schedules and will be unable to post new videos or answer any questions.",
            "channelTitle": "TechRetox",
            "transcript": "hello today I'm going to talk about AVL trees AVL trees are a special type of tree that you would use in computer programming it is a binary search tree if you don't know what that is then please look at one of our other videos but there's one other condition that an AVL tree has it has a balance property what it means is that the tree must always be balanced at all times that means the height of the left subtree in the height of the right subtree can only differ it by at most one what does balance mean for a tree to balance the value has to be a 1 0 or negative 1 to calculate the balance of a tree you would take the height of the tree on the left side and the height of the tree on the right side that is the height of the root roots left branch and the height of the roots break branch here's an example this tree I show each node individually in the list here and it tells you what the balances of each node notice that the height of each node is 0 and except for 13 which is negative 1 because it took the height of the left tree which is 0 and height of the right tree which is 1 so it said 0 times 1 at 0 minus 1 which is negative 1 now what if we insert 16 okay so now we have we have to recalculate the balances of the nodes of the tree and if we do that we notice that the number 13 now has a balance of negative 2 that's bad but I just told you negative 1 0 & 1 are the only values we can have for the heights if there's anything else that comes up then this tree is unbalanced and therefore it would not be an AVL tree to make it an AVL tree again we have to rebalance it when you try to rebalance a tree after inserting something there are 4 possible different situations first that you've inserted a new element into the left subtree at the left child that you've inserted it into the right subtree of the right child if that you've entered into the left subtree of the right child or you've inserted into the right subtree of the left child and for each one if you have to rebalance the tree then it's a little bit different for each one for example if you insert the left subtree of the left child it would look like this if you insert it into the right subtree of the right child it would look like this into the left subtree of the right child it would look like this and and to the right subtree of the left child it would look like that and what i mean here is that the top one here would be unbalanced and your new element that you just added would be down here now when you have to rebalance an AVL tree like I said there are four different possible rotations that you can do in order to balance it there's something called a left left rotation a right great rotation a left right rotation or a right left rotation this is why the left left rotation will look like if you insert the number say 2 into this tree that we have here you can see that we can do a left left rotation because the left let we start insert the new element into the left left side of the unbalanced node and so if we visually look at as we rebalance it this is what it will look like you can see that the middle load a node became the parent of the other two notes we serve just rearranged those three notes and now it's balanced for a right right rotation if we insert a node like 8 then we have a we insert the node into a blue right right the side of the note that's unbalanced now so we can perform a right right rotation was it which is a mirror image of glut left rotation good now the left/right rotation if we enter the number 3 that we see that 4 is unbalanced and when you insert 3 in the left/right part of 4 and if we rebalance it it would look like this a right left rotation again is the mirror image of a left right rotation it seems simple especially if we're doing it all on the paper bed with pictures but you have to keep in mind exactly how you would code this because it's a little more complicated if you do now you might wonder exactly which rotation you have to use at which given time if the unbalanced notes height is positive that is the left side is larger where negative if it's a positive then you should use a left left rotation or a left right rotation otherwise if it's negative then you would use a right left rotation or a right right rotation these are some hints of how you might be able to code it now here I have another example for you we just inserted a new number here nine and now way up high then the node at five is unbalanced well we have to fix that but we inserted it in the right right right space so that's actually three ways down night instead of two so what do we do then well recall what I just told you if though using the the hints I gave you we could say that we should use our right right rotation because that's aside that's gonna be unbalanced that's causing the unbalance so if we do that it would look like this note that the node six is now the child of node five after this right right rotation so these are all different things you have to consider remember to always place the child of the correct parent after each rotation the right rotation the left left rotation are considered to be a single rotation that is they deal with outside rotate and insertions and they're generally simple right left rotations and left right rotations are considered to be double rotations because they deal with inside insertions okay that's about all I have to tell you today you should think for yourself exactly how you might code this and it's not too difficult you just have to think about how you would code each individual out algorithm it helps to create a method for each of the four rotations and call upon them when you think they're necessary good luck and thank you for watching ",
            "url": "www.youtube.com/watch?v=5C8bLQBjcDI",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "disjoint sets data structures": [
        {
            "videoId": "wU6udHRIkcc",
            "channelId": "UCZCFT11CWBi3MHNlGf019nw",
            "publishedAt": "2018-04-04T17:51:26Z",
            "title": "1.12 Disjoint Sets Data Structure - Weighted Union and Collapsing Find",
            "description": "Disjoint Sets Data Structure - Weighted Union and Collapsing Find PATREON : https://www.patreon.com/bePatron?u=20475192 Courses on Udemy ...",
            "channelTitle": "Abdul Bari",
            "transcript": "the topic is disjoint sets in this video I will cover the following things first is what are disjoint sets and operations on them then detecting a cycle see disjoint sets are useful for detecting a cycle in non directed graph or undirected graph so we will take an example and learn how to detect a cycle in a non directed graph then graphically how to represent these disjoint sets and how it can be represented using array and the lastly the time efficient operations on disjoint sets are weighted Union and collapsing find that are based on the ranks or weights we will see that disjoint sets are similar to sets topic and mathematics but not exactly they are little bit change for making them useful in algorithms so the famous algorithm that uses disjoint set is kruskal's algorithm which detects a cycle in a graph so let us see how these disjoint sets are different from normal sets of mathematics let us understand what are disjoint sets seeing here I have a non connected and non directed graph there are two components it's not connected graph two components I have taken and each component I have represented it as a set said s1 is having one two three four these are the vertices of this component and set it to is having five six seven eight these are the vertices of second component so the two different components are representing two different sets and what is a disjoint here so know what X is a common here the numbers are not a common here so if you take intersection of these two s1 and s2 then you will not get anything five empty set so that is disjoint disjoint set means two sets are not having anything common then how we use them what are the operations on them see we prefer performing only two operations that are fine and Union I'll show what does it mean by these operations so first operation find I want to know what x5 belongs to which said it's not here yeah it's here so it belongs to set to find operation is to find out any element or a vertex belonging to which set it's like a set membership operation also means that element is member of which is set so like I want to find out 7 7 doesn't belong here ok here it belongs so it belongs to set 2 then 3 find three five three welders here so it is set 1 so that's it find operation is very simple so you have to find out in which set it belongs to so I am showing you just mathematically later we will come to the data structure now let us look at Union operation see for showing Union operation I'll try to connect these two with an edge I have added this edge this edge that is 4 to 8 so when you add an edge then what we do here is we perform Union operation so we connected what 4 comma 8 we have connected now find for 4 yeah it belongs to set 1 5 8 8 AHA here it belongs so it isn't set to so find 4 and find 8 they belong to two different sets so perform Union s 1 Union s 2 so now we get a set that is 1 2 3 4 5 6 7 8 this is Union operation see in mathematics simply we perform Union on two sets but here there is a reason of performing Union what is the reason if there is an edge u comma V find out to you it is to which set it belongs and find out V to which a set it belongs and if they belong to different sets then perform union of those two sets this is the purpose of performing Union know why we are doing this next I'll add one more edge one two five so this is one two five now we don't have these sets that are Union and we got a new set let us call this as set three so we have a new Center those elements are gone this is the final set now one comma five one yes find one it's present here find five yes it is present here now both these vertices or numbers are belonging to same set and if they belong to same set means there is a second that's it this is the way we find out a cycle in a graph so one of the things we learn what is fine operation what is Union operation and what is the purpose of Union operation then how we can know that there is a cycle in the graph if you take any edge and both the vertices are belonging to same set then there is a cycle in the graph so this was a very simple example I have shown you what does it mean by fine and Union now we will take one example graph and we will see from the beginning how we can detect a cycle in a graph I will form all the sets right from the beginning I will add all there just one by one let us take an example and find out how we can find our cycle how we can detect a cycle in a graph by with the help of disjoint sets here I have taken one example graph and in this I have labeled the vertices so let us say these are some weights so just like let us find our minimum cost spanning tree from this one otherwise you can also say that I have numbered them so first at should that I will be taking is this one then this one second one then third and four in this way I will include all the edges of a graph now how we can take the help of disjoint sets for finding finding a cycle let us check see there are eight vertices I have taken a Universal set with a two vertices each element you considered it as a set now let us start what we'll be doing is we'll be going on taking edges including edges and forming the set so for them one by one so the first edge is 1 comma 2 so the first edge is 1 comma 2 so find one 1 is here and find it - it is here so actually they are in the universal set so former set for them take 1 & 2 so perform Union on 1 & 2 so from this Universal set they are removed and they are brought in to set 1 s 1 now next edge next edge is 3 comma 4 so 3 comma 4 3 is an Universal set remove this find for this is in this Universal set remove it so former set that is set it to with the 3 & 4 then third edge 5 6 so this is 5 comma 6 and they belong to Universal set remove them from there and form a set for them 5 6 the next one is 4th at just seven eight so take 7 & 8 & find 7 it is here find 8 it is here they are a universal set former set for them that is 7 & 8 now the mix edge after the 4th edge this is the 5th edge I am going to take that is 2 comma 4 now I can see that all these vertices are removed numbers are removed they are in different sets now now find the two words not they just forget this one find it - it is here find 4 it is here so they are in two different sets of perform Union so I will form a new set that is set 5 by taking union of these two one two three four I have performed Union on these two sets so now you can see that Union is being performed let us go to our next edge after 2 comma 4 this one 2 comma 4 sixth one is this one that is 2 comma 5 so 2 comma 5 find 2 so 2 is in this set now these are Union remove them this is in set 5 & 5 is in set 3 / some union of these two and foremost six so what are those vertices 1 2 3 4 and peas 2 5 6 see the reason of performing Unionists we are including an edge considering an edge so this set is also gone we have a union that's also gone now we have only 2 sets now right now after this edge vii edges this one 1 comma 3 1 comma 3 I'll remove these sets and I'll just write two sets here find one it belongs to set 6 5 3 it belongs to same set so when the both belong to same set it means there is a cycle yes you can see that by taking this edge I'll be forming cycle I will highlight the edges that I have included so far see I have included these edges I having you did these I have included these edges all right now if I include this edge this will form a cycle so don't include this that's all the edge which is forming a cycle don't include it we have detected 1 cycle let us continue after that 7th edge the next edge 8 1 is this one so 8 is what 6 & 8 6 & 8 let us see find six five six six belongs here find eight eight belongs to this one so they are in different sets perform Union now we will get 7 the set and what is that 1 2 3 4 5 6 from this set and 7 8 from this set 7 & 8 from this set so these two are gone so this is also included now the last edge remaining is 9th one 5 comma 7 5 comma 7 5 5 it is in this set find 7 this also in the set both all are in same set only now as they both belong to same set there is a cycle so this is how crucial algorithm also uses it in the same way for finding a spanning tree like you may be knowing that in crystals algorithm always we select a minimum cos H now shall we select it or not is it forming a cycle or not how we can know by checking in to the sets so this was like working off a criticals algorithm only now how it is done graphically and how it is represented using array that we have to see so I take the same graph and show you let us quickly look at how we can show the sets graphically so I will do the same thing I have the same graph and the vertices these instead of Universal set I have shown them as vertices here that is I have taken notes now I will go on including the edges so the first edge is 1 comma 2 if I include edge 1 comma 2 you remember I was making a set as 1 2 now actually we don't need a set we are not performing mathematical operations here like intersection Union difference come we are not performing that one so what we want is just you want to detect a cycle so we want to do it in the easy way so instead of showing it like this graphically we will take 1 & 2 basically we don't need the name of a set we need just one representative of a set so we will make what X 1 as a parent of set & 2 as a child if you like you can make 2 as a parent and one as a child also so let me show you other edges that is 3 comma 4 so if I take 3 comma 4 and make a set 3 4 so 3 as a parent and 4 as a child of it now third set that is 5 6 5 then set for 7 comma 8 I have included 4 edges I got 4 set graphically they are shown like this now let me include the next one from here you can get the clear picture edge 2 comma 4 v 1 2 comma 4 so where is 2 2 is here who is the parent of 2 1 the next is 4 find 4 4 is here who is a parent of four three so these are at two different sets so you remember we perform Union how to perform Union so we will select one as a and two as a child here and it's a child as a three and four so we made the parent of one said as a child of the period of another set so you will be asking that why did you select a three ever parent if you want you select that one also it makes no difference it makes no difference whether you take three as a parent and one you make it as a child of three it makes no difference then next one after fifth sixth one as a 2 comma 5 2 is here who is a parent of this one 1 then 5 is here so they are in two different sets these are in two different sets so we interviewed that five we will bring it here and six here actually these are gone I will remove them now again one more thing here also you can ask a question why did you select five as a parent see here I have a strong answer that before including this see how many nodes are there 4 gnomz are there so weight of this set is more and this way it is less so we will make this as a parent and this as child earlier although both the sets were having the same number of elements but now this is set to 1 2 3 4 is having more number of elements 5 6 is having just two elements so this is representing this set you see 1 2 3 4 5 6 this is v 6 2 set if you remember already we have done this now this is gone now on extras 7th 1 1 comma 3 1 comma 3 1 is the parent itself and three is parent is 1 so both of their parent is 1 only it is 1 only so they belong to set of 1 so both belong to same set so it's a cycle that's enough I will not go further so this is how we detect whether there is a cycle or not graphically I have shown you now let us see the same thing again with the help of an array how it is done using now I'll show you the graphical representation as well as irony presentation c4 representing a set we don't need the name of a sector we are not performing actual Union intersection or set difference operations of mathematics we just want to perform find and union our objective is to detect a cycle so for that for all eight vertices we will take a single array called parent and the indices are representing these eight vertices and each is having value minus 1 means each vertex is in its own center next to show you graphically how it looks like I have even taken these eight nodes now let us perform the same thing on this graph and see how we will represent sets in a array and also I will show it graphically so fast edge 1 comma 2 1 comma 2 1 who is a parent of 1 minus 1 itself to find to go to index 2 and see what is there minus 1 so who is a parent of 2 itself so how much time it has taken for finding 1 and finding to find 1 minus 1 find 2 is minus 1 so constant a time so they belong to two different sets the perform Union how do you perform Union so graphically I will show I will select one as a parent and two as a child so 2 is a child of 1 so here we will write 1 so who is a period of 2 now 1 and what is 1 minus 1 so there is a parent so if there is minus 1 or negative value that is a parent now I'll do one more thing total how many nodes are there two years are there so instead of writing just minus 1 I'll write negative only so minus 2 so there are 2 things - shows that it's a parent and 2 shows that there are 2 modes here that's it let us continue repeat the same thing for all of them next edges 3 comma 4 3 comma 4 find 3 one itself is apparent 4-1 itself is a parent so former said so who is a parent of four three and what is the three its parent but there are two nodes in this one five comma six the third one so find 5 this is minus 1 5 6 minus 1 so 5 here and 6 here so this is a 5 and this is minus 2 now the next edge is this one 7 comma 8 find 7 itself as a parent find 8 itself is a parent now make 8 as a child of this 7 or 7 as a parent so this is 7 and this is 2 till here we have finished next shift H 2 comma 4 so 2 comma 4 find the 2 1 is a parent find 4 3 is a parent let us do it in an array to go to two one go - 1 - 2 so who is a parent of this 1 1 find so go to four three go - 3 - 2 so who is the parent of this 1 3 and this was 1 they are different parent perform Union so whom we should select as a parent 1 we will select it as spirit so at a 3 I will write 1 then total how many nodes now 4 nodes so graphically 3 will come as a child of 1 and here is 4 that's it so that's all Union is done now let us take next 1/5 now this is 6th 2 comma 5 2 & 5 let us see who is a parent of 2 1 let us look at here - its 1 go to 1 its - for just one step we are going right it's not n at time we considered as constant time only five and five five go to 5 - 2 itself as a parent so for 2 this is a parent and 4/5 itself is a parent now who should become the parent for both we have to perform Union now unite these two so who should be compared in 1 or 5 see what is the right one - for what is there at 5 - 2 whose weight is greater ronk is greater weight or rank both are same only here we call it as rank also whose rank this created once rank is greater so let five come as a child of one so at five we write one now - the rules are added to this so 4 and that - 2 is added so it becomes sorry till your notes are added to it that 4 and minus 2 it becomes 6 so total 6 nodes are here this is how Union is performed let us go to next one after 677 this what 7 this 1 comma 3 this will be interesting find 1 1 okay here in this one itself is a parent find 3 3 who is a parent 1 okay here in an array 3 1 go to 1 minus 1 so the parent is same so for both 1 & 3 parent is same both our parent are same so it means they belong to same set and exacycle if you include 1 comma 3 it will form a cycle see so far we included these edges right we have included these edges and if we include 1 comma 3 this will form a cycle so don't include this one so that's how inclusion of any edge will it form a cycle or not we can know it with the help of this disjoint sets I can continue like this okay let me quickly finish the rest of them also but here 5 comma 6 is gone it is coming under this one now let us take next edge 6 comma 8 6 comma 8 find 6 6 / and is 5 5 / and is 1 so go here in the on array let us see here also 6 / n is 5 & 5 spirit is and once parent there's one itself is the parent so one is the parent of six now or about eight find eight in this graph you can see this is graphically it is seven so go to eight and seven go to seven X minus two so this is the parent so perform Union on 1 on 7:00 now who is greater minus eight is greater this is minus two so make this seventh parent as one and add two more nodes here and graphically show it like this seven and eight that's it now the last one is ninth one this is included no 91 if I try to include five and seven find five pair in this one find seven pair in this one look at here five one only seven one only so for both of them period this one so inclusion of nine will form a cycle so this is how a simple array of values are sufficient for finding whether there is a cycle or not with the help of fine and union operation that's already what just one thing is remaining here see I instead of taking just minus one I was taking a ranks or weight and the Union was performed based on whoever weight is higher right so this is weighted Union now one more term is used that is collapsing fine so let me tell you one thing here see if I say find to go to two one one is negative just two steps find three go to three one at 1 minus eight so one is a parent just two steps constant steps find four go to four go to four it will take you to three go to three it will take you to one then here so the time is more time is more so here for some nodes the time may be more you have to go along the parent and pair and ampere and then finally you will get the root or the main parent of a set so what we do in this situation is when we find that period of six is five and then it parent is one so finally parent of sixes one so for this we have to take multiple steps but once we found out that the parent of sixes one we don't have to keep it there only we can directly bring six under one so here also in six five is the parent five spur in this one so four six also it is one so we can directly modify this one now whenever we say Phi in the six go to index six what is fine there one so at one it is negative so parent of six is one directly in constant time we can know parent of any element so this procedure of directly linking a node to the direct parent of a set is called as collapsing fine but collapsing find we can reduce the time for finding the same value next time first time you may omit spending some extra time but next time in constant time we can get the parent now same way suppose I find 8 from 8 go to 7 from 7 go to 1 let us do it here go to 8 7 7 this one go to 1 experience so once you know that 8 is under 1 so directly bring it under 1 so here also we can write 1 so whenever you find any element you can collapse it to its direct parent so that's all how we can use array for representing disjoint sets and even link lists can be used for doing this so for link list we can explore it I have shown about array in detail everything I have shown you when we use linguists then we have to take nodes and in the node we have to write down these index and stuff index we have to keep it as a value that is the node value and a pointer to the parent pointer to the next node so you can explore that by yourself that's all with a disjoint sets ",
            "url": "www.youtube.com/watch?v=wU6udHRIkcc",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "ID00PMy0-vE",
            "channelId": "UCZLJf_R2sWyUtXSKiKlyvAw",
            "publishedAt": "2015-06-22T00:07:10Z",
            "title": "Disjoint Sets using union by rank and path compression Graph Algorithm",
            "description": "Design disjoint sets which supports makeSet, union and findSet operations. Uses union by rank and path compression for optimization.",
            "channelTitle": "Tushar Roy - Coding Made Simple",
            "transcript": "Hello friends my name is Tushar and today\nI'm going to talk about disjoint sets using union by rank and path compression. So\nwhat is disjoint sets? Disjoint sets is a data structure which supports 3 operations\nmakeSet,union and findSet. makeSet is an operation to create a set with only\n1 element in there. Union is an operation to take 2 different sets and\nmerge them into 1 set and findSet is an operation to return an identity of\na set which is usually an element in a set which acts as a representative of\nthat set. So what are the use cases of disjoint sets.Kruskal's algorithm uses\ndisjoint set. We also use disjoint sets for finding cycle in an undirected graph.\nThere are few implementations of disjoint sets. The most popular one is\nthe one which uses union by rank and path compression to run this operations\nefficiently. So in the next section let's understand these operations and let's\nunderstand the algorithm which uses union by rank and path compression. Let's\nunderstand disjoint set operations with an example here. Suppose I have 7\ndifferent elements and all of them are in their own set so basically we have\ncalled makeSet on each individual elements. So first operation I do is\nunion 1 and 2. So it means that 1 and 2 will be in\na set of its own and let's say 1 is a representative of this set so basically\nsaying findSet 1 will return 1 and findSet 2 will also return 1.Next\nwe'll say union of 2 and 3. So right now this is in one set and this\nis in another set, so we merge these two sets together so this becomes something\nlike this and let's say 1 continues to be the representative of this set so\nfindSet 1, findSet 2 or findSet 3, all of them will return 1. Next we're\nsaying union of 4 and 5. So here 4 and 5 are in one set and let's say\n4 is the representative of this set. Then we are saying union of 6 and 7. So this is in a set of its\nown and let's say 6 is the representative of this set so findSet 6 and findSet,\nfindSet 7 will all return 6. Then we're saying union of 5 and 6. So\nmerge the 2 sets in which,one of which is 5 and one of which is 6 so\nbasically we'll merge these two sets together and this will become something\nlike this and we decide who will be the representative. So let's say 4\ncontinues to be the representative of this merged set. So findSet 4,findSet 5\nfindSet 6 and findSet 7 all of them will return 4 because 4 is the\nrepresentative of this combined set. Then we are saying merge sets 3 and 7. So\n3 in this set,4 is in this set so we merge them together so this will\nbecome something like this. So at this point all the elements are in the same\nset and now we can decide who will be the representative of this set. So let's say 4\ncontinues to be the representative of this set. So findSet 1, findSet 2,\nfindSet 3,4,5,6 and 7 all of them should return 4 because 4 is the\nrepresentative of this combined set. So hopefully this helps you understand what\nmakeSet,union and findSet means for disjoint set. In the next section let's\nlook at the implementation detail. So we're going to represent our disjoint sets\nusing tree. Every node of the tree will have 3 three properties- rank,data and\nparent. Rank is going to store their approximate depth of the tree, data is\ngoing to store the actual data elements and parent is going to be the pointer from\nchild to parent. So let's try again the same example. So first we call makeSet\non all the elements,7 elements we have. So it results in 7 different sets,all\nthe roots of the set are pointing to itself so the parent is pointing to itself, all\nthe ranks are 0 and the data is 1234567. At this point this nodes are not\nconnected to each other. So first we do is union of 1,2. So we come here and we're saying\ncombine 1 and 2 into 1 set. So what we do is we check the rank of 1 and 2. The rank of\n1 and 2 is same. So in this,in this case it doesn't matter who becomes parent of whom.\nSo what union by rank says that make the guy who has higher rank the parent\nand the guy who has lower rank the child. The reason behind that being that the guy,\nit will keep the depth of the tree as minimum as possible which will improve\nour time. So in this case they are same so it\ndoesn't matter. So let's make 1 as their,as the root\nand 2 as a child so this is this and the parent of 1 continues to point itself.\nSince if we combine 2 different,2 different sets of same rank,the new,the\nnew root will have a 1 rank higher. So this will become 0 plus 1 so this\nbecomes 1 and this is 0. Rank of non-root node doesn't matter. Then,\nthen next we are saying union of 2,3. So we start from 2. We go to,\nwe find which set 2 belongs to so we follow the parent pointer so we reach 1 and\nthen we follow it's parent pointer so that's also 1. So 1 is the root of this\ntree and 3 is the root of this tree.We check which has a higher rank, so union by rank says\nthat the one with the higher rank becomes a parent and other becomes\nchild. So 1 should be the parent and 3 should be the child. So this becomes\nsomething like this. 1,2 this is this way and then 3's parent is also 1\nand 1's parent is itself and then the rank for 1 does not change. So\nrank for 1 continues to be 1. Next we're saying union of 4,5. So again their\nranks are same so it doesn't matter who becomes a parent so let's  convert that\ninto a tree,into,let's combine them together. So rank here is 1,rank here is 0 and\nthis guy is pointing to itself. Then union of 6,7. So again by Union\nby rank it doesn't matter who becomes parent of whom. So let's make 6 as a parent.\n7 point in this direction and rank here is 0 and rank here is 1. Then we're saying\nunion of 5,6. So at this point we go to the 5's,we find the\nrepresentative of this set which is 4 so we follow the parent pointer so we\nreach this guy and this pointer is pointing to itself so it means this is the\nrepresentative of this set and this is the representative of this set. Then we check who\nhas the higher,who has the higher rank. Again they have same rank so we merge them\ntogether and it doesn't matter who is the parent but let's keep 4 as a\nparent so this becomes something like this. 4,5,6,7 and since we merge two nodes,two sets\nof same rank then the new rank will be 1 greater. So this is 2,this is 0.\nAgain for non-root node it doesn't belong,doesn't matter what the rank is\nand then this is pointing to itself. At this point if someone says findSet 7,\nso basically give me the representative of the,representative\nelement of the set which 7 belongs to. So we follow the parent pointer, we reach 6,again\nwe follow the parent pointer,we reach 4 and then we follow the parent pointer and\nthen it's 4 itself so we know that 4 is the representive of this set. Again\nthere is a,here we do a small optimization. What we do is we do path\ncompression which means that now what we do is we make 7 point directly to\n4. So we decrease the depth as much as possible and then make this guy point\ndirectly to 4 so next time there's a query for 7,7 can directly reach 4 and we\ncan find the root very, so we can find the representative element very quickly. So\n7 now starts pointing to 4. Then we say union of 3,7. So we come here and we\ncome here,we start with 3,we find the representative element of this set.\nSo we follow the parent pointer,we reach this point and for 7 we follow the parent pointer\nand reach this point.So we check who has a higher rank. So 4 has a higher rank.\nSo this becomes the child of this guy so let's merge them together so this becomes\nsomething like 4,5,6,7 all of them have parent pointer pointing\nto 4 and then we will have this so that's 1 and then 1 has 2 and 1 has 3\nand this is 0,this is 0,0 and this is rank 2 and the pointer is in this\ndirection. So this our merged set at this point. So the rank at the route is\n2 and the rank of the non-root node doesn't matter but you can see the\npointer direction,direction of the parent pointers 2 to 0,0 to 4,3 to 0,0 to 4.\nNow if someone says findSet 2 so give me the set which 2 belongs\nto. So 2 goes to 0,following the, following the pattern pointer,then 0\ngoes to 4 and then 4 is pointing to itself so 4 is the set in which this\nbelongs to but also has a path of as a, as a,as a improvement we also apply path\ncompression so what happens is this starts pointing to 4. So next time if\nthere is a query for 2,2 can directly go to 4 instead of going via this route.Also\nif there's a findSet 3 so we go to 0 and we go to 4 and then\nultimately this will start pointing to 4 so that as an optimization. So in\nthe next section let's look at the time and space complexity. Space complexity is\npretty straightforward. If there are n elements in the set,the space complexity\nwill be O(n). What about time complexity. So if there are 'm' operations\nand if there are n elements,the time complexity will be O(m alpha n). So\nthere's a proof in the CLRS book describing how this will be the time\ncomplexity. Here alpha n is a very slow, slowly growing function and for all\npractices,practical purposes alpha n is less than equal to 4. So this\nwill pretty much become O(4m) where m is the total number of operations which is as\ngood as O(m).So next let's look at the code for this disjoint sets.I have a\nclass disjointSet. In there I have an inner class Node.Node has data,parent\nand rank and we already talked about what each of them does and then I have a\nmap of data to know this will help us quickly and efficiently find the node\ngiven the data. So I have 3 methods here, makesSet,union and findSet. So\nwhat makeSet does is it creates set with single node so it assigns the data\nin the node and then it points a parent to itself and rank is 0 and then we put\nthis data and node into the map. Then let's understand what union and findSet\ndoes using this examples. So I have two sets,one with rank 3 and 1 with rank 2.\nThe representatives of the set are 1 and 11. So now I'm saying union of 7\nand 13. So we go to this method union,so first we do is we get the nodes for 7\nand 13. So we go to the map and we get node 1 which is the node pointing to 7\nand we go to map and get the node 2 for node pointing to 13. Then we call findSet\nand try to get the parent for each of these nodes. So we go to findSet,so we\ncome to this point and then we get the parent so we go to 7.7's parent is 5 and\nthen 5's parent is,so 5 is not same as node so then we again go into a\nrecursion and findSet again so 5's parent is 2 and then 2' s parent is,again we\ngo into the recursion and so we call findSet again and 2's parent is 1. At\nthis point 1's parent is also 1 so we get into this if condition and we return\nparent so by returning parent we are setting the parent of every node in the\npath to 1 so that is a path compression so 2's parent will become one 1,then\n5's parent will become 1 and then 7's parent will also become 1 and we already\ndiscussed this as a part of path compression. After applying path\ncompression this is how my set 1 looks. like where 5 points directly to 1 and 7\nalso points directly to 1. So then it, the line number 49 also returns\nparent 1 which is 1 so then we go to, execute line number 50 and node 2 is,\nnode 2 is 13 so we call findSet and try to get the representative of set\n2.So we again go to findSet and here parent is 11 and 11 is not same as 13 so\nwe again go into the recursion and here we pass node as 11 and the parent of 11\nis 11 so we return parent and then it will come back here and we set 13's\nparent as 11 and then return 11. So we come here,come back to line number 50 and\nparent2 is 11 so then we apply our logic for union by rank.This statement here\njust makes sure that if the parents are same we do nothing because they are\nalready in the same set otherwise we check a parent whose rank is higher so\nin this case parent1's rank is 3 and parent2's rank is 2. So parent1's\nrank is higher so we go into this if condition and we check did parent\n1 and parent 2 have same rank so in this case parent1 and parent2 do not\nhave seen rank so we do not change the rank of parent1 and then we also set\nparent2's parent as parent1. So 11,now 11's parent now instead of pointing to\nitself now starts pointing to 1. This is how the final picture looks like\nafter we do the union of 7 and 13 so 11's parent is now 1. Next let's try\nto do a find on 14. So we come to find findSet and then we pass 14 so in the\ndata so first thing we do is we get the node for 14 from the map and then we go\nto findSet here. So parent of 14 is 12, so\nparent is not same as node so we again go into the recursion and this time node\nis 12,again parent of 12 is 11 so they are not same so again we go to findSet\nand we go to 11. Parent of 11 is 1, again parent is not same as node so\nwe go on to findSet and then this time node is 1 and parent of 1 is 1 so\nat this time we go into this if condition and return parent. So basically\nwe return 1. So while going back what we do is we set 11's parent as 1\nand then we set 12's parent as 1 and then we also set 14's parent is 1.So\nthis is how my tree looks like after findSet 14 is executed.14 points to 1 and\nalso 12 points to 1 and this is as per as we discussed for path compression. So\nfinally let's run this code. So in the main I have created 7 distinct sets\nand then I perform a union of (1,2),(2,3), (4,5),(6,7),(5,6) and (3,7) which means that\nall the sets,all this distinct sets should be merged into 1 set. So when I perform\nfindSet from 1 to 7 all of them should give one representative element. Let me\nquickly run this code. So as you can see I get all 4,so all the findSets\nare returning,returning me 4,it means that all of them are in one set now. So\nthis is all I have to talk about disjoint sets. Please like this video,share\nthis video,comment on this video,check out my facebook page and also check out\nmy github link at github.com/mission- peace/interview/wiki.Thanks again for\nwatching this video. ",
            "url": "www.youtube.com/watch?v=ID00PMy0-vE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "gcmjC-OcWpI",
            "channelId": "UCV8fTJu6CO8UXz-KvliG-Qw",
            "publishedAt": "2013-05-15T05:36:31Z",
            "title": "Disjoint Sets - Data Structures in 5 Minutes",
            "description": "DISCLAIMER: This video in no way comprehensively covers the lecture notes, nor are considered \"official\" by any instructor. I am undertaking this series as a ...",
            "channelTitle": "Dickson Tsai",
            "transcript": "hi welcome to data structures in five minutes today I'll be talking about this joint sets and disjoint sets our data structure where allows you to record how a large set of items known as a universal items is partitioned into several little subsets and so all items in this universe are part of exactly one subset and there there's no overlap between any two sets and so here our universe consists of 1 12 6 8 4 & 3 and the subsets and this universe is partitioned into three subsets first subset has 1 12 and 6 the second the second subset has just 8 and the third subset has four and three two operations that you might be interested in for this data structure are fine which is which small set is the item belong to so which subset this item belong to and the second operation is Union which is I want to merge two sets together and I want you to remember the new arrangement and adjust the pointers accordingly and there are two ways to implement this one that optimizes fine and one that optimizes union first quick find is the implementation that optimizes fine and makes a constant time what you do is have all items point to the set up they belong to and each set points to the list of items so looking back at our example here set 1 points to 1 12 and 6 but 1 12 and 6 point 2 set 1 set 2 points to 8 points to set 2 and set 3 points to 4 & 3 & 4 & 3 each point to set 3 and so why find this constant is that all you have to do is look at the item and see which set the item points to and so follow the pointer in its constant time Union however is not constant here it's linear because you have to go through each element and adjust its pointer based on how the new arrangement looks that next implementation is much more important however its quick-union and this is where union is theta1 continent runs in constant time well fine is just log of the number of unions that you have done well you'll see that this can be made very fast based on optimizations that will do enough it and so that's why quick union is important quick union disjoint sets is implemented as a forest a collection of trees so each subset represents a tree and the trees do not have to be binary they can have as many children as they want each set is a separate tree like I said and each set is identified uniquely by the route so the room it represents the entire set and so when you Union to stop the two sets together one of the trees will become a subtree of the other tree and so you lose some of that subset information that you might have with fine but the good news is that you can also find a way to get around that using a different array but for now let's not worry about that speaking of arrays after you've visualized all these subsets as a tree you can squeeze them all into one array and here's how you can have negative numbers represent the route so the elements are the indices you can have negative numbers or present the each set and the size of this set and positive numbers are just elements that are part that are a member of set and the parent is who they point to in the tree and all the elements only have parent pointers there are no children pointers or whatever like or something like that so we have a universe here of zero to six and so we start off with all the elements of being their own set so each one has a size of negative one and there negative so that means that the roots before I elaborate on this example I'll talk about the two optimizations you'll make the first one is Union by size which means that when you Union merge two sets together the bigger set swallows the smaller set and so this allows the tree to be much more shallow than if you allowed the smaller set to take on a bigger set and so that's Union by size the other optimization is path compression so what you do is you find the you find the element then you recursively call find on its parents and you set all those parent pointers to the root and so that way you can make your tree from something very deep to something very shallow so even though find is worst case of log u pad compression makes a subsequent finds much faster and so let's draw this all out all concretely in an example so let's I want it to merge 0 & 1 so 0 now points to 1 and 1 is now size negative 2 I do another merge here to merging with 1 & 2 is the smaller subset and it gets swallowed by one the bigger subset so let me do a merge somewhere outside so let's say 5 now points to 4 so now we have this image here we have 1 & 0 & 2 pointing to 1 and we have 5 with sorry 4 with 5 pointing to it for is the root now if I wanted to merge 4 with 1 they look like that then so for now points to 1 and 1 is now negative five because there are five elements in there and now say I wanted to find five member that we have a path compression which is one of the optimizations here so we find 5 5 points to 4 & 4 points to 1 um so what we do is we recursively call find on 5's parent 4 and force parent gives us 1 and so we know that 5 is now a part of 1 so all we have to do is reassign this pointer from the parent to the root and so now 5 points to 1 and so when you find 5 next time you don't have to go through the long path you can just go directly from 5 to 1 and so that's how path compression and union by size help us make a tree that shallow enough so that find works very fast in fact you can see if you read Wikipedia or something that fine grows asymptotically like the inverse Ackermann function which is very much just the constant yeah it's the inverse Ackermann function is very slow and so that's it for districts ",
            "url": "www.youtube.com/watch?v=gcmjC-OcWpI",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "j8uAsZbBD7U",
            "channelId": "UCUGQA2H6AXFolADHf9mBb4Q",
            "publishedAt": "2020-06-28T21:51:13Z",
            "title": "Disjoint Set: the Union-Find Data Structure",
            "description": "Table of Contents: 00:00 - Introduction and Prerequisites 00:47 - Problem Definition 01:13 - Very Simple Solution 02:28 - Improving Find to O(1) 04:58 ...",
            "channelTitle": "Algorithms with Attitude",
            "transcript": "This video is on the disjoint set, or union\nfind data structure. It\ndoesn't have too many prerequisites, but you should at least know the\ndata structure basics like linked lists, dynamic arrays, and trees. This might be my favorite data structure. The code is simple enough\nto use pseudocode throughout the video, yet the final analysis is too\ncomplex to cover here. Best of all, the structure itself seems simple\nenough to develop even if you have like a regular sized brain. This will be part of my \"You're not a freakin\nmoron\" series, so I will walk down a plausible path to create the data\nstructure from scratch and unsurprisingly, at no point in time will\nI look like a genius. The data structure needs the ability to create\nsets with one element each, to find out what set any element is\nin, and to combine two sets into one. That's it. It doesn't do much, but it does it very well. First, come up with any way to solve the problem. You can use a\ndynamic array. I made mine big enough that it won't need\nto resize. If you want to make some new set with some\nobject, just stick it into your array, along with a unique set ID for\nit. If you want to find\nout if object B is in the same set as object E, you walk through the\nset to find E, walk through the set to find B, and if they don't have\nthe same ID, they aren't in the same set. If they are in different\nsets, to take their union, walk through the entire array, changing all\nof the objects with E's ID to have B's ID. Really simple, really slow. Adding an item takes average constant\ntime, but find and union can each take time n if there are n items,\nand you have to come up with unique IDS. That's not too hard, but why\nnot just use the objects themselves? That's easy, its why I named my\ndog 'dog'. Each object is distinct, and sets are disjoint,\nso if each set has one object that it uses as it's representative,\nthat works. Of course you aren't copying the object, you\nare keeping a reference to it, so the array only needs to hold two\nreferences for each item in any of the sets. How can we speed that up? There are a few things you can do, but it\nalso depends on what you are putting into the set. Are they objects\nthat you can mess around with? Like, can you store references in the\nobjects? For this data structure, the assumption is\nthat you can. This won't be a black box data structure like\na linked list or array list. You can use those without having direct access\ninto the internals of whatever you are storing. Here, we will modify the\nobjects themselves, to hold information, like how we might write a\nvariable like discovery status into a vertex of a graph while\nsearching it. Once we have that, we can store a reference\nto the set representative right in the object itself. The code gets really simple, find is\ntrivial, we just return the representative from the object in constant\ntime. Union still takes linear time in the entire\nset of objects, but the code and other runtimes are great. What can we do to speed up union? It seems pretty wasteful to go\nthrough the entire set of all objects to look for those in just one\nset. We could keep a list for each set, and walk\nthrough it to update that set when we call union. The list for a set starts with just one item,\nand when we call union, we append one list to the other. You can use a linked list or a\ndynamic array. Linked lists will take time proportional to\nset $x$'s size. Dynamic arrays sometimes take longer when\nthey resize, but on average have the same asymptotic bounds, probably\nwith better constants even though the linked list append\ntakes only constant time. But now look at the code. What's the main dynamic array doing for us? We add to it, but never use or look at it. It's a vestigial organ,\nand we can evolve to get rid of it. The representative is a special object within\nthe list, I'll draw it above the others. You can visualize both versions similarly,\nuntil you get to a vertex with more than one other\nmember in its set. Then,\nyou would expect the linked list version to have linked list nodes\nlinking sideways to other elements of the set. For the array version,\nthe representative has direct access, through the array, to each of\nthe other members, but I wouldn't make sideways links. Also, to keep\nit clean, I will only draw references in one direction there. Both look a lot like a one level tree, and\nboth of those strategies are used in different tree implementations\nto store a list of children. When these animations finish, we see something\na bit awkward: when we combine this size 4 set with a size 8 set,\nwe go through the entire size 8 set to fix its representatives. But when Amazon acquired\nTwitch, it wasn't an even merge, they didn't flip a coin to see who\nwould take over the company as a whole, the big company absorbed the\nsmall company. We can do that here too, let's append the\nsmaller set to the bigger one. Now the data structure starts to look pretty\ngood. I'll just\nanimate the less visually cluttered version. MakeSet and Find still\ntake constant time, and Union's time is now proportional to the size\nof the smaller set. If you think about an object in a set, every\ntime its representative gets changed, the size of the set it is in\nhas to at least double, so if there are n total objects, no object can\nchange its representative more than lg n times. For this data structure right now, if there\nare n objects, n calls to union can't take more\nthan n lg n time total, for lg n average. That's not bad, but we are two observations\naway from awesome. The first is that this data structure is really\nproactive. You have\n10 things in a set and it merges with a larger set? You run to every\none of those 10 things to tell them they need to update. Then, in the array version, you run through\nthe list to append one to another just so that you can proactively update\nevery object's representative the next time. Maybe object K there doesn't even care\nwhat set it is in, and you just keep running up to it to tell it that\nit has a new representative. It would be like doing every problem in\na textbook, so that it is ready to turn in, just in case the teacher\nasks for you to do that problem for homework. You'll know your stuff\nreally well, but it's not the quickest way to do homework. Relax. Be\nmore lazy. Don't tell everyone they have a new representative\nif they don't ask. When a set merges with another, just update\nthe representative of the smaller set to make it reference the representative\nof the larger set, and don't worry about the other objects in\nthe set. Now, they don't\nreference their representative, but they do reference an object closer\nto the representative. How does that change our code? First, you don't have to walk through the\nlist during the update, you just change one representative. Once you do that, you don't use the\nlists except for their size, so just store their size, don't store the\nlists. Now each object just has to keep one reference\nand a size. The set is\na tree, but objects don't keep track of their children, only the size\nof their set. It's like if I know I have 2 kids, but I don't\nhave any idea who they are, and I don't worry about\nit because I never look for them to tell them anything anyway. Okay, that sounds kind of bad. Now that representatives aren't all proactively\nupdated, we have to fix find. The set representative knows its the representative,\njust like your congressman knows they're your congressman. For anybody else, recursively ask your last\nknown congressman who their congressman is. Finally, because we don't have direct links\nto our representatives, we use find instead of\nthat direct link. We don't need to store lists now, but what\nabout speed? Union makes\ntwo calls to find, but otherwise only takes constant time. But it\nisn't great for find: the representative can check that it is its own\nrepresentative in constant time, but other vertices need to walk up\nthat tree to get to the root. Excluding find, union is really fast,\nbut find is slower, and union calls it, so that seems like a bad\ntrade-off. Find isn't terrible, we still do union by\nsize, so the tree height can't be more than log of its size, and the\ncode still looks clean, I coded it recursively instead of using a loop. But the real problem is\nthat before, find took constant time and union was logarithmic, but we\ncould only have n-1 slow calls to union with n items. After that,\neverything was in one set. Now, we can have lots of slow calls to\nfind, like if we call find on A, it walks some path to the tree root. Is that bad? It's not great, but we see the real problem\nif we call find on A again. We repeat the same work. That's not just lazy, it's\nstupid. We went from being over-diligent, updating\nevery object's representative even if it didn't care, to\nnot even bothering to record an updated representative, even after we found\nit. If we are forced\nto do the work anyway, save it. If your congressman loses their\nelection, and you call them to ask if they are still your\nrepresentative? They will be annoyed. If you call them the next day\nto ask them again? They'll be pissed. To find A's representative, you ask every\nobject on the path to the root what their representative is. Update them all. I wish these\nwere called lazy but not stupid trees, but it's instead known as\npath-compression. So here is my favorite part, where we see\nhow clean recursion can make our code. How do we add path compression to this code? We\nrecursively update the representative or parent, a few characters of\ncode. That's it. Let's take a look at how that runs on the\nsame set of operations. MakeSet looks the same, and we don't see any\ndifference until we call find on a non-root vertex. Any call to find on a non-root will break\nand reform its link, even if its to the same node, because if an item\nisn't the representative, it automatically reassigns a new\nrepresentative when you call find. There is no order for the children. Remember, in this social\ndystopia, the parent node doesn't even know who its children are. My\nanimation displays children left to right in order of how recently the\nlinks were made, which changes with path compression, but that's an\nartifact of the animation, not the data structure. But that will\nexplain why, when you call find on F, it changes from being the left\nchild of J, to its right child. The data structure has no left or\nright. Finally, when we call find on a deeper vertex\nlike A, you see its path compress, it keeps the trees from\ngetting tall here. Trees can still get to be logarithmic in depth,\nbut for that to happen, you have to keep taking the union\nof roots, or something near the root. Find takes time proportional to the depth\nof the node, so those unions are really quick. Basically, to get a find operation\nthat takes log time, you have to first get a whole bunch of unions and\nfinds that are fast, so the average time per operation will be much\nbetter than logarithmic. How much better? If you have n objects the\naverage time per operation will grow strictly asymptotically slower\nthan log star of n. More precisely, it can grow as fast as the\ninverse Ackermann function, which I won't even try to define here. The Cormen text and others use something called\nunion by rank instead of union by size, which has the same asymptotic\nbounds. If you didn't\nhave path compression, the rank of a set would just be its height, but\nonce you add path compression, keeping track of height can hurt your\nefficiency. So, rank is what the height would have been,\non the same operations, if there was never any path compression. It's easy to\ntrack. Some day I might get to a video on the runtime\nanalysis proof, but just defining the Ackermann function and its\ninverse is more complex than anything in this video. Some day I might get to a video on the\nruntime analysis proof, but just defining the Ackermann function and\nits inverse is more complex than anything in this video. That video\nisn't too high on my priority queue and I know how to be lazy. I'm\nalso told I need to hire a continuity editor, whatever that is, it's\nprobably not too critical. ",
            "url": "www.youtube.com/watch?v=j8uAsZbBD7U",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "0jNmHPfA_yE",
            "channelId": "UCD8yeTczadqdARzQUp29PJw",
            "publishedAt": "2017-04-08T00:38:05Z",
            "title": "Union Find - Union and Find Operations",
            "description": "=============================================================================== Developer tools I used in the creation/testing of the ...",
            "channelTitle": "WilliamFiset",
            "transcript": "ok so now we're going to talk about the Union and find operations we can do on the Union find or the disjoint set this is the video where I demystify how those actually work internally so to create our Union find the first thing we're going to do is we're going to construct a bijection or simply a mapping between our objects and the integers in the range 0 inclusive 2 and non-inclusive assuming we have n elements so this step in general is actually not necessary but it's going to allow us to create an array based unit find which is very efficient and also very easy to work with so if we have some random objects and we want to assign a mapping to them then we can do so arbitrarily as long as each element maps to exactly one number so that is my random by ejection and we want to store these mappings perhaps in a hash table so we can do a look up on them and determine what everything is mapped to next we're going to construct an array and each index is going to have an associated object and this is possible through our mapping so for instance and the last slide a was mapped to 5 so slot 5 or index 5 is going to be a slot so what you see in this picture is at the top is that array we just created which contains our mapping and in the center is just a visual representation of what's going on the value in the array for each position is currently the index which it is at this is because originally every node is a root node meaning it mapped to itself but as we perform the instructions on the left of unifying groups together or objects together into groups we're going to find that we're going to change the values in our array to map to other letters and specifically the way we're going to do it is for some index I in our array index eyes parent is going to be whatever index is at position I so what for instance if we want to unify C and K we look at C and K and we did a scatter that C has a root node of 4 and K as a root node of 9 so either C's won't come case parents or caves when we come C's parent and I chose that case parent is you want to be C so now at index 9 which is case position I'm going to put a 4 because I know that C is a 4 so next as an e we're going to do a similar type of thing and I'm going to say that s is the only 2's parent is going to be e so at s position which is 1 and I put a 0 because E is 0 similar thing for MJ but here's where things get a bit more interesting so now we want to use Phi and B so if I look a a has a 6 in itself but 6 is J so I know that a root node for group Green's J and B is a single node because it's a self-loop and in general I'm going to merge smaller components into the larger ones so now bees are going to point to J because the green groups root node was J so now I want to merge C and D so I find the root node of D which is B and finally we go to C which is C and I'm going to merge the smaller component D into the larger component which is the orange group so now D is going to be part of the orange group now I want to merge D and I so similar thing happens and I now points to see now I want to merge L and F so f parent is e so I'm going to merge L and to be into the red group now I want to merge C and a so this is an interesting example so I find C's root node which happens to be C I find as root node which is J so now component orange has four elements by component green only has three so I'm going to merge the green component into the orange component so now J is going to point to seat so I want to unify a and B so I do so if I go up at follow the parent nodes like I reach a root node as pairs is JJ's parent C so I know that a belongs to the orange group if I do a similar thing with B I also discover that these parent is also C which is the orange group so I don't need to unify them they're already unified together so H and J G they currently don't have a group so I'm going to arbitrarily merge them into a new group so we do the blue group so HMF so if I look HS parentage G and s parent is e the right component is larger so I'm going to merge the blue group into it and now since G was the root node I make it point to e which was also the root node now I want to merge H and B so H is root node is e if we follow up the chain from H to g8e and B's root node to C because we go from B to J to C so now since the orange component is larger than the red component I'm going to point the root of the right component to the root of the orange component so II now points to C okay and note that in this example I'm not using a technique called path compression this is something we're going to look at in the next video which is an optimization on the union-find to summarize if we want to find out which component a particular element maps to what we have to do is find the root of that component by following all the parent nodes until we reach a self-loop or a node whose parent is itself and that will uniquely determine which component that element belongs to and to unify two components together what we do is we find the root nodes of each component and then if the root nodes are different because if they're the same that they belong to the same component already so if they're different make one of the root nodes point to the become the parent of the other root node so just some remarks about this union-find data structure so in general we don't really onion yin elements just because this would be inefficient as we'd have to update all the children which point to that node and we don't have access but we could probably in theory keep track of that I just don't see any application currently but there there might be also remark that the number of components in our union fight is going to be equal to the number of root nodes remaining because each root node is responsible for a component and also remark that the number of root nodes never increases that always decreases because all we do is unify components so components only get bigger and bigger and bigger so now I want to talk about the complexity of the Union find so I said in the first video that the unit line has an amortized time complexity however the implementation I just show you does not happen amortize time complexity not yet not without the past compression which is something we're going to look at in the next video which is what makes the Union fine an absolute beast of a data structure you must watch the next video but just as an example if we need to check if H and B belong to the same group or a different group it's going to take five hops in the worst case and well potentially much more so H we find the root node which is C and then we go from B and then find the root node it's also C so this takes quite a few hops so in the next video I'm going to be covering path compression so absolutely make sure you watch that video it's what makes you find so great and also if you're interested in some source code for the Union find go check out my github repository with all of these data structures I've been covering so guys thank you for watching and I'll catch you next time ",
            "url": "www.youtube.com/watch?v=0jNmHPfA_yE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "if1e9OzgLh4",
            "channelId": "UCG7VjibP1ugLpiu9-GX_KrQ",
            "publishedAt": "2019-03-07T18:15:25Z",
            "title": "Disjoint Sets",
            "description": "Advanced Algorithms lecture 20190307.",
            "channelTitle": "Hyrum Carroll",
            "transcript": "this is dr. Kara welcome to another exciting day of advanced algorithms okay we're in March now and we get a covered disjoint sets and then we'll start to get into graph algorithms today we will pick those up again in three weeks that sounds really weird three weeks next week is strictly devoted to the midterm exam and but do notice that there is an applications quiz that is due Tuesday before then you can take it right now if you want but it is there and that that may help you study for the exam the midterm and so do take that before taking the the midterm there is a hyperlink topics list here for you to review and help you guide your study in terms of what what topics to cover i've naturally received several questions about what is the midterm gonna be it won't be essay okay unless there's drawn complaints will actually know even if there was drawing them light so it still won't be essay I I don't want to make you guys write essays I don't want to grade them you don't want to write them so it's a win win win so you can expect questions like the quiz you could expect some a little bit of code questions as is fair game you could expect some graphical graphs choices or structures you could expect some big Oh questions any questions about the questions okay you are welcome to study with each other if your remote then that could be posting a discussion question or emailing students that's completely fine to study together and and the exam is proctored it opens up on Tuesday at 7 a.m. if you're going to have it proctored and closes at a week from today at 12:15 that's all Easter's standard time since the course is being hosted from Eastern Standard Time if you have any remaining questions about midterm please email me or call me or stop by my office to let me know the week after that parking for the face-to-face class is gonna be really really really good but it won't I'm not gonna be here okay two weeks for me I won't be here I've already put out on the calendar what we're doing partly so you can see that the graphs continue here and it heads up about a future quiz which hasn't been posted yet but to look for that and to give you a heads up so you can be prepared because we won't be having lecture after today before that any questions okay let's let's jump in here's the class notes which will be posted after class and so what we're gonna be talking about is the data sets and algorithms for when we need to store several elements in two disjoint sets okay and what I mean by disjoint sets is no members are in common okay no members of the sets are in common this is all so that this data structure is also known as a union-find data structure or a merge find set based on the common operations that make use of that so common operations include make set where we give it an element where we're going to where it makes a set with just element in it as the only member maybe you could have called that create but we're making a set a very simple set that has just one element fine set in in general returns what what does it return we give it a name it's called the representative it's the representative and what that is is it's a member of the set with element in it okay so the representative may be element or it may not be so some applications require the representative to be the lowest member other applications just require that it is the same if the set composition hasn't changed from one call to the next so if we haven't changed this set fine set has to return the same but some applications are going to assume that that's lower the min or the max or whatever the application dictates okay so just something to watch out for now Union is where we combine the set with element a that's sorry element one with the set that has element two now notice the the wording there it's not combine element one set an element to set well because what we deal with this sets is they're not ordered or at least not all implementations are ordered for the the sets and so we have a representative to say Oh element one is in this set and the way we name that set is with the representative okay so that's maybe a little different than what we've encountered before we're gonna see these over and over again these three operations on different implementations and in different ways okay so let's talk applications so certainly across walls algorithm which is finding the minimum spanning tree of a graph so stay tuned we'll be covering that next month is a clear application of disjoint sets but in general its connected components of an undirected graph so here we have some graph they are connected components but we have we have four connected components here in this graph and so up here in the a part and so this illustrates what we're trying to store okay this this image is the figure one from chapter 21 in the textbook and so what we could do so that we're talking about application here and one of the applications is connected components of an undirected graph is we we might want to determine what the connected components aren't so here's some some pseudo code it's not Java it's kind of close to Java but the pseudo what do you think about the pseudo code in the book it it's not terrible if I feel like it's not quite as digestible as I would have liked how's that for a non technical description of it very technical and that's part of it is it's very technical but I would so I kind of translated it into Java like pseudo code or code this lot closer to Java so that in the hopes that between the two of them that one of them is readily digestible I also added comments you could use this as a as a motivation to comment your code in general in terms of the benefit of comments and how far they can go now they document in their code because that they have paragraphs describing it so it's not like they don't explain it but when I glanced at the code I start to dig into code without reading the paragraphs they could use some well-placed comments okay and so here we have a function that creates a set for connected components in a graph G okay and so initially we're gonna just start with each vertex in its own set and so here's a for each loop and so we have graph G we're getting all the the vertices out of it and assigning each one of them and turn to V if you're not familiar with this notation and then we're just making a set and I've chosen to lowercase them because of coding conventions are u lowercase functions uppercase classes okay so so we we go through make all the vertices a set and then we go through each of the edges and if they don't belong to the same set then we Union the two okay we're Union the two if they don't belong to the same set if they already do great they're they're already in the same set and there we go and now after we've done that then we could call same component on to the vertices oh I forgot we have vertex you vertex V and so then we find if they're the same if they have the same representative not quite sure if it's going to be you V or some other one then it's returned true otherwise return false the image here shows the progression of that the the figure if we start with our initial sets and then we we go through the edges and some arbitrary order and then we combine them so D is combined with B here so that they're in the same set and then our final answer here is ABCD or in one set yep ABCD and they are all connected meaning you can get from any one of them to any other one and it's not connected with anything else but e F and G are all connected and so as H I high and J okay questions on that okay so let's do an exercise so here we have this this graph it's pretty big maybe I can make it a little smaller and so let's trace the sets that are produced by running connected components using this following graph okay and so using this graph go through connected component C let me get them both on the screen okay so I'm going to pause the video I'm going to float around so if you're watching this remotely then take a second pause your video play of it and complete it and then what we'll come back together Oh for simplicity let let's end sorry for what's the word I'm looking for if so that our results match process the edges in alphabetical order so then it'll be easier to follow the the steps when we when we come back together alright let's walk through this so here we're gonna trace the sets produced by connected components using this graph and here here's a different notation of it here in the the text window on the left but it's the same this is actually the representation stored in a dot file in case you're curious which is really cool but we don't we're not gonna talk about that today okay so the first step that first for loop says create sets for each one of them and I'm going to need larger window okay so we created sets for each one of them and my apologies let me shrink it just a little bit more so this does not wrap there we go okay and so then as I mentioned I said let's process the edges in strictly alphabetical order so if you took all the edges and listed them its undirected so list the the list the two vertices in alphabetical order and then list all of the edges in alphabetical order so I've done that here so as we process these edges in that second for loop we're going to process a e first so that means we're going to take the set E and we're going to Union it with a so this is to go through and just get the the the basic application of disjoint sets going we haven't talked about implementation yet just a mathematical representation of them so we've combined a and E now we've combined we've we removed set H and combined it with the set that had a and E in it okay and so now that that completes this completed this connected graph here and as we keep going through now we're gonna start on the larger connected graph so B and G we can we Union those two and then we Union in J and then we work on another part of it because they're sorted alphabetically but then they'll come together now because we're we just took care of this edge here in this set and then Dee and I okay going strictly alphabetical okay so we're obviously not done yet we need to so that's all the less part of that leftmost connected graph now GI GJ and then I J and then we're all done here and so we have this connected graph so it's all in one set and now this is all in one set and now and don't forget lonely see there which is why it's important to make sets with all of them from the beginning is so that we take that into account so now if we called same components then we could pick any two of these and ask are they connected and it's yes or no and so if we have an application that needs to find that answer - are they connected then we have a simple way to do that a fast and efficient way to do that or we could ask our a and B connected the answer is no that because the representatives are different sets questions on this okay they put this in the class notes all right okay that's great we got a high level and we got some applications down which i think is good to cement this so now let's talk about implementations the two main implementations are linked lists and disjoint set forests so let's talk about those in in turn so first a linked list representation of disjoint sets so here we have each set is its own linked list with its own head and tail pointers okay so that that's how we store that and now the representative is the element that head points to okay so so let's look at this visually here so here in a we have two two sets each each element has a pointer to this link this linked list node which has a head and a tail on it and so very simple data structure just a little bit more complex than a traditional linked list but so if we now if we asked hey what if we did find set on G we would follow this pointer and then follow head and would say okay it's F ok so then we need to traverse two pointers and then we can determine the fine the the representative for into any any element okay so what do you notice about this implementation well what what will work well well well what won't work well okay and so this this is a basic implementation and so you using linked lists so let's talk about operations so again we talked about make set find set and Union so here with the linked list that's just gonna creates a new linked list okay for this straightforward we like that's good so then we also find set and so as I mentioned it follows the pointer to the the set node so meaning this node here and then the head node the head pointer okay and then we have the representative that way now with Union what we're going to accomplish is we're gonna concatenate that's gonna it concatenates these sets okay and this is illustrated here in this died in be the part here we took S sub 1 and S sub 2 and we combine them the union of them in this case we actually and so what we did is we just use s1 and then we said okay now Union means whenever we add called find set on CH e or B that they are going to give us some referee the representative is some element of that set and the way we just determined how we were going to find it is we'll have a pointer to this node and then a pointer to head okay now could we have done this any faster it's a slight optimisation this one has four but this one has three so computers are not lazy they're efficient ok I like to say fish and that sounds so much better than lazy and so but what if this was two elements and this was a million then we would clearly want to do it on the one with two versus the one it's a million so if we had to do this over again would actually be more efficient to do the smaller one adding it into the larger one and so we call this weighted Union and so that's with free Union we add the smaller set to the larger set to the larger one okay and that'll be a simple test but then it could save us a lot in performance okay questions about linked list implementation okay let's go to disjoint set forests so sets here are stored as rooted trees okay the nodes are the members and representatives are the root node okay so representative are the root node okay so now we have same operations make set not surprisingly creates a new rooted tree okay now find set what it does it follows the parent pointer or pointers until the root okay and so we might be at the bottom of the tree we might be at the the top of the tree and so we just follow the pointers until we find it and then once we've gone to the top then we called that the representative for the set then for union of the two elements this connects the root of the tree with element one to be the child of the root of the tree with element 2 okay so that that's what Union does we're going to link these two trees together so that way if we called find set on either one of them will get the same answer because we've said hey put them in the same set so let's visually see this one as well so here on the Left we have two rooted trees we have C notice it has a pointer to itself okay that just makes the code easier because we can follow the point we can assume that the parent pointer is always valid and we just check to see if it points to itself so we have these two rooted trees here and then if we took the union of them we could we would be linking C into F for example and that's illustrated here now if we asked find set on any one of these it would eventually traverse up to the root node and it would say F for all of those okay now you're like well that's great but that all has the same time complexity as linked lists so let's talk about some optimizations then sorry the linked list implementation version so let's talk about some optimizations which will make it go much faster okay and they're called Union by rank and path compression so let's first start with Union by rank and so like the weighted Union optimization for a link list that we just talked about we're going to make the tree with the smaller rank point to the tree with the larger rink right and so that will change less things up and it will also have the benefit of making the trees shorter the trees will then be shorter in general rather than cascading Li being longer and longer now here we're talking about rank and it's in the optimization name so it's it's probably worth the talking about so rank here is the upper bound on the height on the height of a node okay it's not necessarily the height of the node but it it is the upper bound of it so we for application purposes we'll use the height of the node okay and so that's Union by rank simple change just like weighted Union is a simple change but it's going to have good benefits in terms of performance so now let's talk about path compression okay and now okay so what path compression does at a very high level no pun intended is it flattens the rooted trees each time we have to traverse so if we're already traversing them in fine set then let's just make it let's just take a little bit extra work and let's flatten them so that we don't have to traverse them again okay because we actually want flat we want short so it trees so let's see a representation of this so we have here on the Left we have a rooted tree where B is the parent of a and F is the representative of this set of this disjoint forests and so if we called find set on a what we want to do is flatten it so now if we ask for any member of the set we can quickly determine the answer okay and so that's good we already had to traverse the parent traverse the parent traverse the parent traverse the parent to risk the parent and so what why we've already done that let's just update all of them to flatten it so that we don't have to traverse as long again okay so let's look at some pseudocode here so a node here in these rooted trees is going to have two things it's going to have a node so some a pointer to a parent okay and it's also going to have a rink so which is technically speaking the upper limit of the height of the height of the node okay and now make set we pass it a node and here the definition of root node for our implementation is that the parent pointer is itself and so this ensures that the parent pointer is always valid and so we set that because we're just creating a new set and so then that is the representative and then it's rank 0 it it doesn't have a height so we can just we need to initialize that ok now now let's look at Union Union is going to combine the trees that have x and y in it and just to be clear here it assumes that x and y are in different sets otherwise it actually won't work correctly so I'll leave that to the interested student to see what goes wrong if x and y are in the same set okay and it's pretty boring or it's pretty straightforward code in that we just call link after finding the representative for the two nodes so link is we're gonna make the shorter tree point to the taller tree again if we arbitrarily just point put the left one into the right one then that would have the effect that we could get taller and taller trees but we just want to do a simple check so that we don't keep increasing the height of the trees unnecessarily so which tree is taller well we'll just look at its rank remember at this point we've already got the representative here for x and y so maybe these should have been named rep of x and rep of y if we're considering x and y but that's okay we're just arbitrarily calling them x and y and so if y is taller and so we don't need to add to its height because we know that it it's taller so that we we know that it can take in this the smaller tree and we all have a problem otherwise the X is taller or they're the same height and so it's just very simple we linked it by changing its parent for the root node and then we check if they're the same rank that means we actually increase the height of the tree so if they're the same rank because we have to consider all cases here then it's the same height and so now Y is actually taller because they were the same height okay questions on link okay now find set as I mentioned it it it gives it returns the representative for X and it's gonna recursively perform path compression and thereby flattening or shortening the tree now it's very few lines of code but because that's common with recursion but it does the job so let's look here we have the base case if it's not the root node root node B by definition is X is equal to it it's its parent is equal to itself then let's find the root node and then set it to its parent and so we recurse down we recurse down rehearse down or your curst down or recurse up and then once we find the parent we return return return and so then we reset all of the children parents on the way back down and then we finally return it okay so if so one way we so we could see this played out here let's let's pull up that image okay so if we are calling fine set on a okay then find set on a is a not equal to AIDS parent no it doesn't K so then we're gonna call fine set on its parent and I'm gonna indent here just to show that we were increasing the stack we're pushing on the stack that this call came from this call and then B you're gonna see a pattern here so B is gonna call C and that's gonna call D maybe we should have had a shorter tree okay and then finally when we call it on F F does equal its parent so its parent does equal it and so then we here with this call we are going to return F okay and so when we when we turn F here then that means we come back here where D is here and E was no I'm sorry he was here and F was here so when we returned from this it returns F so we set the ease parent to F which is just redundant but it makes the code simpler okay and then we're done and we return F okay so then we've popped this off we pop this off now now we are where we had D here we called the e and we just completed and now we return F here so this is DS parent is now equal to F okay so now we've done this link we did this link although it's already that way then we did this one and then we returned F the newly set F and now we have C here and D here so then we return F again then we're gonna return F again F again so we've just gone through the recursion gone all the way up and on the way back then we've set the reset all of the parent pointers including the one that was already set so that we have shortened this tree so that if we called find set on a again we would be right right next to the parent and be able to execute it much more quickly questions on operations okay let's talk about time complexity here this is where it gets really interesting okay so make set for both of them is really quick just a few lines of code and so it runs in constant time now for the link list here it runs in constant time because we're just looking at two pointers and and so that that's constant time Union on the linked list though is it's gonna take n time you know I disagree with the authors here in terms of how long it takes I say it takes order n time because if if we look at this diagram we can walk through the smaller set but let's say they were equal sized okay so then we're n divided by 2 and we are just updating one pointer for each item in the list to now point to S sub two and then we and then we need to change this tail pointer it's next to point to the heads and then update the tail pointer here and we're done to me that sounds like order in anybody want to disagree with that why they belabor it all that extra work why not just put it in a loop and be done so I didn't I didn't understand why the added complexity so maybe maybe I'm missing something but so I feel like it's order in so worse worst case is we're n divided by two because let's say that the two sets are equally sized we go through it with a little bit of overhead and we're done okay so take note of that I say it's order n okay now on disjoint set forests here I don't want to get into the analysis but for completeness the Big O is M times alpha of n where the alpha function is the inverse of the Ackermann function and M is the number of disjoint operations on n elements okay and so the inverse of the Ackermann function grows very slowly and so for intensive for all intensive purposes we can consider a constant and so that's awesome because now we have sped up the Union so if we're doing a whole bunch of union operations we just sped them up okay which is great okay okay now that we've looked at that let's look at some application here this would help prepare for a quiz for example here's part two we have all these operations here makes that makes it make set Union Union fine set Union Union fine set Union finds it and so let's go through it and exercise the these two for both linked lists and rooted trees okay let me pause and so if you're watching this pause and start to work on it okay alright I'm serious if you're watching this online you got to pause and work it out otherwise you won't catch little nuances okay so so let's go through this let's first do the linked list one with weighted Union and so that makes set 1 2 3 4 5 6 7 is just going to make a set and I the notation I'm using as the star represents the representative and so we just quickly make these sets and now we have seven sets each with its own each is its own representative I'm not drawing all the links to the linked list node and then the header node and all the next nodes but we would have 7 of those overhead nodes each one for each set and that this is mathematical notation the braces define a set but that's a lot of ASCII art and arrows so I just did sets ok ok so that's hopefully straightforward now let's start doing unions we're doing union by weight and I'm just using the convention that if they're of equal weight they're equal lengths then we'll just do the the right one into the left one now real quick I forgot to mention with union by weight by Union that assumes that we just added one more field on that linked list node that kept track of the length and we updated it so that we don't have to traverse it every time just to determine that but you probably figured that out okay so we took the Union of 1 & 2 that gets rid of that set puts it in this set and makes it a and its representative is 1 ok with linked lists you can think of these very much just like we did before with the abstract version so now when we do Union 2 or 3 now it's not arbitrary the representative set for the representative for 2 is 1 we would follow the link to the linked list node and then it would fall it to a head node which would be 1 and that has a length of 2 whereas 3 has a length of 1 so we are definitely adding 3 to the set with 1 & 2 now and we do find set 3 we're going to follow the pointer we're assuming we have some reference or pointer to 3 and then we'll follow that link threes link back to the linked list node and then fall it to head and so as illustrated here the star it's one little returning one Union 4 & 5 is similar as above we're combining 4 & 5 they're the same length so we're just arbitrarily going left right here which is by the way different than will do for the next one so then 5 & 6 we are combining this list and that's the this set and this set and so we'll just add in this the 6 & 7 into the 4 & 5 set and now when we ask for 6 find set 7 it's going to follow its pointer to the linked list node it's going to follow a head pointer to 4 and so it returns for that ok and then Union of three and seven what are we gonna do for that the shorter it goes into the longer and so we're gonna add in one two three to the tail of four five six seven okay because 3 is less than four there's three elements and this one and there's four in here so we waited Union says we're at we add the smaller to the larger so we did that now when we do find set three it had we would follow its pointer to the linked list node and follow it to its head in this case it is four okay returns four questions on that implementation okay so unions can take order n time so now let's let's make unions a lot faster by using rooted trees with Union by rank and path compression now either Union by rank by itself is an optimization and path compression by itself is an optimization but combined they have even better effects okay so make set is just we're gonna have all these sets and I'm changing my notation here because now we have rooted trees so now these are nodes in a rooted tree where the when in parentheses it keeps track of the parent and the rank okay and so I'll also show that show the parent with my ASCII art arrows and the ring can be inferred from its height but I'm just gonna make that explicit here so these first seven these these make set operations here would result in seven trees each one having its parent pointing to itself and each one with the rank of zero okay now let's start combining them now let me point out here when we do Union one two if their ranks are the same the code says that we are making one a child of two okay so the code has to have it one way or another for this class I'm saying that one is a child of two if they're the same rank okay one becomes a child of two if they're the same rank and so I've Illustrated that here with my beautiful ASCII art we made it this node say it's parents - it still has a rank of zero this one we increased its rank and then we said its parent is itself okay so there we have the union of one and two just to be clear one becomes a child of two when equal rank let's do another Union two three now here they're not of equal ring two is the representative for element 2 and it has a rank of 1 but 3 has a rank of 0 so we are clearly adding 3 as a child of 2 and so for all three of these the representative is 2 now let's go to fine set 3 so fine set 3 is going to follow its parent pointer until it it's pointing to itself in this case it's just pointing to 2 and so it's going to return true and we don't really see the effects of path compression because it didn't update it didn't change any pointers although it did update them so now Union for 5 okay this is pretty straightforward we keep this rooted tree here and we have four point two five not five two four four point two five and then fives rank is increased next we're doing the same the similar thing with 6 and 7 6 is a child of seven okay now when we do a union 5 & 6 they're the same rank and so that means 5 becomes a child of 6 well actually the representative the 6 which is 7 okay so notice now 7 has a rink of two it doesn't have a rink of three but it has a rink of two because we we didn't make 5 a child of 6 we made 5 a child of 7 okay now and we call fine set 7 it's fairly straightforward we're just going to return we're already at the root node and so then we returns 7 hmm and I have it wrong there it says 4 that should say 7 my apologies but there is no changes to the tree now when we combine 3 and 7 we take these this tree we say ok its representative is 2 and then 7 is its own representative oh the this representative has a rank of one this one has a rank of two so we're gonna add 2 to be a child of 7 I'm showing that here there's just one more pointer going to 7 okay and that they are different heights so we did not update the height for that tree and then now when we call find set on 3 we follow it to its parent we follow it so it's paint and we get there but is there anything more we need to do so when we called find set on 3 we actually did path compression and so 3 said well hey who's my parent that's two okay well who's your parent 7 and then on the backside of the recursion we said hey make two's parent 7 which it was already but then make threes parent be 7 shortening our tree here or flattening it a little doesn't tech it didn't change its height but we're working on that so three parent is now seven so we can update that here threes parent is seven and so and that's updated let me change this these seven as well do you see that so that's path compression we only saw it its effects in the very last example there need questions about this joint sets okay well that was great except that we didn't get into any graph topics but do not worry graph topics are not on the midterm exam okay and so let me push back this quiz and we will start covering the elementary graph algorithms in one to three weeks you might want to refresh on upon it before a lecture in three weeks because it's such a long time let me know if you have any midterm questions have a wonderful and then of course have a wonderful spring break and you can expect the next video to be posted in three weeks thank you ",
            "url": "www.youtube.com/watch?v=if1e9OzgLh4",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "UBY4sF86KEY",
            "channelId": "UCEOGtxYTB6vo6MQ-WQ9W_nQ",
            "publishedAt": "2013-06-17T03:07:05Z",
            "title": "Practical Programming Algorithm: Disjoint Sets",
            "description": "Disjoint sets supports union() and find() function. Notes can be downloaded from: boqian.weebly.com.",
            "channelTitle": "Bo Qian",
            "transcript": "hello everyone today we will talk about disjoint sets which is a very useful data structure for graph algorithms suppose we have a universe of items which we want to manage with disjoint sets disjoint sets is a group of sets where no item can be in more than one set so each item can belong to only one set as an example this is an example of disjoint sets we have four disjoint sets as well as 2s 3s 4s 3 contains 2 items as well as 2 as for each contains only one item disjoint sets support at least two operations find and a union which is also known as find the union algorithm find will take one item as a parameter and then return the disjoint set this item belongs to so find D will return as three because D is an element in s 3 Union takes two disjoint sets as parameter and as a result those two disjoint sets will be merged into one set so the result of Union s 1 s 2 is this both s 1 and s 2 are merged into the same disjoint set s 1 and both a and C are items inside s 1 so this is an example of disjoint sets and what kind of operations that it can do the next question to consider is how do we implement a disjoint set there are a different ways to implement disjoint sets the most commonly used is she based disjoint sets or disjoint set forests so this is an example of tree based disjoint sets for tree based disjoint sets each set is a tree so as three is a tree and each item has a pointer that points to another item a set is identified by the loot of the tree the loot of S 3 is B and the loot of s 1 is a the loot of s 2 is C loot has a unique attribute that it's pointer is pointing to itself so all the loads can be identified by their self pointing pointers when we call find D we'll find the parent of D which is b and b is representing as 3 so we claim that we found the disjoint set of d is as 3 and when we call Union s 2 s 1 we're merging s 2 and s 1 into one disjoint set so the result is this as 2 is gone and C is no longer a root both a and C belong to s 1 and s 1 is represented by its loot a and then if we call union s1 s3 we are merging s1 s3 into one disjoint set and that the result is this the elements of ABCD or belong to the disjoint set s3 and s3 is represented by its loot B now let's consider what the complexity of the tree-based disjoint set Union is very fast because for Union we only need to change one pointer for example the point of a originally was pointing to itself and now it points to B and we have finished the merging so Union only takes constant time find take the time of the depth if we try to find that disjoint set of C first we find its parent a and then find its parent B so the time of find is proportional to the depth of the chi-chi based disjoint set can be easily implemented with pointers so if we have an item whose data structure is like this it has some kind of data and there has an appointed at points to its parent which is another item so with this we can easily implement the tree-based disjoint set but sometimes this approach of using pointers is not so convenient for example what if the item data structure doesn't have a pointer and this item is defined in a third party library therefore you cannot change it then things become difficult you have to create a wrapper class of this item and adding a pointer inside the wrapper there is another way of implementing a tree that doesn't use pointers at all which is using hash table using hash table has the advantage that it is not inclusive we don't have to change the data structure of the item to add pointers if it doesn't have one we can use the item as is so for today's coding demo I'm gonna use hash table to implement sea-based disjoint sets this is a simplest implementation example of disjoint set so in this case the type of our items is char and the universe of items contained five chars ABCDE the key data in the disjoint set is this parent which is a hash table and this hash table defines the parental relationship between the chars and in the constructor we take each item of the universe and set its parent to be itself which means we'll have five disjoint sets and each set contains only one item and then we set the parent of D to be B and as a result of that B and D are in the same set and B is the loot so essentially we have created this disjoint sets B and D are in the same set and a CAE are in their own set the fine function take an item as parameter and the return that disjoint set where this item blonde - if the parent of this item is this item itself which means this item is the loot and the loot is a representative of the disjoint set so we can claim that we have found the disjoint set and return the loot otherwise we'll continue to find the parent of the item the Union function takes two disjoint sets as parameter and there's two disjoint sets are represented with their roots and what this function does is it sets the second dilute to be the parent of the first alert as a result the first load is no longer a loot and the second loot is there a loot of both disjoint sets so they are merged in the main function I have created a disjoint set D s and if I do D s dot find C this should be returned C because C belongs to a single item disjoint set as is shown in this picture and then I do the s dot you mean C a so I'm merging the disjoint set of C and the disjoint set of a so as a result a and C in the same set so in the picture basically we have done this a is the new root of this new set and now if we do D s dot find C again this will return a and if we do D s Union a a is the new loot so it represents that set and we union a with B and the B is the loot of the set that contains B and D so as a result is a C B B are in the same set so in the picture what we have done is this so this is how a disjoint set data structure can be used now let's analyze if there's any way we can improve the performance of disjoint sets the union function only takes constant time so there's no room to improve the Union function but the find function is slower it is in the order of the depth of the tree so the deeper the tree grows the slower the find will become so if we can find a way to let the tree more grow towards the side then grow in downward then we can flatten the tree and we can improve the performance of the find function let's look at our code so where do the trees grow the trees grow in the union function and here I just randomly choose the second load to be the new root so if I'm unlucky my tree will grow deeper and deeper and the find function will become slower and slower now let me implement some strategy in choosing the new root if I always choose the loot of the deeper G to be the new root then the tree will not grow deeper let me repeat if I always choose the root of the deeper G to be the new root then the tree will not grow deeper and that is a very good news for us but in order to do that we need something to record the depth of the trees so let's do it will create another on ordered map which is from char to int that's quite rank and this is to record the depth of cheese initially we made every disjoint set to contain only one item so that means the length of each key is 0 and after we merged D and B the length of B becomes 1 and that the Union function needs to be more complicated so this is my new Union function remember will choose the loot of a deeper G to be the new loot so if the rank of set 1 is bigger than C 2 which was set 1 to be the new loot if the rank of set 2 is bigger than set 1 then we'll choose set two to be the new root else if both three are of the same depth then we just randomly choose insert 2 as the new loot but the rank of said two were increased by 1 so only when both trees are of the same depth the tree will grow deeper by 1 now we'll have much more flat energies than previous implementation therefore we'll have better performance with the find function that's all for today feel free to subscribe to my channel and check out the other videos I have bye-bye ",
            "url": "www.youtube.com/watch?v=UBY4sF86KEY",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "kd-trees data structures": [
        {
            "videoId": "XG4zpiJAkD4",
            "channelId": "UC05LugecRCvKLip8Tqz2krA",
            "publishedAt": "2020-04-06T22:37:20Z",
            "title": "Advanced Data Structures: K-D Trees",
            "description": "",
            "channelTitle": "Niema Moshiri",
            "transcript": "but KD tree or k-dimensional tree is a k-dimensional extension of a binary search tree so what does this mean well first of all it means that a one-dimensional tree so a KD tree with K equals 1 is exactly a binary search tree but basically a KD tree is a binary tree where for every level of the tree we're only looking at one dimension of the points so let's take a simple example where we have a 2d set of points let's say the first point that we insert is the point 21 comma 42 so maybe in yellow I'll put the points that I'm adding in order so 21 comma 42 so I'm inserting this into an empty KD tree so what this would do is it would create a root node just like with the binary search tree and insert that new node into the root so this point X is 21 y is 42 this point is the root of my KD tree now let's say I add another point 10 100 so a KD tree we go level by level alternating which dimension were looking at and at a given level for that corresponding dimension we act just like a binary search tree so here I'm inserting 10 comma 100 so the x-coordinate is 10 the Y point is 100 I start at the root this is level 0 let me actually maybe draw some some lines dividing my tree space by dimension so when I'm in this level I'm going to be checking x-coordinates so binary search tree operations like binary search tree comparisons precisely as they are in binary search tree but with respect to the x-coordinates this level with respect to y coordinates this level with respect x coordinates this level of this vector Y coordinates so on and so forth so I'm adding the note 10 100 so I start at the root there's a note here so I'm going to compare our x coordinates the x coordinate is 21 I'm 10 I'm less than 21 so I should be to the left of this node there's nothing there there's no left child so I will add this as a new left child of the root let's say the next note that we're adding is maybe let's say 15 comma 200 so I start at the root there's a note here so I compare our x-values I am 15 the current node is 21 so I should go left okay now I'm on this bubble I should be comparing y-coordinates I am 200 the current node is 100 so I completely ignore the x value I'm only looking at the y coordinate because I'm on the Y level I'm bigger than 100 200 is bigger than 100 so I would add this as the right child of that node so this is 15 comma 200 what if I were to insert the node let's say 20 comma 50 so I started the root I'm comparing x-coordinates on this level 20 is less than 21 I should traverse left okay on this level I'm comparing y-coordinates 50 is less than 100 I should traverse left there is no node there so I will insert this as the left child 20 comma 50 so 20 was less than 21 so I went left 50 is less than 100 so I went left answer date here let's do one last example let's say we're gonna insert 20 comma [Music] let's say 20 comma 300 let's see what happened so 20 is less than 2 some comparing x-coordinates 20 is less than 21 I go left 300 is greater than 100 I go right I'm comparing x-coordinates now 20 is less 20 is greater than 15 so I would go right 2,300 so here I was comparing 20 with 15 20 is greater than 15 so I went right so in general I'm doing things precisely like a binary search tree with respect to whatever the current levels coordinate is so here I'm comparing like a binary search tree with respect to x coordinates here with respect to y coordinates here with respect to x coordinates here with respect to y coordinates let's try another example of inserting elements into a Katy tree but this time let's use 3 dimensional values so our points are now three dimensional points and our layers of our KD tree will alternate X Y Z X Y Z etc etc etc so I've laid out the outline of my different layers and I have my points here let's insert them so the first point is the point 10 0 100 my k/d tree is empty so this just automatically gets inserted as the root so this point is done the next point is 5 10 15 so I start at the root and I'm comparing x-coordinates 5 is less than 10 again I completely ignore the other coordinates 5 is less than 10 therefore I go left there's no left child so I will insert this as the left child of the read there we go it's like I 1 is on the third point is 7 7 7 so again I start at the root 7 is less than 10 again I don't even care about the other dimensions just looking at Dimension X right now 7 is less than ten so I go left seven is less than ten so again I'm only looking at Y coordinates now so this 7 is less than this 10 so I go left again there's nothing there so I will add this as the left child that one's done now 9 0 0 so 9 is less than 10 so I go left 0 is less than Z is less than 10 so I'm comparing Y coordinates I go left again Z coordinates now 0 is less than 7 so now I would go left for fun let's add one more element maybe let's try adding maybe let's say let's try adding 11 10 9 so 11 10 9 I start at the root my x-coordinate is 11 this is greater than 10 so I would add it here what about let's say 11 maybe let's say 1100 so I would start at the root 11 is greater than 10 they go right 0 is less than 10 again I'm comparing y-coordinates here so be the left child of this node so same exact thing again every layer I'm doing the exact same comparison as I was doing with a binary search tree except the layer I am away from the root dictates which coordinate which dimension I'm looking at at the root I'm looking at Dimension X then I'm looking at dimension Y then dimension Z then Dimension X then dimension Y so on and so forth it keeps alternating ",
            "url": "www.youtube.com/watch?v=XG4zpiJAkD4",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "Glp7THUpGow",
            "channelId": "UCV2g02zq5y7unJ_GSr-de2w",
            "publishedAt": "2020-10-09T16:40:08Z",
            "title": "KD-Tree Nearest Neighbor Data Structure",
            "description": "KD-Tree is a data structure useful when organizing data by several criteria all at once. Consider an example where you have a set of points on a 2 dimensional ...",
            "channelTitle": "Stable Sort",
            "transcript": "kd3 is a data structure useful when organizing data by several criteria all at once consider an example where you have a set of points on a two-dimensional plane now suppose you are asked to find the nearest neighbor of some target point what data structure would you use to store these points to be able to solve that problem a naive approach would be to perhaps store the points in an array sorted by one of the properties such as the x coordinate then you could easily do binary search to find a point with the closest x-coordinate but unfortunately you'd still not necessarily be any closer to finding the point where the y-coordinate is also nearby to convince yourself of it just think of the case where all the points share the same x coordinate clearly you'd have to examine every single point one by one to find the nearest neighbor of the target point hello and welcome to stable sort kd3 data structure is very much like a regular binary search tree except instead of holding just one value in every node it holds k values when traversing a kd tree we cycle through the index to the values list based on the depth of a particular node the k in the name kde tree refers to the number of properties that each data point has in our example since it's a two-dimensional plane we have exactly two properties the x-coordinate and the y-coordinate so the root node starts off arbitrarily picking one of those let's suppose it's the x coordinate then its children the second level alternate to using the y coordinate the grandchildren nodes cycle back to using the x coordinate and so on when inserting a new node just like in a typical binary search tree we compare the node's value and go left if it's smaller right if it's bigger it's just that as we go deeper and deeper down the tree we keep alternating between using the x and the y values in the comparison note that in our example since we started with comparing the x values the y values were ignored and as a consequence the second layer nodes break the binary search tree rule where all the nodes less than the root are on the left side and vice versa but amazingly it turns out that this is okay the magic here is that we can check for this inconsistency on the way back when unwinding the recursion visually you can think of the root node dividing the x y plane into left and right sides since we decided so to start off with using the x coordinate then the next point will fall into either the left or the right side and in turn divide that side into top and bottom sections so as more and more nodes are inserted into the tree each point splits parent section into two subsections alternating between splitting the section into left and right versus top and bottom suppose our target point is 9 4 and our goal is to find its nearest neighbor so we walk down the tree and keep calculating the shortest distance found so far [Music] note that on the way down we missed the point 10 2. this happened because when comparing with the second node of the tree point 13 3 the y-coordinate was smaller than the y-coordinate of our target point 9 4 so we traverse the tree by going right once we have gone as far down as we can we then recurse back as you would in a regular binary tree search we do have a candidate closest neighbor but there is a possibility of a closer point still think of the shortest distance as a line going from the target point to the candidate point let's call this line r this line is probably going to be at some random diagonal angle but if the line directly perpendicular to the section that we chose not to visit when recursing down is shorter then there's a chance that that section may have a closer point so this is where the magic happens as we recurse back we also calculate the distance to the section that we did not visit if that distance let's call it r prime is smaller than the best distance found so far then we traverse into that section as well but note that this does not mean that we visit every node in the tree if the height of the tree is h then at most we'll visit two h nodes in other words this is still a logarithmic search in respect to the number of nodes in the tree here is a pseudocode for the nearest neighbor function we mod the depth of the node by the number of dimensions that the tree uses so as we go down the tree the depth is incremented but mod operation cycles through the values that are being compared choosing which branch to follow is very much like a regular binary tree search but on the way out of the recursion we check if the radius is greater than the distance to the other section of the plane that's the magic line just a couple of final notes the closest subroutine simply chooses between two passed in nodes without recursing any further and we don't bother taking the square root of the distances and just compare the distances squared so as to save some cpu cycles for the full source code see the link in the description so far in our example we've been using a two-dimensional plane but the methodology works equally well in higher dimensions each node would still have a left and right branch but the number of values in each node could be arbitrarily large suppose you are designing a database for a hospital that keeps track of each patient's blood type white blood cell count and blood pressure then a new patient comes in with an unknown illness using a kde tree you would be able to quickly select one or even a set of patients that share similar properties these would be the nearest neighbors with a higher likelihood of having a similar illness thank you for watching i hope you enjoyed this video please subscribe to support this channel and i'll see you in the next one ",
            "url": "www.youtube.com/watch?v=Glp7THUpGow",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "TLxWtXEbtFE",
            "channelId": "UCs7alOMRnxhzfKAJ4JjZ7Wg",
            "publishedAt": "2014-01-20T01:21:26Z",
            "title": "KD tree algorithm: how it works",
            "description": "http://bit.ly/k-NN] K-D trees allow us to quickly find approximate nearest neighbours in a (relatively) low-dimensional real-valued space. The algorithm works by ...",
            "channelTitle": "Victor Lavrenko",
            "transcript": "so let's look at KD trees the basic idea of KD trees is remember we're a low dimensional continuous space so what are we going to try to do is we're going to try to cut that space into halves and just do the search in one of the in one of the quadrants so the way the algorithm works is let's say this is our data set and now the axes have two attributes and then X 1 and X 2 what you do is you pick an attribute you find the median and then you split the data set along that median so in that case the median happens to be 6 for the first time tribute right so I have 1 2 3 4 5 & 5 attributes smaller than 1 2 3 4 5 greater than or equal to 6 so I would first split it on the 6 and then look at the second attribute the second attribute so here I get the following numbers and the median of the second attribute happens to be 4 in these numbers and it happens to be 8 in those numbers so geometrically what does it look like it looks kind of like that right so these are all the points in my data set I look at the first attribute the X 1 find the medium everything that's greater than or equal goes on one side everything that smaller goes on the other side and then I find another median but I use a different attribute so now I use I'm calling it Y should go at X 2 so I find the median and there are things above the median or below the median so what I'm doing is I'm taking this space and I'm cutting it in half every time and I'm cutting at the median but I'm using different attributes different dimensions at each step so as a result I'm going to fracture the space into these little cubes hypercubes when I have a tree like structure so when I get a new data point I can just walk down the tree until I end up in one of these hyper cubes so my new data points is 7 4 so I'm going to compare it I'm going to compare the first attribute to 6 it's greater than or equal so I'm in this branch this means I'm on this side in space now next time can compute the compare the second attribute to four and it's going to be no sorry to eight and it's going to be smaller than eight so that means that I fall into this bucket into this region of space so what I can do then is I stop and within that bucket I'm going to compare my testing point to all the training points that fall into that bucket and in this case I'm going to compare it to this guy and to this dye it is an approximate technique because you will make mistakes all right that is the nearest neighbor and that's not part of the bucket because that ended up on the other side of the median split and you would never end up considering that so it's approximate technique you will miss some nearest neighbors but it allows you to quickly drill down to a bucket that has roughly right looking examples okay so that's what you do for low dimensional data ",
            "url": "www.youtube.com/watch?v=TLxWtXEbtFE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "-e7oHgAepQA",
            "channelId": "UCORLeCUCDYj9eVhVdnf4pzg",
            "publishedAt": "2020-05-26T14:29:14Z",
            "title": "K-D TREE | K-DIMENSIONAL TREE | APPLICATIONS OF K-D TREE | EXAMPLES ON 2-D TREE | 2-D TREE |",
            "description": "This video contains a description about 1. Introduction to K-D tree or K-Dimensional Tree. 2. Applications of K-D tree 3. Example problems on 2-D tree.",
            "channelTitle": "DIVVELA SRINIVASA RAO",
            "transcript": "hi friends today I am giving a lecture on one of the advanced three called as k-dimensional pre-order simply we can call it as kd3 okay so it is one of the important concept in advance of data structure okay first one first point in a k-dimensional tree the KD tree for a k-dimensional tree was personally developed by John Bentley okay so in the K dimensional tree K stands for number of dimensions and D is nothing but dimension if K is equal to 2 then it can be called as a two dimensional tree water to d3 if K is equal to 3 then it can be called as a 3d pre-war a three dimensional tree if K is equal to 4 then it can be called as a 4d pre-war a four dimensional tree ok so K is equal to 2 then it can be called as a two dimensional tree K is equal to 3 it can be called as it three dimensional P K is equal to 4 it can be called as a four dimensional tree in the case of 2 dimensional tree each and every known can contain only two dimensions so this is the 2d p in that one each and every node can contain two dimensions so that is this is why dimension so exit coordinate refers the extra dimensional value y coordinate represents the Y dimension by in the case of 3d 3 so each data point in 3d T is the node that node contains supremes first value is x coordinate second value is y coordinate third that you is a jet coordinate x coordinate represents on extra dimension y coordinate represents on my dimension just coordinate represents and J dimension in the case of 43 each data point can contain four coordinates cook in each and every coordinate in refers to for one dimension so four coordinate represents four dimensions okay next one what is KD 3 ok suppose there are some data points are there for authorizing the data points on it k dimensional experience here k value to a value TK value food okay meeting Billy for organizing all the data points in a k-dimensional business faith we have to require a space partitioning data structure that data structure is called as KD 3 in the KD 3 okay the data points are organized in the form of the tree so that tree is called as KD 3 so each and every data point can be represented by a node okay next one each node in the KD tree contains a data point okay so this is a node this node contains a data point that data point contains how many number of coordinates first coordinate second coordinate first coordinate is x coordinate second coordinate is y coordinate x coordinate represents an extra dimension y coordinate represents on Y dimension okay so each node contains at most two children okay every node every node can a masterful children and most of you telling me it may contain two children it may contain one chain it may contain goj so this road contains how many number of children two children this is left shed and this is my chain this nodes contain how many number of children what children so there is no right children okay only left the child is there there is no right chain for these No Oh many number of children's are the only one left child is there there is no light rail is there for this road there is no change zero checks for this no zero chains okay each node in the JTP may contain lost two children at most two children means it may contain 0 j it may contain one child it may contain two chains next one each level in the KDP heavy cutting dimension so cutting dimension means which coordinate which coordinate we have to consider that means multi dimension we have to consider so each level of each level in the KD tree as the cutting dimension for example we are taking this level this level is the first element the first level patek dimension is extra dimension this is the second dimension is one in the third level the cutting dimension is yes so this is a 2d tree okay we are taking two dimensions because 2d means two dimensions we have taken two dimensions okay first root or extra dimension we have to consider next 11y dimension we have to consider two dimensions are completed again we have started with extra dimension for the next level for the next level Y dimension after that x and y again I sent by our repeated okay so here there are two dimensions octave for the cutting dimension for the first element is X the cutting dimension for the second eleven is my once two dimensions are completed again we are taking X for the next 11 next we are taking white after that this is the repeat later XY XY XY XY is the repeated for the corresponding letters suppose we are taking three degree ok how many number of dimensions are there in the three DP three dimensions content first level 20 dimension is the X second level heading dimension is by third level cutting dimension is engendered X by debt once completed again they are repeated for the next elements okay so cutting dimensions means multi dimension we have to consider for taking stuff for considering its chain okay so that can be discussed in this example okay now example insert the following points into an initial and B to D 3 3 3 means it is a two dimensional tree each and every data point can contain two dimension first one is x coordinate x coordinate can be presented on extra dimension y coordinate represents on Y dimension okay so now initially we are taking the MP to d3 okay there is no nodes are there in the empty 2d tree first we are considering the 53 comma Cody okay so this is the first two node and this is the root node because before inserting this data point so there are no data points are there so we have to insert 53 comma Fergie okay next next back next to data point is 27 and 28 now 2720 point and be inserted as the lefty chain for this suit has the right shape for this know how we are concerning here here cutting dimension is yes okay now we are considering only extra dimension extra damage means x-coordinate so in this one x coordinate is 2 T 3 now we are inserting this data point 53 is compared with 27 so 53 is compared with 27 27 is the lesser so that 27th comma 28 can be access the left to check for 53 comma 14 because the 13 dimension is X that means we are considering the x coordinate value so x coordinate value is will be 3 here this one in this one x coordinate value is 27 53 is compared with the 27:53 is greater under 27 is the lesser so that 27 comma 28 can be inserted as a length chain of 53 comma 14 so now this data point is also inserted next to data point is T comma okay first 30.com 11 is compared with the DS known as a binary search tree first we have to compare this data point a bit the root node we are conserving x value extra dimension in that level so 30 is comparative beta 53 so 30 is less than 53 go to the left subtree in the left subtree we are taking another lorry search here 27th or 28th here we are concerned in this level we are why dimension okay so here impact 1 by Y for each value visit 28 here in this one y coordinate value is 11 so 28 is compared with 11 so 11 is less than 28 so go to the left so here we have creating a a node in that month we are inserting the data points so now 13 comma 11 is the left child of 27 comma 28 okay so here which cutting dimension you are selecting only that corresponding dimension Cora coordinate that can be compared with the inserting value inserting value coordinates okay so now it is also completed next we are taking 67 comma 51 first this data point is compared with this data point here we are considering cutting dimension is X so now 67 this is x coordinate value 67 is comparable top 53 because we are considering X 2 coordinate 67 is compared with 53 it is a greater go to the right subtree okay so now 67 comma go to the right should be sure there are no notes on there now 67 comma 51 can be inserted as the right shade of 53 comma 40 okay after in 1367 comma f\u00e1tima so this is the tree we have to be next next next value is 70 comma 3 first 70 comma 3 is compared with the root node so here we happened we are considering only extra dimension so 70 is compared with 53 so 70 is greater so go to the right subtree okay in the right subtree one note is there that 51 so now this no this data point is compared with this node here we are considering Y dimension Y - y coordinate y coordinate is here 3 here 2 t 1 so 3 is comparable to 51 3 is less than 51 so that here Miriam there are no nodes are there so now we are creating a new node and inserting the data point 70 comma P as the left child of 67 comma 51 okay so now all the data points are completed now this tree is called as 2 DP that means two dimensional three next let's examine extra example inserting the following points into an initial and B 2 D 3 ok it is also a 2 D 3 each and every data point can contain two dimensions so this is extra coordinate can be represented an extra dimension y coordinate can be represented on Y dimension so initially there is no tree is there okay so whatever the first data point we have to insert that is the first node in the 2d tree okay first so there are no roads on it so first 30 , 40 okay so this is the first data point we are inserting into that two dimensional data space so 30 or 40 so we are creating a new node and inserting this values into that loop okay so now the 2d tree contains a single node that when they said they have point value 30 ,  okay now it is completed okay so next next here next to data point is 5 comma 25 oh so 525 this data point is compared with the now we are considering cutting dimension yes yes that means we are considering only the extra coordinate values so now five is compared with 30 so five is compared with a 35 is less than 30 so go to the left subtree we are creating a new node and inserting this data point into that node so now 525 as the left side for this node 30 , funny okay so now this is also completed next one is 10 comma 12 okay so 10 comma 12 is compared with the data point in the move node here we are considering x-coordinate I think that mention is a X so that we are answering the extra dimension 10 is compared with 30 so 10 is less than 30 go to the left subtree so in that left subtree if one node is there that node contains the data point 5 comma 25 now 10 comma 12 is compared with the 5 comma 25 okay here we are considering Y dimension that means we are considering y-coordinate so here y-coordinate is 25 here y-coordinate is 12 so 12 is compared with 25 12 is less than 25 so that go to the left subtree we are creating a node and inserting and cannot fall into that node now 10 comma 12 data node is the left child of 5 comma 25 okay so now 10 power 12 is also completed next 70 karma 70 okay now so this data point is compared with the data point is the moon no so here we are considering so here we are creating this also in the [Music] so now this becomes is so this is so so so in the is the so this is compared with a 70 point in that note here we are considering why dimension here 45 divided by coordinate here 70 is the y-coordinate so 45 is compared with the 70 45 is less than 70 so that go to the left subtree so here the left sub tree contains you know 50 comma 30 so now 35 comma 45 is compared with 50 comma 30 by considering the extra dimension that means x coordinate we are considered 35 is 50 so 35 is less than 50 go to the left subtree it is empty now we have to create a node and inserting the data point into that hole now this node becomes the left side of 50 comma 30 okay so these these are the applications of K DT that means we're in which applications KD tree is used first one is worry processing in sensor networks so in the sensor network to process that query we are we have to use KD tree next one nearest mi verses such okay suppose we are taking a node okay what are the nearest neighbors for that known we have to search the nearest neighbors for you know so for that one we have to use KD tree next in optimization we have to use a KD tree in ray tracing we as we are also using KD tree next database search by using multiple keys okay so we have to use multiple number of keys keys so like primary secondarykey super each candidate key that are different keys are there so we have to search the database by using multiple number of keys so for that one we have also kd3 so these are the applications of kd3 so thank you thank you for watching this video if you liked this video please share this video to your friends and classmates if you like this video please subscribe my channel a so big fellas three universal ",
            "url": "www.youtube.com/watch?v=-e7oHgAepQA",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "Z4dNLvno-EY",
            "channelId": "UCErsE23hf-34e3mqw3TlMFA",
            "publishedAt": "2016-12-11T18:14:36Z",
            "title": "KD-Trees and Range search",
            "description": "Explanation of how to build a KD-tree and how to use it for Range search Music: Colorful Spots (Ukulele/Guitar Background Music) by Nicolai Heidlas Music ...",
            "channelTitle": "Niklas Lundstr\u00f6m",
            "transcript": "imagine you have a database containing thousands maybe millions of medical patients each dataset with us reduce suggest the patient's height weight whether or not the patient has been diagnosed with a particular disease etc the new patient comes in and to get the hint of our particular treatment who will come out we may want to compare two previous cases with similar patients let's say we want to search on database for people who trade in a 1780 kilo between 170 180 centimeters and who have been diagnosed with let's say some kind of heart problem how can we in an efficient way search for all patients within this multi-dimensional range we cannot possibly go through all elements in the database every time we want to make ourselves we therefore need to have a data structured in ordered way speed exam but how do we order mouths dimensional data the answer is a data structure called KD tree or K dimensional tree so how do we build such a data structure imagine that we have a space with a number of points we start with finding the median of the points x values and split the set into two different branches in each branch we will now find the median along the y axis and divide into branches once again we will continue like this alternating between splitting along the x and y axis until each cell only contains one point we now have our finished tree Sparky now how do we use this structure to find the points in a given range let's say we want to find all points between this and this x-value and between this and this y value we start by looking at a tree root since both branches intersects with the range we need to continue searching along both branches we now look at the second level and see that only the upper or right branch intersects with the range we can thus discard the left one while continuing on the right door upper branch we see that both branches intersect the range Madonn has a look at the actual points in the excel and see it lays within range for our main right brows we do the same thing we look at the upper and lower branches and see if they intersect with the range continuing along those that do intersect and discarding those who don't when we reach a leaf we look if the point lies within the range or not and that is a final range search for multi-dimensional data you ",
            "url": "www.youtube.com/watch?v=Z4dNLvno-EY",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "Y4ZgLlDfKDg",
            "channelId": "UCs7alOMRnxhzfKAJ4JjZ7Wg",
            "publishedAt": "2015-09-15T14:36:08Z",
            "title": "kNN.15 K-d tree algorithm",
            "description": "",
            "channelTitle": "Victor Lavrenko",
            "transcript": "so let's talk about that in detail KD trees so I suppose that this is our data set 2-dimensional instances and what I want to do is I want to in candy trees you built a data structure that organizes this data set as a tree and then when you want to find nearest neighbors to the query point you navigate down the tree to the region that will hopefully contain most of the near neighbors for your testing point so how does the algorithm work how does it build the tree the way it works is it takes all of your training instances so these or these are all the points that I have in my data set it picks a random attribute so in this case I only have two attributes x1 or x2 so let's say that X 1 and then for that attribute it finds the median okay and it uses that medium to split the data set and it'll split it evenly you will get approximately half the data points on one side half the point half the data points on the other side because you're picking the right by definition half the points are smaller and half the points are bigger than that so in this case the median is 6 so if I split on the median I'm going to have 5 points to the left so these have x1 attributes smaller than 6 1 2 4 3 and 5 and everything on the right side is going to be a greater than or equal to the median so I get five data points in the right branch of the tree so I split my dataset into two if you look at it geometrically that what it looks like doing that split corresponds to doing a vertical cut on the X 1 axis at the value of the median so everything to the right of the cut is going to be one subset and everything to the left of the cut is going to be in another sub subset and then I repeat that procedure at the next iteration I take a different random attribute in this case I only have X 2 so I'm going to pick X 2 again right and I'm going to repeat the process so now I take this subset of the data the five points in the left branch and now I'm going to split them based on the x2 so I'm going to find the median the median happens to be 4 and I split it again into two parts so I'm going to have two data points 2 3 4 1 in the left branch and 1 9 3 7 5 4 in the right branch based on their second attribute be bigger or a greater than or equal to 4 and I'm going to do that in the other branch of the tree so the one where x1 was greater than or equal to 6 I'm going to pick the median there and this time the median is going to be different right it's natural because I have a different set of points so the median is going to be different and based on that median I'm going to split it into two different sets so geometrically what I'm doing is I've taken an attribute x1 and I cut it right down the middle where the middle is defined as a point where half the points are on the left and have to put on the right and then I'm going to recurse on the two halves of the space on this space now I'm going to cut it with a horizontal line along the middle and same thing on the right side with a horizontal line along the middle I repeat this procedure until I end up with a predetermined number of points left in each branch of the tree and you can predict what that so once you know what that number of points is going to be you basically know how deep your tree is going to be because remember at each level I'm splitting the data set in half and because I'm picking the median I'm splitting it exactly in half so the data sets gets twice as small or sort of half as large with every step so the depth of the tree cannot be greater than log base 2 of M where m is the total number of instances in the dataset all right because after a log base 2 and steps I'm gonna end up with Singleton's now so there's no point in splitting further so I know how deep the tree is going to be ah so let's say that I want to stop if I have 2 or 3 are nodes in each leaf so in this case I would stop here and that would be my final chunk or cutting of the space into into regions so then you take this data structure and you use it for finding nearest neighbors to testing queries right so a testing point X comes along and I'm going to say for that point X is x1 bigger than 6 yes it is so I'm going to go on this branch of the tree is x2 greater than or equal to 8 no it's not so I'm going to go in this branch of the tree and I end up at this leaf node and what I'm going to do then is I'm going to take this testing point 7 4 and compare it to these two training points these are my potential nearest neighbors and I'm going to end up comparing to that note that the technique can easily miss real nearest neighbors so for example that point right there is it would be the nearest neighbor but you cannot find it through a KD tree because it has chosen to split it off it's another branch why do you you cannot you cannot you cannot really find that point so you're missing nearest neighbors that's the downside the upside is fairly quickly in the time that is at most logarithmic in the number of instances I am finding a set of potential nearest neighbors from and in the tree on ",
            "url": "www.youtube.com/watch?v=Y4ZgLlDfKDg",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "oRwYNAEuNK8",
            "channelId": "UC0RhatS1pyxInC00YKjjBqQ",
            "publishedAt": "2020-03-17T13:31:47Z",
            "title": "K-Dimensional Tree [Find Minimum] | GeeksforGeeks",
            "description": "This video is contributed by Yashvardhan Rautela. Please Like, Comment and Share the Video among your friends. Install our Android App: ...",
            "channelTitle": "GeeksforGeeks",
            "transcript": "hello friends welcome to geeks or geeks in this tutorial we are going to see how to find minimum in the given dimension in a k-dimensional tree a KD tree also called as a k-dimensional tree is a binary search tree where data in each node is a k-dimensional point in space in short it is a space partitioning data structure for organizing points in a k-dimensional space while non-leaf node in KD tree divides the space into two parts called as half spaces points to the left of this space are represented by the left subtree of that node and points to the right of the space are represented by the right subtree now let us look at what do we mean by the minimum of a k-dimensional tree suppose we have this K dimensional tree here the value of K is 2 so for x axis then a minimum value is 5 therefore when the value of dimension is X the minimum node will be 525 and for the y axis the minimum value is 12 therefore for the Y dimension the minimum node will be 1012 now let us look at the algorithms to find minimum we Traverse nodes starting from the root the root of this tree is 30 40 if dimension of the current level is same as given dimension then required minimum lies on left side if there is a left child suppose the dimension we need to search is X and we are starting at the root node so the current dimension is X and the required dimension is also X while constructing a KD tree the smaller elements are inserted to the left side of the tree therefore the as both the dimensions are same now we will look in the left node of the tree when dimension of current level is different minimum may either be in the left subtree or the right subtree or current min node may also be minimum now at this node the value of dimension is Y and the required dimension is X therefore the dimensions are different so the required minimum dimension can either be in this node or its left node or its right node if it exists so we have to find out the minimum of all these three nodes we will use recursion to carry out this procedure now let us have a look at the code in the function we have passed the root node individual D which signifies that the dimension in which we have to find the minimum and the current depth the base cases when root is equals to null that is when the tree doesn't exist then the minimum would not be defined and we can return integer max the current dimension of the node in the tree can be found out using the formula depth modulus K now we have two cases either the current dimension is equal to the depth or it is not when the current dimension is equal to the depth we again have two cases when the current dimension is equal to the depth we only have to search the left subtree suppose we are starting at 30 40 the required dimension is X and the current dimension is also X so therefore we will search only in this left subtree if root arrow left is equals to null that is when the node doesn't have any left subtree then we can conclude that the current node is the minimum node and return it but in case there is a left subtree in the node we have to find the minimum of that subtree by recursively calling the function and passing the left node the dimension and increase the depth by one we also have to compare the value with the current node and return minimum of these both values but in case the current dimension is not equals to the current depth we have to search the minimum in the left subtree as well as the right subtree and the current node suppose the required dimension is y and the current dimension is x so the minimum element can be either in the left subtree or the right subtree or in the current dimension to find the minimum of all these cases we could recursively called the left subtree and the right subtree and we also compare it with the current node i hope you understood the code thanks for watching please leave us your comments ",
            "url": "www.youtube.com/watch?v=oRwYNAEuNK8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "DNuXnstsf1U",
            "channelId": "UC_IX6gMOIBfxxbouPfrF26A",
            "publishedAt": "2020-05-13T09:40:09Z",
            "title": "KD Tree : Advanced Data Structure Java Implementation",
            "description": "K-D trees are a simple and efficient space partitioning data structure. This tree structure is widely used in numerous applications like computer graphics, neural ...",
            "channelTitle": "Josue Contreras",
            "transcript": "[Music] hello we're team zero Morpheus and we will be presenting on the KDE treat data structure our team decided to work on this project since ke trees are widely used because of their efficient algorithm and timing performance this efficiency is possible because the space is divided into subsets and organized into the left and right subtrees there are two queries that take advantage of such property the first one is a rain search that searches for a point within the queried region the second is a nearest neighbor search in which the closest neighbor to a point is found in using the spatial deconstruction these algorithms along with the data structure allow them to be applied into the computer graphics neural networks data mining and data analysis here is an example of two dimensional points added to a two dimensional tree the first point is inserted as the root of the tree with the vertical orientation Division shown in red the next point is less than the root as it is added to the left subtree with a horizontal subdivision this process is repeated until all the points are added to the KD tree as seen in the final box the space is subdivided into regions enabling to easily find points within this regions and their neighbors implementing our KD tree turned out to be very similar to implementing a normal battery search tree just as in a regular binary search tree we get insert and contains functions our recursive functions that will repeatedly search into the above or below sub tree in order to find the correct location to either insert or access one of the points in the tree the difference between this and a regular binary search tree is of course that there are multiple coordinates to check and via the KD tree algorithm the coordinate that's checked and compared against will alternate each time so the first comparison against the root will always check the vertical coordinate followed by the horizontal coordinate and back and forth until the correct location is found we decided to organize this code using a custom KD node class to maximize the readability of the code and also implemented a few extra features that made it a bit easier to use in particular the KD tree class implements the iterable interface giving an iterator that allows for inorder traversal of the tree we also implemented a balancing algorithm that generates a balanced KD tree from the given list of points this is important as it ensures o of log n performance for all functions as if this wasn't the case and the trees weren't guaranteed to be balanced it is possible that suboptimal cases can occur where the time is not generally logarithmic when balancing the KD tree it is important to note that there is an interesting edge case normally if we look at this cage we tree here the screen node over here is a child of the middle green node which is the root and has a second child which is this red node here normally the children of the KD node will just get put into either the above or below sub tree depending on whether they're on the above or below site of the associated line but what happens when the point is on the line an arbitrary choice has to be made in order to make sure that the get and other recursive algorithms are capable of knowing which sub tree this child is in in this case we'll make the arbitrary choice to call it above so it will move into this sub tree here and this is what we also chose to do in the code because a convention has to be chosen here this can prevent a perfectly balanced KD tree of some points have equal coordinates however it will still be optimal and in general it will be very close to balanced a major application of the KD tree is then neighbor query it works by walking down the tree to find where point-p would have been inserted and then unwinding the recursion in order to update the value of the current closest note while doing so it needs to determine whether we need to search in the other side of the tree for any candidates very close or node and in the end return the closest one despite sounding like a very complex problem it can be implemented in this few lines of code this block over here is to figure out where the point would have been inserted and is the same logic as any of the other methods in the KD tree like insert or get this is the recursive call and once we clear the recursion then we compare the current node with the closest we found in that subtree and the main bit of insight is here with the perpendicular distance so this is how we determine if we need to search the other side of the tree as you can see here currently we searched this subtree and the closest node was the root but since the boundary distance does distance from the point to the boundary is smaller than the distance to the root it's leaving this whole region for other points that can be closer to exist in the tree so we must search the site and if we find a node that is closer we have to return that instead in most cases this recursive algorithm work in about a long time which is much better than the brute-force implementation however it is possible to force the nearest neighbor implementation to search every single node in a circle since all of the points are equidistant and all of the regions are very overlapping when we put the point close to the center it ends up having to search almost every subtree because thus it devolves into just linear time in addition to the KD structure our team decided to develop an interactive GUI this GUI is implemented using the swing Java library this allows our end user in this case Professor Hyneman and the TAS to be able to run the GUI without having to install external libraries we were inspired by the retro look of the old days therefore we went for a retro Neal theme the layout of the GUI is simple and easy to use it is divided into the control panel on the left the two dimensional space interactive window in the middle and the information panels for the KD node displayed information on the most right now we will show you how to use the GUI this is the KD tree visualizer to use it just click with your mouse on the draw window this will add a node as you can see it right here and it will give you the information as the orientation of this node is vertical the points and the regions then you can add more nodes by just clicking on the GUI and with this you can also load all the nodes right here to see each point where they are located their orientation and the regions it is important to notice that these are not in the order that they were inserted in but they are in the order from left to right in the K tree structure another cool feature that this visualizer lets you do is put an x coordinate like 200 and a y-coordinate like 500 and it lets you find the nearest neighbor this is the point that we input it and this is the nearest neighbor as follows also you can clear which will clear the window the information panels and it will initially initialize the KD tree I'm going to be talking about the evaluation and the results of our data first off this is the worst case of our KD tree um nearest neighbor query in the bottom right and as you can see the KD tree in the brute force time efficiency are very similar for the majority of the performance and this happens when the points form sort of a circle and the nearest neighbor query has to search through more of the trade leading to more time efficiency this is our time efficiency for the average for the nearest neighbor query in this column and the brute force average is in this column here and as you can see the nearest neighbor time efficiency is much better for the majority of the datasets um as you can see up to about 11 the brute force average actually kind of competes with it and then it really pulls away after the dataset size of two to the eleventh and it starts getting a lot bigger as you can see by this graph right here [Music] ",
            "url": "www.youtube.com/watch?v=DNuXnstsf1U",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "b-trees data structures": [
        {
            "videoId": "aZjYr87r1b8",
            "channelId": "UCZCFT11CWBi3MHNlGf019nw",
            "publishedAt": "2018-03-30T10:22:27Z",
            "title": "10.2  B Trees and B+ Trees. How they are useful in Databases",
            "description": "This video explains B Trees and B+ Trees and how they are used in databases. Insertion, Deletion and Analysis will be covered in next video. Each node of a B+ ...",
            "channelTitle": "Abdul Bari",
            "transcript": "hi the topic is Beatriz and B plus trees this is one of the important topic and is a difficult topic for the students to understand this is useful in databases what are the things that are required for understanding B trees and B plus trees thoroughly this is the list of topics if you understand all these things hence you'll know all these things then you can understand what B trees and B plus trees are mostly type people try to understand how insertion and deletion is done just they try to learn the procedure without knowing everything so this video will be little nd reason I am going to cover all these topics that are related to B and B plus trees and help you understand perfectly what B plus a and B and B plus trees are let me read out the topics discus structure how are this looks like and how the data is stored on the disk then nix when you are storing data from databases then indexing is used for faster searching then what is indexing what is multi-level indexing then we will also discuss what are M basis trees and that--as massages are converted to B trees and then B plus trees so this is a little bit lengthy but I suggest you listen everything go through it then you will never forget this topic let us start with a disk structure let us look at disc structure this structure is likely discuss like a platter on which the concentric circles are made these are logical circles this is not physical and these are circles are called as a track so let us say this is a tag 0 track 1 track 2 and track 3 then this pieces are called as sectors so this is sectors and this is also sector like this let us say this is sector 0 sector 1 sector to sector 3 & 4 & 5 so discus divided into many tracks and sectors the intersection portion of track and the sector this one or this one all these intersecting positions these are called as blocks so any location on the disk can be addressed with track number and sector number so the address on a disk that is block address block address is mentioned in the form of track number and sector number so like this if I take this particular block then this is track 1 and sector 0 this block tracked to sector 1 so each block can have its address in the form of track number and sector number and typically the block size we take it as 512 bytes for steady purpose we take it as 512 bytes it can be of any size it depends on the manufacturer or for disk so we assume that every block is of fight will bytes when the disk is read when we read or write to and from the disk we always read and write in terms of blocks now if I take just one block that is not 512 bytes the beginning address that is first byte is 0 and the last byte is 5:11 then each byte can have its own address that is called as offset let us say this is the tempt byte so we can refer any one byte on the disk in terms of first of all block address and inside that block we will take offset that is the address of that particular point every block we assume that the addresses starts from 0 and last addresses fight will file Evan because total fight will so any address any byte we can take it as address and that address is called as offset to reach a particular byte on a disk we should know track number sector number and the offset let us say in this particular block this particular point I want to read this is suppose this is one byte for reading that by I should know these three things then let us understand one more thing this is mounted like this on a spindle and the head post will also be there so by spinning it will change the sectors by this arm movement of a header that is the header that is reading the data from the disk or writing the data on the disk by this movement tracks are changed so we get position ahead in a particular track and in particular sector by moving this post that is head post or spinning this one so by spinning sectors are changed by moving head tracks are change this about the disk now the data on the disk is always stored in terms of clocks now one more thing let us take this as main memory usually we call it as RAM RAM is a technology and the type of memories main memory with all our programs inside main memory and the programs will access data suppose they are accessing the data from the disk then the data from the disk must be brought into the main memory and then only it can be accessed and if any results are obtained and the results are again written back onto the disk so the data cannot be directly processed upon the disk it has to be brought into the main memory and then access and this is one important point to understand and one more time I'll tell you organizing the data inside the main memory that is directly you sued by the program data inside the main memory that is directly used by the program that is data structures and organizing the data on the disk efficiently so that it can be easily utilized that is DBMS so study of the methods or the approach used for storing the data in an efficient way there on the discus all about DBMS designing organizing everything now here study on this one is data structures now let us move on to the next how data is stored on the disk now let us know how the data is organized on the disk in the form of database I have an example database table here with some columns and some rows let us say they are hundred rows and how the data is stored on the disk in the form of blocks holiday we have studied that and assume that the block size is 512 bytes now this table the structure of a table is given here there are more number of fields I am not showing them there but here I have written all so total there are five fields and these are their sizes employee IDs of size 10 bytes and this is of 50 bytes and the Department is 10 bytes so on so total it takes 128 bytes now it means each row size is 128 bytes this each rules 128 bytes now when we want to store that table on the database then in each block how many rows can be stored that is how many records can be stored so number of records per block so the block sizes 5-12 and the required size is 128 so this is 4 it means we can store four rows of this table in one block it means that these four rules will go into one block and these four rules will go into next block every 4 rows are stored in one block so one block can contain just four rows as we have a hundred rows here that is 100 records here then how many blocks are required then 400 records how many blocks there are hundred records and each block can contain just four records so this is 25 so total 25 blocks required for storing this database table on a disk now when we this table is taking 25 lakhs imagine if you want to search for any particular record you have written a query select from employee table that is employ table and I want so-and-so record for employee ID 5 or employee name Smith if I am searching then how much time it will take so the time depends on number of blocks you are accessing so for accessing this entire table we have to access 25 blocks so number of block access is more 25 because the record may be present anywhere we don't know where the record is present so we have to search in the table so for that at most 25 blocks we have to access we can access block by block and check for that particular record which we are looking for but at most 25 blocks we have to access can we reduce this time yes now we will prepare index for this database table so index index what we will store in index we will store a key that is my ID and pointer pointer to a record so let us say employee ID 1 this is present here and employee ID - this is present here employee ID 3 this is present here so we will have a pointer actually to the table inside the disc inside the block so we'll have a pointer to a record so this we call it as a record pointer we will have a pointer to a record on the disk in the block for each record we will have an entry inside the index so this is called as a tense index next where do you store index we will store index also in the disk only let us say in this block we are storing an index this is for index this is for the database table and no record more blocks are there because it is taking 25 lakhs now index is also kept on the disk now the question is how much pays this index we'll take on the disk let us analyze see employee ID is 10 bytes then what about this record pointer the pointer that we have taken here the record pointer let us assume it is taking 6 bytes so each entry size is how many bytes 16 bytes each entry is taking 16 bytes so how many entries are there here hundred entries are there now the question is how many blocks required for this one so entry sizes 16 bytes right now number of entries per block so block sizes 512 and each entry size is 16 so this will be 32 so it means we can have a 32 entries in one particular clock so total how many entries are there here hundred entries so 400 entries hundred by 32 so how much this is three-point-something let us say 3.2 just assume it is more than 3 so it means that we require 3 plus blocks for storing this index so let us say 4 blocks are required for storing this index now whenever we want to search we access index so at most how many blocks we require four blocks four blocks of index and once we got a particular key let us say suppose I am looking for this using that address I can access the record so for accessing the record I have to access one block one block so maximum four blocks of index and one block of database table so first search in the index atmos how much time four blocks then once you got the index entry then go to that particular block of database so that is what no block so total four plus one blocks are required for accessing any database record for accessing any record we have to access four plus one that is just five blocks 35 blocks because we don't have to look into the entire table this is the benefit of index na next I will talk about multi level index next what if the index size is also growing how insurers have indeed known have thousand records thousand records means 250 blocks now here we require four blocks nor acquire 40 blocks because there will be thousand entries just I am adding zero to it when the rows where hundred we require four blocks now thousand let us say 40 blocks are required just assume I am NOT doing all calculations then the searching in the index itself is larger so can we have a index above an index yes now how you prepare this index for every entry here if shall we have a entry in this next level index high level index know for each block block so how many entries can be possible in this block 32 entries so we will have one pointer to 32 entries of this particular index right so let us say the starting key is one right next key will be 33 and it will be pointing on to the next block so this is a sparse index it will not have each entry for one entry here like it will not have the same number of entries it will have one entry for one block of index now as I said there are 40 now again what is the size of this one just sixteen only so how many are possible 32 are possible in one block then for this particular index how many blocks are required just one plus point something let us say two so two blocks are required so this high level index can be stored just in two blocks so database table into 50 blocks first level index 40 blocks then next high level index just two blocks so search into blocks once you get an entry access a block here then once you get an entry accessible okay so total how many blocks two blocks from this side one blocks from here one block from here so in this way by adding one more level of index we are reducing the number of block access so this is the basic idea originating for P and B plus trees I will just draw multi level index and then I will show you how it looks like let us look at multi level index once again suppose this the main index now above this we need one more index suppose this is too large then how this will be having it will be having a pointer to set of entries in an index then the pointer to set of entries in an index I am just taking randomly I am NOT drawing every counting and drawing so this is having a pointer to this suppose this is also large this is also large then you can have one more index which will have a pointer to set of entries and a pointer to set of entries this is how we can go on adding multi level index if the database table suppose here is a database table and if size is growing this index will grow and we will add one more index one more index adding multi-level indexes will reduce the number of block access so if I just turn it around and see it like this next level index then next level index if I turn it around and see this this all the multi level index looks like now what is the requirement of multi level index shall we add the index by manually shall we check that the database size is growing and then we should I add indices one by one that is high level in missus no we want the high level indices to be added automatically and deleted also automatically if this is increasing table size is increasing and this index is increasing then you add one more index if you are deleting the records then the ISIS eyes will reduce and then you remove the high level index we want self-manage high level indices that is multi level indexing so the final thing else we want self-manage multi level indexing and that's all it gives the idea of b-trees and B plus trees so now you can see that this multi level indices are looking like a tree if I just turn their side ups then it looks like this P trees and maple streets are actually originating from and they search trees so next I will discuss what are my search trees then finally we'll go to B trees and B plus trees let us talk about M based search tree C for knowing about my search tree let us recall about binary search tree which is useful for searching purpose and for searching any key value we start from the root and if the key value is smaller we go on the left hand side if the key value is larger we go on the right hand side like this is a binary search tree if I am searching for 15 then 15 is greater than this I will go this side 15 is smaller than this soil go this side and it is found so we know that the smaller keys are arranged on the left side and the larger keys are arranged on right side this is what done in binary search tree in binary search tree how many keys we can have per node just one key and how many children each node can have how many children there can be two children each node can have maximum two children so that's why it is called as a binary tree binary binds two children it means can we have a tree with more than two children or more than one keys let us check 20 and 50 these are the two keys now this side I will have the keys which are smaller than 20 so that is 10 and 15 and here I will have the keys that are in between these two that is 30 35 and here I will have the keys that are greater than this so that is 60 and 90 so yes we can have a Saoirse tree like this also there's a search tree this is the following the idea of same as binary search tree see the keys are arranged such that they are in the increasing order so if you see the keys here see first key is smaller than second key and smaller than third key if you have more keys they will be arranged like this and if I am searching for 30 then I'll start from here 30 is greater than 20 30 is less than 50 so it must mean this child come here today is found so no doubt the amount of time taken for searching is little more than binary search tree but the approach of searching is same so these trees are called as same resources so what is this envy see how many keys it is having in this example it is having pinkies then how many children it is having so each node can have maximum 3 children so this is three ways search tree this is a three way search tree this is called as three velocity so in this way my search tree means what a search tree in which each node can have at most M a children and a search tree so each node can have at most M children so how many keys n minus 1 keys so M s based on the number of children that is the degree of a node so my search trees are the extension of binary search trees you can say or else you can say binary search tree is a type of my search tree with a degree 2 so you can have degree 3 also degree 5 also degree hundred also degree thousand also so it means you can have 100 keys here and each node can have hundred hundred plus one children so you can have any degree of search tree this is about MV sauce tree let us look at the load of my sauce tree like for binary search tree Harvey prepare a notice we will have data here and two children then here you need more number of children so let me draw the node for this one if the MV search tree is search tree st am writing it suppose form a search tree means each node can have four children and three keys let me draw a node structure this should be a child pointer pointer to the child and this is key one and again this is a pointer to a child and this is a key to and disappointed to a child and this is key three and disappointed to a child so for child pointer so this is four weig and when it is a four-way then there can be three keys that is my search tree and Lord can have M minus 1 keys so it is just like this this is a diagrammatic representation and if you are making a data structure then the node structure looks like this so if there are a m'children than M minus 1 key spaces are required no next can we use this search trees these no structure for preparing index let us see so I will try to use this for making index so let us check how we can do this for for a search tree where there can be 4 children so this is a child pointer okay now this is key 1 and this is next child pointer then this is key 2 then this will next child pointer then this is key 3 and for child pointer so child pointer 1 2 3 4 then what is this I am adding see this after every key I have a pointer this is nothing but C if you have keys here and you are taking a my search tree benefit of my search tree other index then apart from the child pointer you should have also a pointer to a record that is a record pointer so yes we will also have a record pointer so this is a record pointer record pointer so we can utilize my search trees for indices that is multi-level indices like tree will have multiple levels so for making multi level indexes we can utilize my search tree but the node structure should be like this so just remember this known structure see keys are there and child pointer so for degree 4 so for child pointer 3 key so 3 record pointers for each record for each key there is a pointer to the record to the database record now if we simply use MV search tree what will the problem and how we can overcome the problem and we introduce B trees now we are going towards B trees now till here we have discussed about my search tree no I am taking you to be tree and in B tree we will use the same node structure just remember this again I may not be showing you this will there with no structure that is followed in B trees but first of all let us know what is the problem with MB search tree then how B trees are different from my search trees let us see how insertion is done in my search tree and what is its problem then we'll move on to B trees for that to make you realize the problem I have taken 10 way search tree 10 Ravens a degree 10 means each node can have 10 children and the nine keys and suppose I have to insert these keys let us see how I can insert first 10 there is nothing so I will create a node and insert 10 how many more keys I can have here 8 more key I can have here but for inserting 20 I will create a new mode as a child and insert 20 then inserting thirty ten that smaller 30 comes from right side so I will not insert here but I will come to this and 20 30 is greater in this oil insert 30 here so I can insert like this also but this is wrong I should first fill up this node then only I should think of creating next node but there is no control on my search tree you can insert as you like so it means if I have and the keys then what will be the height of and missus T n so this will be too much time-consuming language become similar to linear search that's the problem of return my search tree so what is the problem with my search tree the creation process is not under any control there are no guidelines for creation process you can create as you like if suppose you are creating it like this then it's a waste of time it will take a lot of time for searching then there must be some rules or guidelines for creating my search t yes those guidelines are called as B trees so B trees are nothing but in the search trees with some rules let us see what are those rules I will explain let us see what are B trees beeps trees are nothing but MB search trees with some rules so what are the rules let us see see the first thing every node you must fill at least half half what if the degree is M I mean by 2 children must be there so M by 2 seal value is taken not flow and by 2 missed if degree is it 10 means 5 a children must be there for an or every node must have 5 children then only you think of creating new node that's what to control the height of MB sir this is the rule you can create a next mode only if the current node is at least half of filled with the children this is fun and by do children must be there then second thing how we can impose this condition on the route we cannot impose this condition on a route if we impose then we cannot insert even a first value also so route can have minimum two children so route means the first one so first node can have minimum two children right so it means it can have just one key also no problem but what about all other nodes they must have at least half of the children this is the conditions - conditions not trade conditions then the third rule is all leaf nodes must be at same level all leaves at same level that's it these are the three things if you are following for creation of M based search tree so actually we are creating B tree and one more important thing here is that the creation process is food point is the creation processes bottom-up creation processes bottom-up so now I will take some keys and I'll show you how a B tree is generated from bottom up so for that I will not take a 10-way search tree I will take a small degree tree and show you how a B tree is created in other words how insertion is attack we will create a bee tree of degree 4 means each node can have 4 children and 3 keys so I have taken some of the keys here then I will be inserting more and more nodes so I will add more keys afterwards let us start first there is no node at all first key I am inserting so that is 10 first key so it can have how many children do children and as per the index 1 he said that it can have one record a pointer the next 20 20 will be inserted here that is greater than 10 40 is inserted here mixed is 50 there is no space for 50 already 3 keys are there degree is full so we cannot insert 50 50 there is no space then what we should do split this node and create one more node so out of 10 20 40 and 50 two keys I will take this site and one key I will send this side 40 I will send it in the root then this is the left child this the right child that's it so when the node was a fill there was no free space then for inserting a key we have splitted a node and one of the key we have send it on the road out of 4 including 50 out of 4 to this side 1 that side 40 up this is how splitting is done while creating a b-tree and you can see that the tree is growing upwards so that's it it's created bottom-up and I was telling you that this is B trees are useful for implementing multi level indexing that if you say this is one first level index then above that this is the second level index created automatically if you add keys here automatically this was created now let us see I will add more keys here then again you can see that this is growing so let us continue I will insert few more keys let us say 60 so 60 comes here then 70 70 comes here then 80 80 there is no space here 80 should come here there is no space then split again then what I should do including 80 50 60 70 and 80 so 80 should grow this side and 70 should be in the root that's the child now that tail looks like this then next I will insert 30 30 30 will come here then I will insert 35 there is no space for 35 here then split so as there is no space I will split this side so out of 10 20 30 and 35 35 this should go in the root and the 10 painting this side and 35 on the side right side 35 on this side then who will go in the route 30 so I will redraw it 30 40 and 70 I'll remove this yeah what's yeah this is the child Hispanic child and this is the child and this is the child this is what the tree looks like now see whenever the node is becoming filled we are splitting it and we are sending one of the key in the parent now we'll try to fill few more keys here and let us see I want to insert five so where's five income side income in the beginning so 5 10 and 20 now I want to insert 15 15 there is no space so 5 10 15 and 20 there is no space for 15 then arrange them in this order then there is no space man split it so for splitting I will create one more node on this side 5 and 10 this side and 20 this side now 15 should go up here this should work right I shall no point here everything that vitae why I am sending third key I want to send second key okay that is your choice so you can make it either less bias or right by asked so either way you can do that no it is left by us means it is more keys or on the left side so whichever one you want you can take it so 15 goes off 20 on this side and 5 and 10 decide now there is no space here also so here also you split it so out of how many keys 15 thirty forty and seventy so fifteen and thirty this side seventy that side and forty in the parent so this will be on this side this will be on this side now all these links will also change because we are splitting it so this is on this side this is on this side this one and I will draw it a little far from this one seventy then 70s left and seventies right so now you can see there are three levels one two three so three levels of indices are created and this is how v3 is generated by inserting keys and the height of a b-tree is increasing and this is same as multilevel in this so this is the creation process so it's under control and all these nodes are at same level so they are looking like more like or index and this has same level this is forming index and above one is also an index so I have shown you how to insert and how to create a b-tree now let us see how it is useful for the databases just minor things are very important and key points I am showing you as we discussed just now that every node will have a pointer to the child node as well as a record pointer this 20 will have a record pointer 5 will have a record pointer 10 will have a pointer 15 will have a record pointer 30 you have a record pointer every key will have a record pointer also that is pointing on the database so this is useful for implementing multi level index apart from the child pointer this is a record pointer so a b-tree node can have what key child pointer that is a block pointer and this is a record pointer that's it that's it about be trace I did not show deletion it depends how much we have understood from this one just you reply me back leave you a comment and if required I will prepare deletion also okay actually I wanted to show you what is the application of B trees and B plus trees so I have started my topic right from indexing and brought you up to this point so that you can understand the relation with the databases and B trees otherwise mostly people study just support B trees and B plus trees without knowing indexing and databases so now you can relate it with the databases now the last thing what is B plus tree it's a very simple thing let me show you quickly just I will modify this what is B plus tree in the B plus tree we will not have a record pointer from every node we will not have a record pointer from every node we will have record pointers only from leaf nodes only from leaf nodes will have a record pointers then what about these keys every key will have its copy in the leaf node so means who is missing here 15 is missing here so 15 will be here also 20 so 15 will have its copy here also so there will be record pointer from 15 also 20 also then 30 here will have a copy of 30 also and 35 know what about what about 40 40 we will have a copy here also 40 will be having a copy here so 40 and 50 and 60 so 3 record pointer so 70 will also be present in this one so every key in the tree will definitely present in a leaf and this leaf nodes are connected like this like a link list so this becomes a dense index now this is exactly like multi-level indexing so this is B plus tree so what are the differences from B tree to B plus C let me quickly tell you that all the keys are present in the leaf nodes and in non leaf nodes there duplicates may be present every key must be present in leaf and there are no record pointer for non leaf nodes the record pointer will be from only leaf nodes so leaves knows all these nodes as they are at same level they'll form a linked list these are the points then this becomes a dense index this will becomes a dense index then this is a sparse index next level the next level is pass index so rather than be 3 B plus 3 is more like multi level index so what is Plus in this one that I have shown you so if you understand me tree understanding B plus tree is not difficult that's all with this topic there are analysis and a lot of things are there so it's a big topic the purpose of coverage of this topic was to relate it with the databases all right so I have covered more from the database site than just be T's and B plus trees so just be plus B be trees and B plus trees can also be taken as a topic and discuss leave your comments let me know if required I will prepare a separate video ",
            "url": "www.youtube.com/watch?v=aZjYr87r1b8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "C_q5ccN84C8",
            "channelId": "UCjFO5t0MLyQaidKGpGoRewg",
            "publishedAt": "2016-10-11T16:32:43Z",
            "title": "B-Tree Tutorial - An Introduction to B-Trees",
            "description": "In this tutorial, Joshua Maas-Howard introduces the topic of B-Trees. You'll learn how B-Trees are structured, what their benefits are, and when you should think ...",
            "channelTitle": "Fullstack Academy",
            "transcript": "right right all right so my name is Joshua mah soured today I am here to give you an introduction to be trees so to start us off what's a tree you may be asking you've all probably seen trees before in computer science we like to think of the tree as upside down it kind of helps us visualize what we are trying to talk about and what are we trying to talk about when we talk about trees we're talking about an organizational structure for the storage and retrieval of data so here you see we have a set of data some numbers and it's organized into a tree structure we can talk about seven as the root node our leaf nodes are three nine and thirteen meaning they don't have children or sub trees extending from below and this tree that we're looking at right now is a binary search tree so it's probably something that you're a little bit more familiar with with a binary search tree every node has a maximum degree of two meaning it's not going to have more than two children or two sub trees branching off of it and so with a binary search tree we can talk about the left subtree of a node which is only going to contain nodes whose values are smaller than the parent node and the right subtree of a node will have larger all larger values than that parent node so with this tree we have our root note of seven and you notice that in the left subtree all of the values are less than seven so this is helps us find numbers pretty quickly it helps our efficiency but there's a problem here's another binary search tree this is all of the same values but arranged into a different ordering and suddenly we've lost kind of all of the benefit that we got out of a tree now if we wanted to search for the number 18 for instance before if we were searching for 18 we'd say 18s bigger than seven so it'll be in the right subtree 18s bigger than 17 so it'll be in the right subtree oh that subtree doesn't exist so we know 18 is not on this binary search tree we didn't have to search through all the other nodes but in this arrangement suddenly we're gonna have to go from the root node of 3 all the way to the leaf node of 17 to be sure that we don't have 18 in our tree so this is called an unbalanced tree and considerable impacts on the efficiency of working with that tree when you have a balanced binary search tree you can get a time complexity of Big O of log n for insertion searching and deletion but if it becomes unbalanced or degenerate as that last tree was suddenly our time complexity is Big O of n because we're having to look at every single element it's basically like we're looking through a linked list so you may be asking what's the remedy right we have self balancing trees there are many different implementations of self balancing trees but the general idea is that when you insert an element into the tree the tree will adjust to ensure that it kind of maintains its balance and there are self-balancing binary search trees one implementation is a red black tree that you guys will hear a bit about later from Tony but right now I'm going to tell you about another type of self balancing tree B trees winnie-the-pooh discovered B trees now actually what they were invented by root of Rudolph Bayer and Ed McCreight working at Boeing research labs in 1972 and so what is a B tree so here's an example B tree you'll notice right away that suddenly each node can have more than one value or in the case of B tree we call them keys so our root note in this case has two keys and three children and that's not a coincidence that it has one more child then it has keys because the relationship between subtrees and keys in a B tree is such that you'll notice our left subtree here with one two five and six all of those numbers are less than seven our middle subtree with the values of nine and twelve or the keys of nine and twelve are greater than seven but less than sixteen that's why it's kind of branching off from that spot between seven and sixteen and our right subtree with 18 and 21 consists of keys that have a greater value than sixteen so in general this is an order 5b tree by the way because it has for a maximum of four keys a maximum of five children per node so in general a b-tree of order M every node has at most M children so we can't any node on this tree cannot have more than five children a non leaf node with K children contains K minus 1 keys that's a little bit of a mouthful but it's basically what I already said which is that if you have two keys like this root node has two keys you have three children you have one more children than the number of keys for any given node and the greatest number of children again is going to be M so in this case five so this tree cannot have any node cannot have more than four keys and you can kind of tell that the node with one two five and six that blue space is sort of full so you can think of that node as full it's not going to accept another key inside the root is gonna have at least two children if it's not a leaf node this satisfies this tree here satisfies that condition it has three children every non leaf node except the root has at least the ceiling of M over two children another mouthful so essentially with an order 5b tree any non leaf node besides the root will have at least three children right because M divided by two is 2.5 rounding up is three children here we don't happen to have any non leaf nodes besides of the root so this rule wouldn't apply to any of the nodes on this tree and lastly and very crucially all leaves appear in the same level so this is kind of how we maintain a balanced tree and maintain our sort of optimized time complexity that we benefit from with the B tree but so you're seeing these constraints and it there's kind of a lot going on here there's a lot of complicated constraints in a V tree and if you imagine trying to insert values it can be a lot to juggle so let's start imagining sort of a simple example if we were to insert the number 20 we would compare 22 so the first thing we do is we find the leaf node where the number would fit so with the number 20 we compare it to 7 it's larger than 7 it's also larger than 16 so we send it to the right subtree we compared it to 18 it's larger than 18 and 20 is less than 21 so we've sort of said it between those two which works well because there's space to put it there now let's imagine we were trying to insert the number zero zero is less than seven so we would send it to the left subtree with one two five and six and we hit a leaf node that's where we want to put our new key of zero but there's not room for it right we can only have four keys in that node so what we do is this sort of tricky operation where that node gets split into two and one of the two nodes is going to have the two smaller values so in this case zero and one one of the nodes is going to have the two larger values five and six and the median value which is two is going to get promoted to the node above it it's gonna move up that's pretty tricky right so we're gonna look at a demonstration this is a kind of cool site not the flashiest design but it's very functional and it lets you choose a degree for a b-tree to create and then insert and delete values and kind of like watch how that happens so I have set up I hope you can see it I've set up the tree that we had on this previous slide same values and we're gonna insert the number 20 I'm gonna make sure that animation is slow enough that you can kind of see it and so 20 should end up right here I it's gonna check against the root node it's gonna send it down to this leaf node and then it's gonna insert it between 18 and 21 simple enough what about when we insert our zero so you're gonna be watching for it sending it to this leaf node and then splitting and promoting the key to to the parent node which in this case is the root node so that was kind of crazy right kind of crazy and you can imagine that here's another more common a little bit more complex tree this one is max degree or an order 3 meaning that it has maximum three children and two keys so if we were to try to insert say the number negative 3 its to try to insert it here but that's gonna split this note and push up to here which is gonna split this node push up to here and that's gonna have to create a new root node so you can kind of like watch that happen splitting promoting splitting promoting splitting so then we end up increasing the height of the tree by one so so that was the demo of kind of how insertion works but just to sort of reiterate inserting into a b-tree find the leaf node where the item should be inserted if the leaf node can accommodate another item as in it has no more than M minus one items then you can just put it right there but in the other case if the node is full you need to split the node into two and promote that median value above which may split the parent node and it could repeat all the way until it reaches the root node which may need to be split as you saw and that will cause the height of the B tree to grow by one deleting from a B tree is equally complicated so I'm not gonna go into the logic it's you know we don't have time for that right now but importantly it ensures that the B tree continues to meet the constraints and to stay balanced so that you continue to benefit from the time complexity of a B tree which speaking of which is really good you can maintain that time complexity of Big O of log n always for searching inserting and deleting operations so you might be wondering when our B trees useful to use basically whenever you're interfacing with some kind of external memory and the time to access the data of a node greatly exceeds the time spent processing that data so you can imagine that if you had millions of data points and you couldn't load them all into memory maybe you just have the root node loaded into memory and every time you want to access the children of that node you are having to read from disk and that operation reading from the disk takes a lot more time than much much more time maybe a hundred times or a thousand times more that's a thousand times more time than even these sort of complicated operations moving values around and also so this is often used when you are doing something like reading a tip from a disk with a database or a file system and also keep in mind that right now we're using we used a b-tree of order 5 just to kind of visualize easily but usually you'd want to maximize how much am i reading all at once because if I'm going to the disk anyways to read I might as well take a bunch of information so you might have like an order 500 b-tree or something like that with up to 500 children and then you can imagine every time you move from a node to a child node you're eliminating because the tree is balanced you're eliminating like 499 500 of the values contained in that tree every time you go down so you can really significantly reduce the number of disk reads in your database or in your file structure so that is B trees I know they're a little bit intimidating but hopefully with this introduction you will if you find a good use case for them you'll get really excited and go implement them yourself you can check out these resources and you can slack me with any questions thanks ",
            "url": "www.youtube.com/watch?v=C_q5ccN84C8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "TOb1tuEZ2X4",
            "channelId": "UCEBb1b_L6zDS3xTUrIALZOw",
            "publishedAt": "2016-03-04T22:12:29Z",
            "title": "R2. 2-3 Trees and B-Trees",
            "description": "In this recitation, problems related to 2-3 Trees and B-Trees are discussed. License: Creative Commons BY-NC-SA More information at http://ocw.mit.edu/terms ...",
            "channelTitle": "MIT OpenCourseWare",
            "transcript": "The following content is\nprovided under a Creative Commons license. Your support will help\nMIT OpenCourseWare continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: So this\nis a 2-3 tree. So as you can see, every node\nhas-- so the 2-3 is either two children or three children. Every node can have either\none key or two keys. And the correlation\nis that every-- so if there are n keys in a\nnode, it has n plus 1 children. So the way that works is\nsimilar to binary search trees. So if you have value here, the\ntwo children surrounding it-- so this side is less,\nthis side is more. So it's essentially sort of\ngoing in order reversal, left child, root, right child. So [INAUDIBLE], it's ordered. So generally a B tree\nwill have some nodes. So let's say n and\nn plus 1 children. And if you take\nanything in the middle, look at the two children,\nall the keys in this sub-tree are smaller than the key\nhere, and all the keys in this sub-tree are\nlarger than the key here. So that's the general node. So before we go\ninto more details of the properties\nand everything, the question is why use B-trees. So if we do a quick\ndepth analysis, we can see that the\ndepth is to log n rate. Is that clear to everyone sort\nof, why the depth is log n? Because you have branching just\nlike in binary search trees. In fact, you have\nmore branching. But in any case,\ndepth is to log n. But why use B-trees over\nbinary search trees? Anyone have a\nreason why you would prefer to use B-trees or not? So all the operations\nare still log n. Any guesses? None. OK. Well, OK, the reason\nis memory hierarchy. So normally in\n[INAUDIBLE], we just assume that the computer\nhas access to memory, and you can just pick up things\nfrom disk and constant time and do your operations with\nit, and you don't worry about caches and everything. But that's not how\ncomputers work. So in a computer, you\nhave-- so those of you who have taken some\ncomputer architecture class [INAUDIBLE] or something,\nyou will know that hierarchy. So there's a CPU-- so\nlet's draw it somewhere. So you have your CPU. And [INAUDIBLE] CPU,\nyou have some registers. You have your caches,\nL1, L2, L3, whatever. You have your RAM. You have disk after that. So disk [? loads. ?] Then\nyou have your, I don't know, your cloud, whatever. So each level, your\nmemory size grows and your access\ntime grows as well. So in the basic memory\nhierarchy model, we have just two levels\nof hierarchy, let's say. So you have cache connected\nby a high bandwidth channel to the CPU, and you have a\nlow bandwidth channel to disk. So the difference\nis-- so essentially you can consider that cache\njust has infinite speed. Cache, just like,\nwhatever you can take it. You don't have any cost for\nbringing in stuff from cache. But it's finite size. So the way cache works is it\nhas a bunch of words, which is a finite number of words. So each word has size B, and\nlet's say you have m words. However, hard disk is just,\nlet's say, infinite memory, but it has some cost\nassociated to accessing things. Also when you access\nthings from hard disk, you copy them into cache. When you copy a block of\nsize b, you take it up from the hard disk,\nand you take a block, and you put it into cache. And you have to get rid of\nsomething because it's fine. So what you want to do\nis you want to utilize that b block efficiently. You just want to bring\na b block every time you want to access a new node. In a binary search tree,\nnormal operations are what? You start in the root\nand go to a node. But that's not very easily\ncorrelated with this. Right? So if you want to\nutilize an entire block, you would want something like\na block which sort of goes down the tree. But that's not how\nbinary trees are stored. Binary trees are\nstored this way. So that's the nice\nthing about B-trees. So this is just a 2-3 tree. This is not a general B-tree. A general B-tree will\nhave a bunch of nodes, and we'll come to that number. But generally you want to make\nthat number of nodes something like the cache-- what is it? The word size in the cache. So once you do that, you can\nget an entire node from disk, like work on that, and then\nget another [INAUDIBLE], so your height is reduced. And you can do your\noperation much quicker, because you're not accessing\ndisk every time you're going down a level. Sorry. You are accessing disk every\ntime you go down a level, but you're utilizing\nthe whole block when you're accessing disk. Good? Sort of make sense? OK. So let's write down the\nspecifications for B-trees now. All right. So number of children. So first of all, a\nB-tree has something called a branching factor. So in the 2-3 tree, the\nbranching factor is two. So what that means is\nsimply that it just balances the number of children. So the number of children has to\nbe greater than or equal to 2. Other than the root node. The root node can have\nless than B children. It's fine. Also it's upper bounded\nby 2B [? plus ?] 2B. Notice that this is\na strict upper bound. So you can have at most 2B\nminus 1 children from a node. Also remember that the number\nof keys, the number of keys is just 1 less than\nthe number of children. Therefore, these inequalities\nare just reduced by 1. So you have minus 1 and\nyou have 2B minus 1. So the number of keys can be\nbetween minus 1 and 2B minus 2. The rationale for that\nwill become clear-- yeah? AUDIENCE: Is B the\nheight of the tree? PROFESSOR: No, B\nis the branching. B is the branching factor. So that is the\nnumber of children. It's not the number of children. It's a bound of the\nnumber of children. So like in the 2-3\ntree, B is equal to 2, and this is a 2-3 tree. So the 2 refers to-- you\ncan have either two children or you can have three children. And so the upper bound on\nchildren is 2B minus 1. 2B minus 1 is equal to 3. So you can have two\nor three children. And correspondingly, you\ncan have either one or two keys in a node. Make sense? AUDIENCE: Yeah. PROFESSOR: Cool. OK So coming back to this. So the root does not\nhave a lower bound. The root can have one\nchild in any tree. So you have a B equal\nto 5 tree, the root can still have\none child-- sorry. Not one child, one key\nelement, two children. All right. It's good. Also it's completely balanced. So all the leaves\nare the same depth. So you can see it here, right? So you can't have a\ndangling node here. This is not allowed. You have to have a leaf. You have to have\nsomething going down, and everything ends\nat the same level. All right. So that's the thing. So also the leaves obviously\ndon't have children, so this condition is\nviolated by the leaf. So that's the basic\nstructure of a B-tree. So the first operation\nwe'll consider on B-trees is searching. So that should be\nrelatively straightforward. So remember how searching is\ndone in the binary search tree. You bring in a value\nx compared to the key. Let's say x is less than\nK, you go down this path. Let's say x is greater than\nK, you go down this path. So similarly in a B-tree. So let's say we\nbring in a value. Let's say you are\nlooking for 20. So you bring in 20\ncompared to this. 20 is less than 30,\nso you go down here. Now you have two values. So where does 20 fit in here? Not here. Not here. It fits here. OK. Go down this tree. You find 20, that's it. So in general, you bring in a\nkey K, you look at this node, and you go through\nall the values. So something I forgot to\nmention, which should be clear. All the keys in a node, they're\nsorted, one after the other. So your values go like this. So they're increasing\nin this way. Make sense? So you bring in a key. Look at all the keys in\nthe node you're looking at, pick the place where K fits\nin, unless it's already in the node. Then you're done. You've found it. Otherwise, let's say K fits\nin between these two guys. So you go down this\nchild and continue. So searching with log\nn, similar to BSTs. So searching is not\nvery interesting. So next is insertion. So insertion is a little more\ninteresting than searching. So what you do in\ninsertion is you-- [SIDE CONVERSATION] PROFESSOR: So before we resume,\ndoes anyone have any questions about the structure of B-trees. We rushed through\nthat quite fast. About how B-trees\nare structured, everyone good with that? OK, also any questions about\nsearching in a B-tree or a BST? Go ahead. AUDIENCE: Just a\nrandom question. So the 38 there, it can\nonly have two children. PROFESSOR: Yep. So one value, two children. So you have some\nnode in the B-tree, and whatever is\nbelow it is split into parts by the elements. So if you have n\nelements, it splits it up into n plus 1 segments. AUDIENCE: You said that the root\ndidn't have to follow the root. PROFESSOR: No. AUDIENCE: Why is that? PROFESSOR: Well, you'll see when\nwe do insertion and deletion why that's necessary. But essentially you can\nconsider that it's an invariant. And all we have to do is\npreserve that invariant. So the root, it has to\nstill have less than two-- it still has to have\nthe upper bound. But it doesn't need\nto have a lower bound. AUDIENCE: How do you choose B? PROFESSOR: Well, the whole\n[INAUDIBLE] cache size, so something with that. So you probably want 2B to\nbe about your cache size so you can get the\nwhole block in one go. I've never implemented\na B-tree, so I don't know how it's\nactually done in practice. But that is the reason, so\nI'm assuming it's something to do with the cache length. AUDIENCE: Is the 14, is it\na child of both 10 and 17? PROFESSOR: Well, it's\nnot a child of either. It's a child of this node. So this node has two\nelements, so it's being divided-- dividing the\ninterval up into three parts. So it's in between 10\nand 17 is the point here. AUDIENCE: So then this\nnode has five children? PROFESSOR: Sorry? No, it has three children. So don't think of\nevery key as a node. Think of the whole\nunit as a node. So it's not necessarily--\nin a binary search tree, you have one element,\nbut here every node has multiple elements. That's the point of it. Anyone else? OK, let's start with searching. So let's leave this here. Well, you have the formulas\nup there, so that's good. Insertion. Let's start with insertion. We already did searching. So insertion is you\nbring in a new key K, and you want to insert\nit into the tree. So what's the problem\nthat could happen? You can find the location where\nyou want to insert it, just like searching. You just go down the tree and\nfind where it should be placed. But once you do place\nit, you have a problem. What is the problem? The problem is that one of your\nnodes will become overfull. Whatever. It'll overflow, and\nthat's not what you want. So you want some way\nso you can manage this. How do you manage this? So I have this lovely prop here,\nwhich I hope to demonstrate. OK. So here we have B equal to 4. So let's first figure\nout the number of keys. So what is the minimum number of\nkeys, anyone for B equal to 4? AUDIENCE: Three. PROFESSOR: Three, precisely. So what is the maximum\nnumber of keys? AUDIENCE: Six. PROFESSOR: 4 into\n2 minus 3, yeah. Correct. 3, 4. It's not seven, there's\na strictly less than sign somewhere. Yes. And you'll see why it's\nnot seven in a minute. [LAUGHTER] Oh. Hypocritical of me. All right. So as you can see,\n1, 2, 3, 4, 5, 6, 7. So some insertion happened. Is the writing clear? Can everyone read the numbers? 49 looks a little skewed. Anyway, essentially\nthese are all sorted. This is the parent node. Doesn't matter what's over here. All that matters is 8, 56,\nand whatever's in between. So what we do when we\nhave an overfull node is something that's\ncalled a split operation. So split. And there's something\nwhich is called a merge, which we'll\ncome to later when we're doing deletion. But a split is--\nvery intuitively, it splits the node\ninto two parts. So what it does is when\nyou have an overfull node-- so the number of\nelements here is what? 2B minus 1, which is\njust 1 over the max. So what do you do is you\ntake the middle element and remove it. and now you split the\nnode into two parts. Observe that there are\nthree here and three here, which is perfect. And now what you do\nwith the middle node-- so now you're\nactually disrupting the structure of the\ntree, because there was one pointer going in. There was one child. And now you have two children. So somehow you need to\nadjust the parent node, because the parent node\nhad only one child. Well, at least there are other\nchildren off to the side. But here it had only one child,\nand now it's split apart. So you do something very simple. You just insert\nthis guy in here. And then you say,\noh, this points here, and this points here. Make sense? I'm going to get\nrid of these two. And you can even\nconvince yourself that this preserves all\nthe nice properties. So your children have\nnicely fallen back into their interval. Your sequence is\ncompletely correct, because this was the\nmiddle element of this. So this divides this\ninterval properly. This is also between 8 and 56,\nbecause this was in this node. So all the properties. But there's one property\nthat is a problem. So you have just increased the\nsize of the parent node by 1. So now it's possible that the\nparent node has overflowed. So what do you do? You split it again. And split it again. And if at any\npoint, you're fine, you look at the parent node\nand go, OK, that's fine. That's in the range. But every time it overflows,\nyou can keep going. And how many times\ncan you do this? You can do this all\nthe way up to the root. And when you reach the\nroot, either it's fine or the root is too big. It's reached 2B minus 1. And then you split\nthe root, and you get one single\n[INAUDIBLE] up there. So that, in answer\nto your question, that is why you need that\nproperty in some sense. Not a very convincing\nargument, but sort of. So let's actually\ndo an insertion in this tree we have here. So we are going to insert 16. So 16 comes in here. It's less than 30,\nit goes to the left. It's between 10 and 17,\nit goes in the middle. 16. And it's greater than\n14, so we add 16 here. All right. That seems good. All the properties fine. This still has two elements,\nwhich is the maximum, but it's good. It doesn't overflow. Let's insert something else. Let's insert 2. So 2 goes to 30,\ngoes down, goes down. And we have a problem, because\n2 has overflowed this node. So we split. And the way we split is we\ntake the middle element. So we split the node here. And 3 goes up to the\nparent, so 3 goes here. And all good, except for\nthe parent has overflowed. So what do we do\nwith the parent? We split the parent again. And this time, it's right down\nthe middle, the 10 goes up. So OK, let's get rid of this. So now that we split the\nparent, the 10 goes up here. And you're good. It's a bit cluttered, so\nlet me reposition the 17. Did those two\noperations make sense? Questions? AUDIENCE: If your node size\n[INAUDIBLE] number of-- PROFESSOR: So just pick\nthe-- first of all-- OK. If the way we're doing it--\nwhen your node is overflowing, it's returning only one\nthing at a time, right? AUDIENCE: Yeah. PROFESSOR: So if your\nnode is overflowing, it'll be 2t minus 1, which\nis an odd number always. There might be a case where\nyou get an even number if you do something weird. Maybe you have a-- there are\ndifferent ways to do B-trees. But if it does, you can probably\npick the one, either of them, and then [INAUDIBLE]. I'm not sure about that. I'll look into it. But in general, if you're doing\nit this way, it's always odd. So you don't have\nto worry about that. Anything else? AUDIENCE: If we did reach\nall the way to the root and then went one more up-- PROFESSOR: So what\nyou would do is-- AUDIENCE: That root would have-- PROFESSOR: That root would\nhave two children, one element and two children, which is\nfine because we didn't put that restriction on the root. That's good. How we doing on time? OK, we have some time. Let's jump into deletion, unless\nanyone else has questions. AUDIENCE: [INAUDIBLE] any point? PROFESSOR: So-- oh, yeah. That's a good-- thank you. So you are going\ndown to the leaves at most-- at most\nof the leaf ones, and you're going back up one. So it's like log n plus\nlog n, and you're good. Let's do deletion. So deletion is more complicated. So the reason, it'll be clear. So the problem in deletion\nwill be remove a node and a node is now underfull. So it has less than B minus\n1 keys in it suddenly. So let's turn this around. So again B equal to 4. This node is a problem. Only two things in it. So what do we do? So before we go into that,\nlet's make this assumption that-- there are two\nsteps to deletion. The first step is making\nthe deletion at a leaf. How do you do that? So the way you make a deletion\nat a leaf is, let's say, you have a key. You come down in your\nB-tree, and you add a node. Oh, this key needs\nto be deleted. But it's not a leaf. So what do you do? So essentially what you do is\nyou look at these two subtrees. So it might have\nonly one subtree. If it's at the end,\nit will have only one. Actually, no, that's not true. Ignore that. If it's not a leaf,\nit has two subtrees. So either take the\nrightmost element in this subtree,\nwhich is a leaf, because you can always\nkeep going down, right, right, right, right\ntill you get to a leaf, or the leftmost element\nin this subtree. So that is just the next\nelement after this guy. So you delete this, and\nyou bring this up to here. We'll do an example of\nthis, and it'll be clearer. So you take either the rightmost\nelement in the left subtree or the leftmost element\nin the right subtree and bring it up here. So you sort of like move\nthe deletion to the leaf. And now it's easier\nto deal with. So we will come to that. Also just note that this is not\nwhat is done in the recitation. This algorithm for\ndeletion, I think, is not done in the\nrecitation notes. This is a different thing, which\nI'll send out a link for later. But I believe it\nworks, because I got it from the [INAUDIBLE] reference. So once you move to the leaf--\nso now let's look at this. So this is a node\nthat is underfull. And you want to fix it. So how do you fix it? So what do is you\nlook at its siblings. So in this case,\nit has one sibling. It can have up to two siblings. It can have left or right. So what you do is you\nlook at a sibling. And this sibling is\nactually 1 over the minimum. And if it's 1 over the\nminimum, then it's really easy. All you have to do is take\nthe leftmost thing here-- or if it's the\nsibling on this side, take the rightmost thing here. And look at its parent. So you bring the parent down,\nand you move the sibling up. And there we go. So you basically are rotating\nthe thing into place. So you move the parent down\ninto the underfull node, and you replace the parent\nby the leftmost thing here. Everyone see why that\npreserves everything? And the child is also shifted. Make sure you see that. So the child which was in this\nsubtree is now in this subtree. But then you can\nhave the situation where you don't\nhave a nice sibling to take care of your problems. So in this scenario, the\nsibling is barely full. It has three things, and it\ncan't donate anything to you. So what do you do in that case? So then you do something which\nis a parallel of the split operation. You do a merge. So what do you have? So here you have B minus 2,\nand here you have B minus 1. And you get 2B minus 3. Well, you've got\nanother element. You also take the parent. So how do you do the merge. I just want to show\nyou the merge first. So the way you do it is\nyou move the parent down, and you merge these two. Seems OK? So you move the parent node\ndown and merge these two. And, well, now this\ncomes together, and this points\ninto the new node. Sort of clear what's going on? Questions? Yes? AUDIENCE: So now the\nparent is underfull? PROFESSOR: Well, so you\nhave-- yeah, exactly. So you have decreased\nthe size of the parent, so it might be underfull. So you propagate. Anything else? AUDIENCE: So are these\nall different techniques for doing that? PROFESSOR: So there\nare two cases. So either you have a sibling\nwhich has extra nodes to donate to you or you don't. If you don't, then\nyou have to do this. AUDIENCE: But what\nabout that case? Or is that just like-- PROFESSOR: No, that is\nmoving it down to the leaf. Once you move the\ndeletion down to the leaf, so here we have something now. And now you move it\nall the way back up. So there are two cases. Let's do an example. That'll make it clearer. How are we doing on time? Five minutes, all right. So we are going to delete 38. 38 is gone. But we want to move\nit down to the leaf. So let's take an element. Let's say we take 41. So we take 41 and\nmove it up here. 41 is the leftmost thing\nin the right subtree. So this vacancy doesn't\nreally affect anything, because this node still has\nthe right number of things, because it's still got one\nthing in it, which is good. So you're fine. This is now just 48. Let's say we now delete 41. So 41 is gone. So now that 41 is\ngone, what do you replace this blank spot with? Either this or this, right? Doesn't matter. So let's just do this\none for consistency. So you have 48 here. And now you a problem\nbecause you have a blank box. So can you rotate? Yes, no? No, right? Because sibling is barely full. So what can you do? So you merge. And how do you merge? You move the 48 down, and\nyou combine everything. So this is kind of\nhard to understand, but this is like a\nzero-element node. So when you merge, you\nhave 32, 48, and nothing, so it's just 32 and 48. So what you do is--\nso this seems weird, but this is just\nanother empty node. You just propagated\nthe emptiness upwards. Now you take this empty node,\nand you look for its siblings. Again, its sibling is--\nwell, it's barely full. So what do you do now? You bring the 30 down,\nand you merge this. So let's do that. 30 comes down, and there we go. Looks fine? Does that tree look good? Questions about the operation? I'm sure it was not\nclear, but-- anything? Make sense? OK, let's do a deletion where\nwe can actually do a rotation. So let's go ahead and delete 20. So you do your searching,\ngo down the tree. You find the 20 under here. So now, OK. So you're left with just--\nactually never mind. We'll do another one. So this doesn't do anything. You lost the 20, and you're\nleft with the 24 this time. So now you delete the 24. So now that you've\ngot rid of the 24, you have a blank box here now. But its sibling is\nnot barely full. It has something to donate. So anyone, which elements\nare going to rotate? AUDIENCE: 17 and 16. PROFESSOR: 16 and 17, right. Cool. So 16 goes up, 17 goes down. And you're done. You're consistent again. So that was deletion. Those are the two\ncases for deletion. Does that make sense? Anyone? Any questions? OK. So that's all the topics we\nwere supposed to cover today. Any questions about\nany of the operations, any of the other topics,\nlecture, anything? ",
            "url": "www.youtube.com/watch?v=TOb1tuEZ2X4",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "aNU9XYYCHu8",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-01-24T02:27:18Z",
            "title": "5.27 Insertion in B-Tree of Order 4 (Data Structure)",
            "description": "Learn how to insert data in b tree of order 4 in data structures and algorithms See Complete Playlists: Placement Series: ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "hi guys welcome back to my channel and in this video I'm going to discuss with you how to construct a b-tree of order 4 so the question is construct a b-tree of order 4 with the following set of data we are given some integers and we are supposed to create a b-tree and that Petri will be having order of 4 ok see the order is for means M value is for the maximum keys any node can have as M minus 1 that is 4 minus 1 and that is 3 ok now see first of all scan this you know this even a set of data from left to right first number is 5 we will insert this 5 into B tree but initially we have you know MPTV tree so one node will be created when node will be created and that node can have maximum keys 3 ok 1 2 & 3 first as first number is 5 5 will be inserted at this position and this node now next is 3c now I have already told you that all the numbers in that node will be you know stored in ascending order or the data will would be in sorted fashion so next number is 3 we cannot put 3 at this please why because 3 is less than 5 so first of all we'll compare 3 with this one 3 is less than 5 ok so where 3 will inserted 3 and here it will be fine fine next s2121 would be inserted at which place greater than 3 greater than 5 21 is greater than 3 and 5 to 21 will be inserted at this place now next is 9 now first of all see it's not like this node is because maximum we can insert only three keys any in any node so firstly we would split this node and then we will insert this nine no first of all we have to find out proper place to insert this nine in this node where you can insert this nine after five means at this place before 21 and after nine three four after five three five nine and twenty one now now see maximum keys can be three only and but in this node we have four keys so what is the procedure now this tree would be splitted in two parts and how this splitting will be done we'll find out the median or you can say the middle element of this node and that middle element would go one level up or you can say to the parent of this node but obviously you can see in this node we have only one no truth note the parent is kakou any in that case that middle element would go on level up and that middle element will become the root or though is take our joining those root K children now see three five nine and twenty one now what is the middle element of this one and we have only four numbers now the middle element can be see even number has a middle element SK those of them five either you can take five as a middle element or you can take nine as a middle element 3 5 9 and 21 sorry either you can take five as a metal element or nine as a middle element if you take five as a metal element then the tree up create guru-guru KOCO five up aperture logica and the left child of five is three the right child of five is 9 and 21 okay if you take nine as metal element then what will happen 9 would go one level up 90 haja again the left child of nine would be 3/5 and right would be 21 and this 1 3 5 and right would be 21 okay both please sir right now this tree is known as left biased and this tree hugger a basically eight kuru Gary if you would create take nine as a metal element and this is known as right biased Applebee's miss a metal element lace-up to take it when you know the order is even in that case it will happen so see let us take five US metal element okay that tree would be left biased how many five core metal element considered here than the tree would be five would go one level up left child off here you can say left subtree of this fight would be only three okay and the right would be nine to anyone fine okay sorry the next number is one nine hundred cooking the next is one no no ha you have to find out the proper position to insert this one in this bee tree and one rule is that any new number will always be inserted in leaf node you cannot insert into root node 1 but firstly we will compare this one himesh a compare Jehovah's yoga insert carrying a tow from the root node compare root node say start over but insert huh Michigan's over our leaf node so one would be compared with this five from a path I 1 is less than 5 so we will go to the left part of 5 now we have tree in this node now this is leaf node the 1 would be inserted at this place but you cannot insert one and in this place why so because one is less than 3 to a 3k left my hand so 2 to 1 cap insert over at this place and here would be 3 now next is 13:13 go Vampiro 13 is greater than five I'm right part Matangi 13 is greater than 9 but less than 21 to 30 in would be inserted at this place 13 and 21 now next is to now find out proper place 4 to 2 is less than 5 from your hapa jiying a 2 is greater than 1 and less than 3 the 2 would be inserted at this place 2 & 3 fine next number is 7 now find out 7 is greater than 5 so we'll go to the right part greater than Heather less than over the left middle now find out the proper place for 7 after that we will split this node okay now 7 can be inserted at this place before 9 because 7 is less than 9 less than 13 in less than 21 obviously the 7 campaigns are to achieve at this place 7 but we cannot insert 7 at this place why so because maximum key any node can hold this 3 only those splitting would be done now splitting seok up key were here middle element find out Kannada kupuna your happy home Natalia the middle element 5 MATLAB tree was left biased okay you have a biopic a leaner middle element 9 Lena 13 carbonyl a certificate trees left by some left element go middle limit consider curvy m3 create carbine take a split current so here 9 would be middle element 2 9 comma PJ I got to to its this node K parent node more you can say one level up to nine copies a notch here you have a 5k position and we can insert nine at this place because Hammadi past maximum k can use up to three and we have only one key now the tree would be five and nine left part of v phase one two and three c9 other one level up Shailaja MATLAB s this node would be splitted in two parts the nine car left child would be seven this one seven up Cuyahoga and the 90 right child kidney only thirteen and twenty one you have 13 and 21 fine next s7 home insert cut sugar next element is in now compare ten with five and nine five and nine say but I had ten so we'd go to the right part of nine okay then you hop insert rows up there now ten can find out grow proper place ten is sorry less than 13 to 10-year happens hurt over ten after that you have had 13 OD hompage a cop car 21 fine next is 12 now find out find out proper position for 12 12 is also greater than this 9 to him right partners hang it while you're happy Kehinde set ho sakta hai after 10 and before 13 so 12 of cahuachi at this place - el 13 in 21 Yahoo notch a but you cannot insert this at this place why so because maximum key is happening evening or something a 3 so splitting would be done splitting call the middle element middle element here / 12 left biased have not read well o 13 layers at they become left biased become Quran 12 Kohi consider occurring as my daily limit take that middle part middle element would go one level up and you can say to its parent no disc apparent node have 5 for 9 in this node so 1200 I skip Assam Toya I insert cursive theme because one place still we have left now the tree would be may see me update career develop a hot July of ever 12 commercial again this node will be splitted in two parts 10 would be the left child of 12 okay - lk left make our hagar a gap new pass only 10 or 12 your right part to make a happening pass gas at 30 knots 21 take a 12 right path now next is 4 now compare 4 is less than 5 205 cut your left part our Hodja in your for copper your high insert corner for a coin circles after one two three after three four up coins our community visa to Yahoo together but come in sir disco carnies at the because obviously maximum company through subhansin splitting would be done splitting my middle element middle element emits piss considering is too cool then to would go 111 upper you can say to its parent node see I got to have got to Jagger at this place to a guru pers I got through obviously apna five say less than Heather you happy insert or not you to five nine and twelve but here also we have you know that this note is also full because three key already here so we cannot put two at this place so yeah happy be again yeah okay splitting movies after come proper find out any curses cuddle a position to splitting again and again ho today yeah by splitting way to Korea very happy Jaya in that case yeah be splitting movie appeal or Ajay part split okay Kafka the middle element will go one level up to its parent node parent any to the middle element won't become the root of this tree now this middle element is Co considering if v go because trees have now left biased so the tree would be five five up now partial again this node would be splitted now then what is the left part of five this to fine and what is the right part of this five right children nine and this five got nine and twelve ticket now come to this level up took a left part yoga to forget a to took a left part mega hope now only one we have only one what is the right children of two three and four you have your right can be up K three and four ticket see seven copies I got seven o'clock I have five cigarette within her to five K right part of me he's on a TV but 9 K left me here to you 9 you're happy Niner this car left part media hog only 7 now 10 is the right children of this 9 9 K right make a solid a gap now this one 10 and 13 and 2 LR this right part of actual children of this 12 right sub-tree or you can say 13 and 21 fine the last number is 8 now find out the proper position for it where you can insert this 8 compared with this 5 8 is greater than 5 then we would go to the right part of this 5 take a now compare it with this place you see you cannot insert it at this node because why so because you cannot you cannot insert you know any newly coming number into the internal nodes you can only insert the data into leaf node okay now it would be compared with this one now 8 is less than 9 to hommies 9 ke ke left part measuring you okay see now this node is leaf node fine yep Naga has 7 leaf nodes can eat a scale ft apart right part which mean a now find out proper position 4 8 8 is greater than 7 throw it up campaigns are to get this place fine next up nahin e so this is the final B tree of order 4 fine another variant is say this is also right another variant is that right biased tree you can take this 9 as a you know middle part and you can put 9 at this place 3 5 at this place into and 21 at this place like this you'll proceed and that one another tree would be there though jo aapke even number what the hair that order is given with this even number to up K 2 3 is possible have one is left biased and one is right biased fine so I'll see you in the next video guys till then bye bye yes ",
            "url": "www.youtube.com/watch?v=aNU9XYYCHu8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "hMGhs63sCO0",
            "channelId": "UC8wZnXYK_CGKlBcZp-GxYPA",
            "publishedAt": "2020-09-20T23:16:02Z",
            "title": "B-Tree &amp; B*-Tree Explained - Algorithms &amp; Data Structures #23",
            "description": "This is the last episode of this tutorial series for now. If the demand for a continuation suddenly becomes high, I might make some more videos in the future about ...",
            "channelTitle": "NeuralNine",
            "transcript": "[Music] what is going on guys welcome back to algorithms and data structures tutorial series in today's video we're going to talk about b trees which are also self-balancing trees and up until now i've talked about binary search trees and avl trees that are also self-balancing and um the reason we introduce b-trees is because when we get to big data sets or big sets of data we usually don't save these in the ram so the access time is uh much much longer because the random access memory of course is way faster than uh the external storage meter that we save these big data sets on and also these external storage media usually have a block oriented structure which means that when you access one thing you access the full block not just one individual element but you access the full block and because of that it makes sense to come up with a kind of tree structure that allows you to store information in blocks and thus limit the height of the tree because when you limit the height of the tree and you can still do all the operations in logarithmic time it's not only logarithmic runtime complexity which is already very good but you also have a very very small height which means that the logarithmic or the logarithm of the elements is actually very small so you don't only have a very efficient runtime complexity but you also have very few levels that you can navigate to and this is a very good thing because because of that we limit the amount that we have the amount of times that we have to access data or we have to to ask left or right for example or left right or middle for example so this is what we're going to do today we're going to talk about b3 so let us get right into it so now let's look at this example of a b tree here we're not going to talk about the formal definitions the exact formal definitions too much we're just going to take a look at what a b tree has to be kind of and then we're going to talk about how to rebalance it how to insert elements find elements and so on now every b tree has a certain order and this order in this case is 3 so m is the variable for the order in this case we have a b tree of order three uh and this means that we can have a maximum of m child nodes now in this case you can see uh of three child nodes sorry um in this case you can see here we have three child nodes we have so this thing here is one note one block uh and this one block here can have three children as a maximum but at the same time it has to have m divided by two and the result sealed so rounded up uh child notes as a minimum so except for the root note example uh for example the root note has to have a minimum of two children the root note has to have a minimum of two children but all the other notes except for the leaf nodes of course have to be i have to have a minimum of m divided by 2 and the result sealed child nodes in this case 3 divided by 2 is 1.5 and 1.5 sealed is two so we'd have a minimum of two child nodes um what does that mean this means that if we are below the minimum or above the maximum we have to open up a new level we have to reshift values we have to rebalance the tree adjust the structure so that we can fulfill this property also the amount of child nodes has always to be larger than the amount of keys so if i have two keys here i have three child nodes if i have one key i have two child nodes if i would have a b tree of order six or something and i have five keys i would have to have six child nodes and so on so this is another rule that has to be fulfilled when we're talking about b trees and one rule that's also very important is uh all the leaf nodes are at the same level the leaf nodes are at the same level which means that we cannot have um a bunch of them here and then you know i mean doesn't make sense anyway now but i cannot just go ahead and open up this here as a new level and then i have some leaf trees here um leaf nodes sorry leaf nodes here and then some leaf nodes here all the leaf nodes have to be at the same height at the same level and those are basically the criteria for a b tree and once these criteria or as soon as these criteria are not fulfilled anymore we need to rebalance restructure and do something about it so let's go ahead and try to insert a new element and unbalance the tree or violate these criteria to see what happens now let me just delete this real quick and what we're trying to do now is we're going to add the element 80 to the b tree and see what happens and see how we can rebalance it now if you want to add the element 80 i go to root note it's 25 so i need to go to the right then we have 37 44. uh 45 sorry 80 is larger than 37 so we're not going to the left it's also not in between 37 and 45 because then we would have to go down here that's not the case uh but it's larger than 45 so we need to go to the right and then we have those two keys here so we have 67 77 and um actually would have to go to the right but since we're at the leaf level we just append it here into the same block and see what happens now the problem is that we have a block of three with three keys which is not allowed because we have the order three which means that the maximum amount of keys is two because the child notes has always always have to be larger than the keys and the keys cannot be larger than two if the child's notes have a maximum of three or are a maximum of three so what we need to do now is we need to adjust so what we do is we shift up the center value one level uh shift it up one level yes so what we do is we essentially say by 77 and we shift it up uh into this level here so actually let me just delete a bunch of things here so that it doesn't look too messy we'll just delete this uh so actually 77 is removed from this leaf level here and what we would do next is i'm also going to delete the 80 here and rewrite it so now we have 80 down here and we have 77 up here uh but now we have the same problem here because um here we also have three keys and of course you know what i could do is i could say okay then we have 80 because obviously we need to do it like that or something but that doesn't make sense because we are not going to leave 77 here because we have a b3 of order 3. so what we do here next is we shift up the center value again and what happens then is we shift up 45 into the root note um and then essentially what happens is we remove it and we essentially replace it by 77 we replace the position by 77 with 77 and i'm not sure what number it was 45 uh i think it was 45 and then we end up with this year and because we end up with this here we have two keys and three child nodes we cannot just have two child nodes and two keys we need to um say the middle points to 37 and the right points to 77 so let me maybe again clear this up a little bit here so that we don't have it too messy um i'm just going to delete these red arrows here and redraw the 45 so what we would do is we would say okay these are now separate blocks so again we're going to split them like that and we have 37 here and 77 here and then we connect those two and then we say okay to the right you have 80 to the right to the left you have 67 so essentially you also split these two notes here come on don't do any dumb here we have 80 here and 67 to the left it's not the most beautiful tree that you can draw but that's essentially what you do when you enter an element and the structure violates the criteria you shift up the center element because we had three keys at the leaf level so we shifted up the center key then we had three keys at one level above that we had to shift the center key again and now everything's fine because we have two keys that's okay in a b3 of order three we have a balance structure here we can find elements in logarithmic runtime complexity it's not a problem and all these criteria are still satisfied and met remember we had the leaf nodes leaf nodes same level leaf nodes had to be at the same level level uh and all these um all this criteria here is satisfied so the b3 is rebalanced now let's look at what happens when we delete elements and violate the criteria what happens then is uh i mean it depends on what kind of deletion you perform because in b-trees you have many different scenarios for insertion and deletion my recommendation to use if you want to get a basic understanding of what's happening or not a basic but a deep understanding of what's happening i would recommend going online and typing b3 simulator into google or dr go whatever and uh play around with it a little bit because reading the formal definitions you know you can learn it you can memorize everything but i think you'll get more of an intuition by playing around with a simulator with a visualization tool uh you can also additionally uh go to a textbook and read all these definitions there but i think they're going to confuse you more than just playing around with the simulator uh but essentially you know if you delete a read if you delete a leaf node what happens is you essentially just rotate so that the missing place gets filled up so in this case if we delete 22 for example what would happen is we would of course delete 22 and then the obvious thing to do here is you just have to rotate so that 15 ends up at that position here and you shift 11 so you shift 11 up here and 15 down here and you'll rotate basically in similar way to uh the avl tree rotation so that you end up with 4 at the left side and 15 on the right side and in general it's 11 up here so that's a single rotation a very simple rotation if we delete a if you delete a leaf node now what happens when we delete a node in between in a level in between uh this is a little bit more complicated but it's still very similar to the avl rotation so if we delete 15 for example what happens now is we rotate the whole tree so we say this is a rotation here and what happens is we have 25 here now um and we replace 25 by 37 but then we need an additional um so we say 37 but then of course we need an additional rotation here because now we have uh we have this note here removed and we have only one key at this level on the right side and because of that of course we cannot have three children here but it would also not be correct to just take 35 and put it into the same block as 43 because 35 is actually less than 37 and cannot be on the right side so what we do is we actually combine these two blocks here so actually 35 and 22 are combined so 35 and 22 are combined and that's how you rebalance the tree in an avl-like way so you essentially just rotate the way that you need to rotate in order to fill up the empty slots and then you um make sure that the individual elements are on the right side like not on the right side but on the correct side and as i said if you want to get a real good feeling about this a really good intuition about this i would recommend playing around with a visualization tool uh there are a lot of visualization tools for b-trees online because as i said i don't see a lot of value in reading the exact definitions unless you want to program an algorithm with it or something like that but in order to understand what b-trees actually does and how they balance them rebalance themselves and so on i think it's enough to just play around with the simulation tool now last but not least we're going to talk about why this is possible in logarithmic time again uh obviously because the rotations in the same way that it was true for the avl trees we're not going to have more rotations than there are levels um or at least not single significantly more so we'll end up with logarithmic runtime complexity and also when we have when we add elements we need to shift up shift up shift up and so on but we cannot shift up more times than their levels because then of course we would be above the root note and this doesn't make sense so all these operations finding elements adding elements inserting elements removing elements or rebalancing the tree everything is possible in logarithmic time but b trees have the additional advantage that we have data saved in blocks and because we have more data in one node in one block we have less less many times uh we need to access less many times and this is very beneficial when it comes to external storage media with a block-like structure or block-oriented structure so last but not least we're going to talk about b star trees which are a little bit special because all the notes in between here all the values in between here are just used for navigation now the b star tree has the property that all its elements all its actual values that we're interested in are leaf nodes we don't have any value that we're interested in that is not a leaf node all these values here are just values that are guiding us that are navigating us towards these values that we're actually interested in so 3 8 14 27 are just values to tell us you need to go left you need to go right you need to go to the center and so on they're not values themselves that we're interested in now this is essentially what a b star tree is and uh this this number here the value of the navigation key is always the largest element of its uh left child so in this case you know you have three because three is the largest element of its left child tree uh the actual element we're not talking about navigation elements um five is five because it's the largest element of this left subtree eight is eight because it's the largest element of the left subtree 14 is 14 because it's the largest element of its left subtree 18 because 18 left subtree 27 because 27 and so on so it's always like that and this is the pattern here we always have these in between layers in order to navigate um and the amount of actually the amount of elements that we can store at the leaf level is determined by a so-called k star parameter in this case star parameter let's say it's two in this case uh means that we can have from k star up until two k star um elements at the leaf level so you can have a minimum of two or uh a maximum of four so two three or four elements at the last leaf level you can't have less than those you cannot have you cannot have more than those because if you have more or less we're going to restructure the whole tree we're going to add an additional level or we're going to remove a level and restructure everything so that it still fulfills this criterion notice however that this parameter here is different from the m parameter from the order of the tree the order of the tree is still three here so it's an ordinary b tree but we have the property that in the leaf level we can store two to four um elements per node so this is essentially what a b tree is a b star tree is uh a b tree where we have essentially all the layers in between are just used for navigation and all the actual data is stored at the last level at the leaf node level so that's it for today's video we now talked about b trees and b star trees b star trees usually have a smaller height than b trees because you know you only need the navigation tools and all the data is stored in large blocks at the leaf level so you have a smaller size a smaller height of the tree um and you know for now we're done with the algorithms and data structures tutorial series for beginner uh for beginners there are actually more topics that we could cover here um but i want to focus more again on python projects on ai projects it was a uh an interesting tutorial series and i know that a lot of you enjoyed it and it was very popular in the beginning uh the more advanced topic got less views because probably they're either too complex or not too interesting to a lot of you guys um if there is enough demand and if i notice that there is interest in more advanced topics like p problems np problems np complete problems all these dynamic programming issues and so on um if there is demand for that and if i see that people are interested in it i might make some more videos but for now this algorithms and data structures tutorial series for beginners is done if you have any questions you can leave them in the comment section down below if you like this video or the whole series you can leave a like and let me know in the comment section by writing a comment about that also make sure you subscribe to this channel in order to see more future videos for free we're going to do a lot more python now again a lot more projects a lot more networking ai and so on um so we're going to get back to the old kind of videos here so thank you very much for watching see you in the next video and bye [Music] you ",
            "url": "www.youtube.com/watch?v=hMGhs63sCO0",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "DqcZLulVJ0M",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-06-24T07:03:13Z",
            "title": "5.29 B+ tree insertion | B+ tree creation example | Data structure",
            "description": "Learn how to insert data in b+ tree of order 4. Step by step instructions showing the insertion process in b+ tree Properties of B-tree: ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "if order is given off a tree then maximum children would be same as the order given em minimum children would be my tour ceiling maximum Keys would be M minus 1 and me home keys would be M by 2 ceiling minus 1 right so here I am going to take this example order is 4 so here maximum children can be 4 right minimum children can be to maximum keys can be 3 and minimum keys can be one except root mode see these rules are not applied on root node the root node can have maybe two children root node can have zero child root node can have one key like that now the me one main important property of B plus 3 is what in B plus 3 the data see this given data this data is stored only in leaf nodes right and in B tree data is stored in leaf node as well as in internal nodes but here the data is stored only in leaf node now what is stored in internal nodes in B plus tree only the pointer so you can see the indexes fine indexes to the data which is stored in the leaf node those indexes are stored in internal nodes and second important point is the data which is present in leaf node those data is present in a formal linked list right all the leaves are connected with a link with each other I will show you how we are when we are creating a B plus tree with this example right so these are the two main differences I am going to make a proper video on V + 3 properties and how we plus we are different from B tree in this video I am going to tell you how data is to be inserted in B plus tree right c + b + r ACB tree is what it was a generalization of BST binary search tree so data in parent node right so the data to the left of parent is always less than parent and data to the right of parent is always the greater than that parent so that property is always that properties also for loading meter here as well as in B plus free so now let us start see here order is four so initially no trains there are three is empty so we are going to construct our node you can say right and that mode can have maximum how many keys three keys so that node can have maximum one two three keys and maximum children can be one to see one two three and four so in between these four links only three keys are possible right so now see first first number is 1 insert 1 so we can insert 1 right so next next is 4 now we're 4 is to be inserted food is here only 1 node is there right so 4 is greater than this one so 4 has to be inserted to the right of this one so here we will insert 4 next is 7 7 is greater than 1 also greater than 4 also here we will insert 7 next is 10 now where we can insert 10 after this 7 here but it is not possible you cannot insert 10 in this node why so because it is all flow condition maximum keys in a node can be only 3 here fine in this case so now what should be done now this node should be splitted now B 3 and B plus 2 you also always grow towards root root upward direction not to the towards leaf direction right so we are going to find how how this node is to be splitted now find out the middle element now here we have 4 nodes right see don't do this mistake that 10 you are supposed to insert we cannot insert 10 here so remaining elements are 1 2 & 3 find out the middle of this 1 4 4 would go up and one is to the left of 4 and 7 is to the right of 4 no you have pretend you have to pretend it that you have inserted this 10 and now we are going to split this node right but actually we haven't inserted because we cannot answer maximum limit is only three keys so now the middle element can be this one and this one because we are having even factor four right so if you if you consider this as a middle element and you will split from this node you will split from this data then the tree would be left biased and if you consider seven as a medial middle element and you split from this node then you the tree would be right biased so it's up to you you can take four also you can take seven also but in starting if you if you construct the left bias tree then during the completion of the complete tree you are supposed to follow that rule also the left bias tree and if here you selected that way as right biased then in the whole the complete tree you are going to follow that rule that right biased row right so here I'm taking semanas middle element I am going to construct right biased tree right you can construct left biased also and so your answer would be different from my answer but that is also correct right so now seven suppose seven is middle element so I am going to split from this later now house wedding would be done seven would go one level up or you can say to its parent now here we don't have any parent so seven would go up and that seven would become parent now the tree would be something like this C seven would go up so create another node the maximum capacity is three keys to the left of 7 to the left of 7 we have 1 & 4 1 & 4 right here also we can insert one more data and to the right of 7 to the right of 7 what we can insert maximum capacity is 3 to the right of 7 we have 10 right plus in B plus 3 what you will insert you will insert this 7 also in this node 7 and 10 why so because see I have told you in B plus 3 the data over the data this data should be present in leaf node right so if you do not insert 7 here so this is the leaf node and 7 is not present in the leaf node so data should be present in leaf node now you are inserting seven to the right of this this seven why can't you insert seven here so another rule is that to the left of this one all the data should be strictly less than this node right and to the right of the snow to the right of this node from where you are going to split to the right of that node the data can be either greater than or equal to this node so 7 is equal to this 7 so we are going to insert 7 to the to this right side of this 7 to the right child of the 7 right now see the 7 is only for the index value you can see just pointer to this leaf node actual data is present here right another thing I have told you all the leaf node are connected with a link the data is stored in the form of a linked list so this this leaf node is also connected with this one using a link with this leaf node right now next next we are going to insert is this 17 now where 17 can be inserted always data is to be inserted in the leaf node that you have to take care now 17 is greater than 7 so go to move for this link 17 greater than 7 greater than save this 10 so here you will insert 17 next is 21 we're 21 can insert 21 is greater than 7 greater than 17 and 21 so here you can insert 21 but actually we cannot insert or flow condition is there now you have to split this node now how splitting needs to be done the metal I'll take the middle element and that middle element would go one level up right so now I'm constructing the right by astrayed Oh Here I am going to take 17 as middle element so 17 would go to its parent node or you can say one level up so here you can insert 17 because 2 spaces are still free so now the tree would be 7 and 17 and here still we have one space left same here we have 1 and 4 right and 17 would go up so to the left of 17 7 then to the left of the 17 we have seven eight ten right notice maximum capacity of node is three so one space is free and to the right of seventeen to the right of seventeen the data would be 17 and 21 right because the data should be present in leaf node fine so now next is 31 now where you can insert 31 greater than 7 greater than 17 so go to this link greater than 21 so we'll insert 31 here only now next s 25 very open insert 25 25 has greater than 7 greater than 17 so go to this link greater than 17 greater than 21 and less than 31 so where you can insert 25 here after 21 before 31 right because it is BST also you have to follow the property of BST fine now this cannot be done our flow condition is there now spitting would be done now spitting is what find the middle element sounds I'm going to construct the right bias tree so middle element out from the 17 21 25 and 31 is 25 so 25 would go one level up so 25 would go here only fine now I'm going to update this this tree only so 25 would go here so still we have one space left so we can insert 25 here and if you are splitting from this nor then to the left of 25 way of 17 and 21 fine to the left of this we have 17 and 21 and to the right of 25 what would have 25 and 31 so to the right of 25 you will have 25 and 31 and one node is still free and here also one node is still free now next is 19 where you insert 1919 is greater than 17 but less than 25 so go to this link 19 greater than 17 but less than 21 less than 21 so here you will insert to 19 and 21 would go here next is 20 where you can insert 20 greater than 17 less than 25 greater than 7 greater than 20 in less than 21 so you can insert 20 at this place 17 here you'll write 17 19 20 and 21 right there's no rule with something like this but you cannot answer 21 here you have to split this node from where you are going to split middle element is 20 so 20 would go up fine and here also now you cannot answer 20 because this node is also full now you'll repeat the same step of splitting you will split this node also fine and that that node that from where you are going to split that element would go one level up fine so I'm going to first of all do one splitting from this node only fine so if this node is splitted then 20 would go one level up so now now this tree would be something like this seven seventeen so now if 20 would go one level up so in this node where 20 can go after this 17 here you would write 20 and hill will write 25 right and to the left of 7 we have 1 + 4 to the left of 17 we have 7 and 10 to the right of 17 now from here splitting is done 20 would go up so to the left of 20 we have 17 and 19 to the left of 20 we have 17 and 19 and to the right of 20 we will have 20 and 21 so here you will have 20 and 21 and to the right of 25 you will have 25 and 31 but this is the intermediate space we are not done that is why I am doing there's something like this now again this is not all this is not possible you have to split this node also now from here middle element is 20 20 would go one level up so after that after that after this waiting tree would be something like this see 20 would go one level up when another node would be created having maximum space of 3 keys to the left of 20 we have 7 and 17 7 and 17 at this level right to the right of 20 according to the rule what should be the piece 20 and 25 so to the right of 20 we should have 20 and 25 right and as it is these elements would be 1 and 4 to the right of this we have 7 and 10 to the right of 17 we have 17 19 right now these are leaf nodes right and this is internal node and this is also internal node so now the rule is these keys this cannot be repeated in internal nodes so here you have written just 20 so here you cannot write this 2 and D are going to cross 20 from here because what actual data is in leaf node and in internal nodes we just have indexes so what is the point to repeat the same index again and again we just need one index and using that index are using that pointer only we can reach to the actual data on ax right so that is why in this internal nodes we are not going to repeat the same data so here we have written 20 so we are not going to write 2 nd here fine so here you will just write 25 so now here 20 is not there to the left off to the left of this 25 if the data is to the left of 25 the data is what 20 and 21 \u00b0c due to the left of 25 we have 20 and 21 20 and 21 fine and to the right of 25 we have 25 and 31 so this is from this stage that tree would be something like this so I am going to rub this intermediate stage fine now here 20 is not present so here we don't have any element 20 is not there when you just have 25 now next next is 28 now where 28 can go 28 is greater than 20 yes greater than 25 go to the right side of 25 you go to this link greater than 25 but less than 31 so here you will insert 28 here you will write 31 next is 42 42 can go to right of 31 so here you can insert 42 but actually you cannot insert this is our flow condition again sweating would be done and middle element is 31 31 would go one level up here only here we have a two space left so that is fine 31 can go here so after this the tree will be something like this we have 20 here we have 7 and 17 to the right of 20 we have 25 and I am 31 31 will go one level up so here here we have 31 right these elements would be same 1 and 4 here you write 7 and 10 here you will write 17 and 19 fine to the left of 25 would be 20 and 21 right and now to the right of 25 would be c 31 would go up so to the left of 31 the data is 25 and 28 to the left of 31 the data is 25 and 28 n to the right of 31 31 and 42 fine and yeah I forgot one more thing see this link this link will all the present in all the between all the leaf nodes from this leaf node to this one from this to this from this to this from this to this from this to this so this link would be present in all the leaf nodes like this you have to insert this link also and from here to here something like right this is the final B+ tree here also you are having the space of the node is having space of three keys so here I have shortage of space that is why I have just made a little bit mashed up fine so I hope you are getting this is that way fine these nodes are having space of three keys right maximum you can insert three keys now see as you can see this this data of this data is present in the leaf node all the data you can check fine and in these internal nodes we are having just the indexes fine or you can say pointers as well as these these leaf nodes are also linked with each other so when you are going to accessor data that is why see that is why in B plus tree searching is very easy because the data is present in the leaf node you have to just fetch the root to block this block and only one leaf one leaf node because one this this leaf node is having the pointer to this leaf node then this then this then this and something like this fine so searching is very easy when data is stored in the form of B plus tree I am going to discuss with you all the properties of B plus tree in next video and in next video we are also going to discuss how to delete a data from B plus tree fine so till then bye bye take care ",
            "url": "www.youtube.com/watch?v=DqcZLulVJ0M",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "heaps data structures": [
        {
            "videoId": "t0Cq6tVNRBA",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:16Z",
            "title": "Data Structures: Heaps",
            "description": "Learn about heaps. This video is a part of HackerRank's Cracking The Coding Interview Tutorial with Gayle Laakmann McDowell.",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. Today we'll talk about a topic that a lot of candidates\nforget about, heaps. Heaps come in one of two forms, a min heap or max heap. We'll\njust focus on min heaps today because a max heap is essentially the reverse. In a min\nheap the elements are all smaller than their children so the root node will be\nthe very smallest element and then looking down the tree down the heap, the\nelements get bigger and bigger and bigger. So that's the basics of what a heap is but\nhow do we actually create and maintain such a data structure? So let's start\nwith just insertion. So when we insert an element it always goes in the next empty\nspot looking top to bottom left to right. So we go, first we insert an element here,\nand then here and then here and then here and so on through the tree, through\nthe heap. So that's how insertion works. But then of course what happens if\nthat's not really where the element should go? What we can do is we can insert the\nelement there and then bubble it up until we get to the right spot. So we\ntake the inserted element, we compare it with its parent, if it's out of order,\nswap them and then keep going up the tree in this process. Now what about\nremoving the minimum element? So we know the minimum element will always\nbe the root node and so that's easy to find but then if we want to remove it we\nmight have an empty spot. So what we do here is we remove the min element\nthere, so we take out the root and then we swap that value at the root with the\nlast element added. And then of course that element might not be in the right spot,\nso we take the root element and bubble it down to the next spot so we compare\nthe root with its children, its left child and its right child, and then swap it\nwith the smaller of the two. And then we keep going down the tree until the heap\nproperty is restored. So that's how a tree operates, let's think about\nimplement- that's how a heap operates, let's talk about implementation now. So\nimplementation is kind of interesting. You might have assumed that we'd\nimplement it a simple class node with a left node and a right node, and\ncertainly we could do it that way. But there's an even better way of\nimplementing it. Note that when we add elements to the\nheap they're always getting added in a very particular spot. There aren't gonna\nbe any gaps in the heap so we have the zeroth element here and then the first\nsecond third fourth etc and so that means that we can actually use an\narray instead to store these values and that makes it very compact. And a simple\nsimple equation can map from an index to its left child its right child or to\nits parent. And so we can still get to the left and right child but we don't\nneed to have this overhead of a node class. So now that we've covered the\nbasics of what a heap is let's turn to the actual code for this. We'll implement\nmin heap with a simple class that wraps this items array. This is going to be\nan array of a fixed length but if it gets too big we'll increase the capacity.\nNow I'm gonna get a little bit of a head start and cheat a little bit by just\nadding a whole bunch of simple helper methods. So these are just simple\nmethods that get the left and right child of the parent index. Actually you\nknow check if they exist, or actually get the values themselves. So I'm\njust getting a little bit of a head start here and I'll get another little\nbit of a head start by adding in two extra methods here. One is a swap method that\nswaps the values of two indices and another one is an insure extra capacity\nmethod. Now what this does is it checks if the array is full and if so, it creates a new\narray of double that size and it copies all the elements over. And this by the\nway is the basics of how an arraylist operates. Now let's turn to the real code.\nThe first method I'll implement is a peek method and this first checks if the array is empty if so\nreturns an exception because there's nothing at the front. Otherwise it just returns\nthe first element in the array which will always be the minimum element, and\nessentially the root of the heap. The next method we'll do is a pole method. Now what this does\nis actually extract the minimum element and actually so actually removes it from\nthe array. So first we'll check if the arrays empty, if so throw an exception. Otherwise I need to actually get the\nvalue so item is item of 0 then I need to take the very last element in the array\nand move it into the very first element then I need to shrink my array. Or shrink essentiall the size of it. And\nthen I need to go and actually re-heapify. So I removed the root element so I\nneed to heapify down and I'll go fill this in, this method in shortly. So in this case if we remove the ten, the\nminimum element, it's going to get deleted. Then the 17 is going to get\nmoved up to where the ten is, so seeing the array, that's like this, the 17 gets put in here. And then we go\nand adjust the heap to shift elements down as needed. My next method is going to actually add\nan element in here. So first thing I want to do is I wanna make sure there is\ncapacity, so I'll call my insure extra capacity method. Then I'm gonna add\nmy element into the very last spot so items of size equals this new item then\nincrease my size. And then I need to actually heapify up so I need to\nfix the heap looking upwards. Swapping each element with its parent as\nnecessary, so in this case if we want to add an element say, 8, we'd add it at the\nvery last element and then we'd go and adjust our heap moving things up as\nnecessary. Now for the real fun. I need to actually\nimplement these heapify methods so heapify up is going to start with the\nvery last element added which is that size minus 1 and then it's going to walk\nup as long as there's a parent item and as long as essentially I'm out of order.\nSo as long as my parent item is bigger than me then hey, things are out of order,\nso swap my parent index, swap my value with my parent and then walk upwards. So let's walk through this on the 8\nthat was inserted. So what we do here is we'll compare 8 to this 15, it's out of\norder so we'll need to swap those values. So 15 goes down here and 8 goes up here\nor on the array it will look like this. Then we compare this 8 to the 10 and then\nthat's still out of order, and so we'll go and move the 10 down and swap the 8\nup there and now we've returned to the root, to the heap properties. We have 8 at the top, 10 and 20 below it then 17 and 15 below that. Heapify down is a\nlittle bit more complicated but it's still quite manageable. First we're going\nto start off with our root element which is at index zero. And then we're going to\nsay well as long as I have children, keep walking down and trying to fix up my\nheap. Now I only need to check if there's a\nleft child because if there's no left child then there's certainly no right\nchild. Then I'm gonna set this smaller child index equal to the smaller of the\nleft and the right child so I'm going to take it guess with, set it equal to the left\nchild, and then I'm gonna say hey if there's a right child, and my right child is even smaller than my\nleft child, small child index should equal my right child. Now what I'm going\nto say, remember I'm looking downwards on the\nheap, so now what I'm gonna say is hey, if items of index, if I'm smaller than the smaller of\nmy two children then everything's good, and everything's back in order here and\nI can just exit. If that's not the case then our heap is\nstill out of order and then I need to swap my value with my smaller child and\nthen move down to my smaller child. I'll just actually move this out here. Alright so that's the basics of how\nheapify down works. Let's walk through this on an example. I'll make this example\nslightly larger so if we do an extract min such that 20, 10 gets removed then\nwe remove 10, we replace it with 25. I'll do it on the array too so you can see what's\ngoing on there. Then we compare 25, the root, and replace it with the smaller of\nits left and right child. So we swap the 25 and the 15, so 25 comes down here, 15\ncomes up there, and we can do it down here too. So 15 goes here 25 goes here\nthen we compare 25 to 17. It's still out of order since 25 is bigger than\n17 so we do 17 comes up here we swap those and 25 goes down here. So now we\nhave a heap again that looks like 15, 17 20, and 25 and as you can see our min\nheap property has been restored. So now that you understand what a heap is and\nhow it works, why don't you try out using a heap\non a new problem. Good luck. ",
            "url": "www.youtube.com/watch?v=t0Cq6tVNRBA",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "HqPJF2L5h9U",
            "channelId": "UCZCFT11CWBi3MHNlGf019nw",
            "publishedAt": "2019-03-08T20:14:37Z",
            "title": "2.6.3 Heap - Heap Sort - Heapify - Priority Queues",
            "description": "... Data Structures using C and C++ https://www.udemy.com/course/datastructurescncpp/?referralCode=BD2EF8E61A98AB5E011D C++ Programming ...",
            "channelTitle": "Abdul Bari",
            "transcript": "the topic for this video is heap under this topic we are going to learn about these things I will be explaining these things that is a representation of binary trees complete binary tree heap how to insert and delete in heap then heap sort this is one of the important topic and heapify this is one of the famous algorithm or a procedure for creating a heap I'll discuss this one then heaps are famous for being used as a priority queue so we learn about priority queues so these are the subtopics under this heap topic right and if you know all these things then you can understand heap sort you can also understand he be fine and periodic you unless you know these things so directly jumping on this it's difficult to understand that so that is the reason I am covering all these things so if you already know few things you can skip and go to that topic right any particular topic now before I start I have to say something see I have two courses in udemy one is for c++ second one is for data structures both the courses are for beginner level as well as advanced level means if you already know data structure and c++ you have lot of things to learn there and also if you are a beginner if you have never done any programming then you can take up c++ course and start learning programming and both the courses are suitable for academics as well as for interviews so C++ programming one courses there and that is from beginners to advanced level you can learn up to the level of it will be you can crack any interview then data structure course using C and C++ and some algorithms are it's not completely algorithm is just a data structure using C and C++ right and few algorithms are there so that subject is for academics as well as for cracking job interviews or coding interviews right so I have covered all the topics in greater detail so that will definitely improve your skills so you can buy those two courses those are paid courses those are not free and though please don't ask for free coupons the link for those courses is given in the description you can check the description and there is a discount code is there discount coupon code is that is around 10 $11 so you can click and go to udemy and if more discounts are applicable udemy will give you that discount that don't worry about that if still it can be reduced it will not use it so I suggest you take this course and by clicking on this link you go there so let us start with the topic first I will discuss about representation of a binary tree using array so here I have some examples this is a binary tree I have taken alphabets here so that easy to read this is a binary tree and if I have to store it in an array this is an array already have taken in the C C++ programming array starts from index 0 but here I have to confirm on onwards so this is just a theoretical on paper when you want to program write a program then you tend to start from index 0 also but usually this is studied by taking index 1 onwards so I have taken index 1 then these elements are stored here so how they are stored C for storing a binary tree we have to take care of two things one is we have to store all the elements second is the relationship between them who is a parent who is a child who is left child who is right child so these are the things that we have to take care so elements and the relationship between the elements so how they are preserved watch here see the elements are stored here ABCD efg so actually they are filled level by level ABCD efg yes they are filled level by level then where is the relationship the relationship between them is formed by these formulas so what are these let us look at see if any node is at index I then its left child is at index 2 into I right child is 2 I plus 1 and its parent will be I by 2 floor value so let us look into this example and observe really these formulas are used here or not let us check B B is at index 2 whose a left child of B D so where it should be to entwine so 2 into 2 4 yes it is not for then is right child where it should be 2 into I plus 1 2 into 2 plus 1 that is 5 so check on 5 yes then see see is at index 3 then it's left child s so 2 3 6 so it should be 6 years then the G is the right child it should be 2 into I plus 1 2 into 3 plus 1 7 yes it is at 7 so yes these are followed now one more thing s who's a parent of sense this is 6 6 by 2 is a 3 go to 3 yes C is the parent so you check here in the tree then 4 7 this one G who is a parent C 7 7 by 2 7 by 2 is 3.5 but we have to take floor of elements just 3 so go to next 3 yes C is there so this gives the parent so normal on that actually these elements are stored by following the formula now every time you do can't use the formula and put them right so instead of using the formula one thing we do is we fill them level by level a-b-c-d-e-f-g so that's it so this formulas are automatically followed now let us look at another example here I don't have these nodes ok no problem fill their level of 11 in b c d e 3 ends here so ABCDE so if you apply those formulas you check by yourself they are followed right left child right child and parent formulas are followed automatically now let us look at this one a B C then D no when I am filling level by level without using the formula and I want the formulas to be followed automatically then I should fill level by level and if any element is missing I should leave a gap there yes this is the important point now actually we should have its left child which is not there right child which is not there so put a blank there yes a B C Blanc Blanc de BC Blanc Blanc de this is how they're filled now if you see Dean who is a parent of a d6 by tube this one six by two three yes three who is there at the three C is there if I don't write D there if I write here then it becomes a left child of B that will be wrong so it means left child is not there for B so this place must be blank and it should be filled here so without following formulas if you want to fill them then make sure that if there are missing notes you leave a blank there so that's all about a representation of binary tree that is done using these formulas these formulas are for maintaining relationship and the elements are as it is stored in an array now next we will understand what is complete binary tree now let us learn what is full binary tree and what is complete binary tree so first full binary see this binary tree this we have already seen it so this is a full binary tree what does it mean by full C the height of a binary tree this is 0 1 2 so the height is 2 0 1 2 height of a binary tree is true and in that height it is having maximum number of nodes if you want to add any no water then the height will increase and if you remove any node then this is missing it's not having all possible node one more node is possible so you can take this you know this is having full in height 2 now this is in high 2 3 this is full binary there is no space for any new node so that tree is called as a full binary tree and if the height of a binary tree is H then a full mana tree can have 2 power H plus 1 minus 1 number of nodes maximum these many nodes so a binary tree with the maximum number of nurses a full binary know what is complete by a tree let us learn this now see look at this fun when I have represented this in an array then from last first element to the last element there is no missing element so this is complete if you look at this if you check the first and the last element there is no missing element it's a complete binary tree here from the first element of the last element if you check in an array there are some missing elements so even if there is a single missing element it is not a complete binary tree this is not a complete binary right so the definition is my definition is if you represent a binary tree in an array then they should not be any empty locations or gaps in between the elements bins from first element to last element in between anywhere right after the last element spaces there then there is no problem like suppose this array is having only five element if I have one more six location that's not a problem right but in between the elements that's the important thing now if you look at this now you tell me whether it is complete or not yes it is full as well as complete so every full binary tree is also complete monetary now check this is it complete or not check a level by level one node is there two nodes are there 1 2 3 4 nodes are there then this next next next yes it is complete binary if I remove this node then it's not a complete binary tree this is missing this is missing so no node must be missing if I remove this then this is not a complete binary tree so this is missing so if you go level by level there should not be any missing one then in this level two nodes in this level four nodes yes all are there last level all nodes are not there all those are not there no problem if all nodes are there then it's a full binary right so one more definition of complete binary this mostly you find in the textbooks see of complete money trees a full binary tree up to height H minus 1 if you hide this NC it's a full binary and in the last level the elements are filled from left to right this is one of the definition you will find in the textbooks a complete binary of height H height H already our full binary up to height H - one last level the elements are filled from left to right that same thing I am saying that if you represent this in an array you'll not get gaps like this if you're getting gaps it's not a complete binary without gaps it's a complete binary now one more important thing see the definition of complete monetary what I gave you sometimes or some authors some people call this as almost complete binary also okay but in most of the text books you will find this as complete monetary so I am calling it as complete battery now I will draw a few trees and show you which one is complete which one is not complete so that you get comfortable with complete binary trees so I'll remove this and I will show few binaries look at this is it a complete binary tree check level by level first level one node then two nodes then four nodes all four are not there if you start from left side then one two no load is missing so it's a complete Banerjee get this one row this one in the next level two nodes next level four are there all four are not there but left-hand side by exchange left side is there so yes it's a complete monetary rotus one then to this level two then next level all those are not there but first which node must be there actually it should have this node than this node then this is allowed so these two are missing so it's not a complete binary now this one first level one the next few notes okay next level all those are not there but first of all we should have this node then this node then this node then we can have this so we should have the notes from left to right but the three nodes are missing there it's not a complete binary tree so if you represent this in an array let us say this is 1 2 3 and this is 4 then 1 2 3 gap gap and the gap and then 4 so you'll get 2 3 blank spaces in between the elements so it's not a complete bantering what about this let us check first level 1 next level 2 nodes next level 4 moves must be there one two three food these are missing so it's not a complete vanity what about this this is their right two modes then four must be there one two this is missing it's not a complete one tree this one one then here two moons then here one two three four knows okay then last level all those are not there but we have this exchange left yes this is the end point after this nodes are not dead that is not a problem this is a complete bunny now you are comfortable with what is complete binary and one last point of a complete binary is that the height of a complete binary will be minimum only that is log n height of a complete binary will always be log and because unnecessary we are not going to the next level unless one of the level is filled unless this is filled will not go to the next level see unless this is filled will not go to this level it is not a complete binary if you are going to the next level so always the height of a complete binary tree will be minimum that is log and this is the interesting fact of a complete binary now next we will learn about he let us learn heap see for that I have example binary trees here this binary tree is a full as well as it's a complete binary tree yes the important thing is complete binary this is also complete this also complete now first of all heap is a complete binary tree then next condition see the condition let us look at the elements 50 then 30 and 20 are smaller than 50 years 15 and 10 are smaller than 30 and heater and 16 are smaller than 20 so it means every parent is having the value greater than all its descendants every node is having the value greater than all it is descendants so a road will have the largest value that is maximum value so yes if the elements are arranged like this then it is called as max heap so I repeat max heap is a complete monetary satisfying the condition that every in know what is having the and greater than all its descendants greater they're not equal to all so all it is descendant so duplicates are allowed here so if you have the blinkers you can have them in descendants coming into this one here this is 10 30 and 20 others children that are greater on this 35 and 40 or greater than 30 and also 10 so 32 and 25 are greater than 20 and also in turn they are greater than 10 also so here the smallest element is there in the root so every node is having the element smaller than all its descendants or smaller than or equal to all its descendants so this is called as mini heap so again I repeat mini heap is a complete binary satisfying the condition that every node is having the elements smaller than or equal to all its descendants so there are two types of heap max heap and min heap so whatever we have to study will study upon one heap and same thing applies on the next shape also so we will take max heap and study this one so we will learn how to insert and delete the element so first let us look at insert operation in a max heap I'll show you insert operation in the max heap let us understand how insertion is a ton so already I have a max heap here this is a diagrammatic representation of a heap that is complete by a tree and that is this is the array representation of same thing this is stored in an array if you check root 50 then this is 30 20 30 20 15 10 860 15 10 8 16 there are no gaps in between the elements in between these two there are no gaps so it's a complete - it's perfect let us insert I want to insert a element 16 so let us insert 16 so I want to insert the 16 this max heap so let us see see where the 60 should come a room should have the largest element so 60 should come in the root yes now what usually people think I will talk about that then I will show you what is the right method people think that 60 should be inserted here then where 50 should go 50 should go 30 that is 20 so this is small enough if they should go this side okay then where this 20 should go Bailey should come at this side so in this way it will extend in this direction 16 will come here and this will become 20 and this will become 50 and this will become 60 now if we do it like this is it a complete binary no all these are missing element then we have the 16 here this is wrong so don't insert it in the root so I have shown you the wrong procedure or wrong assumption what people will have this is wrong it is not inserted in the road then how it is inserted where it is inserted look at this the correct procedure see we actually implement in an array so that 60 should be inserted here at the last free space in an array our heap was ending here right it was ending here now I have 16 included there at this free space right so in diagram where it will be 60 will be on the left child or for 15 check it where is 15 and 4 2 4 8 yes it is a left child of 15 so this 60 is inserted here inserted here yes it's not a part of heap I have kept it separately now is it forming a heap known that condition is violated every node should have the value greater than all its descendant but you see 60 is there that is a child of 15 wrong then what to do are just the element are just the element make it as a heap or inserted in the heap how compared with the parent who is a parent 60 is greater than 15 so 16 should go up again compared with the parent 60 is greater than 30 also so it should go up and 16 is greater than 50 also so it should go up so check here in this Dyke in this array representation 8 8 by 2 4 so check with this one 4x2 to check with this 1 2 by 2 1 check with this one so 60 is compared with this one and its parent on each parent so 60 is compared with all this ancestors and it will reach its right place so it will swap all these element and 60 will there so I will draw it here c60 will come here I will draw a tree first - then I will fill the elements right after inserting how it looks like now this is our array so here I kept them empty just watch it 60 will go up 15 will come down and again 60 will go up and 30 will come down 30 will come here then 60 will go up and 50 will come down so we adjust the element like this so 60 comes here so it has moved up in the hierarchy towards the ancestors and it has reached the road because no it is the largest element so in an array if you see 60 was here so 15 when 60 was here so this 15 went there and 60 came here then again 30 went there and 60 came here than 50 went to its place and 60s in Surrey here so this is how the heap looks like diagrammatically and also in an array so this is insertion we have inserted only one element in a heap that we have taken max-heap now a little bit analysis how much time it has taken it has taken the time equal to the number of swaps so maximum how many swaps 1 2 3 so actually this is depends on the height of a tree so what is the height of a complete binary tree height of a complete binary tree is log n yes so it means the time is big-oh of log n or order of log n so the time taken for insertion is log in how many swaps are required 1 2 3 so that depends on the height log in number of swaps are required and one more thing if suppose this was not 60 if this was 6 then we don't have to swap anything zero swaps so we can say that the time taken for inserting one element in a heap is minimum Big O of 1 and maximum is log n it can be from one constant to logon minimum Tammis knows who are being is required maximum the swapping requires depends on the height so that is log n so this was inserting just one element in existing now before going to delete I have something to show you observe one thing see when we are inserting we have to send the element upwards first we add the new element as a leaf then we adjust it by comparing with the ancestors so element moves from leaf towards route so the direction of adjustment is upwards this is the important thing this is the important thing so anyway next I will take the same example then in this one only I will show you how to delete so let us look at the now let us look at delete operation on max-heap here is a max-heap with seven elements that are also they didn't have array now which element you want to delete see the first important thing you cannot delete any other element you should not delete any other element but root element so only one element is deleted from the heap without asking or without giving any options or choices only root element is related yes if you are deleting root element then only it is a heap see this heap is just like if you have seen in the market at the Fruit Shop if apples are arranged how they arrange they arranged like a pyramid heap like so the apples are arranged one above another like forming a pyramid like shape so on the top which Apple is kept the best Apple the most shiny one among all fresh one is kept on the top so that is the best one so same concept is used in heap also so all these elements are there which the topmost element best element what is best for us maximum element so that is max heap so 50 is on the top so if you want to remove the Apple which happily will remove you cannot remove any other Apple from that heap you have to remove the top most happen only that's what so you follow the same method here we will remove only the root element right similarly in the mini heap also if you say no maximum element is not important for us minimum is important then that you follow mean heap okay coming to this let us delete the element so only I can delete fifth t-50 is gone no again sometimes people mistake here the thing that thirty should go up because this is bigger okay thirty will go up then who will come into place of thirty fifteen so is fifteen goes here thirty goes here then this node is gone if this node is gone is it looking like a complete battery no so if you try to adjust as you like it will not be a complete binary tree so you have to be careful for preserving complete monetary property then what to do so when 50 is gone who should take its place see the last element in complete binary this element this element will come in its place that is 16 will come here so 16 is removed from here so 16 is brought here 16 is removed from here this is gone so 16 is brought there 50 is go gone outside we have deleted that 50 50 has gone out we have deleted it then in its place the last element in complete binary last element and complete abandoned humans in an array the last element will take its place now this is how it looks like so I will remove this one now okay I will remove this this is gone so you have already seen it it's here now now this is complete binary tree but not a max-heap so we have towards just the elements okay we will let just the element that's not a big deal ix aning complete binary property is very important so we preserve that now adjusting the element so we will adjust how from the route towards leaf we will send it so let us check how to do this compare children of this 16 that is new route which the child is greater 30 is greater so 30 will take its place 16 will come into its place so I will draw it here so here 30 goes here 20 and 8 remains 16 comes here and 15 and 10 as it is so I will fill them in this array also 30 is here 10 and 20 and this is 15 and 10 and 8 this place is free last place is free so how we have done it is see the 16 was a compared with its a children who are children of 16 2 and 3 left children right chain left children right share 1 into 2 1 into 2 plus 1 so 2 into 1 & 2 into one plus one so if you remember this formula - why do i plus 1 so this is 2 and this is 3 2 & 3 these are 3 20 and 30 are the children we compared and 30 is brought here 60 so now this is one step we have completed still we have to check with the descendents so let us check with the descendents 16 who are the children of 16 15 and 10 compare them which is greater 15 now is this 15 greater than 16 no first of all compare the children and we shave our child is greater that you compare with the parent okay afterwards you compare it but 16 is greater than both of them so leave it it's already there in max here so this is a max if you don't have to swap them so this is a delete procedure so I'll just repeat this steps quickly see always in delete we remove root and the last element in complete binary will take the place and we push the element downwards towards leaf and adjust the elements to form a max heap so we have adjusted downwards right so from route towards leaf if you remember in insert the adjustment was done from leaf towards root but now that this man is done from route towards leaf so in division adjustment is done but the direction is different so in both insert and delete adjustment is done but the directions are different now little bit of analysis how much time it has taken for deleting one element it depends on the height so what is the magazine you adjust when you have to do that depends on the height so the maximum time is login login yes so deletion takes log n time now one important thing we understood here is that from the match see for whenever you delete you get the largest element from the heap 50 was largest 50 was gone but now who is largest next largest element is 30 if you delete which will be deleted 30 then from the remaining 20 who will come and sit in the root 20 will come and sit in the room so if you delete next 20 will be deleted yes so from maxi whenever you delete you get the next largest element from min-hee whenever you delete you get the next minimum element so you get the smallest then next small as the next small it's and so on now last important thing this is very important listen carefully right see this is important here the array size was seven one element is deleted know what is the heap size six heap is still six only from one to six seventh place in an array is a free that is not a part of habeus leave it no problem our heap is still six only that space is vacant after that so it's not a problem for us but what element we deleted 50 where it is we are using it but if you want to maintain that copy of 50 there is a free space here you keep 50 here this is interesting I get 50 there is it a part of you know it's outside him yes so it's not a part of him just a space was free so I kept it there that's all away from him right now from the six elements if I delete again what will be lit it 30 will be deleted and eight will come here then we are just so 20 comes here and eight goes here then eight with it's a child that is 10 so 10 comes here it goes there so now the heap reduces to this so the heap size is 5 which element I deleted just no 30 these two places are free all the way I kept 250 there not 30 keep it here next free place if I do this what happens what happens next element will be 20 next element will be 10 and so on see this was 16 anything is so it will be so on so what happens you we are getting the elements largest the next largest the next largest in the slashes largest so if you read the elements from this side they are sorted they are sorted yes this is the idea of heaps heart if you have a heap that delete the element and fill it in the empty place obtained after deletion so if you go on filling the elements there then automatically gets sorted so from the heap go on deleting the elements and start filling them in free spaces so this is he sought so let us take fewer elements and see the complete heap sort right now heapsort heapsort have two steps first us for a given set of elements create a heap by inserting all the elements one by one then once the heap is formed delete all the elements from the heap one by one the elements will get sorted so I repeat the procedure of heaps would have two steps for a given set of number first of all create a heap then delete all the elements from the first of step create a heap second step delete all the elements from a heap so I already have some set of elements here in an array these are the elements we have to sort them so I will first show you how to create a heap how the heap will be created inside the array I am also going to show you diagrammatically so let us start suppose these are the set of elements that we have to sort they are not sorted so first of all create a heap so for that initial array these elements are initial array so we assume that in this first element is already in a heap so this is ten so right now there is only one element in the heap so when you have only one element you can call it as maxi also mean heap also it's a heap definitely it's a heap now we will insert second element so second element we will insert that is 10 is already in the heap now we'll be inserting 20 so 10 is already there so 20 we will insert so 10 here 20 here so rest of the elements I am NOT writing them okay I will be right one I will be writing one by one now inserting 20 how do we insert already have shown you compared with the ancestor that is parent and its parent and so on and try to add the element check 20 with 10 right so this is greater so 20 should go up and 10 should come down 20 should go up and 10 should come down so here in an array 2 is the in the of twenty two by two is one compared with the parent one so yes twenty will come here ten will go there right now this is him so we have a heap of two elements there's a heap of two elements now third element we will include so right now we have twenty and ten now the new element is the next three space so next three spaces this one yes so the new element is fifteen so we are going to insert fifteen now this one earlier we have inserted the elements from here right now 15 we are inserting so right now we have 20 and 10 here so 15 is in inserted here now try to adjust it how compared with the parent so who is the parent of 15 3 by 2 s 1 so temporary with the parent 15 is smaller so already it is in the maxi form we don't have to adjust so till here we got a heap now insert the next element 30 so already we have elements 2010 15 now this is the next free space right 2010 15 next free space we have 30 so 30 we are going to insert 30 this is complete by a tree but not some max-heap are just the element company with the parent and its parent so that is greater than 10 and also greater than 20 so 10 will come into place of 30 yes here it is compared with this one then again it is compared with 20 so Teddy comes here and at this place 30 will be inserted so this will modify 10 comes here 20 here and this becomes 30 now this is a heap but till here so we have four elements in heat now the last element 40 I am going to insert so right now we have 30 20 15 and 10 so 30 20 15 and 10 so the new element that we are inserting is 40 here so 40 is inserted at next free space here so it's a complete monetary but not a maxi compare with the parent yes what is greater than its parent what is greater than that also so 40 will move up so this is the parent 5 by 2 is 2 then its parent so yes 20 will go at this place and 30 will go at this place and what he comes here so it means so it means 20 comes here 30 comes here and 40 is here so this is a max-heap so one by one we have inserted all the elements and every element was inserted at a next free space and it was moved upwards and we got a max-heap now before going to the next step let us analyze how much time it has taken we have inserted and the elements total and elements we have inserted how much time it takes for inserting an element in a heap depends on the height what is height of a complete mana tree or a heap it is login so n elements each element we assume that it is moved up to the root so it is login so the time taken is and the log n so this was the heap creation for system now from that heap I will be going on deleting the elements so this place I will show you how the elements are deleted and they are also sorted so let us delete the elements now second step for heapsort already we have created a heap now the same heap I have taken this is the heap that we go now let us delete the element so we know very well how to delete the element so in this let us delete so which element get deleted 40 gets deleted 40 is gone out that who will take its place last 20 this will take its place 20 will take its place so in the diagram I will show 40 is removed and 20 will go in its place 20 will go in its place so it means this element is gone this element is gone now this is completed by entry but not a max-heap so we have to adjusts we have to adjust downwards so this 20 is gone right 20 is removed now 30 and 15 30 is greater so 30 will go in the place of 20 and 20 will come here so this becomes 20 and this becomes 30 then I get it compared to India with the 10 so it's perfect so these are the changes so now 40 is deleted and we got one free space now here I will show a large elements see we have 30 here and 20 here 15 and 10 so the elements in the heap are 30 20 15 and 10 heap is tell 4 elements only 40 which was deleted I will put it here at a free space that is not a part of heat now delete next element so next element which element will have deleted 30 will be deleted 30 is gone who will take its place last element in cupola 2010 so in this array 30 is gone so the 10 last element will come here this element came here so this is not there so one more element reduced we have to adjust this one compared with the children 20 is greater so 20 moves up and 10 comes down right so this becomes 20 and this becomes 10 so this is deleted I remove this arrow now 30 is deleted and this is in a max-heap perform now next step here I will show we have the elements 20 10 and 15 and heap is ending here 40 was already there we got one more free space so keep 30 there the newly deleted element and in the diagram this is 20 10 and 15 still we have to delete three more elements no next delete one more element which element get deleted 20 is deleted from the array this is gone who will take its place last element in complete binary will take its place 15 so 15 will come here last element in the array that is in the heap 15 comes here so this is place is free so this is gone I just already 15 is greatest so child is smaller no need to swap the element it's already perfect so this is the result then next is space I will write out this is 15 and this is 10 so this is 15 and 10 and heap is reduced still here see there were three element now there are only two early already I have 40 at the last and 30 at the second last place one more free space I got there I can insert 20 so just a store two nd I should not say insert just I have stored 20 they are kept at 20 there now these elements are deleted from the hem these are remaining still in the heap not delete next element which element is deleted 15 is deleted who will take its place last elements so it means this is gone so here also 15 is gone 10 will take its place now do you have to adjust you don't have to adjust anything now what will be the result this is 10 so this is 10 now heap ends here now we already have 20 30 and 40 here we got 1 3 space so they use 2 or 15 so that's how the elements are sorted so the heap sort first step if the elements are given then create a heap then second step go on deleting the element and store the element at the free space we are obtaining after deleting the element so finally the elements are sorted so you look at this so you have to observe it because too much board work gives there a lot of board work is there so you may miss at some place so I suggest you just pause the video and have a look at it complete example is there on board right and do it by yourself once you do it by yourself then you can remember it always how it is working just take a snapshot or copy everything from my board if we do the analysis already creation process we have seen and log in creating heap and login now how much time this is deleting of all any an element is taking and there remains we are deleting and each element takes how much time for deletion also it takes login time we have already seen it so that is n log n so n log n for creation and log n for deletion so total how much 2 n log N and this is Big O of n log n right 2 times of log n is also dependent on n log n so the time is order of n log N or Big O of n log n so heap sort takes n log n time so that's it this is heapsort now I have to its new heapify and heapify is a process of creating a heap already we have created a heap how it is different it's different how does different we will see but before that if you remember here we were inserting the element always in the leaf and we were adjusting towards route adjusting towards who it was sent from leaf towards route adjustment was upward now in heapify the direction is different how it is done I will show you how to remove the sensual now he makes topic is heapify heapify is a procedure for creating a heap so already we saw how to create a heap by inserting elements one by one here also will do the same thing but the procedure was inserting an element in the leaf and adjusting upwards now let us see how he b5 works so for explaining heapify already I have an array right and if you see it diagrammatically is this a binary tree and so complete binary tree but it's not a max-heap we want max-heap now if we just repeat the procedure of creation let us look at it quickly already we saw in creation process what we did we kept tonalities inserted 20 20 went up then inserted 15 then inserted 12 than 40 then 35 then 18 one by one we inserted starting from this element so we inserted except this element we inserted 2015 12 or t25 18 so we started from left to right is it possible if we change the direction can we create a heap let us start from right to left so if we start from right to left then shall we still that just the element upward no let us do it downward downward how in the deletion if you remember we were adjusting the element by sending it down towards leaf from root so the direction was from top towards leaf that procedure will follow let us follow the process now I am explaining heapify watch this first go to element 18 look down there are no children so only a single element look at all of the nodes just 18 and it's descendants there was no descendant so 18 is a hint yes then go to next element 25 25 look downwards it's a heap there is nothing there are no children it's alone it's a heap 40 is a heap next element 40 next element 12 downwards it's a he no you will understand what does it mean what I was saying just next next element 15 so from here at just 15 downwards yes children are there compare which is greater 25 so 25 will go up and 15 will come down yes this is the procedure 25 will go up and 15 will come down so 25 will go up and 15 will come in its place this one right so if you look only these nodes 25 15 and 18 it's a heap yes only one element I have adjusted now next after 25 this one 20 is there this is over right 15 was there this is over now we are on second element right this one look downwards is it a max-heap no it just this one so compared with the children 40 is greater so 20 will come here 40 will go up right so 40 this will be changed to 20 and this will become 40 so I have just adjusted just two elements now after second element first element here only this element is not in the heap so adjust it compare with the children 40 is greater so 40 goes up 10 comes here compared with the children and 20 is greater so 20 goes up 10 comes here right so this will be swapped with the child so this will become 40 and this is 10 then again swap with the children that is 20 and 10 2012 and 20 was there so it will be so after 20 and this comes here this is a heap so we adjusted the elements at downwards and we started from the last element so we have scanned this array from right to left the procedure we were using in the deletion after deletion we were at in Delhi when same procedure we followed and we got the he created so this procedure is called as heapify right direction is different that's all right and what is the time taken by this one analytically the time taken by this hippie fie procedure is Big O of n we go theta Omega or whatever you want notation you use anything commonly we use Big O so this is Big O of n so if you remember the procedure for creating a heap creating a heap so creating a heap was and the login we go off and log n right but this is heapify heapify procedure is order of n so this is faster now what is the minimum time taken for creating a heap Big O of n using HIPPA file so that's all about HIPAA Phi now the last thing is what are priority queues it's a simple topic so I will finish with that one next we will see priority queues now priority queue priority queue so actually cuman's FIFO but priority cuman's it's not free for strictly the elements will have priority and they are inserted and deleted based on the priority right so always if in a queue when you want to delete always we want highest priority element from the queue the element having the highest priority that should be deleted for so this is the discipline of priority queue elements are inserted with the priority when you delete we want higher priority element so let us see what does it mean by high after ID see these are the numbers what is the priority of a number number itself is the priority okay here in our example number itself is the priority there are other example of priority queues also like in operating system also there is a concept of priority queue it is not same as that one this priority queue is mostly used in algorithms right so let us see what is the priority eight is the variety of eight six is the priority of six so 10 is the priority of 10 so that number itself is the priority then who is higher priority I can say that smaller number higher priority so which is high as turning this one then this one right then this one yes smaller the number higher the priority so three is of highest priority here so if I delete I want three from the array then otherwise even I can say that larger the number higher priority I can say this also so larger number higher priority so who is having higher priority 10 then 9 then 8 so yes when I want delete I should get 10 from that one so this is about priority queue elements they value itself is priority and there are two methods of giving priority smaller number higher priority or larger number higher priority okay now let us see how to insert and delete see in an array if I want to insert suppose I have one more element simply I can insert after this one now say when I want to delete from the this type of priority queue I want 3 then for how much time it takes for deleting an element from an array or orphan because if I am deleting 3 I should shift the rest of the elements rest of the elements I should shift say takes order of n time so if you implement periodic you just using normal array than the time for insert or delete may be order of M so I don't want to discuss in detail you can study it by yourself means you can analyze by yourself if you say no I want to keep them sorted order then for sorting also it takes time again for a deletion or insertion you have to spend order of n time then what is the better method heap which takes how much time login time for insertion and login time for deletion so yes heap is a best data structure for implementing priority queue so if you have smaller number higher priority then create a min heap if you have larger number higher priority then use max heap same set of numbers I have created already created I mean he already created maxime so for one element insertion how much time it takes login right then one element deletion how much time it takes login so this is the best data structure which works faster otherwise if you use normal array like this then insertion may take maybe deletion is faster otherwise deletion will take order of endtime and insertion may be faster any one of the operation will definitely take order of n time but in heap the time taken is login so heap is a faster data structure for implementing priority so that's all about periodic you so predict you can be implemented using heaps of either min heap or Maxie if you want always smaller number min heap if you want always larger number max so that's all in this video and if you want to take the course you can check in the description and you can buy the course for C++ and data structure subject there are two different courses right so go through the course see the contents and then you decide that's all ",
            "url": "www.youtube.com/watch?v=HqPJF2L5h9U",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "q7R_upR81FU",
            "channelId": "UCTtZPn_bD6ekitgbfakcsgg",
            "publishedAt": "2014-05-25T03:41:17Z",
            "title": "Data Structures: Heaps",
            "description": "Here is my Github link for code examples:https://github.com/ajn123 Check out my website and like or comment any other tutorials you would like to see!",
            "channelTitle": "Apple Juice Teaching",
            "transcript": "what's goofy everyone it's AJ here again and today I want to talk about another data structure that's similar to a binary tree but it has some kind of some different rules and some different quirks but I really like it because it's simple and I feel I can explain it well so is how to do let's get into the heap data structure so as you can see here a heap looks a lot like a binary tree if you know what that is but but a heap is classified by its order and what a heap does is it retains tools one is that the parent is always greater than the child and that it's always a complete tree and so by complete tree means every single row is filled every row is filled just like like the first true fill the second one was filled except for the last row but the last row must have its nodes going from left to right so for instance all the nodes are filled here when you start it left and then the emptiness starts at the rightmost side so that's a complete tree but also what I said the parent must always be bigger than the child in this example that is not true but that is um what I mean by that is that the parent must be greater than child relative to the child so this would be called actually a min heap because I am saying the minimum element is the greatest element has the greatest power you can also have a max heap which we'll see in a second is where the maximum element has the most power so as you can see 100 is the root of the node which is which is what I want and then see as you can see 19 is greater than 17 and 3 and then the two children of 2 and 7 are less than 17 and as you can see this again is a complete tree well 2 and 7 all the way to the left and then other children's of these nodes are incomplete so another thing about heaps is they can be represented in an array you know if you're going to make a heap you want to just use an array you don't need you don't you can you you can use generics but really you don't we use a tree structure you just want to use an array and the reason because it's going to be how you're switching around the tree so for instance here I have 5 9 and 11 and you'll notice I have the 0 in the beginning and that's because in this example I am not using position zero position zero is kind of just like a null value it's a blank value that will not really use it's just a holder value and we're never going to touch that but I have five nine eleven fourteen eighteen and if you can see here these nodes are going from top to bottom left to right so for instance five is the first element then nine then I go right eleven now I go to the next row which is all the way on the Left fourteen eighteen nineteen twenty one thirty three seventeen twenty seven and the thing that's special about this array is that I mean yes this array is that heap has a special property and how you can find the children so for instance let's look at five here it's childs are 11 or sorry it's childs are nine and eleven and the way to find a child is to simply take the position of what of whatever node you have and times it by two and if you times it by two that will always be the left child and then if I did 2n plus 1 so take the position times 2 plus 1 that will give me my right child and you can try this on anything else for instance on 9 it's at position 2 2 times 2 is 4 which is the left child 14 at position 4 and then 2 times 2 plus 1 is 5 which is 18 which is my Y child so that always works and then kind of oppositely let's say I wanted the shot the parent of 27 so 27 doesn't have any children but it does have a parent so the way to do that is simply take the position and do n divided by 2 so n / - 10 10 divided by 2 is 5 which is 18 which is my parent and this works for the left and right child for instance 19 right here is not a right child 21 7 so if I do 7 divided by 2 that's 3.5 but I'm going to round it down to 3 you always round it down I rounded down to the integer like in computing and I'm going to get 11 which is my parent so that so that's a simple way to kind of that's the way I can exchange your switch elements in the array as well show so now we're going to talk about insertion so insertion really is pretty easy and what we do is simply what you want to do is you want to add it to the lot you want to first of all start you want to insert it at the empty slot which in the complete tree is the next empty slot going from left to right so for instance right here in the source heap on the left here we're going to try to we're going to insert negative two right here we're going to insert it to the as the right child of six and then what I'm going to do is no matter what element is I'm going to look at the parent by doing my n divided by two in the array and say okay does that child need to be moved up in the case of inserting negative two and a min heap it does need to meet moved up so I'm going to flop six and negative two I'm going to flop six and negative two so now negative two is right here and six is right here and so then I'm going to check I'm going to keep on doing this until I get stopped so then I'm going to do okay is negative two greater than one in this case it's a min heap so yes it is so then I switch that and you get you get what you get on the right negative two is now the root and now I'm done with that so that's pretty cool and now we're going to talk about another thing called deletion and so deletion is usually kind of the hardest thing with a tree so really the thing in deletion though is you don't delete any node you you just delete the root because in a min and max heap you really use it only because you want the minimum or maximum of your data structure you don't really want care about any other elements you just care about the minimum maximum so maybe you just care about the high point of a statistical analysis but that's all you're going to care about in the heap so you can you only really have a remove a remove root method which could be your minimum or maximum position depending on what type of heap you have so right there so right now what you want to do is you want to remove your root just like here I want to get rid of four and what I want to do is I want to replace that with my bottom rightmost element so what is you know what is the rightmost bottom list on the complete tree and the way so in this case that's eight so I'm going to push that to eight and then what I'm going to do here is I am going to I'm going to shuffle eight down and I what I'm going to switch I'm going to bring it down and I'm going to purposely you know make the tree right again because now that I moved eight down and this is a min heap eight is not the minimum element so that cannot the root five is so what I'm going to do is I'm going to look at my two children I'm going to look at my two children and I'm going to swap with which element is the greatest element so that way I bring up the greatest element so now my greatest element is now the new glute node and everything is fine in this case of a min-heap five the smallest number has the most power is the most powerful so I'm going to swap with five and then as you can see right here in my bottom in this bottom part in this bottom picture that that array is now fine I have now removed that I have now cut the heap is now following the right order five is the lowest element has the most power six and then eight and and nine so it still fits the rules that fought five is less than six and eight and nine is less than six well guys I hope you've enjoyed this video and I hope you guys have a great day ",
            "url": "www.youtube.com/watch?v=q7R_upR81FU",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "B7hVxCmfPtM",
            "channelId": "UCEBb1b_L6zDS3xTUrIALZOw",
            "publishedAt": "2013-01-14T20:26:48Z",
            "title": "4. Heaps and Heap Sort",
            "description": "MIT 6.006 Introduction to Algorithms, Fall 2011 View the complete course: http://ocw.mit.edu/6-006F11 Instructor: Srini Devadas License: Creative Commons ...",
            "channelTitle": "MIT OpenCourseWare",
            "transcript": "The following\ncontent is provided under a Creative\nCommons license. Your support will help MIT\nOpenCourseWare continue to offer high quality\neducational resources for free. To make a donation or\nview additional materials from hundreds of MIT courses,\nvisit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: One of the cutest\nlittle data structures that was ever invented\nis called the heap. And we're going to use\nthe heap as an example implementation of\na priority queue. And we'll also use heaps to\nbuild a sorting algorithm, called heap sort,\nthat is very, very different from either\ninsertion sort or merge sort. And it has some nice properties\nthat neither insertions sort nor merge sort have. But what I want to\ndo is get started with motivating the\nheap data structure, regardless of whether you're\ninterested in sorting or not. So the notion of a\npriority queue, I think, makes intuitive\nsense to all of you. It's essentially\na structure that implements a set S of elements. And each of these elements\nis associated with the key. And as you can imagine, a\npriority queue is something where you queue\nup for something, you want to buy something,\nyou want to sell something. You have certain\npriorities assigned to you, and you want to pick the maximum\npriority or the min priority. You want to be able to\ndelete it from the queue. You want to be able to insert\nthings into this queue. You want to be able to change\npriorities in the queue. So all of these operations\nare interesting operations that should run fast, and\nfor some definition of fast. Obviously we are interested\nin the asymptotic complexity definition of fast. In that case, we'll be saying\ndoes this operation run an order n time, order\nlog n time, et cetera. So in general, I think\nfor the next few lectures, you're going to see a\nspecification of data structure in terms of the operations\nthat the data structure should perform. And those of you who have\ntaken six double O five, you'll see that it's basically\nan abstract data type that's associated with\nthese operations. So it's a spec for the\nabstract data type. In six double O\nfive, you had really spent a lot of time on\nasymptotic complexity, or the efficiency of operations\non the abstract data type. Here, in double O six,\nyou'll specify this ADT, and specify the set of\noperations or methods in the ADT. And we'll talk about whether\nthese are order end complexity log end complexity, and compare\nand contrast different ADTs. So today's ADT is a heap. And what is the\nset of operations that we'd like to perform\non a priority queue? So we can use that to motivate\nthe development of the heap. And those are, insert s x. So you have a set of\nelements s, and you want to be able to insert\nelement x into set s. You want to be able\nto do max of s, which is return the element of\ns with the largest key. And different from\nmax of s is extract max of x, which not only returns\nthe element with the largest key, but also removes it from s. So you have a queue, and\nthe person in the queue was serviced, or the element\nin the queue was serviced, and then removed from the queue. And finally you can\nimagine changing the priority of a particular\nelement x in the set s. And this priority,\nthere's an associated key as we have up there\nwith each element. And that key is called a k. And increase key s x k would\nincrease the value of x's key to the new value k. And k could correspond to,\nit's just called increase. Most of the time, you're\nincreasing the value in maybe a particular\napplication. You could have suddenly\na decrease key, and you would have to know\nwhat the previous value was. And is just a matter\nof exactly what operation you want to perform. You could call it update, or\nincrement, whatever you like. I'm going to spend most\nof the time here talking about how you maintain a\nrep invariant of this data structure called the heap,\nthat allows you to do these operations in\nan efficient way. And we'll talk about\nwhat the efficiency is, and we'll try to analyze the\nefficiency of these algorithms that we put up. So let's talk about a heap. A heap is an implementation\nof a priority queue. It's amazingly and\narray structure, except that you're\nvisualizing this array as a nearly complete\nbinary tree. And what does that mean exactly? Well, the best way\nto understand that is by looking at an example. We got 10 here, so. 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. So here's my array\nof 10 elements. And the elements are\n16, 14, 10, 8, 7. So some set of elements\nthat are in random order, clearly not sorted, and\nI'm looking at the indices, and I'm looking at the elements. I'm going to visualize this as\na nearly complete binary tree. Is not a full binary\ntree, because I only have 10 elements\nin it, and it would have to have 15 elements to\nbe a complete binary tree. And we want to be able to do\nthe general case of an arbitrary size array, and so that's why\nwe have nearly complete here. So what does it mean to\nvisualize this as a tree? Well, index one is\nthe root of the tree, and that item is\nthe value is 16. And what I have are indices\n2 and 3 are the children, and 4, 5, 6, and 7 are\nthe children of 2 and 3. And 8, 9, and 10 are\nthe children of 4 and 5, in this case. And so that's the\npicture you want to keep in your head for\nthe rest of this lecture. Any time you see\nan array, and you say we're going to be\nlooking at the heap representation of the array,\nthe picture on the right tells you what the\nheap looks like. And so that I'm not going\nto fill in all of these. You can, but I'll do a couple. So you have 10 here,\nand 8, 7, et cetera. So that's a heap structure. So what's nice about\nthis heap structure, is that you'll have tree\nrepresentation of an array, and that lets you do a\nbunch of interesting things. What do you get out\nof this visualization? Well, the root of the\ntree is the first element corresponding to i equals 1. The parent of i is i over 2. The left child of i is 2i. And the right child\nof i is 2i plus 1. So that's essentially what\nthis mapping corresponds to. Now on top of that, this is\njust what a heap corresponds to. We're going to have\nparticular types of heaps that we'll call\nmax-heaps and min-heaps. And as you can imagine,\nmax-heaps and min-heaps have additional properties\non top of the basic keep structures. So this is essentially\na definition of a heap. Now I'm going to define what\nthe max-heap property is. And the max-heap property\nsays that the key of a node is greater than or equal to\nthe keys of its children. OK, that's it. It's obviously\nrecursive, in the sense that you have to have this true\nfor every node in the tree. And when you get down to\nthe leaves of the tree, they're not children\ncorresponding to the leaves, So that's a trivial property. But at higher levels, you're\ngoing to have children, and you have to check that. So if you look at\nthis example here, maybe I should fill\nthis whole thing out. A have eight and seven\nhere, and six would be nine. And I have three over here,\nand then two, four, one. So we can look at this\nand check whether it has the max-heap\nproperty or not. Does it have the\nmax-heap property? This heap? Yeah. All you have to do is\nlook at these nodes. one, two, three indices,\nindex four, five, six, but you don't have to look\nat six and seven, because they don't\nhave any children. But you could shop\nwith five here, and you look at the\nchildren, and there you go. To the parent is greater\nthan or equal to either of its children, or its only\nchild, in the case of node five. And so you have the\nmax-heap property. So fairly\nstraightforward property. And you can imagine defining\nthe min-heap property in an equivalent way. Just replace the greater\nthan or equal to, with less than or equal to. So right off the\nbat, what operation is going to be trivially\nperformed on a max-heap? This is kind of\ntrivial question. Yep. Just finding the\nbiggest element. Exactly right. The max operation. Now, what about extract max? Is that trivially\nperformed on a max-heap? No. What do I mean by that? When you say, max is\ntrivially performed, what it means is that\nyou can return the max, you can find the maximum\nelement, or a maximum element, and you obviously\ndon't modify the heap. And the heap stays the same,\nso it stays a max-heap. In general, when we talk\nabout data structures, and this goes back to\nrep invariance, which I've mentioned\nalready, you typically want to maintain\nthis rep invariant. And so the rep invariant of our\ndata structure, in this case, is a max-heap property. OK. So we want to maintain\nthe max-heap property as we modify the heat. So if you go from\none heap to another, you start at the max-heap, you\nwant to end with the max-heap. It makes perfect sense,\nbecause in one of the simplest things that you want to\ndo in a priority queue, is you want to be able to\ncreate a priority queue, and you want to be able to run\nextract max on the priority queue, over and over. And what that means, is that\nyou take the max element, you delete it, take the next\nmax element, delete it, and so on and so forth. And there you go. It's a bit of a\npreview here, but you could imagine that if\nyou did that, you would get a sorted list of\nelements in decreasing order. So you see the\nconnection to sorting, because you could imagine\nthat once we have this heap structure, and we can maintain\nthe max-heap property, that we could continually\nrun extract max on it. And if you could build extract\nmax in an efficient way, you might have a fantastic\nsorting algorithm. So, the big question\nthat really remains, is how do we maintain\nthe max-heap property as we modify the heap? And the other question,\nwhich I haven't answered is-- this array that turns\nout it was a max-heap, but it's quite\npossible that I have a trivial example of an array. In fact, let me make this one. That is not a max-heap. It's not a max-heap, it's\nnot a min-heap, it's neither. Right? it's just a heap. So if I just\ntransform, or visualize I should say, this array as a\nheap, I don't have a max-heap, I don't have a min-heap. So if I'm very interested\nin sorting, and I am, there's this\nanother thing that's sort of missing here\nthat we have to work on, which is how are we going\nto build a max-heap out of an initially unsorted array. Which may or may not\nturn into a max-heap. This trivially happened to\nbe exactly the right thing, because I picked it, and\nit turned into a max-heap just by visualizing it. But it's quite\npossible that you have arrays that are input to\nyour sorting algorithm that look like that. OK, so let's dive\ninto heap operations. I'm going to have spend\nsome time describing to you a bunch of different methods\nthat you would call on a heap. And all of these\nmethods are going to have to maintain\nour representation invariant of the\nmax-heap property. So what are the heap\noperations that we have to implement and\nanalyze the complexity for? Well, we're going to\nhave build-max-heap which produces a max-heap\nfrom an arbitrary or unordered array. So somehow I got to turn\nthis into, for example, four, two, one. Which is in effect,\nsorting this array. Or changing the order. Maybe not fully sorting\nit, but changing the order. So that's what I have to\ndo, and build-max-heap is going to have to do that. In order to do build-max-heap,\nthe first procedure that I'm going to describe to\nyou, is called max-heapify. Heapify. Sounds a little\nstrange, but I guess you can -ify pretty\nmuch anything. So you correct a\nsingle violation of the heap property in a\nsubtree, a subtree's root. And I'll explain what I mean\nby that in just a minute. So max-heapify is the\nfundamental operation that we have to understand here. And we're going to\nuse it over and over. What it does, is\ntake something that is not a heap, not a max-heap. When I say not a\nheap from now on, pretend that I'm\nsaying not a max-heap. We're only going to be\ntalking about max-heaps for the rest of this lecture. What max-heapify does,\nis take something that is not quite a max-heap. It can't take\nanything arbitrary. It's going to take\nsomething where there's a single violation of\nthe max-heap property at some subtree of this\nheap that is given to you, and there's a single\nviolation of that. And it's going to fix that. And we need to be able\nto do this recursively at different levels\nto go build a max-heap from an unordered array. Then once you have\nthat, you can do all sorts of things like insert\nand extract max, and heap sort, and so on and so forth. So let's take a look at\nmax-heapify using an example. I'm not going to write\npseudocode for max-heapify. I'll run through an example, and\nthe pseudocode is in the notes. The big assumption,\nand you think of this as a precondition,\nfor running max-heapify, is the trees rooted at left\ni and right i are max-heaps. So max-heapify is going\nto look like a comma i. a is simply the array,\nand i is the index. Max-heapify is\nwilling to, you're allowed to crash and\nnot do anything useful if this precondition is\nviolated in max-heapify. But if the precondition is\ntrue, then what you have to do is, you have to return\na max-heap correcting this violation. That's the contract. So let's take a\nlook at an example. I think what I want to\ndo is start over here. I want you to see all\nof the steps here. So we'll take a simple\nexample, and we'll run through max-heapify. And let's take a\nlook at 16, four-- I'm just going to draw the\nindices for this first example, and then I won't bother. So there you go. Is this a max-heap? No. Because right here,\nI've got a problem. 4 is less than 14, therefore\nI have a violation. And so, if you look at the\ncall max-heapify A comma 2, this is an index 2,\nand all you have to do is to look at this subtree. And what you need to\nbe satisfied in order to run max-heapify, is that the\nsubtrees of nodes index two, which is this four\nnode, are max-heaps. And if you go look below, you\nsee that this is a max-heap and that's a max-heap. Most of the time,\nby the way, you will be sort of\nworking bottom up, and that's why this is\ngoing to make sense. This will all work\nout, because leaves are by definition max-heaps. Because you don't have\nto check anything. When you put two\nleaves together, and you want to create a tree\nlike that, or a heap like that, then you run max-heapify. And then when you have a\ncouple different max-heaps, and you want to\nput them together to make it a bigger max-heap,\nyou'd have run max-heapify. So that's the way\nit's going to work. So you want to do a\nmax-heapify A comma 2. One of the things that's\ngoing to be important, not in this example, but\nwhen we get to sorting, is that we want to know what\nthe size of the heap is. And in this case,\nthe heap size is 10. So, what does max-heapify do? Well, all max-heapify does\nis exchanges elements. And so, if you looked at\nthe code for max-heapify, and you walked through it,\nthis is what it would do. You're going to\nlook at 4 and 14, and it's going to\nsay, OK, I'm going to look at both my children. And I'm going to go ahead and\nexchange with the bigger child. So I'm going to\nexchange AA[2] with AA[4]. And what that would do is,\ntake this, make this 4, and make this 14. And that would be step one. And then when you\nget to this point, recursively, you'd realize\nthat the max-heap property at this level is violated. And so you would go ahead and\ncall max-heapify A comma 4. And when that happens,\nthat call happens, you're going to look at the\ntwo children corresponding to this little subtree\nthere, and you're going to do the exchange. You're going to have\n8 here and 4 here. So you would exchange\nAA[4] with AA[8]. And now you're done, so\nthere's no more calls. So, fairly straightforward. It's actually not any more\ncomplicated than this. There may be many steps. What might happen is that you'd\nhave to go all the way down to the leaves. And in this case, you\nwent a couple of steps, and then you got to stop. But obviously, you\ncould have a large heap, and it could take\na bunch of time. So, what is the\ncomplexity of max-heapify? Anybody? Yeah. Back there. AUDIENCE: Ultimately,\npotentially, if the tree is\ntotally upside down, you could potentially switch\nevery node to make it order in. PROFESSOR: Every node\nto make it order in. Everybody, anybody. Do you have a different answer? AUDIENCE: Log n. PROFESSOR: Why? Why is it log n. AUDIENCE: Because I think\nthe worst case scenario, all of your-- the\nworst case scenario you would have [INAUDIBLE]\non the left-hand side, [INAUDIBLE] right-hand side. And it would be skewed. [INAUDIBLE] PROFESSOR: So you're\narguing that the solution to the recurrence gives you\na logarithmic complexity. Alright. Not quite. There's an easier\nway of arguing this. this Yeah. Back there. AUDIENCE: [INAUDIBLE]. PROFESSOR: That's right. AUDIENCE: [INAUDIBLE]. PROFESSOR: That's right. So what is the complexity? AUDIENCE: Log n. PROFESSOR: Log n. Great. Excellent. Definitely worth a cushion. Missed you by that much. AUDIENCE: Thank you. PROFESSOR: It's pretty\nsoft, by the way. Right. OK. So, if I hit somebody,\nthey get a cushion. OK. That's exactly right. Thanks for that description. So, first off, there's\ntwo important aspects to this argument. The first thing is,\nthat we're visualizing this is a nearly\ncomplete binary tree. It is not an unbalanced tree. Alright? We'll talk about unbalanced\ntrees and balanced trees in the next couple of lectures. But the visualization of a heap\nis a nearly complete binary tree. And, in fact, if\nyou had 15 elements, it would be a\nperfect binary tree. So the good news is, that the\nheight of this visualization tree is bounded by log n. That's the good news. And you want to\nexploit that good news by creating algorithms\nthat go level by level. If you can do that, you're going\nto have logarithmic complexity algorithms. So that was one aspect of it. The other aspect of it,\nis the key assumption that we're making, with\nrespect to build-max-heap, that there was a\nsingle violation. It is true that the answer that\nwas given that was order n, would be a problem. I could set it up so that's\nactually the right answer, if I did not have this\nassumption-- where do I have that here-- assume\nthat the trees rooted at left i and right i are max-heaps. So maybe that's what\nyou were thinking. But this is a key assumption. This is going back\nand like making connections between classes. This is a precondition\nthat makes the algorithm more efficient. Makes the implementation easier. And this precondition\nessentially says that you have to just go\ndown and do a number of steps, that's the number of levels in\nthe tree, which is logarithmic. So that's the story here\nwith the max-heapify. It's order log n, in\nterms of complexity. That's the number of\nsteps that you have. And it's a basic building block\nfor all of the other algorithms that we look at for the rest\nof this lecture, and in section tomorrow. Let's talk about how you\nwould take max-heapify and use it to do build-max-heap. So the first step\nnow, let's say that we want to go and get a\nnice sorting algorithm. We don't like insertion sort,\nwe don't like merge sort. We'd like to get a\nheap-based sorting algorithm. One of the things that\nwe need to do, as I said, is to take an unordered\narray, and turn it into a max-heap, which is\na non-trivial thing to do. And once we do that, we can\ndo this extract-max deal to sort the array. So the first step is, we\nwant to convert an array A 1 through n into a max-heap. And the key word\nhere is max-heap, because every array can\nbe visualized as a heap. And I am going write the\npseudocode for build-max-heap, because it's just\ntwo lines of code. And that's about the limit\nof a size of a program I can really understand,\nor explain, I should say. And this is what it looks like. Alright. that's it. Build-max-heap says go from\ni equals n, by 2, down to 1. Max-heapify A of i. So someone explain to me why\nI can start with n over 2, and why I'm going down to 1. Yep. I saw you first. AUDIENCE: [INAUDIBLE]. PROFESSOR: Leaves are good. Leaves are good. I'll let you go on in a second. Leaves are good, because if you\nlook at elements A of n over 2, plus 1 through n,\nare all leaves. That's a good observation. And this is true for any array. It doesn't matter what n is. Doesn't have the power of\n2, or 2 [INAUDIBLE] minus 1, or anything like that. And leaves a good,\nbecause they automatically satisfy the backseat property. Continue. AUDIENCE: OK. [INAUDIBLE]. PROFESSOR: That's exactly right. Beautiful. I won't hit anybody here. So that's it. The reason this works,\nis because you're calling max-heapify\nmultiple times, but every time you call it,\nyou satisfy the precondition. And the leaves are\nautomatically max-heaps. Then you start with n over 2. You are going to see two\nleaves as your children for the n over 2 node, right? I mean, just pick\nan example here. Our 2 is an A of 5, right? You're out here. In this case, depending\non the value of n, you may have either two\nchildren, or just one child. And you have one child. But regardless of\nthat, that's going to be a max-heap,\nbecause it's a leaf. And so you'll have\ntwo leaves, and you need to put them together. And that's a fairly\nstraightforward process of attaching the\nleaves together. You might have to do a swap,\nbased on what the element is. One operation and you\nget a little small tree, that's a max-heap. And then you do a\nbunch of other things that all work on leaves,\nbecause n over 2 minus 1 is probably also\ngoing to have leaves as it's children, given\nthe large value of n. There will be a\nbunch of things where you work on these level\none nodes, if you will, that all have\nleaves as children. And then you work on\nthe level two nodes, and so on and so forth. And as I said before,\nyou're working your way up, and you're only\nworking with max-heaps as your left child\nand your right child. That make sense? If you do that, and this\nis a fairly straightforward question, if you do\na straightforward analysis of this, what is the\ncomplexity of build-max-heap? Yep. AUDIENCE: [INAUDIBLE]. PROFESSOR: Right. So that's order. Order n log n. Now, this is through\na simple analysis. Now I'm going to\ngive you a chance to tell me if you can\ndo better than that. Or not. In terms of analysis. It's a subtle question. It's a subtle question,\nthat I'm asking. I'm saying, this is\nthe algorithm, alright? I don't want you to\nchange the algorithm, but I want you to\nchange your analysis. The analysis that\nyou just did was, you said, I got\n[INAUDIBLE] n steps here, because it's n by 2 steps. Looks like each of the\nsteps is taking log n time. So that's n log n. And I was careful. I put big O here. OK? Because that's an upper bond. So that's a valid answer. Can you do better? Can you do a better\nanalysis-- and I'll let you go first-- can you do\na better analysis that somehow gives me better complexity? AUDIENCE: I think you\nbring it to [INAUDIBLE]. PROFESSOR: OK. How? AUDIENCE: So each node get a\nmaximum of two [INAUDIBLE]. So, for some n, there will be a\nconstant number of comparisons to max-heapify that [INAUDIBLE]. PROFESSOR: Yeah. It's hard to explain. You're on the right track. Absolutely on the right track. So it turns out that,\nand I'll do this, it's going to take\na few minutes here, because I write some things out. You have to sum up a bunch of\narithmetic series, and so on. So it's a bit unfair to have\nto speak out the answer, but the correct\nanswer, in fact, is that this is order n complexity. This algorithm\nthat I put up here, if you do a careful\nanalysis of it, you can get order n out of it. And we'll do this\ncareful analysis. And I'll tell you\nwhy it's order n, in terms of a hand\nwavy argument. A hand wavy argument is\nthat you're doing basically, obviously no work\nfor the leaves. But you're not\neven counting that, because you're\nstarting with n over 2. But when you look at\nthe n over 2 node, it's essentially one\noperation, or two operations, in whichever way you\ncount, to build max-heap. And so for that\nfirst level of nodes, it's exactly one operation. The first level that\nare above the leaves. For the next level, you may\nbe doing two operations. And so there is an\nincrease in operations as you get higher and higher up. But there are fewer\nand fewer nodes as you at higher and higher up, right? Because there's only one node\nthat is the highest level node. The root node. That node has logarithmic\nnumber of operations, but it's only one node. The ones down on the bottom\nhave a constant number of operations. So I'll put all of this\ndown, and hopefully you'll be convinced by the time\nwe've done some math here, or some arithmetic here, but\nyou can quantify what I just said fairly easily,\nas long as you're careful about the counting\nthat we have to do. So this is really,\ntruly counting. Analysis has a lot\nto do with counting. And we're just being more\ncareful with the counting, as opposed to this\nstraightforward argument that wasn't particularly\ncareful with the counting. So let's take a look at\nexactly this algorithm. And I want to make\nan observation. Which is what I just did,\nbut I'd like to write it out. Where we say, max-heapify\ntakes constant time for nodes that are one\nlevel above leaves. And, in general,\norder L time for nodes that are L levels\nabove the leaves. That's observation number one. Observation number\ntwo is that we have n over 4 nodes\nthat, give or take one, depending on the value of n. I don't want to get hung\nup on floors and ceilings. And in any case,\nwe're eventually going to get an\nasymptotic result, so we don't have to\nworry about that. But we have n over four nodes\nwith level one, n over 8 with level two. And 1 node with log\nn, sort of the log n level, which is the root. So this is decrease in\nterms of nodes as the work that you're doing increases. And that's the careful\naccounting that we have to do. And so all I have to do now\nto prove to you that this is actually an\norder and algorithm, is to write a little\nsummation that sums up all of the work across\nthese different levels. And so the total amount\nof work in the 4 loop can be summed as n divided\nby 4, times 1, times c. So this sum, I have\none level here, and I'm going to do some\nconstant amount of work for that one level. So I'm just going\nto put c out there, because eventually I can\ntake away the c, right? That's the beauty\nof asymptotics. So we don't need to\nargue about how much work is done at that one\nlevel, how many swaps, et cetera, et cetera. But the fact is that\nthese n over four nodes are one level above the leaves. That's what's key. And then I have n over 8 times\n2c, plus n over 16 times 3c, plus 1 times log of n c. I've essentially written\nin an arithmetic expression exactly what I have\nobserved on the board above. Stop me if you have questions. Now I'm going to set--\njust to try and make this a little easier to\nlook at, and easy to reason about-- I'm going to set\nn over 4 to 2 raised to k, and I'm going to simplify. I'm just pulling\nout certain things, and this thing is going\nto translate to c times 2 raised to k, times 1,\ndivided by 2 raised to 0, 2 divided by 2 raised to 1,\n3 divided by 2 raised to 2, et cetera, k plus 1\ndivided by 2 raised to k. Now, if that was\nconfusing, raise your hand, but it's essentially identical\ngiven the substitution and sort of just applying the\ndistributive law. And the reason I did\nthis, is because I wanted you to see the arithmetic\nexpression that's in here. Now we do know that 2 raised\nto k is n over four, of course. But if you look at this\nexpression that's inside here, what is this expression? Anyone? Can you bound this expression? Someone? For the cushion. Remember your arithmetic\nseries from wherever it was. AUDIENCE: [INAUDIBLE]. PROFESSOR: Yeah. You know better than I. I guess\nyou took those courses more recently, but what\nhappens with that? Those of you who\nhave calculators, I mean, you could plug\nthat in, and answer that. No one? Go ahead. AUDIENCE: [INAUDIBLE]. You know that it's\ngoing to merge to two. PROFESSOR: That's exactly\nwhat I was looking for. Essentially, well, it's not\nquite two, because you have a 1 here, and you have a 1 here,\nbut you're exactly right. I mean, two is good. It's asymptotic,\nI mean, come on. I'm not going to complain\nabout two versus three, right? So the point is it's\nbounded by a constant. It's bounded by a constant. This is a convergent series\nand it's bounded by a constant. And we can argue about\nwhat the constant is. It's less than three. And it doesn't matter\nof k goes to infinity. And you want k to\ngo to infinity, but it doesn't matter if\nk is small or k is large, this is bounded by a constant. And that's the key observation. What do we have left? What do we have left? We have a constant there. We have a c, which\nis a constant, and we have a 2 raised\nto k, which is really n. So there you go. There you have your\ntheta n complexity. Now I can say theta n,\nbecause I know it's theta n. But big O of n, theta\nn, that's what it is. So that's what I'd say\nis subtle analysis. Clearly a little more\ncomplicated than anything we've done so far, and let me\nsee if there are questions. How many people got this? I did too. Someone who didn't get\nit, ask a question. What didn't you get? What step would you\nlike me to repeat here? Any particular step? AUDIENCE: [INAUDIBLE]. PROFESSOR: This thing here? Right here? OK, so you're not convinced\nthat this expression got translated to\nthis expression. So let me try and convince\nyou of that, alright? So let's take a look\nat each of the terms. n by 4 is 2 raised to k. I'm just looking at\nthis term and this term. n by 4 is 2 raised to k. c is c. And I just wrote 1 as 1 divided\nby 2 raised to 0, which is 1. And the reason I\nwant you to do this, is because I want to show you an\nexpression where in some sense, this is the term that is the\nsummation for your expression. If we just replace this,\nyou can write this out as i equals 0 through k, I plus\n1 divided by 2 raised to i. That is the symbolic\nform of this expression, which came from here. And then the argument\nwas made that this is a convergent series and\nis bounded by a constant. That make sense? Good. So that's pretty neat, right? I mean, you have the same\nalgorithm and, whala, it suddenly got more efficient. Doesn't always happen,\nbut that tells you that you have to have\nsome care in doing your analysis, because what\nreally happened here, was you did a rudimentary analysis. You said, this was order\nlog n, big O log n, and you said this was theta\nn, and you ended up with this. But in reality, it's\nactually a faster algorithm. So that's the good news. Build-max-heap can be\ndone in order n time. Now in the time that I\nhave left, it turns out, we are essentially all\nthe way to heaps sort. Because all we\nhave to do is use, once we have\nbuild-max-heap, I'll just write out the\ncode for heap sort, and you can take a look\nat examples in the notes. The pseudocode, I should\nsay, for heap sort. And it looks like this. The first step that you\ndo is you build max-heap from the unordered array. Then you find the\nmaximum element AA[1]. All of this I've\nsaid multiple times. Now the key step is, you\ncould do extract max, but one nice way\nof handling this, is to swap the elements\nAA[n] with AA[1]. Let me write this\nout and explain exactly what that means. Now the maximum element is\nat the end of the array. When you do the swap. That's the one step\nthat I will have to spend another minute on. Now we discard node\nn from the heap, simply by decrementing\nheap size. So the heap becomes\nn minus 1 in size from n in the first iteration. Now the new root after the\nswap may violate max-heap, we'll call it the\nmax-heap property, but the children are max-heaps. So that's the one node that\ncan possibly violate it. So what that means, is we can\nrun max-heapify to fix this. And that's it . Once you do that, you\ngo back to that step. So what's happened here exactly? Well this part we spent\na bunch of time on. element is the maximum\nelement, so you grab that. And you know that's\na maximum element. One way of doing it is to\nuse extract max, but rather than doing extract max, which\nI haven't explained to you, you could imagine\nthat you go off and you swap the top element\nwith the bottom element, and then you discard it. So here's a trivial\nexample, where let's say I had 4, 2, and\n1, which is a max-heap. What would happen is you'd\nsay, I'm going to take 4 and I'm going swap it with 1. And so you have, 1, 2, and 4. Now four used to be AA[1], and\nthat's the maximum element, and I'm just going to\ndelete it from the heap, which means I'm going to end up\nwith a heap that looks like-- a heap, not a max-heap--\nthat looks like this. And I write down 4 here. 4 is the first element\nin my sorted array. Now I look at 1 and\n2, and 1 and 2 there's obviously not a max-heap. But I can run max-- I know\nthe child is a max-heap, so I can run\nmax-heapify on this. And what this turns\ninto is 2 and 1. And at this point, I know\nthat the max is the root, because I've run max-heapify\nand I take 2 out, and after this, it\nbecomes trivial. But that's the\ngeneral algorithm. So this whole thing\ntakes order n log n time, because even though\nbuild-max-heap is order n and max\nelement is constant time, swapping the elements\nis constant time. But running max-heapify\nis order log n time, and you have n steps. So you have an order\nn log n algorithm. But the first step\nwas order n, which is what we spent a\nbunch of time on. So I'll show you\nexamples in the notes, and that will get\ncovered again in section. I'll stick around for questions. See you next time. ",
            "url": "www.youtube.com/watch?v=B7hVxCmfPtM",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "WCm3TqScBM8",
            "channelId": "UCUGQA2H6AXFolADHf9mBb4Q",
            "publishedAt": "2015-02-06T04:37:03Z",
            "title": "Introduction to Binary Heaps (MaxHeaps)",
            "description": "Table of Contents: 00:00 - Heap Structure 01:16 - Heap Shape 01:59 - Heap Property 03:32 - Representation 04:41 - Find Maximum 04:59 - Insertion and ...",
            "channelTitle": "Algorithms with Attitude",
            "transcript": "This is an introduction to the basic operations on binary heaps, in well under 10 minutes.  Binary heaps are rooted binary in well under 10 minutes.  Binary heaps are rooted binary tree structures with two special properties.  The first property is the shape of the heap.  It is going to be a perfectly balanced binary tree where every non-leaf has exactly two children, and all of the leaves are at the same level.  It gives us this great shape. Well, it gives us that perfect shape, if we happen to have exactly the right number of nodes to make a perfectly balanced binary tree. Instead we can have an arbitrary (number of) node(s), where the last nodes are going to be filled in, on the bottom, from the left.  This is called a complete tree, and notice, when we have an even number of nodes, 32 in this case, we do have one node which has only child instead of two children. But, once we insert another node, now we are back up to an odd number of total nodes, 33 in this case, every non-leaf has exactly two children.  We can fill in as many nodes as we want, we are always filling in from the left on the lowest level, and we get this nice shape.  That's the entire parent/child structure of the heap. But, it doesn't really give a great impression of the heap's shape. Because, well, every level of the heap has twice as many nodes as the level above it, so if you want a more accurate intuition for what the shape of the heap should be, it's more like... (grunting) By the power of Asgard...   Okay, so that gives us the full structure, and shape, of the heap. The next thing that we are going to talk about is called the heap property.   To discuss the heap property, we are going to actually have to look at some values in the tree.  So a heap is an abstract data type, you can store whatever you like, but for our purposes, we're just going to look at it with some integer keys.  Now the (max) heap property says any node has a value at least as large as the values in that node's children.  So 90, is at least as large as 89 and 70, in this case, 89, the left child, happens to be bigger than 70, the right child. That (max heap) property is going to happen throughout the heap, so if we look at 89, 89 is a node, and is value is at least as large as the values in its children, 36 and 75. In this case, 75 happens to be the right child and it's bigger than the left child, there's no left/right orientation of which is larger in the heap, also notice 75, even though its on a lower level of the heap, has a larger value than 70, that can happen as long as 75 is not a direct descendent of 70. Now, that's the second property, and notice, if we have those two properties together, we get something nice:  every node is actually the root of its own subheap, (which) has the right shape, has the right values, everything is nice. The next thing we are going to need to talk about is the heap representation.   So the shape of a heap is so regular, that we can really represent it nicely.  We know for instance, that every heap with 10 nodes has exactly the shape of this heap, and that the tenth node is the left child of the right child of the left child of the root. So, what we are going to do is we are going to use an array to store all of the heap values.  We are going to store them top to bottom, left to right, and there, we know, in this case the tenth value is going to be the tenth value in the heap. We are going to use the indices of our array, it is called our implicity heap description, the indices of the array to describe the parent-child structure.  If, for instance, we are indexing from 1, then the left child of index i is at 2i, and the right child is 1 past that, or the left child of 3 is at 6, the right child is at 7.  If we are indexing from 0, we are going to be set off one from there. Okay, finding the maximum node is going to be the easiest operation we have because BAAAAAAAAAM, there it is, it's right in the first place, right in the root, first spot of the array, can't go wrong.  Easiest operation there is. The next operation we are going to talk about is insertion.  It's probably not the most important operation, but it is really easy.  We know what the shape of the heap has to be after you insert, so we are just going to insert a value there and if we happen to insert this value, let's say 12, and it's smaller than its parent node, we're done.  Well, what happens if we insert a larger value, like 72. Well, 72 compares to its parent, it's bigger than its parent they swap, compares to its new parent 70, it's bigger than that, so they swap, compares to the root, in this case 90, it's not bigger than 90, we're done.  It just keeps moving up until we're done.  One other thing we can do, let's say we insert a 70.  Well, 70 ties with its parent, no need to continue, done.  That's insertion. How about deletion.  Well, if we want to delete the last leaf, great, we just get rid of it. There's nothing else to do.  But that's a really weird operation, because there is nothing special about the last leaf.  Basically it's an easy thing to do, but there's not much of a reason to do it.  Much more likely, we want to delete the root.  The root is a special value, this is a max-heap, the root is the maximum value, so what we are going to do is we are going to take that root, we are going to swap it with the last leaf, and now, delete the last leaf, which we know is so easy.  Now everything looks great, we have these two subheaps, and that node up there which might not have the right value this is actually an operation called max-heapify or it has other names, depending on what book you are using, but this is probably the most critical operation for a heap. We have two perfect heaps, and a node above them that gives the correct overall heap shape, but that top node might have a value which isn't larger than the value of its children, which is the case here.  So in this case, we compare it to the left child, the left child is bigger, so we are going to compare the left child to the right child, because we want to know which child is larger, the left child is larger, we are going to swap the root with its left child in this case.  Now we are going to compare that node, well, everything looks good, except [the heap property]. So we are going to compare it to its left, the node itself is bigger, so we are going to compare it to its right child, the right child is bigger in this case, so again, we are going to swap them.  Now we compare the node to each of its children, the left child, it's bigger, compare the node to its right child, it's the biggest value, stop. Great, let's do one more example there, this time I won't draw the subheaps as we go. So we are going to swap 12 up to the root, 12 12 compares to the left, the left is bigger, the left compares to the right, the left is still bigger.  We swap down to the left, then we compare to the left, the left is larger, then we compare the left to the right, the right is larger, we swap down to the right.  Now we are going to compare 12 to its one and only child 15, 15 is bigger, so, we are going to do that last swap and we finish because now we're at a leaf position. Finally, let's talk about efficiency.  Finding the max value, very easy, constant time.  To do insertion, assuming that we have enough room at the end of our to just put a value there in constant time, well, for each level of the tree, we might have to do one comparison and one swap, up to the height of the tree, that's logarithmic, logarithmic time.  To do deletion, well we start off with a swap, then, for each level that a node might go down, we're going to have two comparisons maybe, and one swap, again, logarithmic in time.   This is the longest of the \"[Basic] Heaps\" videos, there is going to be four of them maybe, the next one is going to talk about building a heap in worst-case linear time, then we are going to have heapsort, then we are going to have some other operations that you might want to use heaps for priority queues.  There will also be a few more advanced heap videos, please watch them.  Anyway, I am late for my colonoscopy, I have to go now.   ",
            "url": "www.youtube.com/watch?v=WCm3TqScBM8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "j6iP4lDTKyI",
            "channelId": "UCKS34cSMNaXaySe2xgXH-3A",
            "publishedAt": "2018-08-08T17:06:31Z",
            "title": "Heap tree | Min &amp; Max heap | Data Structures | Lec-45 | Bhanu Priya",
            "description": "Heap tree insertion, min heap & Maximum heap with example.",
            "channelTitle": "Education 4u",
            "transcript": "hi students let us continue with the subject data structures so the next topic is the heap trees so in the previous video I explained about the AVL trees and now let's see the heap tree actually what is a heap tree heap tree is nothing but it is a complete it is a complete binary tree the one thing is it is complete a binary so what is a binary tree we know that the binary tree means a children at most a node is having at most two children then you can say it is a binary tree okay so whenever that last level the chair is the tree suppose if you take this 20 30 40 23 26 you can say this is a complete binary tree okay and you can't say 20 30 40 50 so this is not a complete binary tree it is not complete binary tree okay so this is the difference between the complete binary tree and the non complete binary tree so whatever the children you are having still you can say this is also a complete binary tree okay so it should be the levels you have to check the levels whether it following the same levels or not now coming to the he trees so I said whatever the tree you're constructing you have to make sure that that the tree should be in the form of complete binary tree that condition you have to follow that in the heap trees whenever you are inserting the elements you have to check that tree is in complete binary tree or not the heap trees there are two types of heat heap trees two types of heap trees so what are they min-heap max-heap the two types of heat tresor min he and Maxie so first let me write the definition of a heat keep freedom so what is the hip tree I said heap tree should maintain a complete binary tree but I didn't explain what is a heap tree heap tree is a special balanced binary tree it is a special balanced binary tree data structure it is a complete binary tree data structure where root node is compared root node is compared with its children and you had to arrange accordingly arranged accordingly so it is a special balance to tree balance reminder e tree where root node is compared so whatever the root node is there so this should be compared with the children node it should be compared with its children node and you have to arrange accordingly so how are you going to arrange recording that so I said he pries of two types one is the min heap and another is max heap so now I am arranging the elements the root node is compared with its children if it is a heap very minimum heap tree how I am going to that minimum heap tree means the value of parent node that is a root node the value of parent node is less than or equal to either of its children either of its children means then root node should be less than I drove its children so let me take here I said value of parent no that is a root node or a paranoid both are the same the value of parent node is less it should be less or else you take its leaven suppose leaven and when compared to the either of the children's so here the root node should be less means all the children's are greater than the parent know that you call it doesn't in here then whatever the maxy maxy means the value of parent node is greater than greater than or equal to two its children so how can I arrange that max-heap so let's take these are the nodes so here you need to write the parent should be greater 55:11 and you had to remember that the parent should be greater you had to arrange like that parent should be greater and nine eight thirty okay this is further for this two children this is a parent the parent should be greater and for this parent this is the true children the parent should be greater that is a maxi so that's why I'm saying that heap trees a special balances binary tree where root node this is the parent node that is a root node is compared with its children and arranger accordingly so you had to arrange the numbers according to that whether you have taken min-heap means the parent node should be less than the children and if you are constructing the max it means the parent node should be greater and restaurant should be less than the parent that you had to be remember so now let me construct one key tree by inserting the elements I am going to construct and heap tree Hiep tree insertion so first you had to choose whether you have following the maxi pod min-heap and let's let me take the maxi so max it means the parent should be parent is larger than all children you had to arrange like that and heap condition means it has to insert elements to make tree as complete binary tree so this thing you had to be remember that so whatever the element you are inserting at that stage you have to think whether it is maintaining complete binary tree or not so let me take one example the elements on 44:33 7711 5588 66 so these are the new elements now I am constructing the heat-treat now let's see first is 4444 in the binary tree always insert the element starts with the left side so next element is 33 next is 77 so now check the condition my parent should be greater than the children so this side is okay but here the parent is less than the children 77 is greater than 44 so just swap it now 77 33 44 now try to insert next the next is 11 77 33 44 so first I said you insert the element left sign so this becomes complete binary tree now you have to insert the element at left side 11 so 33 is larger than 11 so no need to swap now next is 55 70 7 33 11 so where you need to insert this time you want to make the tree as a complete binary tree so let this the node should be complete this root should be complete so just insert 55 here but here this is not in the form of max-heap so because the root is less than the chair so just swap it just swap it because 55 is greater than 33 swap so now it becomes 77 55 11 33 44 okay so next in such 88 so where you have to insert this is this becomes complete binary so now you have to make this tree as a this subtree has a complete tree 77-55 11 33 44 so where i had inside first i how to insert left side but this here the parent is less than the child so just you need to swap the numbers so just swap because 88 is greater than 44 just swap so after swapping this is 77 55:11 33 and this is 88 and 44 okay but again you can observe here this two are violating the maxi because this is less and here this is the parent this is the larger the parent should be always greater than the J so 88 is greater than 77 so you need to swap again so before inserting another element again you need to swap 8855 so the one condition is you have to check the complete binary tree and another condition is you have to check whether it is following the max-heap rule or not 33 44 okay now this is gray that all and for this route these two when compared to these two this is greater and when compared to Sanderson forty four the seventy seven is greater now the still the which number is remaining so so far we have completed 44:33 7711 5588 66 so these are the numbers we completed inserted now let's insert 66 so where you insert 66 you had to make the tree as a complete binary tree so this time you need to insert right side of this 70 cell 8855 77 11 33 44 66 now check whether it is following the heap max-heap or not so parent is greater than the children okay here the parent is greater than the children okay and this parent is greater than all children's okay so now this is a heap tree and which is complete binary tree so this is how you're going to insert the elements by following the head pro thank you ",
            "url": "www.youtube.com/watch?v=j6iP4lDTKyI",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "dM_JHpfFITs",
            "channelId": "UC8butISFwT-Wl7EV0hUK0BQ",
            "publishedAt": "2017-05-13T18:25:16Z",
            "title": "Heap Data Structure (max and min)- Beau teaches JavaScript",
            "description": "A binary heap is a partially ordered binary tree which satisfies the heap property. What is the heap property? Watch the video to find out! Also see how to ...",
            "channelTitle": "freeCodeCamp.org",
            "transcript": "a binary heap is a partially ordered binary tree which satisfies the heap property it has some similarities to a binary search tree except the order is a little different each node has at most two child nodes the heap property indicates a specific relationship between the parent and child nodes you may have a max heap in which all parent nodes are equal than or greater to than the child nodes so you can see the the biggest numbers on top and the smallest numbers are on bottom or you may have a min heap in which all child nodes are greater than or equal to the parent nodes so the child nodes are the biggest ones and the parent nodes are the smallest ones the Oder between child nodes on the same level does not matter so you have 10 6 and 12 here here we have 5 6 and 1 you can see that it goes from a small number to a big number to a small number the order doesn't matter if they're on the same level binary heaps are also complete binary trees this means that all levels of the tree are fully filled and if the last level is partially filled it is filled from left to right so if you see the example down here so here's level one then we have level two here level three level three is all the way filled level four is only partially filled because there's nothing over on the right side here but you can see it's filled from left to right binary heaps may be implemented as tree structures with nodes that contain left and right references like what I showed in my binary search tree video however heaps are more often implemented as arrays this is possible because of the partial ordering according to the heap property we can just compute the parent-child relationship of the elements now this will make a lot more sense with this diagram here so if you see this array right here this is the array representation of this tree right up here the number 1 is 20 and that's the root you can see that right up here and then 2 and 3 are the child knows 19 and 17 right here and now I want to pull your attention over to these equations up here so that the left child is going to be I times 2 the right child can be I times 2 plus 1 let me show you what that means so if you look at here which is at index one in the array also I should point out that there is no index zero so when you're representing a heap you're just going to leave index zero as null to make the math work out a little better so if we go back to index one well the equation for the left shell is I times 2 so 1 times 2 would be 2 so yeah 19 is the left child and the right child is I times 2 plus 1 so 1 times 2 plus 1 is 3 17 that's the right child now let's say we go to number 13 here that's index 4 well if we go to the equation I times 2 4 times 2 is 8 so if your index 4 and you go to index 8 11 yep that's the left child now we start index 4 and we do the right child equation I times 2 plus 1 that's 9 so if we go to index 9 yep that's the right child here so that's how you can use these equations to find the left and right child from an array representation you can also figure out the parent so the equation for a parent is I divided by 2 if we are on 11 that's index 8 8 divided by 2 is 4 index 4 and this really should be floor I divided by 2 because you divide the index by 2 and then round down to the nearest whole number for instance 5 divided by 2 is 2.5 but if you round out it's 2 and then 2 would be the the index 19 here also you can see in this diagram that the last index is also the size of the heap size 10 this diagram is a max-heap I'm going to show you the code for a min heap but in the same file down here we I also have the code for the max heap down here so you can check the link in the description so you can review this actual code yourself and you can review the max upon your own but like I said we're just going to review the the men heap right now but before I show you the actual code I want to show you a visual representation of how it works when you're inserting and you're removing items from the heap those are the main two commands insert and remove and then there's one more I'll show you at the end but let me show you this representation here so you can see this is the array representation and I'm going to insert some numbers and you'll see them show up as a tree representation so let's see 4 you can see 4 goes at the top that's the the root node now I'm going to put in 6 6 just goes down to the bottom there 8 so as it builds the node one thing to keep in mind is that it's going to build one level of the tree at a time I'm going to put in 10 it's going to be on the very left side now so far I've been putting them in order but now I'm going to put in the number 5 here and when I insert the number 5 you're going to see this it's going to first go to the end of the array here you'll see their array which is going to first appear right down here and then it's going to move up to the correct position so let's see that so then as you see it checks what position to move it up to so I'm going to put in a few other numbers here see 16 3 okay so you see it always puts in at the end of the array or the end of the tree and then it moves it up to the correct position now I'm going to show one more where I put in one where it's going to put it put it down here and it's going to move it all the way up to the top and it's a check one at a time to see if it has to move it up also another thing would just be removing what when you remove you always just remove the smallest it's going to remove what's in index one which is always going to be the smallest and then it's going to pop the last node to the first node and then it's going to sort them so let's see how that works so did you see that so it moved the last node to the first node and then they have to keep checking and keep moving it down until it gets to the right position so let's move remove three okay so now let's go to the code and you can see how that works in the code so before we insert anything you can see that we've created a heap with an array that just has one item and it's the item null at index zero so when we insert something we pass in a number and we're going to push that number on to the end of the heap so if you pass in the number three there's going to be index zero is null index one would be three now if the length of the heap is more than two that means there's more than one item in the heap if it's less than two there's one or zero items in the heap and that makes things really easy but let's say it's it's more than two so we're going to let the index equal keep that length minus one so that means we're finding the last index and the heap while heap at that at the last index is less than heap and then see this equation right here that is the the parent equation so now we're saying if the last item in the array which is the item we just inserted right here if the last item in the array is less than its parent well if it's less than its parent we're going to have to move it up because the smallest numbers have to be at the top in the men heap so if the index is more than or equal to one that means if we haven't reached the root node then we're going to do this now this is es6 destructuring syntax which just means we are going to switch the node we just inserted with the parent node we're going to we're going to switch them so here is the parent node here is a node we just inserted and now we're going to switch them so the node we just inserted is going to be first and then the painter node is going to be next so it's just a way to swap them for more information about the es6 destructuring you can check out my video about that topic so if math math dot floor index divided by two is more than one this just means if the parent node is not the root node because remember this is the equation for the parent node is the index of the root node so if the parent node is more than the root node then we're going to set the index to map that floor in X divided by two that's the parent node which if you remember up here we just put the number we pass in into the parent node so now the index is still going to refer to the number we just passed in because that number has went into the parent node and so now we're going to set the index to that node and since this is a while loop when I keep going through this and we're going to keep switching the the node to its parent node as long as it is smaller than the parent node else break so once it's not smaller than the parent know we just get out of this while loop and that's the insert so let's go down to remove it's a little more code and but it's some similar concepts so we are always going to remove the top node the smallest node so we're going to let this smallest equal heap one so that just means that the first node in the array is the smallest node so that's the easy part the hard part is rearranging the array after you've removed that node so if heap that length is more than two that just means we have more than one node in in the tree we're going to set the first node in the tree which remember was the smallest node but we're going to set this to the last node the last node in the array now gets moved to the first node in the array now we're going to heat that splice keep that length minus one this just shortens the array by one so we just remove the whole the last index of the array completely since we've already moved that to the first index if heap dot length equals three that means there's only two numbers in the tree and that makes things really easy just if one is bigger than the other then we just switch them this is the destructuring syntax again so if the first one is bigger than the second one then we switch it so the second one is bigger than the first one and then we just return the smallest if there are more than two nodes in the array that's where it gets slightly more complicated so we're just going to set the index equal one we're going to set the left equal two times I and the right equals two times I plus one remember that was just that the equations from up above the equations right here we're just putting them into our formula down here now technically you would not need to put this equation here since we know that I equals one you could just put three here you just put four here but this is just so you know we're using the equations from above so we remember one is the root notes or starting with the runo so while the root note is more than or equal to its left child or the root note is more than or equal to its right child we're going to do everything in here that means we're going to have to basically move it down and keep moving it down until we get to the appropriate spot so if the the left node is more than the right node then we're going to switch the root node with the left node this is the destructuring syntax again so we're going to just swap the nodes so for instance we would be swapping if we're on this node and this so we just swap those two nodes and then we're going to set the index to the left node so we're going to set the index to be the node that was at the top node but has now been swapped else that means the right node is less than the left node we're going to switch the node with the right node so we're just going to swap with the right node and then we just set the index to be the right node so the node just moved down a little bit and then we set the index to point to the node that we just pushed down a little bit and then we have to set the new left and right node so we would set the left and right node to be the left and right of the the one we just passed down and then if the the left child or the right child equals undefined that means we're at the very bottom of the tree so we can just break out of this while loop and if it's not undefined we just keep going through until we find the place where the node that we're moving down the tree is not more than equal to the left node and is not more than or equal to the right node else if it's only equals two that means there should be only one element in the array so we just cut off the last element else we return null that means there were zero elements and they Raye to begin with and then widgets been returned the smallest element which is just the element we just set up here the last thing I'm going to talk about is this now a common use case for the heap data structure is for heap and sort this is one of the most efficient sorting algorithms with average and worst-case performance of o of n log n heap sort works by taking an unsorted array adding each item in the array into a min heap and then extracting every item out of the main heap into a new array the min heap structure ensures that the new array will contain the original items in least to greatest order so this is the function that you would use to do that heap sort the hard part is creating the all the code we just already went over and this is just going to use that code so let result equals new array while heap that length is more than one we're going to add if that remove so we're going to remove the element on top of the tree and we're going to push onto the result and we're going to keep doing that until we've moved removed all of the smallest elements and push it on to the result and it's going to put the elements in order well that's all I'm going to talk about for heaps feel free to check out this code and create your own heap and and add some items and remove some items just to see how it works thanks for watching my name is beau Carnes don't forget to subscribe and remember use your code for good ",
            "url": "www.youtube.com/watch?v=dM_JHpfFITs",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "hash map data structures": [
        {
            "videoId": "shs0KM3wKv8",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:14Z",
            "title": "Data Structures: Hash Tables",
            "description": "Learn the basics of Hash Tables, one of the most useful data structures for solving interview questions. This video is a part of HackerRank's Cracking The ...",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. Today's topic is one that you really don't want to\nmiss - hash tables. A hash table is possibly the most useful data structure\nfor interview questions. It comes up all the time both in interviews and in real life.\nIn fact one technique I often tell people is just, for any problem, have hash\ntables at the top of your mind as a possible technique to solve the problem. So let's talk a bit about what a hash\ntable is. At a high level a hash table is a key value look up. So it gives you a way of, given a\nkey, associating a value with it for very very quick lookups. So suppose you had\nsome situation where you needed to associate somebody's name with some set\nof information about them. A hash table would be the perfect solution for this problem\nbecause you can just put this into the hash table and then you can say, okay\ngive me the data associated with Mary and then boom we can get that\ninformation immediately. So in a hash table the key as well as the value\ncan be basically any type of data structure. A string is often used but it\ncould be a circle, a square, a person, pretty much anything, as long as you have\na hash function. So what does that mean? Well let's turn to the implementation to\ntalk about that. So at a high-level we do want to store the\nobjects in an array. So let's picture that. But how do we actually jump from\na string to a particular index in the array? Well that's what a hash function does. So\na hash function takes in a string, converts into some sort of integer, and\nthen remaps that integer into an index into that array. And then that's where we\ncan find the person we're looking for. So it's important to understand that the\nhash code is not actually the index inn this array. We map actually from the key\nto the hashcode and then over to the index. And one of the reasons for this is\nthat the array that actually stores the data from the hash table might be much\nmuch smaller than all the available potential hash codes. And so we don't\nwant to have an array of three billion just because there's three billion\npotential hash codes. We actually remap it into something\nsmaller. Now note here that two different strings could actually have the same\nhash code and that's because there are an infinite number of strings out there\nbut a finite number of hash codes. So it's theoretically possible for Alex and\nSarah to actually have the same hash code. Additionally since we're remapping the\nhashcode into an even smaller index, two things with different hash codes could\nactually wind up mapped to the same index. So what do we do when this happens, which is called the\ncollision? There are different ways of resolving collisions and I really do\nencourage you to look this up on your own time, but I'll just talk about one of\nthem which is called chaining. And chaining is possibly the most common one\nand it's very simple. But it basically means is just, hey when there is\ncollisions just store them in a linked list. So rather than this being an\narray of people it's actually going to be an array of a linked list of people.\nAnd so that means though that when you get a call to say hey get the value of\nAlex, you actually need to look through all the values in that linked list,\nand pull out the value for Alex. Now as you'll note here this linked list contains\nnot just the actual person objects but the actual original keys as well. And the\nreason for that is that if you only store the person object you'd see all\nthese people who mapped to this index but you wouldn't know which one they are. And\nso you actually need to store the keys with them. So when you get a call to say get\nme the value for Alex, then you actually call this hash function, you get a hash\ncode back, you map over to this index and then you walk through and look for the thing\nwith the key of Alex. So that's the basics of how a hash table operates. So\nlet's walk through this from start to end. We're going to have this hash table\nclass that underneath it has a array that actually holds the data. And the array\nisn't going to be an array of the actual values it's going to be an array of the\nlinked list of the values. Then when someone says put the value of Alex, put the\nvalue Alex mapping to this person, we call this hash code function that gets\nus back the hashcode. Then we map from this hash code over to an index and that gets us over\nto this index in the array and then we put it into this linked list. If there's\nnothing else, great, then we're just going to\nhave a one element linked list. But there could be multiple values in there, in\nwhich case we walk through it. Now what if there is already a value of\nAlex in there? Well then we just fix that value\nimmediately. So let's talk now about the runtime of a hash table. Well it really depends on what we're\ntalking about and what assumptions we we make. In many cases we assume that we\nhave a good hash table and a good hash function that really distributes our\nvalues well and so for the purpose of an interview, we often\njust summarize this and say okay, getting and setting in a hash table is\nconstant time. In reality if something weird happens we have a bad hash\nfunction blah blah blah, we could also say it is linear time in the very worst\ncase. But for the purpose of most problems we generally talk about\nconstant time because in the real world we're going to make pretty sure\nhopefully that we have a good hash table. So this is a bit of a high level view of\nwhat a hash table is and how it works. There's a whole lot of complexity you\ncan dive into here about different ways of handling collisions and exactly what\nhappens when a hash table, you start to put a ton of elements in the hash table,\nhow does it grow with new elements? Can it be resized? All that sort of stuff. I really do encourage you to go look at this stuff on your own\ntime. It's a fantastic thing to really\nunderstand a lot of the complexity here. But for the purpose of a lot of\ninterview questions we just sort of simplify all this down and summarize\nthings as, let's assume we have a good hash table and so we get this beautiful\nconstant-time insert find and delete. So now that you understand the basics, go ahead and do try to learn these more\ncomplex details of hash tables, but also go practice some of these basics on your\nown time on your own problems. Good luck. ",
            "url": "www.youtube.com/watch?v=shs0KM3wKv8",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "sfWyugl4JWA",
            "channelId": "UCxX9wt5FWQUAAz4UrysqK9A",
            "publishedAt": "2020-10-29T04:04:53Z",
            "title": "Introduction to Hash Tables and Dictionaries (Data Structures &amp; Algorithms #13)",
            "description": "Here's my introduction to hash tables and dictionaries! The coding interview problem I mentioned at the end: https://youtu.be/GJdiM-muYqc And here's my ...",
            "channelTitle": "CS Dojo",
            "transcript": "hey everyone in this video i'm going to give you an introduction to hash tables and dictionaries first of all let me explain what a dictionary is and then i'm going to explain how it can be implemented using a hash table so here's an example of a dictionary as you might guess this is essentially a table that shows different people's age and you can ask this table or this dictionary how old is paul for example then you get the number 29 right away or you can ask it how old is chloe and you get 88 and that operation can be called search because you're looking for a specific key for example paul to find the corresponding value uh in that case 29 and these pairs are often called key value pairs by the way so a dictionary is basically a collection of these key value pairs or a data structure that can store these key value pairs so that you can retrieve the value of any of those keys quickly and in additionally you can define a few more operations one is insert and that would be adding a new entry to this table by saying bob is eight for example another one is delete and that would be dealing an existing entry for example you might say well i don't want this data about chloe anymore when you implement a dictionary you should be able to implement it ideally so that all of these operations take only one in time on average and a hash table is a good way to do that to build a hash table the first thing you'll need is an array so here i have an array of eight elements just as an example and let's say that we want to use the array or the hash table to represent the dictionary that we saw earlier this one to do that we're going to put each key value pair in one of these slots but to do that we need a way to decide which key value pair is going to go into which slot of this array one way to do that would be to look at the first letter the first character of each key and compare it to the letter a and compute how many characters away it is from the letter a so for example for this key paul you can look at the first letter p convert it to the lowercase p and compare it to the lowercase a and in ascii code you'll be able to see that p is 15 characters away from a but 15 wouldn't be an index of this array because that would be out of range so you would need to use for example the model operator mod 8 mod of the length of the array to get the desired range that would be 0 to 7 inclusive and with that method you would get 7. so at that point you can put this key value pair paul 29 over here at index 7. and just like that we can decide which index of the array we want to use for each key value pair so jane would be over here at index one chloe would be over here and alex would be over here and actually what i showed you here is already a hash table so basically to construct a hash table you need an array and the dictionary you want to represent and a way to decide which index of the array you want to use for each key value pair another way to describe the same thing would be to say we need a function that turns each of these keys whether they're strings or anything else into an index of this array that we constructed and we could call that function for example h1 and with the method that i just showed you h1 of paw would be 7. and this function is usually called a hash function and that's why this whole thing is called a hash table but this particular hash function that i just showed you might not be ideal for a few reasons one of them is this if you consider english names there might be a lot of names that start with j and if you put for example josh in this dictionary or this hash table it would try to go into the same bucket as jane and the same thing with jennifer and that would be called a collision when multiple keys would try to go into the same spot of this array and there is a way to deal with collisions and we're going to talk about those but for now you should know that we want to avoid collisions as much as possible to keep your hash table efficient and so one way to deal with a problem like that would be to consider most of the letters or many of the letters in the given key if not all of the letters and one such function is called djb2 and i'm going to put a link to some information about that in the description just in case you're curious about it anyway when you're choosing a hash function for your hash table there are a few things that you should consider one is that it should be fast to compute and the other one is that is to try to avoid collisions as much as possible and that's pretty much it when it comes to the criteria in some textbooks they might say your hash functions should be uniformly distributed or random looking or something like that but it's really not necessary for practical purposes and it's not necessarily better than non-uniformly distributed functions so if you're choosing a hash function for your hash table you should really only consider these two criteria and when you're choosing a hash function for security purposes you might have other concerns but here we're only talking about a hash function for a hash table okay let's now talk about how to do with collisions we're going to talk about two families of methods for dealing with collisions in this video and the first one is called chaining with this method instead of storing the key value pairs directly in the array we're going to store them in a linked list and from each element of the array we're going to have a pointer to that linked list and that linked list is going to contain all the key value pairs that were assigned to that particular slot in the array so for example if you have another key value pair that was assigned to this same slot then what we'll need to do is we'll need to put the new key value pair at the beginning or at the top of this linked list just like that and if you have another key value pair that was assigned to an empty slot then we'll need to create a new linked list containing this single element and then have a pointer that points to the new linked list from that slot and with chaining insertion only takes oh one in time or constant amount of time and what about search well to explain that i'll need to first define a few variables and here is the number of elements that we have put in so far in this hash table and m is the length of the array so this alpha which is n over m is going to show how full this hash table is so right now because n is 4 and m is 8 alpha is exactly a half and with this you can show that search only takes o 1 plus alpha in time what this means is that if you keep alpha below a certain number below let's say 1 search would only take a constant amount of time and this o 1 plus alpha is the average time and here you might say what if i don't want to use this extra data structure outside of this array then the approach you might want to use is called open addressing and there are a few different flavors for it i'm going to explain the simplest one first which is linear probing with linear probing or with open addressing in general we store all the key value pairs within the array itself just like you can see here let's say here that we have another key value pair that collides with this one then with linear probing all we need to do is we'll need to check the element that's directly to the right of the collision and if it's empty we can just put it there and if another element collides with this one again we'll need to check this element and then this element next until we find an empty element and then we can put it in there so just like that if this new q value pair collides with this one we'll need to keep checking the elements to the right until we find an empty one so i would say linear probing is an okay approach but it could be inefficient when you have a lot of elements and that's because these elements are likely to start forming clusters when you have a lot of them so for example you have a cluster of five elements here and when you have a cluster of five elements or maybe a lot more elements it would take you know extra time to go through all of them and to find an empty spot and one way to solve that issue is called double hashing so let me explain how double hashing works let's say that this key value pair happens to collide with this one then what we're going to do is similar to linear probing in a way that we're going to jump ahead and check other elements to see if they're empty but instead of jumping ahead by one element we're going to pick a number here let's say 3 to determine how many elements we want to check ahead so if we pick three here we're going to check one two three this element the third element and we're gonna check every third element ahead of that so since this is empty we're going to put it here but if another pair collides with this one and if we happen to pick three again we're gonna check the third element and then we're going to jump ahead by three elements again so that would be one two it would be this almond but since it doesn't exist we're gonna jump back here and the nice thing about double hashing is that every time we have a collision uh depending on the key or depending on the starting point we're going to produce a slightly different sequence every time the sequence of the elements that we're going to check so let's say that this new pair collides with this one we might pick uh one for the number of elements that we're going to drop ahead if we pick one we're going to just go to this element and find that this is empty so we don't necessarily jump from here to here and have another equation and that's why we're less likely to have clusters in double hashing and that's why it can be more efficient than linear probing to summarize this we first pick our initial index for the given key with a hash function h1 with the model operator the length of the array in this particular case 8 and then the next index that we're going to check is going to be the original index plus c the number that we're going to pick for the particular key mod 8. and the next one after that is going to be i plus 2c mod 8 and so on and here i think the natural question would be how do we pick this number c well one condition that we need to satisfy is that gcd of c and m or the greatest common divisor or the greatest common factor of c and m should be 1 and m is the length of the array here and that's because by satisfying this condition we can make sure that this sequence of indices will eventually cover the entire array and one convenient way to make sure that's true is to always set m the length of the array to be a prime number and c to be a positive integer and that way gcd of c and m will automatically be 1. okay so how do we pick c uh here's one way of picking it assuming that m is a prime number we're going to use a second hash function which we're going to call h2 and then we're going to put a key into that function and then do some operations here so let me explain what we're doing here here we're applying the mod operation with m minus 1 to the result of the hash function and that way the range of the results that we can get from this whole expression is going to be 0 to n minus 2 inclusive and by adding 1 to that result we're going to get the range 1 to n minus 1 inclusive and that's the range that we want and here the natural question after that is how do we pick h2 for that i ran an experiment and i tried a few different approaches so here's uh the first approach i tried we have h1 the original hash function and to make h2 i simply appended a letter which i picked it could be anything but i picked d here to the key so if the key is jane i just put jane d to h1 and then i used that as h2 and it actually seemed to perform pretty well and by the way the h1 i used for this one is the default hash function of python which seems to be based on dj b2 which i mentioned earlier and the second approach i tried is simply this so i used exactly the same hash function as the original one as the second hash function and so much surprisingly it performed as well as the first approach but i would say if you want to try implementing double hashing yourself you should try a few different hash functions because the performance probably depends on your particular environment and the particular kind of input data that you get anyway with double hashing you can show that with a few assumptions that to complete either the search operation or the insertion operation you need to check almost this number of elements on average that's 1 over 1 minus alpha where alpha is n over m so again n is the number of elements that we've put in so far in the hash table and m is the length of the array so just like i said before alpha shows how full your hash table is so let's say that alpha is two thirds then this expression one over one minus alpha becomes three so that means that to complete search or insertion you need to check at most three elements on average so basically if you keep alpha below a certain number let's say two thirds again you'll be able to complete search or insertion in constant time so what i would suggest if you're implementing double hashing by yourself well at least one way to do that would be to pick m to be a prime number let's say 7 or 701 and then as soon as alpha becomes uh greater than two-thirds resize the array pick a larger prime number than the original m and then transfer all the elements to the new array and that way resizing the array takes extra time but at least for search and insertion it's only going to take a constant amount of time as long as alpha stays low enough okay so that's my introduction to hash tables and dictionaries but there are a few things i wanted to mention before i go one is that there is a coding interview problem that i covered a while ago on this channel and for that problem you can actually use one of these concepts to solve it so i'll put a link to that video in the description below just in case you want to watch it the other one is that i tried implementing a hash table in python so i'm going to put a link to that code in the description below as well and from that code you'll be able to see how i ran the experiment i mentioned earlier too anyway thank you as always for watching my videos and i'll see you guys in the next one ",
            "url": "www.youtube.com/watch?v=sfWyugl4JWA",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "z5tZ0Zb5rJQ",
            "channelId": "UC59K-uG2A5ogwIrHw4bmlEg",
            "publishedAt": "2016-04-18T17:29:52Z",
            "title": "14.11 HashMap and HashTable in Java",
            "description": "HashMap, LinkedHashMap, TreeHashMap, HashTable implements Map Interface Recommend Books : 1. Head First Java : http://amzn.to/2owFrf0 2. Java ...",
            "channelTitle": "Telusko",
            "transcript": "welcome back aliens this is I've been ready from fiscal earthlings and in this video we'll talk about hash map hash table okay we also talked about linked hash map and then we'll talk about map interface so I start with it now let's imagine you would you want to create a phonebook so application which look like phonebook so in this we have we have two things right we have list of names and we have list of numbers right so we want to map a number with a name so let's imagine you know about a des least so in one a dish we can have list of string right so we can have names there and we can have name of the list of numbers time beam let's cap the phone number as string okay so what we can do we can create two at least one for numbers and second for name so I just imagine we have two energies to you one with numbers or one with names and second with numbers and now you can map so we have some names here so we have Naveen we have pooja we have Ali we have Mahesh we have Archana so we have all these names right and with those names we have numbers so with the name so for a particular name we have a pretty good number right but what if if I they move one of the name in between so as soon as I move a name so the other names will go up right so we have a mismatch for the other the remaining elements in there and that's why at least creating two arrays for a phone book is not that suitable why we require a name is because to recognize the number right so in your phone in your phone book of your mobile phone why we have a name so that we can search the number right so when you have this type of relationship where you need our element for the which will act as a key for the value right so your number is the value and your name is the key to search a number you require a key right so instead of using at least we can use something else map interface so using map you can you can have or you can have two values in fact two things one will be key and secondly value so this is how it looks we have map in which you have to specify two things the key and the value right and again we have to use genrich's to specify what type of key and what type of value we have so in our example both are string but it may be integer it may be float anything you want and in this if you want to add value so you have to use a medical as put so using put you can assign two values one is the key and second will be the value right so which is your value key and value pair now each entry in the map so let's say if you are entering Naveen and the phone number so that one thing is was one entry okay because in map interface we also have an interface for entry interface which will hold one entry again we'll talk about that later so we have a map and the entry interface but the problem is map is the interface right how can you create how can you create the object of interface of course that not possible right so we have to search for a class which implements map and we have four classes which implement map in fact we have I guess yeah we are we have four classes so the first class we have as hash map then we have hash table then we have a tree map or tree hash map so we have tree hash map and then we have linked hash map okay so let's start the first one we have hash map here so using hash map you can create the object of map and you can add the elements right that's simple now question arises how to how to add values we can simply say m dot put you can pass two values one through two things one will be the key and second is value so nubbin is the key when mobile number is the value so let's say if I say puja is the name mobile number so that's that's the value all right so the key and the value pair so let's say you have added all the values so you have five values there now question arise how to print this values in case of analyst we can simply specify the index number and you will get the name right put the problem is with with map you need something extra to fetch the value we need a key right so let's imagine I want to fetch the number of puja for that I have to pass the key as pooja right so in map we have a method called as get so we have to say map object let's imagine this is phone book so we have phone book get in bracket you have to pass the name which is a key you may awesome right so if you know the key you will get a number so that's very simple right so if you know the if you know the key you will get the number but it's a problem here the problem is what if you want to print everything start to end how to do that to print all the values we should know all the keys right if you know the if you know all the keys you will know all the all the values because in the get method you have to pass the key it will give you the value but question arise how would we know the key I want all the keys right so in this scenario what if asked map give me all the keys is it possible yes a map has a method or a ski set okay which will give you all the keys now you have to take the set it rate this side so you can use you can see the code here so you can just iterate this set okay with the help of Finance for loop and when you iterate you will get one key at a time pass that key for the method which is get and you will get the value all right so that's that's awesome that's how we can you can fetch all the values from the map so this is one way the second way is using map entry now this is very this is very interesting if you are going for a Java interview this is the frequently asked question what do you mean by Java or what is what do you mean by map entry so entry is the interface in map ok so map is interface inside that we have interface so this is necessary interface can you imagine interface inside interface so that's entry interface inside map interface okay so in your map you have a method called as entry set ok which will give you this set of entries and what is entry key value pair is one entry ok so you can see we have a map and the first the one box is one entry so you will get the set of entries and of course you'll be getting the hole hash table right now what you can do you can iterate this set and when you fetch the value one one value you will not get single string you will get an entry and in that entry will be having two things value and the key and the value right and you can print key and value with the help of get negate key and get value right and that's why this entry map entry interface is so important ok so that's how you can fetch all the elements so this is hashmap but what about hash table then what's the difference between hash map and hash tables so hash table is same as hash map okay working is almost same but there is some difference hash table is there from 1.0 so it was there from Java I know when JA was introduced hash table was there what about hash map it was introduced in 1.2 wasn't so hash map is new newer then hash table a second difference hash map is not thread-safe hash table is ok that means every method in hash table is thread-safe because that that means they are synchronized in it hash map is not synchronized okay of course when it is not synchronize which is more faster of course hash map is faster than hash table because hash table is synchronized and that byte is slow so if you want speed if you if you know that you're working with on this one thread in your application always go for hash map but if you are working with multiple threads at that time you should work with hash table okay oh these are some more difference one difference is in hash map you can have one key which is null but in hash table you cannot have any knowledge keys okay you should have all the elements here that's it as a difference between hash map and hash table okay but then we have one more which is linked hash map the defense this difference is if we talk about hash map and hash table in both insertion order is not fixed okay it may change but if you want your order should be fixed the insertion order should be fixed always use linked hash map okay and let's say if you want the hash map which is in solid format you write it guess we we have we have three hash map in which you have all the elements which is already sorted with the help of pre-sorting okay so this is all about hash map hash table linked hash map and tree map again we'll see the practical of this in the next video so that's it thanks for watching and do such therefore for the videos ",
            "url": "www.youtube.com/watch?v=z5tZ0Zb5rJQ",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "MfhjkfocRR0",
            "channelId": "UCcDGsN3JxMavDkM9INRLGFA",
            "publishedAt": "2013-05-21T04:16:37Z",
            "title": "What is a HashTable Data Structure - Introduction to Hash Tables , Part 0",
            "description": "This tutorial is an introduction to hash tables. A hash table is a data structure that is used to implement an associative array. This video explains some of the ...",
            "channelTitle": "Paul Programming",
            "transcript": "hey everybody this is Paul so in this tutorial I'm going to do an introduction to hash tables so a hash table is a data structure that is used to store information so the information in the hash table basically has two main components so it's going to have some sort of key and then it's going to have some sort of value or some sort of record and so basically a key could be something like for instance my name and the value could be something like my phone number so we could basically create a hash table to store a bunch of people's phone numbers and so what happens is the hash table it's a way that we can implement an associative array and so we're basically going to map this key to this value here and at the heart of a hash table we're basically just going to have this array structure and so subscribe a bunch of different array elements here and we've got index 0 1 2 3 & 4 and if we were to really create a real hash table if we are going to actually implement this in code we're going to make our hash table be much bigger than this but this is just kind of for illustrative purposes so this information can fit on the whiteboard here but in reality we would we would normally make hash tables much larger than this so anyway so the way this works is we're basically going to write a hash function and so what the hash function is going to do is it's going to look at a certain key and then it's going to evaluate that key and it's going to spit out some sort of index number and it's going to tell us what location in the array to store this information so for example we'll just go ahead and just write this out so our hash function is going to take a key value and as a result it's going to give us an index number so for example we could do hash and then as the argument we could enter my name my name could be the key and then we could just say that our hash function evaluated this key and it said ok that in index three and the way the hash function is written is that every time you enter that key if it's the same key it's going to spit out the same index number so every time I enter Paul into my hash function I should get the index number of three so we could just represent Paul as a circle so we'll just go ahead and put that here so this circle is going to represent my name and my phone number and where it is located in the hash table so let's say that we wanted to add some other person so what we would do is we would just put whatever that person's name is as the key so it's going to evaluate person and we'll just say that it spits out an index value of one so person can be square I guess so this square will represent some other person's name in the phone number and according to our hash function we're supposed to place that in index one so we could keep on going and maybe we'd find another person's hash value goes in index two and maybe another one goes there can be a diamond I guess that will represent another person's name and phone number and we find that they go in index four but what happens if we're wanting to add another person and just put somebody I don't know so we're adding somebody else's number and what if they what if we find out that their hash value ends up being three well we go and we look and we go uh-oh there's already a name and phone number stored in index three so there's a lot of different ways to to go about this to avoid a collision and the way I'm going to implement this when I code this in my videos in the next few tutorials is I'm basically just going to create a link and create a basically just a linked list off of each one of these indexes here and so I don't know what shape we could use here we could just do squiggly line or something like that so what I would do here is I would just put squiggly lines name and phone number inside of this element here so basically this is called chaining so if we needed to add more let's say we got another one in index 3 we will just link that off of squiggly lines name and phone number and we could do sideways squiggly line that can represent that person's name and pet yeah that person's name and phone number and anyway I think you guys get the point so all these shapes just represent somebody else's name and phone number and if we end up with a collision then we basically are just going to link it off of that same element so each one of these people's names and phone numbers they basically got index 3 and so the cool thing about this is if we get a whole bunch of names and phone numbers in here and then all of a sudden one day we want to go and look and we want to say okay where is you know where is somebody's so you have the name of a person and you want to know what their phone number is you basically just enter their key inside the hash function and so if there was like a gajillion different names and phone numbers you could just do hash of you know whoever that person was so that person and the hash function is going to basically spit out an index and it's going to tell you exactly where that person is located and so it might be that that person let's say we just got a whole bunch down here you know might be that that person is gets a hash value of two so then what we do or sorry I meant to say one so whatever person we're looking for might have a hash value of one and then we know if this was like a million index units long we know that we don't have to look in 0 2 3 4 or all the way up to a million we don't even have to look at those our hash function tells us exactly which one to start at so then we would basically just start at this one and if we had some chaining we could kind of go down the list and figure out exactly we could search through this list and figure out exactly where that person information was located and then grab that information out of the list that's attached to index 1 and if you do this right you shouldn't have very many very many links basically off of one single index but if you have a collision then we're going to implement this ability to basically add a linked list to each array index to take care of any collisions and this is called chaining and like I said there's other ways to take care of collisions but this is the way I'm going to implement taking care of collisions in the code that I write so anyway I hope that that was helpful to you guys and now you understand the basics of hash tables and how they work let me know what you guys think about this in the comments I appreciate everybody watching you guys have an excellent day stay tuned for more coding examples of this I'm going to go ahead and code a hash table in C++ on the computer screen so stay tuned for that anyway let me know what you guys think about this in the comments have an excellent day and if you haven't already don't forget to subscribe ",
            "url": "www.youtube.com/watch?v=MfhjkfocRR0",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "70qy6_gw1Hc",
            "channelId": "UC_fFL5jgoCOrwAVoM_fBYwA",
            "publishedAt": "2019-05-23T19:00:02Z",
            "title": "HashMap Java Tutorial",
            "description": "This HashMap java code will teach you HashMaps in java easily \u2705Hopefully, this HashMap Java tutorial will help you start programming using hashmaps.",
            "channelTitle": "Alex Lee",
            "transcript": "hashmaps were one of those topics that were pretty confusing to me even just the name itself hashmap like how am I supposed to know what that does well it turns out that hash maps are nothing more than a list of keys and values and different keys have different values this is my hash map Java tutorial hey what is up it's Alex back again helping you learn Java on this channel I make a new Java tutorial that's fresh and new and exciting that you can check out every single week so if you're new here then consider subscribing so let's kick it off by going into our program editor I'll just go to file new Java project hash map cuts tutorial and then open it up right click on source new class call it hash map awesome this awesomeness public static void they finished Java is really great at storing data like we can store integer variables like this into a equals 10 we can store string variables like this string b equals hello and we could store a really long list of data too so we can have an array of numbers c and then set that equal to some list of numbers 1 2 3 and this solves the problem of storing one value into one variable named a is 10 b is hello c is a list of 1 2 3 but what would we do if we had 1 million of these variables say we had a bunch of integers like we have another integer B that's 3 we have another integer see that's like 88 how could we store a is 10 B is 3 C is 88 into 1 easily accessible place this is where hashmaps come in the word hash map itself was a little confusing to me and I honestly don't know why it's called that but I'm going to show you what it is and how you can use it so to store our a b and c into a hash map we would just type hash map with a capital H and M we'll name it - like happy because it makes us very happy that we're finally getting to learn when hashmaps are and set that equal to new hashmap with parenthesis and a semicolon hover over the name hashmap and click this import hashmat Java util this will auto generate this import statement at the very top and just tells Java to bring in the code for a hatch map so we can use it to put a b and c and their corresponding values into happy we just type the name of the hashmap we're just happy type a dot to bring up everything that this hash map can do and this can do quite a bit of things for us but we're gonna say put and hit enter it auto generated some stuff for us but i'm just gonna delete that where ki was I'm gonna put the string inside of double quotes and I'm going to put the integer amount 10 into the second one after the comma and then I'm gonna put a semicolon now inside of happy there's an an e that's equal to 10 I'm gonna do the other ones and then I'm gonna show you more of how it works so we'll do happy dot put B is value three and happy dot put C is value 88 you'll notice that there are a lot of yellow underlines here these first three are just saying that a B and C aren't being used but that's okay these ones if you hover over it it says hash map is a raw type references to generic type hash map Cavey should be parameterised this just means it wants to know the type of the key and the value what's on the left side of the parenthesis is the key or the name and on the right is what is stored into it so to tell it what type our values are we put some less than and greater than sign and then our first one is a string since it's in double code so we'll say string and a comma and the second one is and integer so we say capital integer it has to be capital integer and not lowercase integer because this is a primitive type it turns purple it's a key word and to say the actual type we have to uppercase it it's kind of confusing but this will get it to work for you finally we could just copy this and put it over on this side so now it knows that every key is a string and every value is an integer let's see that this is working by printing out our hash map go to system dot out dot print line and just type the name of our hash map save it and run it and we will see a is equal to 10 B is equal to 3 and C is 88 which is pretty awesome everything that we did happy put as the key on the left so a and the value on the right 10 so if we want to get the value of C I'm just going to go in here we're happy is I'm going to have a dot and we can get the value of C by typing get and replace key with C save it and run it you'll see that it returns 88 which is what we have here now let's do another example where we do some more advanced things to our hash map let's make it by just typing hash map well name it fun and say equals new hash map with our parentheses and semicolon now let's do like a user and a password which are two strings user is usually a string password usually a string and these yellow underlines are saying it wants to know exactly what type we know that so we'll just type string comma string now I'll do the same over here I'll just make this a little wider so you can see more to add our users and passwords is super easy we just type the new or SMAP a dot and then put will say our first user is um Bobby Jo 1996 and the password name is fluffy ponies like that now we'll add another user func put Hello Kitty fan 21 value and put one more pass phrase like password once you three we print out everything just typing turned out fun just down with an E save it running and we get it just like before except now it's with two strings you can remove elements from a hashmap by typing the name of the hashmap dot remove and then type the name of in this case the user so let's say we want to remove Hello Kitty fan 21 just copy type that into there save it and run it and now you see when we print out everything that's no longer in fun the user Hello Kitty fan 21 and the password are no longer in the hashmap what you can also do is see if a hashmap contains a certain value so you can say fun dot contains value and we'll see if it has the value password 1 2 3 in there let's paste that in there save it and it returns true if it is in there and false if it's not in there so in this case it is in there but if I said password 1 2 4 then it would be false notice how if I do cool guy swag into here and save it and run it it still brings back false because this is saying if fun contains the value and the values are always on the right but cool guy swag is on the left that's actually a key but we can change this to contains key save it and run it in that war returned true this is really useful inside an if statement so you can say if fun dot contains key cool guy swag then we know the cool guy swag users in there and we can do different things you can also get the size and other things like that so we'll do fun dot size and we get three you can even replace so say a user changes a password we could do fun that replace will say Bobby Joe 1996 will place his password with better password like that if we run it and print out fun you'll see that this first statement fun that replace returns the old value fluffy ponies right here but when we print out everything you'll see that Bobby Jo 1996 has his new password notice how the order is different this is a big difference between hash maps and ArrayList hashmaps don't really have an order can't rely on the specific order of a hash map only through the keys and values but an ArrayList you can get the certain index based on its position well you can also do is get all of the values of being fun dot Val use let's delete that last one we get all the values and you can do the same with keys but doing key set computer science classes really like hash maps because it sort of tests your brain knowledge of how these data structures are working they're really confusing to me just just from the name hash map alone honestly but they're really not as bad as you think it's just a long list of things on the left that are set to the thing on the right and you can access all of them by doing hashmat dot what I showed you before so if you enjoyed this hashmap java tutorial let me know by leaving a like and i'll see you all in the next video [Music] ",
            "url": "www.youtube.com/watch?v=70qy6_gw1Hc",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "oZ7LymkbmiA",
            "channelId": "UCbaL9AMj6AWWtksi82FRYAA",
            "publishedAt": "2019-05-09T12:30:02Z",
            "title": "Introduction to MAP Data Structure in Java | HashMap in Java with Example | ABC",
            "description": "In today's episode, let us learn about MAP Data Structure in Java, HashMap in Java with Example About the trainer: Mr. Manjunath Aradhya, a technocrat by ...",
            "channelTitle": "ABC for Technology Training",
            "transcript": "in this episode let's understand the map data structure I know they are in the middle of the string episode series and still I'm deviating from strings and going to explain the map data structure to you because the upcoming episodes make use of the map data structure extensively the programs that are there in the upcoming episodes will expect you to know the basics of the map data structure and that is the reason that in this episode they would explore as to what really map is all about during the school days we have learnt about maps the India map the world while these are geographical maps what we are really supposed to understand in this episode is the map which is available in computer science in fact map is a data structure I am sure you have heard about the other data structures such as the stacks the queues the links lists the trees similar to those data structures math also happens to be one of the data structures anyway what is the use of a map how does a map help in solving problems why is it that the IT industry expects a job aspirant to know maps let me even before I speak about the map data structure let me tell you how my data is going to be stored in the other data structures let me consider my data as now how is this data going to be stored in case of a stack in case of a queue in case of Link's list and in case of a tree is what I should be explaining to you well this is how we represent a stack and the data around here can be stored in a stack like this in fact placing the data inside the stack is what we technically call as pushing and removing it is what we call as anyway the same data Aradia can be stored in a queue like this and the data are Athiya can be stored in a Lynch list like well this is a singly linked list there are various kinds of linked lists such as the doubly linked list the circular doubly linked list and so on about which I would not be able to discuss in detail in this episode and not just that the same data can be stored in the tree data structure like and if you'll ask me what is the advantage of storing the data in different data structures and what problems do these data structures solve well if you have to know everything about data structures then I would recommend you to enroll to our classroom training and you would get to know everything that you have to know about data structures not just about data structures about everything that you really need to know to shape yourself as an IT professional but this episode is meant to explain the concept of math so if you'll ask me how is the data are adhered stored in a map well the data is stored in the form of a key value pair I know you are confused that makes the textbook definition of a map is that map is such a data structure which holds the data in the form of a key value pair not just that the two important properties associated with a map is that the keys present in the map have to be unique there cannot be any duplicates whereas the values present in the map can have duplicates I know you are confused with both the definition as well as the properties and let me clarify it for you I will consider my data Aradia again you know the way the data has been stored in the stacks in the queues the trees and the links list but how does it actually get stored in a map well I should tell you but before that how does a map look well in the form of an animation for you to understand things easily I would represent a map as you can see in a map there would be two components one the key other the value and if you ask me how does this data gets stored in the map well it gets told license and if you'll ask what the meaning really is you can notice that the alphabet a is there in the data three times and that is what is stored in the map like this and similarly the other alphabets are all present once each and that is what the map is depicting and now let me get back and explain to you the properties and the definition of a map which had previously confused I had told you the two properties the first one that the keys present in the map must compulsorily be unique there cannot be any duplicates in the keys you can see under the keys column all the alphabets are unique there is no repetition that was what I told you as the first property and the second property of a map that I had told you was that the values present in the map can have duplicates yes you can notice under the values column I have one one one multiple lines all of which are duplicated which goes to show that you have understood the two properties of a map but what about the definition well I had told you that a map is such a data structure which holds the data in the form of a key value pair well look at the first row the key is a and the value is three key value pair put together is what I call my data even the next data you can see that the key is R and the value is 1 so that key and value put together is what I call the beta so that way if you notice the map contains data in the form of key value pair so that was my data and that data is stored in the map in the of key-value pair now you may ask what is the benefit if the data is told in the key value well even before I speak about what the benefit is first me what I have to tell to you is how to store this data in the map like this this is my data Aradia I assume that my data is present also I would be computing the sites all that I have to now do is to place this data inside the map data structure for which I need to create the map data structure even before I create the map data structure let me tell you that there are various types of maps supported by J we have something called the hash map the tree map the linked hash map and so I would not be able to explain the various types of maps because this episode is not supposed to explain to you the concept of collections in Java maybe moving forward I'll speak more about the collection concept in Java but this episode is all about making you understand the basics of map so that I can proceed ahead with a string problem anyway if I will have to create a map whose key is going to be characters and whose value is going to be integers then this is the line of code and upon execution this is how the map gets well at this point in time I cannot be speaking more about this line of code all that I can say is that this line of code can create a map like this anyway how to fill the data into this if I will have to put anything into the map I can make use of the put engagement if I will want to take out anything from the map well I can make use of the get in which methods using the push and the get inbuilt methods how to place that data inside the map is what I'm supposed to tell you but before that you know that as of now my data is present inside an array and whenever the data is in the array I would need a loop index variable so I would create a loop index variable called I and initialize it to 0 this is how I do it in the code and in the animation this is how I demonstrated not just that if I will have to travel along the entire length of the array I would require a loop and the condition I not equal to size would ensure that I would be traveling along the entire length of and what is it that I have to do in the loop I lit inside the loop each time I'll have to check if my map contains the key Y of 5 you know for the first time my Wi-Fi is a and if I would look at the map that key a is not present so I would get the result as false please understand when the result is false it goes to show that the corresponding key is not present in the map and hence it is my duty as a programmer to not just put the key as well as the line so I would put the key a as well what obviously I would put 1 as the value because it is the first occurrence of a and how do I do it programmatically well this line of code does not you know I can make use of the put in bilge method and place the data inside the map and if you ask me what after that well plus plus I is going to take me to and as you can see this time my way of is our and what is it that I need to do well again because I am in the loop I would check if the map contains the key Wi-Fi that is I'll have to check if the map contains are there is no R so again I would get the result as false hence again I enter the if condition and using the put method I would be putting the key R as well as after which well again it is plus plus I and this time my Wi-Fi happens to be a and when a is encountered what happens this time my Wi-Fi is a and when I check if the map thought contains key Wi-Fi yes my map contains the key a so this time I would not be entering the if rather I would be entering the else and what should I be doing in the else well the first thing that I should be doing is to get the value associated with the game the value associated with a is one I would get it and place it inside the variable called old well and this is the code to do that and after that I will compute my new value as the old value plus one so my new value would be 2 and then it is my duty to put back the Y of I along with the new value this is the code and when the code executes this is what happens in the map so after that well I have to increment I and those the next this way I have to secede and when I proceed the in child data present in the array would get into the map likeness so what you basically understand through this logic is that if in case you are encountering the key for the first time the control enters if and just in case you are encountering it for the next time then the control enters else and this logic is such a logic that even though the alphabet may repeat multiple times in the array but in the map it is not well that is the property of a map that the keys has to be unique they cannot be duplicates but the value certainly can be duplicates anyway I think you have been able to understand as to how this piece of code helps me to place the data inside them but what is the real use of this map well if you want to know that watch my next video [Music] you ",
            "url": "www.youtube.com/watch?v=oZ7LymkbmiA",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "c3RVW3KGIIE",
            "channelId": "UCVPASNJQ98XbpQM8Oy3qZJg",
            "publishedAt": "2015-07-14T22:56:48Z",
            "title": "How HashMap works in Java? With Animation!! whats new in java8 tutorial",
            "description": "How does java hashmap work ? HashMap is one of the most popular java.util data structures. Its one of the associative array implementations, here I have ...",
            "channelTitle": "Ranjith ramachandran",
            "transcript": "hi in this video we will see how hashmap works in Java also we will see what are the enhancements done to hash maps in Java 8 plus I will show you a couple of animations through your input and get operations so that the implementation is more evident for you so now let's quickly see what exactly is a hash map the Java dot util package provides a lot of built-in data structures so that we don't have to implement it from our own you know we don't have to hand create them so the popular data structures are like lists sets and maps so maps are basically associative arrays that lets you store key value associations that means you can store key against value and then later if you want to look up the value you can just use the key and look it up so that makes it one of the popular data structures in terms of enterprise applications where you can use this to represent big caches where you will have a key and some big object as the value later on somewhere in the application you can use the same key and reach the value and retrieve the value whenever you need it also you can imagine a hash map or a map as a dictionary so now what exactly is a hash map hash map is one of the implementations of the map interface and hash map is known as a hash map because it it is based on a technique called hashing so hashing is basically a technique where you will transform a large string into a large string or basically as an object into a short fixed length representation so for example you know let's consider the string a large string you can convert that into a small fixed length integer so that helps us faster indexing and lookups at the same time there are some caches that we should be aware of so let's see them so basically in Java as you know each and every object has a hash code method available so that hashcode method is supposed to return the hash of the object for example if you call the hash code API on a string you will get an integer back and and there is a equals and hashcode contract that exists in Java that basically goes like this if two objects are equal they should have the same hash code as gap so that means it's very important to have robust hash code implementation in your classes and if you have difficulty in implementing your own hash code for example you are implementing a account class for example and you are not able to provide a very good hash code implementation you can always let the IDE generate for you and they do a good job sometimes in generating hash code implementations so okay now coming back to the equals and hashcode contract why is it important it is important because the hash code is used in storing values into the hash map so when we look up you know values corresponding to a given key if the hash code is not consistent you won't be able to look up the corresponding value ever so we will see why exactly is that in the following animation regarding hash maps but before that let's quickly touch upon the implementation details so as you can see here on high level hash map is basically implementation of the map interface at the same time if you look at the low level details hash map has a table an array of nodes and nodes are basically int hash key the key that you sent to the hash map the value that you will add to the table and a pointer to the next node so basically the node itself is a linked list inside the tail so each index in this array that you can imagine as a as a node which actually can be linked list of nodes okay so basically each index in the table is known as a bucket for example and each bucket is a node which in turn can be a linked list of nodes so let's see how this implementation works in terms of the put operation so in this example we are trying to put a person name and the score he in a scored in some game or something and we are trying to store that into a hashmap so as we said the hashmap comprises of a table initially and the table is sized based on you know to raise to M so by default the hashmap comes with a table of size 16 that's 1 6 16 and so the index of the table ranges from 0 to 50 so we need to fit these entries into this table so let's see how it works when the put operation happens so first we are trying to put the key King and value hundred into the hash map so the put myth API is called and the put API basically computes hash of the key which is hash of King which is 2 3 0 6 9 9 6 and then we cannot have an array of this size in Java 2 3 0 6 9 9 6 theoretically you can have that kind of an array but if each and every hash a hash map is going to have such a huge array within it soon you learn out of memory and you will have a lot of other issues so that's why the hash map is sized the hash map table is sized to 2 raised to n and now we have to run a little index computation to find out where exactly we can fit this hash code in our table of range 0 to 15 so the index is computed using a modular operation so basically you divide the hash code using the in a maximum value of the range and you get the reminder and the reminder will be a value that you can fit within the range so to make it faster hash map implementation uses the bitwise operation as shown here so the index computes to 4 and that means the entry will go into this index 4 as a node so you can see a new node is created with the key value and the hash value and the value itself which is 100 which is a score and null meaning is not pointing to any other now let's see how the next entry will be entered into the hash so we call a score start put Clark with score 90 so computation of the key hash of the key happens which is a big number so we try to find out on what index we can fit this hash code into so which is the index 2 so that goes into the index 2 of the table as an entry with the key with the hash code with the value 90 and null indicating that it's not pointing to any more nodes right now so now let's try to insert the entry Blake with score 10 into the hash map so the hash of Blake is computed which is six three to eight point nine four zero and we are trying to find out the index where it can be fitted that happens before so here we have in theory some sort of a collision because we already have an entry at index 4 so what we would do is that this entry will be added as the next node of the already existing node at index 4 so that means the pointer in this node which is basically created for King will point to the new node that is created for Blake and it will have these properties in it now let's go and put Ford with score 110 the hash of the key is computed the index is computed as 10 and it's fitted into 10 now comes the next entry which is Smith with value 10 so hash is computed index is computed as 6 it goes to index 6 now we are trying to put word with score 99 hash is computed index is computed as four so we already have two entries here at index 4 so what will be this entry will be added as a new node after the node play so let's see how that happens they're a now comes a score start put Jones with value 99 so the hash of Jones is computed which is this value and the index is computed at zero and the entry goes at index zero so this is how the hash map will look like at the end of all these put operations so as we saw whenever there is a collision theoretically like if all these hash ports were same or if they were computing the same index those entries will be stored as a linked list of nodes and also we should not we should know that hash map lets you store null as a key sonal will always have a hash of zero so the index of null key will be always index zero so there is no confusion regarding so that's how the hash map put operations work now let's see how they get operations work in Java so scores don't get Clarke so we want to get this core that Clarke had so first we call the get operation get object key so the get operation also does the same set of operations it finds the hash of the key which is this number now it computes the index where that key could have fitted so the index computed as to so now if you look up index 2 on the table we have an entry so with that entry we compare the hash code of the key against the hash code available there on that entry that matches now we will compare the key itself that was used against the key that is available on that entry using the equals method that also matches that means we have found a match so the value at that node is returned to the caller and the caller gets the score which is 19 so now let's see how score start get King will work it works in the same way hash is computed for King and the possible index is computed which is 4 so we will see what is there on 4 so we see one entry now we will compare the hash code of the given key with the hash code at the entry matched now we will compare the given key with using equals method against the key that is told on the node that also matches so that means we can return this value to the caller so the score of King we got 100 perfect now let's see how exactly scores dot get word will work so again if you go through the same steps hash forward is computed which is this number now the possible index is computed which is basically 4 so so we see that there is an entry and then we compare the hash code for given key against the hash code at the entry so now the hash codes don't match so we kind of skip that entry and go to the next entry and try to match the hash code against that entries hash code again that hash codes did not match so then we go to the next entry in that linked list and try to match the hash code there and there's a match so since we found a match on hash code we will compare the key using the equals method against the key that was given that also passes that means we return the value 99 to the column so that's how the map look up works in a hash map so what has changed in Java 8 so in Java 8 what has happened is that when we have too many unequal keys which are producing the same hash code or the index as we saw when the number of such items actually exceeds a threshold for example number 8 that is a basic threshold when it exists that threshold hash map implementation internally converts that linked list into a balance tree so a balance tree is theoretically faster than a linked list as balance tree provides you a worst-case performance of log n which is compared to which is compared to order of n performance of a linked list which is definitely better so that is the change in Java 8 which gives you which gives you performance improvements when there is too many unequal Keys providing you the same hash code or resolving to the same index so balanced search tree is basically ordered based on the the hash code as the smaller hash code will be on the left-hand side left hand node and the higher hash code will be on the right side and in case when the hash codes are same the the the the keys are compared and the bigger key goes to the right and smaller key goes to the left so again the efficiency of the the tree based implementation enhancement depends a lot on how your hash codes and comparable implementations that you are provided so that is the enhancement in Java 8 so in our next session what we will see is that what are the various different kinds of maps that are out there in Java and what is the exact purpose of these hash maps or map implementations and when we when we can use them so for today's session we have seen how the hash map works so we what we have to keep in mind is basically what exactly is a map but on what is the importance of equals to an hashcode contract and what what exactly is hashcode collisions basically when two unequal objects creating same hashcode that is called the hashcode collision and how the hashcode collision is managed within the hashmap for example using the link list or the balance tree in java 8 so that pretty much concludes this topic and please stay tuned for the upcoming updates on further videos thank you ",
            "url": "www.youtube.com/watch?v=c3RVW3KGIIE",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "KyUTuwz_b7Q",
            "channelId": "UCSX3MR0gnKDxyXAyljWzm0Q",
            "publishedAt": "2017-03-05T12:30:36Z",
            "title": "Hash Tables and Hash Functions",
            "description": "This computer science video describes the fundamental principles of the hash table data structure which allows for very fast insertion and retrieval of data.",
            "channelTitle": "Computer Science",
            "transcript": "a hash table is a data structure that allows for the very fast retrieval of data no matter how much data there is for that reason hash tables are widely used in database indexing caching program compilation error checking and much more consider a simple one-dimensional array variable to find an item in the list you can employ a brute force approach such as a linear search this would involve checking each item in term for a very big array this could take a very long time now suppose you want to retrieve a value from an element in the array and you happen to know the index number of that element you can look up the value very quickly indeed in fact the time it takes to look up any particular value in an array if you know the index number is independent of the size of the array and independent of its position in the array but how can you know which elements of the array contains the value you're looking for the answer is that each index number can be calculated using the value itself so that the index number is in some way related to the data let's repopulate the array starting with mere we'll take each letter of the word and get its ASCII code will add the ASCII codes together and now we're going to divide this by the number of elements in the array in this case there are 11 and we'll take the remainder of that calculation which is 4 that's where we're going to place mere let's do it again this time with Tim we sum up the ASCII codes and divide by the number of elements of the array 11 the remainder is 1 and that's where we'll place Tim same again for B this time the calculation gives us zero so we can insert B into the array at position zero same again for zoiy zoiy goes in at five jan goes in at six Eider at nine Leo it to Sam at three Lew at seven Maxon eight and Ted in position ten once again the array is fully populated but this time each item has been placed in the array according to a calculation based on its value namely the son of the ASCII codes modulo the size of the array in this case 11 so let's retrieve an item let's say ADA we perform the same calculation again and we use the calculated index number to perform a fast array look up rather than just storing individual items of data hash tables are often used to store key value pairs for example ADA's name would be the key which would be used to calculate the index and her date of birth the corresponding value for this reason a hash table of key value pairs is sometimes referred to as a hash map in fact if an object-oriented approach was taken each person would be an instance of a class and the key would be just one of many different properties by populating the array with objects you can effectively store as much related data as you like for each key a hashing algorithm also known as a hash function is the calculation applied to a key which may be a very large number or a very long string to transform it into a relatively small indexed number that corresponds to a position in the hash table this index number is effectively a memory address for numeric keys it's common to take the key and divide it by the number of available addresses and take the remainder we say that the address is the key modulo n where n is the number of available addresses as you've seen for alphanumeric keys we can divide the sum of the ASCII codes in the key by the number of available addresses and take the remainder another method that can be employed is known as the folding method for example a telephone number can be broken up into groups of two digits these can then be added together and then depending on the size of the table we'll divide this by some constant and take the remainder there are lots of different hash algorithms to choose from some more appropriate than others depending on the nature of your data so far you've seen how to load up a hash table with data that very conveniently didn't cause any problems needless to say that was unrealistic sometimes if you apply a hash function to two different keys it generates the same index number for both but both items can't go in the same place this is known as a collision let's load up the array again but this time with a different set of data mia goes in at position 4 Tim goes in at position 1 just as before B goes in at position 0 when we do the calculation for Zoey she goes in at position 5 but then along comes Sue and when we calculate an index for Sue we get positioned four but this is already occupied so we look at the next place along but this two is occupied but the next place along isn't so that is where we're going to place sue the calculated position for Len is 1 but this 2 is occupied so Len has to go in to the next available space mo wants position 3 no problem here Lu wants to go into position 7 again no problem here button Ray wants position 5 and position 5 is occupied so is position 6 and 7 so ray has to go in at position 8 max wants position 8 but but of course this is occupied so max goes in at position 9 and finally Todd wants position 9 but he's going to have to settle for position 10 resolving a collision by placing an item somewhere other than it's calculated address is called open addressing because every location is open to any item open addressing can use a variety of techniques to decide where to place an item that doesn't go where it should this particular open addressing technique is called linear probing if the calculated address is occupied then a linear search is used to find the next available slot if linear probing gets to the end of the array and it still can't find a free space it might cycle around to the beginning of the array and continue searching from there to look up an item in this hash table the hashing function is applied again but if they've been collisions and some items are not in their calculated positions then finding an item will also involve linear probing that is a linear search the more items there are in a hash table the more likely you are to get collisions when you insert even more data one way to deal with this is to make the hash table bigger than needed for the total amount of data you're expecting perhaps such that only 70% of the hash table is ever occupied the ratio between the number of items stored and the size of the data array is known as the load factor if the hash table is implemented as a resizable dynamic data structure it could be made to increase in size automatically when the load factor reaches a certain threshold in an ideal world every item will be stored in the hash table according to its calculated index in this best-case scenario the time taken to find any particular item is always the same but you can imagine the worst case scenario - depending on the nature of the data used to calculate the index values and depending on the appropriateness of the hash algorithm some items may require a linear search of the whole table in order to be found as long as the load factor is reasonably low open addressing with linear probing should work reasonably well another way to deal with collisions is known as chaining sometimes referred to as close to dressing let's load up this array again Mia goes in at position 4 but what we have here is a pointer to the first node of a linked list Tim at position 1 again a pointer to the first node of a linked list be at position 0 Zoe at position 5 and Sue at position 4 sue is now added to the linked list and Mia is pointing to sue Len goes in at position 1 but Len is just another node in a linked list and Tim is pointing to Len Moe at position 3 Lou at position 7 ray at position 5 she's put on to the end of a linked list max at position 8 Todd at position 9 and finally our hash table is populated to search this hash table you can calculate the indexes before to locate the correct element then use a standard linked list traversal to find what you're looking for with the chaining method of conflict resolution you can see there are a greater proportion of items in the correct place so the lookup is quicker than if you had used linear probing of course traversing a linked list also comes at some cost if the load factor is low it may actually be more efficient to use open addressing when resolving collisions if the calculated address is occupied linear probing involves trying the next place along and if necessary the next and then the next and so on until an empty slot is eventually found but this can result in what is known as primary clustering in other words keys might bunch together inside the array while large proportions of it remains unoccupied there are however alternatives to linear probing that can help to avoid clustering rather than simply scanning along for the next available slot conflict resolution may involve looking at say every third slot along until the free space is found the so-called +3 rehash quadratic probing will square the number of failed attempts when deciding how far along from the point of the original collision to look next each time another failed attempt is made the distance from the original point of collision grows rapidly double hashing applies a second hash function to the key when a collision occurs the result of the second hash function gives the number of positions along from the point of the original collision to try next close the dressing on the other hand involves chaining items that have collided in a linked list or some other suitable data structure if you know all of the keys in advance then it's theoretically possible to come up with a perfect hash function one that will produce a unique index for each and every data item in fact if you know the data in advance you could probably come up with a perfect hash function that uses all of the available space in the array more often than not you'll need a more flexible hash table so when choosing or writing a hash function there are some objectives to bear in mind it should minimize collisions so less time is spent on collision resolution and ultimately data retrieval will be quicker ideally it should give you a uniform distribution of hash values and therefore the data will be spread across the hash table as uniformly as possible the hash function should be easy to calculate and it should include a suitable method of resolving any collisions that do occur to summarize then hash tables are used to index large amounts of data the address of each key is calculated using the key itself collisions are resolved either with open or closed addressing hashing is widely used in database indexing compilers caching password authentication and more and finally the insertion deletion and retrieval of data from a hash table occur in constant time but only in the best-case scenario if they've been collisions this isn't necessarily the case ",
            "url": "www.youtube.com/watch?v=KyUTuwz_b7Q",
            "source": "Youtube",
            "difficulty": 3
        }
    ],
    "graphs data structures": [
        {
            "videoId": "5hPfm_uqXmw",
            "channelId": "UCM-yUTYGmrNvKOCcAl21g3w",
            "publishedAt": "2019-02-19T10:34:08Z",
            "title": "6.1 Graph representation in Data Structure(Graph Theory)|Adjacency Matrix and Adjacency List",
            "description": "In this video, I have explained the two most popular methods(Adjacency Matrix and Adjacency List) for representing the graph in the computer. See Complete ...",
            "channelTitle": "Jenny's lectures CS/IT NET&JRF",
            "transcript": "hi guys welcome back today I am going to discuss with here with you how to represent a graph in computer I'm going to discuss with you the most popular two methods for representing a graph in computer ok the two methods are first one is at the sensing matrix and second one is at the sensei list first one yields this matrix and second one is at this NC list these are the most popular two methods okay although we have more method that is I guess multi list is also there but I am going to discuss with you these two methods adjacency matrix and Addison C list now how to represent a graph in computer see this is the pictorial view you can easily draw a graph on this whiteboard like this but when you are going to represent a graph in computer then you have to use something okay you have to use some methods to represent this graph in computer so these are two methods then one is matrix and one is list first one is I am going to discuss with you this this method Edison C matrix so matrix is simply in mathematics you know matrix is what M cross n where m is the number of rows and n is number of column something like this number of rows and number of columns so in this case let us take this example this one is our graph and you are supposed to represent this graph using this adjacency matrix then how you will represent it this adjacency matrix would be n cross n matrix and where n is what number of vertices in the graph okay now how you will represent it this one is our matrix there should be n cross n matrix where n is what number of vertices how many number of vertices 1 2 3 4 5 then 1 2 3 4 5 number of rows would be there and five number of columns would be there this one should be 5 cross 5 matrix now we are supposed to fill out these entries now see 1 2 1 is there any loop is there any loop in this graph loop means the edge would start from the same node and would add end on the same node like this this would be a loop if you have say check out you have any loop in this graph no you don't have any loop that's why the diagonal elements would be 0 3 2 2 3 4 2 4 there is no edge and 5 2 5 no edge okay now check out 1 2 2 1 2 2 obviously it is undirected graph ok so this edge would be considered as 1 to 2 also and 2 to 1 also okay one two - yes we have edge between 1 to 2 then you can write down 1 1 2 3 no we don't have any edge direct edges between 1 2 3 that way that's why it is 0 1 2 4 yes we have 1 2 4 we have an edge 1 2 5 no we don't have now 2 2 1 2 2 and yes we have because this edge is what undirected edge so this is also considered from 1 to 2 and 2 to 1 by 2 2 3 2 2 3 yes we have 2 to 4 yes we have 2 to 5 no we don't have any direct or any edge between 2 to 5 3 2 1 you have 3 2 1 no we don't ow 3 to 2 yes we have 3 2 to see this one three to three no three to four yes we have three to five yes now four to one yes for two - yes this one for two three yes four to five yes five to one no five to two no five to three yes we have and five to four yes we have fine so you can simply write down like this okay now you simply write down the definition of this addition C matrix is what it is a matrix you can say a n cross n we are representing the matrix with a and n where n is the number of vertices n would be the number of rows and n will be the number of columns and how you will fill these entries a of I J this one is J is equal to 1 if I and J are at this end ok see suppose this one is I and this one is J let us take this one is I we are taking and this one is J so you write down a of IJ 1 if I and J are at the st. 1 and 2 are adjacent to each other that is why we are taking 1 2 2 is 1 a of IJ that is a of I 1 and J is suppose to this one is 1 and I 2 and J is equal to 1 this one is also 1 okay otherwise you we would write here 0 all right now next we'll discuss what is adjacent see list see now this would be as the name suggests we will have we are going to have linked lists fine and how many linked list would be there for each what takes one linked list would be maintained like this in this case we are having how many vertices five I guess 1 2 3 4 5 1 2 3 4 5 number of vertices are there fine for each what takes one linked list would be there in that linked list will have will contain the adjacent node to this node fine like this see now suppose will be a first one is what is number of node is one how many at the center node are there two one one is two and one is four then one linked list would be maintained containing two and four now come to the second note this one second how many addition node are there one three and four this would be one three and four now for three also one linked list would be there and it would contain how many number of adjacent to node are there two three one is to one is four and one is five one is to one is four and one is five four four also we have one now we have what two we have what three and five see one two three and five and four five we have what three and four only three and this one is for how many linked lists would we maintain one two three and four and five how many number of vertices 1 2 3 and or four and five the number of vertices total number of vertices in the graph with Linea po maintain Kenyan number of linked list for each node fine now this is the adjacency list using this list you can a present this graph and this is how you can represent this graph using addition C matrix now when you're supposed to calculate the time complexity now when you represent a graph using this method adjacency matrix then what would be the time complexity order you're sorry you can say the space complexity space complexity would be theta n square in this case right because mat this is matrix n number of rows and n number of columns the space complexity is what n square here it is there C five into five matrix v square five is what number of vertices that is and where n is what number of vertices and for representing a graph using this a distance a list the space complexity would be theta n plus 2 e C and 1 2 3 4 5 these are number of what what s is why we have written this plus 2 e because the one you happy there Co see this one is one edge from one to two fine but you have written this edge two times in this list two times went from 1 2 to one edge you have written and from two to one also from two to one also so two times we have written this edge in this list same you can say with you can say take one to four this one is one edge but you have written this two times one to four fine because 4 is adjacent to one so we have written in this linked list also plus 4 to 1 also four to one like this so every Edge has been written two times that's why we have written here n plus 2 we the space complex that is this one for Addison see a nest and this one is theta n square for Addison when you represent this graph any graph using a distance e matrix so see it would be better to use this adjacency matrix to represent a graph when the graph is dense graph sometimes they can ask you this type of question in case of dense graph it's better to use adjacency matrix to represent that graph and when the graph is sparse sparse graph then it would be better to use this what adjacency list because see when a dense graph means almost or you can say each node is connected with each other node you can say you can take example of a complete graph like this suppose we have four nodes and every node is connected with every node and five nodes every node is connected with every other node like this then in that case it is better to use this matrix okay and when something like this one a very few number of edges are there between these vertices then better to use this adjacency list and this is the space complexity for representing these graph ok so that's all about you know some you can say the basics of how to represent a graph in computer these are the most popular methods I am NOT saying that these are the only two methods to represent a graph but I am just I have just discussed the most popular methods to represent this graph okay so I'll see you in the next video till then bye-bye take care ",
            "url": "www.youtube.com/watch?v=5hPfm_uqXmw",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "gXgEDyodOJU",
            "channelId": "UClEEsT7DkdVO_fkrBw0OTrA",
            "publishedAt": "2014-09-02T11:25:00Z",
            "title": "Data structures: Introduction to graphs",
            "description": "In this lesson, we have described Graph data structure as a mathematical model. We have briefly described the concept of Graph and some of its applications.",
            "channelTitle": "mycodeschool",
            "transcript": "Hello everyone. So far in the series on\ndata structures, we have talked about some of the linear\ndata structures like array, linked list, stack and queue. In all these\nstructure, data is arranged in a linear or sequential manner, so we can call\nthem linear data structures and we've also talked about tree which\nis a non-linear data structure. Tree is a hierarchical structure. Now as\nwe understand data structures are ways to store and organize data, and for different kinds of data we use\ndifferent kinds of data structures. In this lesson, we're going to introduce\nyou to another non linear data structure that has got its application in a wide\nnumber of scenarios in computer science. It is used to model and represent a\nvariety of systems and this data structure is graph. When we study data structures, we often\nfirst study them as mathematical or logical models. Here\nalso, we will first study graph as a\nmathematical or logical model and we will go into implementation\ndetails later. Okay so let's get started. A graph just\nlike a tree is a collection of objects or entities that\nwe call  nodes or vertices, connected to each\nother through a set of edges. But in a tree connections are bound to be in a certain\nway. In a tree that our rules dictating the connection among the nodes.\nIn a tree with N Nodes, we must have exactly N - 1 edges. One edge for each parent child relationship. As\nwe know an edge in a tree is for a parent child\nrelationship and all nodes in a tree except the root node would have apparent\nwould have exactly 1 parent and that's why if they are N nodes, it\nmust be exactly N - 1 edges. In a tree, all nodes must be reachable\nfrom the root and there must be exactly one possible\npath from root to a node. Now in a graph there are no\nrules dictating the connection among the nodes.\nA graph contains a set of nodes and a set of edges and edges can be connecting nodes in any\npossible way. Tree is only a special kind of graph.\nNow graph as a concept has been studied\nextensively in mathematics. If you have taken a course on discrete\nmathematics then you must be knowing about graphs\nalready. In computer science, we basically study and implement the same concept\nof graph from mathematics. The study of graph is often referred to\nas graph theory. In pure mathematical terms we can define graph something like this. A graph G is in order pair of a set\nV of vertices and a set E of edges. Now I'm using\nsome mathematical jargon here. An ordered pair is just a pair of\nmathematical objects in which the order of objects in the pair matters. This is how we write and\nrepresent an ordered pair, objects separated by comma put\nwithin parenthesis. Now because the order here matters. We\ncan say that V is the first object in the pair and E\nis the second object. An ordered pair A, B is not equal to B, A unless A and B are equal. In our definition of graph here, first\nobject in the pair must always be a set of vertices and\nthe second object must be a set of edges that's why we are calling the pair \nan ordered pair. We also have concept of unordered pair.\nAn unordered pair is simply a set of two elements. Order is\nnot important here. We write an unordered pair using curly\nbrackets or braces. Because the order is not important here,\nunordered pair A, B is equal to B, A. It doesn't matter\nwhich object is first and which object is second. Okay coming back,\nso a graph of is an ordered pair of a set of\nvertices and a set of edges and G = (V,E) is a formal\nmathematical notation that we use to define a graph. Now I\nhave a graph drawn here in the right. This graph is 8 vertices\nand 10 edges. What I want to do is I want give some\nnames to these vertices because each node in a graph must\nhave some identification. It can be a name or it can be an index. I'm naming these vertices as V1, V2 V3, V4, V5 and so on, and this\nnaming is not indicative of any order. There is no 1st, 2nd and 3rd Node here. I could\ngive any name to any node. So my set of \nvertices here is this. We have 8 elements in the\nset V1, V2, V3, V4, V5, V6, V7 and V8. So this is my set of\nvertices for this graph. Now what's my set of edges. To answer\nthis we first need to know how to represent\nan edge. An edge is uniquely identified by it's\n2 endpoints, so we can just write the names\nof the two endpoint of an edge as a pair and it can be\na representation for the edge. But edges can be of two types. We can\nhave a directed edge in which connection is\none-way or we can have an undirected edge in\nwhich connection is two way. In this example graph that I'm showing\nhere, edges are undirected but if you remember the tree that I had\nshown earlier then we had directed edges in that tree.\nWith this directed edge that I'm showing you here, we are saying that there is link or path from vertex U to V but we cannot\nassume a path from V to U. This connection is one way. For\na directed edge, one of the endpoints would be the\norigin and other end point would be the destination and we draw the edge with an arrow head pointing towards the\ndestination. For our edge here, origin is U and\ndestination is V. A directed edge can be to represented as\nan ordered pair, first element in the pair can be the\norigin and second element can be the destination. So with this directed edge represented\nas ordered pair (U,V), we have a path from U to V. If we want a path from V to U, when need\nto draw another directed edge here with V as \norigin and U as destination and this edge can be\nthe represented as ordered pair (V,U), the upper one here is (U,V) and the\nbelow one is (V,U) and they are not same. Now if the edge is undirected, the\nconnection is 2 way and undirected edge can be\nto represented as an unordered pair here because the edge is\nbi directional origin and destination are not fixed. We\nonly need to know what two end points have been connected by the edge. So now that we know how to present edges,\nwe can write the set of edges for this example graph here. We have an undirected edge between V1\nand V2 then we have 1 between V1 and V3 and\nthen be have V1 V4. This is really simple and just go ahead\nand write all of them. So this is my set of edges. Typically in\na graph, all edges would either be directed or\nundirected. It's possible for a graph to have both\ndirected and undirected edges but we are not going to study such\ngraphs, we are only going to study graphs in which all edges would either be\ndirected or undirected. A graph with all directed\nedges is called a directed graph or digraph and a graph with all undirected ages is\ncalled an undirected graph. There is no special name for an\nundirected graph. Usually, if the graph directed, we\nexplicitly say that it's directed graph or digraph. So these are\ntwo types of graphs. Directed graph or digraph in which edges are uni-directional or ordered pairs and undirected graph in which edges are\nbi-directional or unordered pairs. Now many real-world\nsystems and problems can be modeled using a graph.\nGraphs can be used to represent any collection of objects having some\nkind of pairwise relationship. Let's have a look\nat some of the interesting examples. A social network like Facebook can be\nrepresented as an undirected graph. A user would be a node in\nthe graph and if 2 user are friends, there\nwould be an edge connecting them. A real social network would have millions\nand billions of nodes. I can show only few in my diagram here\nbecause I'm short of space. Now social network is an undirected\ngraphs because friendship is a mutual relationship. If I'm your\nfriend, you are my friend too. So connections have to be 2 way. Now once\na system is modeled as a graph a lot of problems\ncan easily be solved by applying standard algorithms\nin graph theory. Like here in this social network, let's\nsay we want to do something like suggest friends to a user. Let's say we\nwant to suggest some connections to Rama. One possible approach to do so can be\nsuggesting friends of friends who are not connected already. Rama has\n3 friends, Ella, Bob and Katie and friends of 3 that are not connected to Rama\nalready can be suggested. There is no friend of\nElla which is not connected to Rama already. Bob however, has 3 friends Tom, Sam, and Lee that are not friends with Rama so\nthey can be suggested and katie has two friends Lee and Swati that are not connected to Rama.We have\ncounted Lee already, so in all we can suggest these for users\nto Rama. Now even though we described this\nproblem in context of a social network. This is a standard graph problem. The\nproblem here in pure graph terms is finding all nodes\nhaving lenght of shortest path from a given\nnode equal to 2. Standard algorithms can be applied to\nsolve this problem. We'll talk about concepts like path in\na graph in some time. For now just know that the problem that\nwe just described in context of a social network is a standard graph\nproblem. Okay so a social network like Facebook\nis an undirected graph Now let's have a look at another example.\nInterlinked web pages on the internet or the World\nWide Web can be represented as a directed graph.\nA web page that would have a unique address or URL\nwould be a node in the graph and we can have a directed edge if a\npage contains link to another page. Now once again, there are billions of pages\non the web but I can show only few here. The edges\nin this graph are directed because that relationship is not mutual this\ntime. If page A has a link to page B then\nit's not necessary that page B will also have a link to page A. Let's say one of the pages on\nmycodeschool.com has a tutorial on graph and on this page I have put a link to Wikipedia article on\ngraph. Let's assume that in this example\ngraph that I am showing you here. Page P is my mycodeschool tutorial\non graph with this address or URL \nmycodeschool.com/videos/graph and lets say, page Q is the\nWikipedia article on graph with this URL Wikipedia/org/wiki/graph.  Now on my page that is page P, I have put a link to the Wikipedia page on\ngraph. If you are on page P, you can click on\nthis link and go to page Q but Wikipedia has not reciprocated\nto my favor by putting a link back to my page. So if you are on\npage Q you cannot click on the link can\ncome to page P. Connection here is one way and that's why we have\ndrawn a directed egde here. Okay now once again if we are able to\npresent web as a directed graph, we can apply\nstandard graph theory algorithms to solve problems and to perform tasks. One of the tasks that search engines\nlike Google perform very regularly is web crawling. Search engines use a\nprogram called web crawler that systematically browsers the \nWorld Wide Web to collect and store data about web\npages. Search engines can then use this data to provide quick and accurate results\nagainst search queries. Now even though in this context, we are\nusing a nice and heavy term like web crawling. Web crawling is basically graph\ntraversal or in simpler words, act of visiting all\nnodes in a graph and no prizes for guessing that there\nare standard algorithms for graph traversal. We will be studying graph traversal\nalgorithms in a later lessons. Okay now the next thing that I want to\ntalk about is concept of a weighted graph. Sometimes in a graph, all\nconnections cannot be treated as equal. Some connections can be preferable to\nothers like for example we can represent intercity road network that is the\nnetwork of highways and free ways between cities as an\nundirected graph. I'm assuming that all highways would be\nbi-directional. Intra-city road network that is road\nnetwork within a city would definitely have one-way roads and so Intra-city network must be\nrepresented as a directed graph but intercity road network in my opinion\ncan be represented as an undirected graph. Now clearly we cannot\ntreat all connections as equal here. Roads would be of different lengths and\nto perform a lot of tasks to solve a lot of problems, we need to\ntake length of roads into account. In such cases, we associate some weight or cost with every edge. We label the edges with\ntheir weights. In this case weight can be lenght of the roads,\nso what to do here is I'll just label this edges with some values for\nthe lenghts. Let's say these values are in kilometers and now edges in this graph are weighted and\nthis graph can be called weighted graph. Let's say in this graph, we want to\npick the best route from city A to city D. Have a look at these four possible\nroutes, I am showing them in different colors. Now if I would treat all edges as equal then I would say that the green route\nthrough B and C and a red route through E and F are equally\ngood. Both these paths have to three edges and\nthis yellow route through E is the best because we have only two\nedges in this path. But with different weights assigned to\nthe connections, I need to add up weights of edges in a path to calculate\ntotal cost. When I'm taking weight into account shortest\nroute is through B and C. Connections have\ndifferent weights and this is really important here in this\ngraph. Actually, we can look at all the graphs as weighted graphs An unweighted graph can basically be seen\nas a weighted graph in which weight of all\nthe edges is same and typically we assume to weight\nas one. Okay so we have represented inter-city cities\nroad network as weighted undirected graph. Social network\nwas an unweighted undirected graph and World Wide Web was an unweighted\ndirected graph and this one is a weighted undirected graph. Now this was inter-city road network. I\nthink intra-city road network that is road network within a city can be\nmodeled as a weighted directed graph because in a\ncity that would be some one ways. Intersections in interest city's road\nnetwork would be Nodes and road segments would be our edges, and by the way we can also draw an\nundirected graph as directed. It's just that for each undirected edge\nwe will have 2 directed edges. We may not be able to redraw a directed\ngraph has undirected but we can always redraw an undirected\ngraph as directed. Okay I'll stop here now. This much is\ngood for an introductory lesson. In next lesson, we will talk about some more\nproperties of graph. This is it for this lesson. Thanks for\nwatching ! ",
            "url": "www.youtube.com/watch?v=gXgEDyodOJU",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "c8P9kB1eun4",
            "channelId": "UCSX3MR0gnKDxyXAyljWzm0Q",
            "publishedAt": "2016-04-27T05:44:58Z",
            "title": "Graph Data Structure 1. Terminology and Representation (algorithms)",
            "description": "This is the first in a series of videos about the graph data structure. It mentions the applications of graphs, defines various terminology associated with graphs, ...",
            "channelTitle": "Computer Science",
            "transcript": "the graph data structure has a great many applications in computer science almost invariably to model some type of network travel routes such as road links shipping lanes or aircraft flight paths can be represented including information about distances speed limits wind speed fuel requirements or just about anything of relevance but it doesn't stop there a search engine might model the links between webpages on the internet using a graph the routing of data packets during transmission on a computer network can be represented by a graph the connections between people and groups in social networks the speed and pressure of liquids flowing inside pipes finding the quickest time to complete a project that includes several interdependent steps for example in the field of construction modeling objects in three dimensions usually involves the creation of a mesh which is really just another type of graph the available moves in a strategy game such as chest or the possible scenarios in a computer generated simulation arguably the graph is one of the most versatile data structures in the field of software engineering here's a simple graph it's a collection of interconnected nodes but unlike a tree there are no rules about how these nodes can be connected there's no such thing as a root mode nor are there such things as parent nodes or child nodes in a graph a node is more correctly known as a vertex and vertices are connected by edges typically a graph will have more edges than vertices a graph with lots of edges in relation to the number of vertices is said to be a dense graph while a graph with few edges in relation to the number of vertices is said to be sparse in some graphs the edges are directional this is known as directed graph it's also known as a digraph a graph in which all of the edges are bi-directional is known as an undirected graph or an unordered graph or simply a graph by default a graph is assumed to be unordered each edge in a graph can have a weight associated with it the weight of each edge is sometimes referred to as the cost what each cost represents depends of course on the application for example each cost could be a speed limit the diameter of a water pipe the number of hours to complete a phase of a project you name it a path is a sequence of vertices in a graph a graph is said to be connected if there is a path from every vertex to every other vertex a cycle is a path in which the starting vertex is also the ending vertex a tree is a special type of graph which includes a path from some starting node the root to every other node but a tree has no cycles so how do we represent a graph or to begin with a graph can be described in mathematical set notation a graph is said to be a set of vertices V and a set of edges e we can list the vertices inside curly brackets and each edge can be listed as a pair of vertices for a weighted graph we can add the cost of each edge to this notation now remember an undirected graph is one in which all of the edges are bi-directional so strictly speaking we should do note each possible direction of an edge separately so what if we want to code up a graph and work with the data it contains there are two ways that a graph class could internally maintain the vertices and edges of a graph these are the adjacency list and the adjacency matrix in essence with an adjacency list system we have a master list of vertices then for each edge each starting vertex maintains a list of ending vertices or to put in another way each vertex maintains a list of its neighbors there are several ways this could be implemented but an object-oriented approach is probably the most suitable we could code up a vertex class that each vertex object would be instantiated from the vertex class would have a property to hold information about the vertex such as the name of a city if we were representing some kind of map another property could be an identifier for the vertex and another an array containing the identifier of its adjacent vertices the master list of vertex objects can also be stored in a simple one-dimensional array to represent a weighted graph the cost of each edge could be stored in the adjacency list to using an adjacency list is a very compact space efficient representation of a graph particularly a sparse graph you don't have to store any more data than necessary however determining if an edge exists between two particular vertices would require searching through the adjacency list of one of them for a dense graph the time taken will increase proportionately with the density of the graph with an adjacency matrix every vertex is written as a row heading and a column heading in a grid if an edge exists between a pair of vertices then its weight can be indicated at the intersection of the appropriate row and column note that for an undirected graph there is symmetry along the adjacency matrix is diagonal if there's an edge from A to B there must be a corresponding edge from B to a this symmetry wouldn't be present for a directed graph for an unweighted graph we can simply represent each edge with a boolean value an adjacency matrix can be implemented with a two-dimensional array we would still have a vertex class from which we would create each vertex object but the actual connectivity of the graph would be defined by this 2d array of edges one of the advantages of an adjacency matrix over an adjacency list is that determining whether or not an edge exists between two vertices requires a simple array lookup this takes the same amount of time to do regardless of the edge in question however an adjacency matrix is not particularly efficient when it comes to space for a sparse graph much of the adjacency matrix will be empty furthermore for an undirected graph half of the information stored is just duplication which method you use to implement a graph will ultimately depend on the nature of the information it will represent and of course how you plan to process it ",
            "url": "www.youtube.com/watch?v=c8P9kB1eun4",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "DBRW8nwZV-g",
            "channelId": "UC8butISFwT-Wl7EV0hUK0BQ",
            "publishedAt": "2017-05-21T01:51:53Z",
            "title": "Graph Data Structure Intro (inc. adjacency list, adjacency matrix, incidence matrix)",
            "description": "Graphs are collections of things and the relationships or connections between them. The data in a graph are called nodes or vertices. The connections between ...",
            "channelTitle": "freeCodeCamp.org",
            "transcript": "the graph data structure is not the same as a graph you may have learned about a math class graphs are collections of things and the relationships or connections between them the data in a graph are called nodes or vertices the connections between the nodes are called edges one example of graphs is a social network where the nodes are you and other people and the edges are whether two people are friend with each other there are two major types of graphs directed and undirected undirected graphs are graphs without any direction on the edges between nodes directed graphs are graphs with a direction and its edges an example of an undirected graph could be a social network the nodes are people and the edges are friendships an example of a directed graph could be the internet and web page links the nodes are web pages and the directed edges are links to other pages which might not necessarily point the other way I'm going to show you three ways to represent a graph the first way is called an adjacency list this representation for a graph associates each vertex in the graph with the collection of its neighboring vertices or edges in this image a is connected to B B is connected to a and C and C is connected to B this is how you could show a relationship with texts and here is how you could show this adjacency list with JavaScript this is an undirected graph because it does not show the direction of the edges this can also be more simply represented as an array where the nodes just have numbers rather than string labels another way to represent a graph is to put it in an adjacency matrix an adjacency matrix is a two-dimensional array where each nested array has the same number of elements as the outer array so it's basically a matrix of numbers where the numbers represent the edges zeroes means there is no edge or relationship and one means there is a relationship this table shows an adjacency matrix to represent the image you can see that the labels for the nodes are on the top and left now here's a JavaScript representation of the same thing unlike an adjacency list each row of the matrix has to have the same number of elements as nodes in the graph here we have a 3 by 3 matrix which means we have 3 nodes our graph and adjacency matrix can be used to represent a directed graph here's a graph where the second node has an edge pointing toward the first node and then the third node has an edge pointing to the first node notice how the numbers in the array change there are only ones where a node is pointing toward another node and since there are only two points there are only two nodes the final way I will show to represent a graph is an incidence matrix like the adjacency matrix and incidence matrix is a two-dimensional array however the rows and columns means something else here the adjacency matrix use both rows and columns to represent nodes and incidence matrix uses roads rose to represent nodes and the columns to represent edges this means that we can have an uneven number of rows and columns each column will represent a unique edge also each edge connects two nodes to show that there is edge between two nodes you will put a 1 in the two rows of a particular column as you can see in the diagram edge 1 is connected to nodes a and B now look at the column for edge 1 in the incidence matrix table you will see a 1 in both the a row and the B row this shows the edge 1 connects the nodes a and B here is a directed graph for a directed graph use negative 1 for an edge leaving a particular node and 1 for an edge entering a node and here is a JavaScript implementation of the incidence matrix graphs can also have weights on their edges so far we have unweighted edges where just the presence and lack of edges binary zero one you can have different weights depending on your application a different way is represented as a number greater than one well now you know about different types of graphs and how to represent them in JavaScript in my next video about graphs I will cover graph traversal algorithms thanks for watching my name is Bo Carnes don't forget to subscribe and remember use your code for good ",
            "url": "www.youtube.com/watch?v=DBRW8nwZV-g",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "zaBhtODEL0w",
            "channelId": "UCOf7UPMHBjAavgD0Qw5q5ww",
            "publishedAt": "2016-09-27T19:39:15Z",
            "title": "Algorithms: Graph Search, DFS and BFS",
            "description": "Learn the basics of graph search and common operations; Depth First Search (DFS) and Breadth First Search (BFS). This video is a part of HackerRank's ...",
            "channelTitle": "HackerRank",
            "transcript": "Hi, I'm Gayle Laakmann McDowell, author of Cracking the Coding Interview. Today I want to talk about graphs and common\noperations, like breadth-first search and depth first search. So to go back to the\nbeginning, a graph is basically a collection of nodes where each node\nmight point to other nodes and these edges can be directed so like one-way\nstreets or undirected so kind of like two-way streets. Now suppose you want to go walk\nthrough this graph, and specifically suppose you want to do something like,\nfigure out is there a path from one node to another. There are two common ways of\ndoing this and we'll talk about both of them. The first one is a little more\nsimplistic and it's called depth-first search, and it's a typically recursive\nalgorithm and the way it looks like it's saying, okay we have have this initial\nnode that I'm gonna call s. Now you basically are asking a question, hey S, do you have a path to node T, and S says, hmm, I'm not sure, let me go ask my\nchildren. And first S goes to node A and it says hey A, do you have a path to node T? If you do then hey I'm done I can give you my answer. If you don't then let me go ask B and\nthen C and then D. And so, the first person we ask is A, so A gets asked, hey A do you\nhave a path to T? I'm not sure let me go ask my children. And eventually we might get\nto a node who says why yes of course I have a path, I am T. And so then\nwe go and say boopboopboop all the way back up. Yes there's a path and that's the basis\nof depth-first search. It's called depth-first search because\nwe go deep into some node before you even ask any of the children. Now the\nproblem with this is that we might run really really far away. So imagine for example that B actually\nhas a path directly to node T has edge directly to node T. A might go to all of its children, all\nof its children, all of its children, before you even get to B, and he was right\nthere. There could have been a really fast connection so that's why we might\noften prefer to use breadth first search instead. Breadth-first search says hey go a\nlevel by level out. So first we ask S hey do you have a path to T? And S will say\nwell let me check if any of my nodes are T. No, there's no edge right there. So each of those get in line. And then we\nask the second level out, and then the third level out, and the next level and the next\nlevel and the next level. And so we go level by level, breadth, we go wider before you\ngo deep. That's why it's called breadth-first\nsearch. So I want to talk at a high-level about the implementation of each before\nI dive into some of the details. So depth-first search is implemented with a\nrecursive algorithm. It's probably the simpler algorithm to implement. The only\nlittle trick is that we have to make sure to use it is visited flag so that\nyou don't wind up in some sort of infinite loop where there is, you know, a\ncycle and you keep asking each node of it has, you start running around\nin a circle. With breadth-first search, the main trick need to remember is you\nwant to use a queue. So when you look, when you look at S, you say hey, do you have a path to T? You're going to go add all of its children to the queue, and rather than going recursively\nyou pull out the first element from the queue, check if it has a path, check if it is this final element and if not go add all its children to it. So use a\nqueue so that you go through things in the correct order. So that's the high-level, how it works.\nLet's turn to the real details of the implementation now. I've gotten a bit of\na head start on the implementation but I'll show you just quickly what I've\ndone. So first we have this node class here, and it's going to have some sort\nof ID that represents the node ID and what I've done is give ourselves a\nmapping of from node ID to the actual node and this is mostly going to be used\nfor things like get node and add edge. This way we can actually just go and get, get immediate access\nto the node of the particular ID. And then I've also given us this has paths\ndepth-first search method and it's going to call after this recursive method. So\nif you remember with depth first search, we need to have a way of\nflagging nodes to say hey I've already visited this don't retry it. So one thing we can do is we can\nactually modify the node class to give ourselves and is visited flag, but that\nrequires then making sure we clear that flag later on. Another way of doing\nit is giving ourselves a hash set that lists all of the IDs that I've already,\nof the nodes that I've already visited. It's sort of a replacement for a flag so I'm gonna\ndo it this way, this way I don't have to modify and add a whole bunch of flags in\nand then make sure to clear them later on. So I get the source node, I get the\ndestination node, and then I get this, create this visited hash set and then I\ngo out and call this recursive method. So now is where the fun begins. So first if I've already visited this\nnode, if visited dot contains the source ID then return false because there is no\npath then. Okay otherwise, then what I want to do is, so now I want to go and\nmake sure I update this, mark this node as visited, and then I want to say okay\nif I'm at my source then if I'm at my destination rather, then\nreturn true because yes there certainly is a path then. Otherwise go and check\nall my children and see any of them have a path because if there's a path from a child\nto me then then there's certainly a final, then there's certainly a path from me\nto my destination. So for each node child in source dot adjacent, if there's\na path from child to destination passing in again visited, then return true and\nthat will bubble all the way up the stack. If I get down to the very end and I\nhaven't found a path yet then there is no path from me to my destination. Now\nlet's turn to how breadth-first search works. Ok so breadth-first search, so what I\nneed with breadth-first search is I need a linked list of sort of what I'll call\nthe like next step. So these are the, I'll call this\nnext to visit, these are the nodes that I need to visit next. And just as before I need\nthis visited hash set that represents everything I've already visited, and then\nI want to say next to visit, because the first I need to visit is in\nfact my source. Then as long as there is nothing in, so while visited, sorry\nnext to visit dot is empty so while it's not empty, keep going. Alright so first thing, I need\nto look, grab my very first node to visit so node node equals next to visit dot, I'll\ncall this remove so remove the very first node in that list, if this is my\ndestination then there is certainly a path. Now I also want to do my visited\nchecking so if visited dot contains of node ID, then actually just continue,\nlet's go to the next value, otherwise visited dot add of node dot ID so mark it as\nvisited, and then go and actually add my children so for each node child in node\ndot adjacent go and add each of those to my next to visit. So next to visit dot add of child. Right.\nAnd that's all there is to depth and breadth first search. And then of course\nif i get down to the very end and I haven't found a path yet return false. Let's walk through this code again and\nmake sure that this makes sense. So has path DFS takes in the source and\ndestination IDs and then I get those nodes and then I create this hash sets,\nthat should be hash set not a hashmap. And then goes and actually does this\nrecursive method, so the recursive method has this visited thing so we use a\nvisited hash set instead of marking the actual nodes with a flag. So visited, check\nif it contains the source ID, if it does contain that, if I've already visited this,\nreturn false because there's no path. Then otherwise go and add this visited,\nmark this node as visited, read you know, check my sources, my destination children\nalready there return true. Otherwise go and search all\nof my children. Then so that, and then if I haven't found a path go to return\nfalse. So with BFS we are taking in a source\nand a destination. So here are views nodes, I'll switch this actually to be symmetric and use IDs again and so I'll make that public\nand this private now. Ok so I take in the source and\ndestination IDs and then I go and call this recursive method. My recursive method\nare, sorry this other just helper method, so this takes in the source and\ndestination, I create this list of the next nodes I have to visit, and this\nvisited hash set, that should be hash set again, and this marks all the nodes that\nI've already visited. So I say okay next one to visit is my source then as long\nas there's something left to visit pull out the next node to visit,\ncheck if I'm where I should be if so, return true, otherwise check and\nupdate my visited, who I've visted and then go and queue up my\nchildren at the very end of the queue to be visited next. And those, and this will ensure that my children not visited immediately, but are visited once, sort of everything, everything scheduled has already been visited, so it will ensure it\nwill visit level by level by level. And then if I get down to the very end and I haven't\nfound my destination after all of this, then just return false. So that's how breadth-first search\noperates. In many cases when we want to find if there's actually a path,\nbreadth-first search is often the better approach, because otherwise we could wind\nup searching really really far away when there's actually a very short connection,\nand it's certainly better when we want to find the shortest path. So now that\nyou've seen breadth first and depth-first search why don't you try these out on a new problem.\nGood luck. ",
            "url": "www.youtube.com/watch?v=zaBhtODEL0w",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "pcKY4hjDrxk",
            "channelId": "UCZCFT11CWBi3MHNlGf019nw",
            "publishedAt": "2018-02-24T10:47:25Z",
            "title": "5.1 Graph Traversals - BFS &amp; DFS -Breadth First Search and Depth First Search",
            "description": "... Data Structures using C and C++ https://www.udemy.com/course/datastructurescncpp/?referralCode=BD2EF8E61A98AB5E011D C++ Programming ...",
            "channelTitle": "Abdul Bari",
            "transcript": "hi the topic is dreadful search and depth-first search in this video I will cover these two traversal methods by taking various examples well for such an effort search our graph traversal methods so we'll understand quickly the difference between them throw this a small example then afterward I'll take another example and I will explain you in detail now for quick understanding I have taken a simple graph actually it's a tree but a tree is also a graph so let us see so for traversal both of these traversal we have to know these two terms now for understanding these traversals we should know two terms one is visiting a vertex means going on a particular vertex second Irma's exploration of vertex exploration means if I am on sub particular vertex then visiting all its adjacent vertices is called as exploration so based on these two terms we can understand traversals so first I will explain in breadth first search see I am selecting vertex one as the starting vertex to find out breadth-first search we can select any vertex as a starting vertex now vertex one I will visit the vertex one now once the vertex is visited this word is I will start exploring means I will visit all adjacent vertices so who are those five four and two in which order I can visit I can visit them in any order so okay I will take two first then four then five next I should select the next vertex for exploration so these are already visited vertices after one I have a set at two four five then I should explore explore what I will explode - so who are a listen to two adjacent to two or seven six three in which order you can take you can take them in any order 7 then three then six in any order you can take that's all all the verses are visited and there is no vertex remaining for exploration this is breadth-first search now let us look at depth first I'll start from vertex one then from one I have stowed start its exploration so I will go to vertex two - now who are other adjacent vertices four and five no don't visit them you have reached a new vertex so you start exploring that vertex okay I'll start excluding - then who are adjacent to this seven six and three so I want to go to three okay go to three then shall I use it six and seven also known this is that first search start exploring three so if I start exploring three there is nothing connected to three okay so it means three is a completely explored then come back and then continue the exploration of - so who are there six explore six nothing is there come back go to seven explore seven visit seven explore 7 there is nothing so come back to one now and continue the exploration of one who are adjacent to it for visit fool and explore for there is nothing come back then go to five five no in this way all are explored so the Traverse cells are different results are different so in breadth first search we will explore a vertex then we go to the next vertex for exploration but in depth first search once we extracted exploring once you visited a new vertex we will suspend this vertex and start its exploration so from one we got two so we started exploring - then from - we went on three so we'll start exploring three like this so when the first search approach is different and breadth for such a process is different so I'll take one more example and explain you what is the difference between that first search and depth-first search with a simple example one more example let us find breadth-first search actually this is a binary tree tree is also a graph so let us perform for search and see so as per binary tree I will perform level order 1 then 2 3 then 4 5 6 7 4 5 6 7 this is breadth-first search means breakfast surges just like a level order on a binary tree then what is the depth-first search visit one ok Explorer 1 so he got two so stop exploring one and start exploring two so four stop exploring two and continuing exploration of four there is nothing so go back and come to five now nothing is remaining so go back to one and come on this side then six and then go back and seven so this is like pre-order so that first search is just like level order and depth-first search is just like pre-order traversal of a graph I have taken a bigger graph now we will learn about bid for search and the first search in detail first of all breadth-first search for performing grid first search I will take one data structure that is Q I have taken a cue now I'll explain you initial step then I will explain you repeating step so what is the initial step start exploration from any one of the vertex so which what x I should select as a starting vertex for that for search you can select any what else you like so I will select vertex one so in the answer you show it one in the graph you draw here again then add it to Q this is the first step initial step now we will perform repeating steps so what are those repeating steps take all the vertex from Q and start exploring it so what X 1 who are adjacent to 1 4 & 2 so explore them so first I want to visit for okay add it to result and also add it to Q next to go to to okay added to result and also added to queue no one is completely explored there is no urges on vertex remaining for vertex one this is first iteration completed now repeat the procedure what to do next select next vertex for exploration from queue that is for start exploring for so whose at this into four three so I am drawing it like a tree here so three is adjacent so add it to queue any other adjacent for for nothing is adjacent for four so four is completely explored now select next vertex for exploration that is two who are adjacent to two three five seven eight I can visit them in any order if I check three it's already explored so then I will prefer going on five first so five five next I want to go on eight okay eight so eight and eight next I will go on seven so seven and at seven here not two is a completely explored now select next vertex for exploration who is that three is there any at this one over this is for three yes to eight nine and ten so two is already visited so first I will take ten ten ten and then nine nine added to queue completed three is completely explored now select next vertex for exploration five anybody had just sent to five yes eight and seven and six so eight or the D visited seven already visited 6 this is 6 so 6 and 6 5 is completely explored select the next vertex for exploration 8 who is adjacent to 8 2 and 7 - actually we came from there 7 lloyd dotted line so vertex which is already visited we are drawing a dotted line then next vertex for exploration 7 7 is already explored so is there anything remaining four seven No ten there is nothing nearer to ten no nothing I just said to ten there is nothing as at the same to nine and there is nothing at the same to 6 so that's all this is breadth-first search completed and the tea that we got here is breadth-first search spanning tree dotted edges that we got here they are called as cross edges they are called as cross edges let us see what are the things that we have learned first thing as you can start breadth first search from any vertex you like first point second thing is when you are exploring any vertex 1 then you can visit the suggestion vertices in any order you like this or the second thing then both are leniency is given freedom is given to select any vertex then what is the rule here rule is when you are selecting a vertex for exploration you must visit all its adjacent vertices then only you should go to next vertex for exploration so it if I am exploring one then I should explicit a for as well as two then only I should sell it for for exploration this is the rule the next thing is last thing is you should select our next vertex for exploration from Q only so Q and exploration should be completely done these are the two important points about that first search you follow this one then you can get many answers I will write few more valid breadth first search is here first one I'll start from vertex one that is explore the adjacent vertices so first I'll explode two then four then I have to start exploring two because I have added to first so who are at this into two so I will take eight then five and seven then these are Addison to to all these are a different - - then I should explore which one for so water just sent two for three solid over then explore eight who is adjacent to eight five and seven both are visited now explore 7 so this is six now explore three so ten and nine so ten and nine this is one also this one is also a valid answer then one more I'll start exploration from five from five who are adjacent to eight seven and six now explore two who are resistant 2 to 3 and 1 now explore 8 7 is already visited 7 everything is visited 6 and nothing is there so everything is visited explore 3 so 9 + 10 + 4 so 4 3 9 10 and 4 I have visited 9 explore one nothing is remaining nine ten for not all are visited so this is also valid so like this you can start from any vertex and you can visit the adjacent in any order so you can form numerous number of valid breadth-first search next we will see depth-first search now next is depth-first search for this I will take a stack stack as a data structure used here let us start I can start the traversal from any vertex highlight so I want to start from vertex one so one is visited this is the initial step now the repeating step what I have to do every time as this new vertex is visited start exploring it so or adjacent to that four and two so visit four four four now the role in the first searches once you have visited one vertex still one more is remaining leave that we will see it afterwards first you start exploring four so this is the rule so once you have reached a new vertex start exploring that new vortex what about that one suspend it and keep it in the stable we can explore it later now start exploring for so from four I can go on three so they go to three three is visited now what to do suspend for and start exploring three from three I can go on ten so ten suspend trees start exploring ten there is no adjacent vertex of ten so go back to three so how to know I wait I have to go back this stack will give me their value so this three continue exploring three so I can go on nine 9 and again suspend tree and start exploring 9 from nyla cannot go anywhere then go back to 3 and start exploring 3 so who is the descent to 3 2 so 2 is visited then from 2 whose adjacent suspended to and start exploring two so from 2 8 is Addison so take 8 now start exploring 8 so from there I can go on 7 so suspend 8 so 7 is visited now we have to explore 7 from 7 I can go on 5 so 5 is newly visited now we have to start exploring Phi so suspend seven and push it into the stack then from 5 who is adjacent 6 so visit six suspend 5 and continued exploration of 6 there is nothing at the same to 6 so go back to 5 from 5 where I can go further so I can visit 2 which is already completed right I can visit 8 which is already completed so there is nothing remaining 4 5 so what happens in this way is we are going deep and deep right so in this way almost all vertices are visited only they are completely explored so 5 is completely explored go back to the previous vertex who is that 7 7 from 7 very can go from 7 they can one two which is already visited then go back to eight from eight nothing is remaining so from to where I can go I can go to one right then nothing is remaining so go back before from four I cannot go anywhere from three one I cannot use it anywhere so that's all right so here is the defer search traversal result and this is a DFS spanning tree this is depth full search spanning tree and these are just are called as back edges so for this graph we can make a tree like and perform preorder so this is the pre-order of DISA tree c14 310 then nine then two eight seven five six one four three nine eight two so nine two eight seven five six so this is like pre-order traversal no I will write few more valid depth-first search directly looking into the graph I'll start from vertex 1 1 this is the first one from 1 I will go to tea from - I'll go to 8 from 8 I will go to 7th from 7 and go to 5 then 6 from 6 I cannot go anywhere come back to 5 2 is already completed 7 also completed so what was the route I have taken so come back to 7 7 is completely explore come back to 8 nothing remaining come back to 2 so from - I'll go 2 3 then 9 nothing is there come back and go to 10 then go back to 3 and go to 4 then one is already explode so return back before then 3 then 2 then 1 finished so this is one answer then one more I'll show I'll start vortex train first is three then I'll use it to fool than 1 then 2 then 5 then 6 from 6 and 8 cannot go anywhere come back to 5 come back to 5 and go to 7 then 8 right from 8 and I'm back on to what is already over so simply go back to seven then five then come back to 2 then 2 from there I have already gone to 1 1 is already completed right so come back to 4 then come back to 3 so from 3 who are remaining 10 and 9 so 10 then 9 this is also valid so you can start from any vertex you like and you can visit any neighboring vertex but only thing is once you have visited a new vertex suspend the exploration of current vertex and start exploring new vortex that's all about the first search and breadth-first search and the time complexity of both these methods is order of n and this number of vertices ",
            "url": "www.youtube.com/watch?v=pcKY4hjDrxk",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "4xMsNIPEkwA",
            "channelId": "UCX6rLou1VXXPVsORMVkUryg",
            "publishedAt": "2020-08-02T19:40:58Z",
            "title": "Introduction to Graphs Data Structure",
            "description": "Graphs are a non-linear data structure that consists of a finite set of vertices (nodes) and a set of edges connecting them. In this video, I have introduced the ...",
            "channelTitle": "Fit Coder",
            "transcript": "hi everyone so in this video i will be introducing graphs to you this is the first video in the graph series and here i will be talking about the definition of the graph the properties and the terminology that is used when we're talking about graphs so this session will act as a base for the next subsequent sessions in which i'll be talking about the algorithms which are used for the graphs so let's begin so in computer science data structures can be classified into two categories linear data structure and non-linear data structure so linear data structures can be arrays linked list queue or stack and in non-linear data structures mainly there are two categories tree and graph so graph is one of the most important data structures because it is an important part of the interviews of the lateral hierarchy and also if someone wants to test your data knowledge he will most probably ask you a question about graphs and i've seen a lot of students face many issues in solving problems related to this topic so i thought that maybe i should clarify this topic and go into depth layer by layer so in the first layer i'll be introducing to you what are graphs all about and what are all the terminologies that you should be clear about so the first question comes what is a graph so as we discussed earlier graph is a non-linear data structure so it basically comprises of two parts so it has a finite set of vertices and a set of edges that connect them so in the diagram i have shown a graph so it has five vertices a b c d and e so the vertices are also known as nodes and you can see a lines connecting each of these vertices so this line is called an edge so if you see any graph problem you will see that it has a finite set of nodes and a finite set of edges the nodes are basically where we store the data so here in this graph the data is of the form character so a c b these are all aspects so it can be of numerical data type also or any other data structure that doesn't matter so basically in the vertices we store the data and we have certain set of edges that connect them so this is the basic definition that we can use to describe a graph so now an important question arises that why are we studying the graph what are the basic applications of a graph so i can give you some real life examples that where graphs are used we take an example of the facebook so we have users so users are basically considered as the vertices so if there are two users let's say user a is there and user b is there so if they are friends then there will be an edge connecting them so based on this facebook stores all the data related to friends and then it can suggest to friend suggestion algorithm of facebook also works on this concept so it's check that the user you are friends with so what are the users that there are mutual friends and based on that it can give you suggestions so the algorithm is quite complicated but the basic idea that they have used the basic data structure that we they have used is graphs so second example that we can take is world wide web so that is basically our internet so let's say you open any site let's say you open the economic times you see various news on it you click on a news it opens a new page so this link to a new page can be read can be considered as a edge and when the new page opens that is the data so that it can be considered as a what is so web pages are considered to be vertices and if there is an edge from pager to page b then we can see that page j has link of page v so the third example that we can think of is google maps so we all have used google maps so it is our in our phones in car navigation systems everywhere so google maps when you type a destination it tries to find the shortest destination shortest time that it takes to reach the destination so it uses the graph algorithm to determine the shortest route so what it thinks is so let's say we have this road so we have a cross road so basically this is considered as a vertice and these are the roads so these can be considered as edges so there are various algorithms in graphs that can be used to determine the shortest juice from point a to point b so google maps used those algorithms to find the shortest route when you type a destination and another application that we can think of is flight networks let's say a flight wants to travel for daily to let's say a long distance let's say los angeles then usually the flights don't carry that much fuel so they have to stop at some airport then they reach the destination so then they have to find the shortest route that they can take to reach the destination so that the fuel cost is less and subsequently the ticket cost is also less so what the flight networks do is throw the data in the graph and then they find the shortest path and the fuel that can be used for the route planning so graphic used for the route planning mechanism in the fight networks so next we have product recommendations so when we shop on e-commerce websites like flipkart amazon and all these websites so when you buy a product you see some other recommendations so let's say you have bought face cream and it will suggest some other products which have been brought by other users so how amazon or these sites work is they store these data in the form of graph so let's say for user a has bought some products and if a user b buys one of these products then it is more likely to buy the other products also so to find this mapping so they have used the graph data structures so these are some of the most common uses that we can find of the graphs also there are many more uses which we will subsequently find when we discuss the other algorithms but just to give you a real-life examples where graph can be used when we are talking about graphs if you read some books or you come across some problems you will come across these terminologies that are used here connected graph disconnected graph directed weighted cyclical cyclic simple so these can be pretty confusing if you don't know what are the definitions or what is meant by when you say undirected graph what is meant by when you say sparse graph so here i will try to break down all of these topics one by one with some examples and then it will clarify that what is meant when someone says it is a disconnected graph or a directed acyclic graph let's begin with the first one we have the connected and disconnected graph so it says that graph is said to be connected if there exists at least one path between every pair of vertices so if you take the first example let's say you want to reach point e so the point so the node e can be reached from d d can be reached from c c can be reached from a or b b can be reached from a or c so there exists a path between each pair of vertices so if you want to traverse from you are at point a and you want to reach point e then there exist a path you can go from a to c c to d and d to e similarly from b to d you can go from b to c and c to d so this graph is known as a connected graph because from any point you can reach any other point there exists at least one path and if you take another example so we i have removed one edge from here so now we have this graph so if someone says to you you are at point a and you have to reach point e so there is no way that you can point reach point e or point d from point a because there is no edge that is connecting them so this is known as a disconnected graph so basically a disconnected graph can be a combination of two or more connected graphs and these individual connected graphs these are known as components so this disconnected graph is comprised of two connected graphs or two components so next we come across this terminology which is directed graph an undirected graph so in the previous example when we say that you have to reach from point a to point e so there is no direction here you can see that this is a straight line so you can reach traverse from a to c and you can traverse from c to a also because there is no direction so this is graph is called as undirected graph because there is no direction order traversal order that is defined but if you see here there is an arrow pointed so what this arrow means is that you can reach a point from c so c to a is possible but a to c is not possible so if someone tries to do this this is not possible similarly a to b you can reach b 2 is not possible so b to c so this arrow determines the direction order that you can take so in a directed graph each edge has a direction which determines the traversal order so in a graph either all edges are all edges are directed or there is no direction in each of the edges you cannot have a mix of both like some nodes some edges have direction and some have don't so that is not possible so if you see this here we can traverse in any order c to d or d to c but here you can only traverse from c to d so this is an important concept that you need to understand that what is difference between directed and undirected graph so next we come across weighted graphs so in the early examples we have seen that this h has no weight associated to it so what do you mean by weight so basically weight can be thought of as cost so if you have to reach so let's say you have to reach from delhi to chandigarh so the cost can be the fuel consumption or the total amount that is taken so similarly in computer terminology if you have to reach from point a to point b you have to re incur cost of two so these are the numerical weights that are associated to each edge so if you to reach from point a to c you have to incur five cost b to c you have to incur two cost b to d you have blinker for call c 2 d 5 d 2 e 2 e 2 c 5 so now where it can be useful so you can think of let's say these are the different cities so you can think of like say is delhi b is chandigarh and you can think of is let's say gujarat so if someone tells you what is the least cost effective way to go from point a to e so let's say from daily to gujarat how can you go so how can this problem be solved so one method can be you can find what are the possible ways of reaching from delhi to gujarat what are the different routes that are available you compute the distance between each of the routes and you compare the total cost and all these you compute and then you find which is the minimum that comes up so these two five and five this can be let's say considered as kilometers so from what delhi to chandigarh let's say 300 kilometers is there so instead of two you can write 300 so 300 will be the cost from traveling from delhi to chandigarh and this sea let's say this is lorida from delhi to noida if you have to go you have to incur five cost so in this way you can compute the cost that is required to travel from delhi to gujarat and if you compute all of this cost you can find what is the minimum cost that you have to incur from reaching from point a to some other point so the weighted graphs are useful there when you know what is the cost incurred to reach from a work vertex to a other vertex so this cyclic and acyclic graph so let's have this first graph so this is a directed graph as we discussed earlier so from c you can reach a a to b and b to c you see there's a cycle formed here from made you can go to b b to c and c to a so if there's a graph that contains at least one graph cycle then that graph is contains a cyclic that graph means a cyclic graph but if a cyclic graph processes only one cycle then it is called a unicyclic graph and what is the acyclic graph so a cyclic graph is a graph that is not cyclic so acyclic graph is a very common terminology that you will find so it is also known as dag so dhg means directed acyclic graph so here you can see from c you can traverse to a from a to b so from b you cannot go anywhere so to reach we have to go from c so there is no cycle because you can go only till here and then it ends here but here from c to a a to b and b to c so you can see there is a cycle this is a cyclic graph this is a cyclic graph so you'll come across many graph problems where they'll say that let's say you're given a graph you have to find that if there's a cycle or not so important property of a cycle is that it starts and ends at the same point so here you can see a cycle starts at c it goes to a a to b and b to c so the starting and the ending point of this cycle is c so there are many ways to find out the graphs has a cycle or not so that i will be discussing the next video so here my aim is to get you familiar with all the graph terminology that can be used next to the dense under sparse graph so dense graph is a graph in which the number of edges is close to the maximum number of edges so this is an example of a dense graph we have five vertices we have maximum of 10 edges here so this is the example of a sparse graph we have only five edges so sparse graph is a graph in which the number of edges is close to the minimum minimal number of edges so there is no exact definition but it just to give an idea when someone says it's a dense graph then the social network graphs can be seen that is a sparse graph because a social let's say facebook facebook has millions of users but each user will have only limited number of friends so that will be a sparse graph because the user let's say 100 or 200 friends but there are millions of users in the entire facebook so that graph will be a sparse graph then we have a simple complete graph so this is very confusing sometimes people confuse what is a simple graph and what is a complete graph so a simple graph is a graph which has which is without loops and without multiple edges so what is meant by multiple edges so multiple edges means that let's say from point e and d we have only one edge but if we have let's say another edge and this edge is a cos two and this edge has a cost one then these are multiple edges but if it then that this graph is not a simple graph a simple graph is a graph which has no loops and no multiple edges between two nodes and a complete graph a complete graph is a graph in which each pair of distinct vertices is connected by unique edge so can you tell me what is which one of these is a simple graph and which one is the complete graph okay so this one is a simple graph and this one is a complete graph see the difference between this is so point d and c there is no edge connecting them and here we have an edge connecting each of the unique pair of vertices so we have is a b c d and a so any unique vertices there is an edge characteristic but here there is no edge connecting d and c so this one is an example of a simple graph and this one is an example of a complete graph okay so next comes strongly connected graph so a graph is called strongly connected if there exists a path from a node a to node b in each direction so what i meant here is that let's say you want to go from point a to point b we can see there is a path but if you want to go from point b to point a we can see that we have this path similarly for d to a we have this path and from a to d we can go here then go here for d to c we have this then from c to d we can go like this to this so we can see for any node u if there is a path from u to v then there should be a path from v to u so this should happen for all u and v so if such a scenario is happening then that graph is called a strongly connected graph so next comes these important terminologies that you need to understand for a graph so i've divided them into five types so one is adjacency in degree so this will be comprised of in degree and out degree so i will explain them to you then is path cycle and walk so let's start with what is adjacency so when we talk about adjacency then we should know whether we are talking about vertices or edges so so this graph it has both adjacent vertices and adjacent edges so adjacent vertices are those vertices which have an edge connecting them so if you someone says which of the adjacent vertices in this graph so we can see there's an edge from a to b so a and b a f so these are adjacent vertices so b and f are adjacent vertices of a b and f are adjacent vertices of e e and c are for d e and c are for b and similarly adjacent edges are there is a common vertex between the two edges so the example can be a b and b for a b and b so the common vertex is b so these are the adjacent edges so next i have written a f and f e a f and f b so this is the common vertex so if there's a common vertex then those edges are adjacent if there's a common edge then those vertices are adjacent next is degree so when we talk about degree so degrees degree term is used for a vertex so it is the number of vertices that are incident number of edges that are incident on a vertex so as you know for directed graph there is no concept of direction so the number of edges that are connected to a graph that is known that are connected to a vertex that is known as the degree of that vertex for directed graph we can split it up into integrand of degree in degree is for incoming edges and out degrees for the outgoing edges from of particular vertex so let's take an example so let's say you have this graph so here we have to compute in degree and out degree for each vertex so let's compute in degree what is the indegree for the vertex e we can see there is no arrow pointing inwards to vertex e so the indegree is zero for d we have one h that is incident that is incoming towards d that is e to d so here it is one for c we have to for b we have three for a we have one so this is the in degree and what is the out degree so the out degree for ease out degree for d of degree for c out degree for b how degree for a is 1 so for each vertex we have computed the in degree and out degree of the vertex so it is very simple you just have to check the number of the arrows that are incoming and outgoing so pick any vertex check the number of arrows that are incoming towards it that will be the indegree and check the number of vertices which are outgoing that will be our degree and the degree will be addition of the indegree now degree so degree of vertex a is 1 plus 1 that is 2 negative vertex b is 3 plus 1 degree of c is 0 plus 2 so that is how you compute in degree and out degree in a direct graph and degree in a undirected graph so then there is a common theorem that says that sum of in degree and out degree is even graph so why do we say that so if you see so each edge is computed twice consider twice so this edge is considered as an out degree for vertex e and as in degree for vertex d so as each edge comprises of integrand of degree also so simply it is a multiple of two so we can say that it will be even so sum of in degree and out degree will be even for a graph so next comes path cycle and work so this is very commonly used in all the graphs problem but there's a confusion slight confusion between all of them so i have tried to list them all in a single slide and then we can discuss what our path what is the cycle and what is a walk so basically a path is a sequence of distinct vertices such that the vertices are adjacent so if there is an edge connecting the two vertices that can be considered in a path but the vertex cannot repeat so it has to be distinct if the path is closed that is a cycle so if the where the paths start if it ends at the same point then it is a cycle so basically and what is a walk walk is a sequence of vertices and edges so there is no condition here that the vertices or edges cannot be repeated it is simply a traversal of the graph so let us discuss this with an example so we have this graph a b c d e so it is underrated graph so let's find out what can be the path so the path can be let's say if we go from a we go to d from d we go to c from c we go to b and from b we equal to e so you can see we went only across the edges so we went only to check the vertices which are adjacent to a we pick b from d to c c to b b to e so this is one path so there can be other path also let's let me check other part so from a we can go to b from b we can go to c from c we can go to d and b we can go to e so this can be another parts so they can many parts just that the vertex should not repeat and what can we cycle so cycle is when the starting and the ending is same so if we start from a b c d e and we are end at the same point then it is a cycle because it started at the end at the same point and what is a walk so let's say a walk can be let me choose a different color so walk can be you go from a to b b to c c to d d to e a to b b to c c to d a so we're just traversing across the graph so it does not matter whether the edges are emitted or the vertices are repeated so i hope it is clear so this was all about graph introduction please share your feedback and suggestions in the comment box below if you like my content do like share and subscribe to my channel i will soon be back with the next video in this series until then this is sandeep tapar signing off ",
            "url": "www.youtube.com/watch?v=4xMsNIPEkwA",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "AmXGNdoL_Jc",
            "channelId": "UCx-kFfzekMbhODaBss-ZnsA",
            "publishedAt": "2018-05-05T06:48:25Z",
            "title": "Introduction to Graph in Data Structures : Graph Theory #1",
            "description": "Important data structure is Graph . First video in graph theory.",
            "channelTitle": "Vivekanand Khyade - Algorithm Every Day",
            "transcript": "hello friends in the comment section there are many people who are asking for graph videos so today I am starting the series of videos on graph so now let's start with the topic what is a graph a graph G is equal to V comma E where V is equal to a set of vertices and E is equal to set of edges so you can see here in this graph there are 6 vertices they are a b c d e f and there are 8 edges ok so you can see here V equal to ABCDE F this is the set of vertices and this is the set of edges ok so what are the edges c a b b d b FF e ec then AC BC and D so these are the edges in the graph so what does this graph mean in the real world let's take an example of friends ok so suppose these vertices are the people in the world okay so edge in a and B so this edge a B indicates that a and B are friends ok the example is for friends relation means these vertices are the objects and the edges in those vertices are the relations so friendship is a relation so person a and person B are friends but there is no edge between a and F so that means a and F are not direct friends or you can say they are not friends ok now let's take another example of loads so suppose a b c d e f are the names of cities so the edge between a and b tells us that there is a road available between a and me means there is a direct role between City a to city B but there is no edge between a and F means there is no direct road between a and F here okay so this is the meaning of graph in the real world means the vertices are the objects and the edges indicate the relation between those vertices so now these edges can also have some values associated with them so as you can see a and B are cities we have assumed that these are the cities then the edge a B may have value suppose 10 kilometers means the distance between a and B City is 10 kilometer so the value for this edge is 10 you can say that the weight of this edge is 10 okay then suppose the value for AC is 12 then the value for C E is 30 okay so this is the weight for those edges the age may be associated with some weight some value or some cost now see we have to see what is the order of a graph so the order of a graph is the number of vertices in the graph so here there are six vertices in the graph means see the order of the graph is six you write the order with this symbol means modulus of V see this is the V and if you take modulus of V that means you are finding out the number of elements present in this set so that is the order of graph and that is six now let's see the number of edges means the size of the graph so size of the graph is the number of edges so see 1 2 3 4 5 6 7 eight so the size of this graph is it means the modulus of E is it means the number of elements in this set is it so this is the introduction for graph so in the next video now we will see how this graph is represented in the program means when we write the code for graphs which data structure do we use and how do we write the program to store graph in the memory so we are going to see that in the next video in this series hey friends please subscribe to my channel as I post algorithm videos everyday and if you want a video on any particular topic then please mention in the comment below thank you ",
            "url": "www.youtube.com/watch?v=AmXGNdoL_Jc",
            "source": "Youtube",
            "difficulty": 3
        },
        {
            "videoId": "j0IYCyBdzfA",
            "channelId": "UCh9nVJoWXmFb7sLApWGcLPQ",
            "publishedAt": "2020-08-22T14:00:09Z",
            "title": "Graph Introduction - Data Structures &amp; Algorithms Tutorials In Python #12",
            "description": "In this video we will go over graph data structure introduction. There are two types of graphs, (1) Directed: There is a direction in the way two nodes are ...",
            "channelTitle": "codebasics",
            "transcript": "in this video we will be talking about graph data structure this is an introduction video where where we'll go over some basic theory behind graph and then we'll write python code here i have a picture of my facebook network just a part of it my network is pretty big but in this network what happens is there are nodes which are people and then they are connected via facebook here is my brother bowen who is connected with me and then bavin might have his own connection so this graph can be pretty complex so this is basically a graph data structure it is an undirected graph because there is no direction between two nodes here individual entities are called nodes and the thing that connects those entities are called edges one of the utility of graph data structure is facebook's friend suggestion so bourbon is my friend but barwin has some connection let's say nikisha it is likely that nikisha can be my friend hence facebook will suggest nikissa as my friend's suggestion this is one of the utility of graph another example of graph is flight routes so here there are routes between different cities across the world this is a directed graph because there is a direction there is a flight from mumbai to paris so there is a direction to it hence it's called a directed graph now thinking about this you might think what's the difference between graph and a tree entry there is only one path between the two nodes here you can see that graph is a complex data structure where you can pretty much randomly connect any two nodes thinking about mumbai and new york there are two parts which connect these two nodes mumbai paris new york mumbai dubai new york in fact there is third part which is mumbai paris dubai new york you cannot have this entry entry if there are two nodes there should be only one path so then tree can be thought of as a special type of graph now one of the common utility of graph is finding the route between two cities let's say here in the case of our flight route example you might go to website such as you know like priceline.com uh where it allows you to search for flights or kayak.com you can enter two city names and it will tell you all the routes between those two cities how does it do that so if you are working in priceline or kayak or any website like google flight and if you're a back-end engineer you will be dealing with graphs a lot and you will be given a task to find out the shortest route between two nodes or maybe all possible routes between the two cities in case of mumbai and new york one path is mumbai parish new york the other one is mumbai parish dubai new york and the third one is mumbai dubai new york so these are the all possible paths but the shortest path in terms of minimum number of stop is probably mumbai paris new york and mumbai dubai new york there could be type of a graph where the edges are weighted and this weight in the case of the flight route example will be the distance between the two cities in this case this is called a weighted graph and the shortest path based on a distance is not mumbai paris new york or mumbai dubai new york it is actually mumbai boston hartford new york although there are four nodes in total but the total distance is minima hence in this case if you want to find out the shortest path based on the total number of distance total distance traveled it will be mumbai boston hartford new york there are many other examples of graph that we probably use in day-to-day life you use google maps every day it uses graph behind the scene other example is internet when you are connected to internet you are talking to different computers so the different servers or different computers in any network it could be internet internet those are connected using graph basically it can be thought of as a graph topology facebook is the example we already looked at amazon recommends the product recommendation using a graph data structure and some of the graph theory let's write code to implement graph in python now during implementation of graph the first question that arises is how do you represent this class using a data structure if you think about all these nodes which are cities are these nodes are nothing but pairs so if you think about mumbai and paris the connection is basically a pair between mumbai and paris then similarly we have pear which is saying mumbai and dubai and each of these pairs are routes actually so one way that you can think of is by using tuple so you can have a list of tuples presented like this and every tuple indicates one route here you have your starting city you have you have your end city and this stopper using this tuple i will write a python class the python class will be called graph and here in python the first function that you write in any class is init and what i'll do is i will uh have these routes passed as an input or or an argument to this init function and these are called edges i'm using a generic terminology here that's why i'm not calling it routes i'm calling it ages instead and then self.ages is equal to edges so i'm just storing those edges here and when i create a an object of this class it will be called let's say route graph and route graph is nothing but this routes now we'll be looking at two possible scenarios which is finding all the routes between two cities and finding the shortest route so here we saw that between mumbai and new york there are these three possible routes that you have and you want to find the shortest path based on minimum number of stops you might have seen different website which allows you to do flight booking where you can specify minimum number of stops or maybe you can specify two cities and it will tell you all the possible paths so this is the exit application that we will be implementing so that you know once you learn this theory maybe you can get a job at google flights or maybe priceline so in terms of uh manipulating this information in a proper way what you need to do is you need to transform these edges from list of tuples to some other better data structure because going through these edges one by one every time whenever you are trying to find a path will be uh too expensive often work but what if we can create this kind of a dictionary where you know from mumbai there are two possible paths so one is paris the other one is dubai so just imagine we have a dictionary like this okay and similarly from paris there is a dubai in new york so from paris there will be dubai and new york so this kind of presentation might be a little more effective and we'll see exactly how we can utilize this effective representation so first step we are going to do is transform from this data structure to this data structure and how do you do that well it's a simple for loop that you can run here so i will create a graph dictionary first which will be empty then i go through all the edges so i go through all the edges this is how we go through all the edges okay uh when it's tuple you can unpack the tuple in this way so that you get start and end in two different variables and then when you are inserting this into graph your key is always the starting point so if it is this tuple your key will be mumbai if it is this tuple key will be paris now first time when the mumbai let's say we are processing this record at that time our dictionary will be blank okay and we will not have a key with mumbai so what we'll do is if start in graphic which means mumbai is already there in the dictionary okay it's not there i don't want to think about that for now so let's think about else so this is the place where you're processing the first record where the dictionary is blank in that case you want to insert mumbai into the dictionary and the way you do that is by using this square bracket and then your value will be an array with the destination value okay and once you have fill mumbai in paris you know it will your dictionary will look something like this after you process the first record when you get the second tuple mumbai is already there so you come here what do you want to do now well you want to insert dubai into your value which is a list of your end destination so then this gives you that value and all you do is append that destination and i i will now print the graph dictionary just to see how it looks you can right click and run and you see that the dictionary looks perfect so from mumbai you have routes to paris dubai from paris you have these two routes from new york to toronto you have only one route so my dictionary is prepared this dictionary will be very useful in the other two methods that we are going to write and the first method is get parts so what this method is doing is take start and end as an input and it will return you all the paths here in this case between in mumbai and new york there are three possible paths so we will be written getting these three parts as a return value from this function okay now graph and tree is a recursive data structure so it makes sense that you use recursion here because if you think about it the paths between mumbai and new york can be found by first finding the paths between paris and new york then you find paths between dubai and new york and in those path you append or you prefix mumbai right now we are having just one path between these two or actually there are two parts so between paris and new york there is a direct route and there is paris dubai new york route so first let's find those routes so i find paris new york then paris dubai new york those are the two parts and then i append mumbai or i prefix mumbai actually not happen and that's a recursive approach so we need to use recursion for sure and whenever you are using recursion remember one thing you need to think about the simplest case first whenever you are writing recursive function you need to think about the simplest case okay what is the simplest case simplest case could be my start is same as my end so let's say i supply as start and end if i supply less in mumbai then my path that i will be finding will be what so then i want to return mumbai as my path okay so let's handle that case so if start is end start is equal to and then return path okay what is my path okay so path i need to take as an input argument because it's a recursive function when this recursive function will be called uh between paris and new york it will be returning paris new york paris dubai new york and when it unfolds or when the stack unwinds in the call for parent i expect paris new york and paris dubai new york and i want to append mumbai in front of it so for that reason i need to take path as an input argument and path is nothing but path plus start so path is path plus start okay all right so if i call it just for mumbai mumbai let let's just call it and see what happens so here i will say print okay let me say start is mumbai and is mumbai and paths between start and end this is a python3 format string that i'm using here and those paths will be in route graph you want to call the method called get paths which they start and end as an argument it takes third argument which is path but it has a default value which is blank so when i call it see i i got mumbai as a path so for very simple case it works beautifully okay now let's think about some corner case so the corner case could be i supply um let's say uh some starting point where i don't have any paths initialized for example torrento so torento is in the graph but from torrento there is no flight starting so there is a flight from new york to to toronto but there is no flying that is originating from torrento so what should happen in this case in this kit i should get a blank array which means there are no routes for given start and end so how do you do that well if you look at this dictionary the keys are the starting points so here you don't find torrent oc there is no torrent as a starting point so i can look up in this dictionary and see if there is an there is any value if there is no value return blank array so i can say if start which is an origination point not in graph dictionary then return this so now run this for torrento to mumbai see i get blank okay so for this corner case it is working okay now comes a regular case which is your recursion and in your recursion so what you want to do is to find routes between mumbai to new york first you need to go through in this dictionary you need to go through all the routes that are destination for mumbai then from all these routes which means first i will go through paris and explore all the routes then i will go to dubai and explore all the routes from dubai okay so first thing is running a for loop for node in self dot graph dick start so when i do graphic start here node will be two values paris and dubai okay what do you want to do with paris in dubai okay if node not in path we need to check that if this particular destination has been visited or not because if it is visited it will be in the path so it is let's say paris comes the path right now is just mumbai because we appended mumbai so paris is not in the this particular path okay so then what you will do is you will call this function recursively because now my question is okay how many paths are there from paris to new york so i want to get paths between paris and new york so paris is north and new york is end okay and whatever paths you get here you need to supply this particular path which is mumbai into that that way you can append mumbai to it okay so this will be called new paths and for every path in your new paths you want to append to the path so paths is a variable that we need to create it is all possible paths which is a list and then you want to append that and then you want to return paths i hope this is making sense so here once once again let's go over mumbai to new york case so in the mumbai to new york when the when the code runs for the first time uh so let's say mumbai to new york and i'll just debug it and see so you can set a breakpoint like this you can set debug okay and so this is step into step into my code okay using this button you can go to the code so now you can see that your path has only mumbai and your destination is of course new york so now uh let's go over them one by one okay these are the possible parts that you will get and now first we are visiting paris okay so from mumbai there are two routes paris and dubai so first we are visiting paris and when we are visiting paris now here in this function you want to get all the paths between paris and new york so i will not go over this function inside this function i will just come out of it okay or if you want to go inside okay let's go inside let's see what happens so step into so now i'm on a recursion so recursion stack is here okay and now the function is being called for start is paris and end is new york and you want to return for paris in new york you want to get only one path which is parish to new york if you look at this parish to new york is this one path so then okay we come here all right now we got known as dubai because actually paris to new york there are two parts paris dubai new york and paris new york so now we are visiting paris dubai new york path and that's one more recursion so we go into that and now my start is dubai and is new york so dubai in new york only one path so i want to get just one path as a return value okay so now again this is going for new york to new york so if you do debugging this kind of debugging helps you to understand the recursion better so new york to new york is worth pathway new york to new york will return just new york as an array so now what happened is we came out of recursion and my new paths are mumbai paris dubai new york so that is mumbai paris dubai new york actually i could have gone more deeper but you can do deeper debugging um so this is my final thing so mumbai paris dubai new york is one part the other one will be mumbai parish new york mumbai dubai new york um so first we append that okay so let's append that two parts so you see my path has the first path which is mumbai paris dubai new york now i want to explore other parts so how do i do that well you keep on going okay mumbai paris dubai new york okay now i'm visiting the second node which is dubai mumbai paris dubai new york okay mumbai paris deba new york that is appended okay it's just going into recursion now now we got mumbai paris new york so this is mumbai paris and new york okay so you get an idea you can just go through the recursion one by one and recursively it will keep on appending all the parts and when you run okay in the console you see the all of all the parts are being printed now all the three parts are being printed okay now let's write a function to get the shortest path and by shortest path i mean by number of stops not by number not by the total distance because we are not covering the weighted graph in this video we'll cover that in the later videos so right now we want to get shortest distance based on minimum number of stops for example here mumbai paris new york or mumbai dubai new york will be the shortest path and our function will get give you one of these paths okay doesn't matter you want to get a path which has sort minimum number of stops so how do you do that well one more function get shortest path okay start and path is this okay so now i want to implement this function this function if you think about it is quite similar to the previous function so let's go step by step again this is a recursive function so you want to think about the the simplest case first which is let's see if i do get shortest path uh where the starting point is toronto so from toronto there is no flight so i should get none basically so let's do that so here if start not in self dot graph dictionary return none and let's test it so get shortest path my start is to render it will come here it will not have a key torrent is not a key in this dictionary hence it will return none so let's verify you can say it's none and this is shortest shortest part okay and now what if i supply new york and new york okay in that case you want to get maybe like this because that's the shortest path basically just one city so then um okay if start is equal to n then what written what okay here again i will do the same thing which i did here for obvious reasons and then i return that path so now it's new york and new york run it and i get this okay now we need to run the same for loop so it's the same for loop okay so let's run the same for loop okay and here when i am here i i want to make a call to recursive function which will be get shortest path because the shortest path between mumbai to new york is equal to shortest path between paris to new york and then shortest paths add into that the shortest path between paris to mumbai hence when i go recursively i'm always looking for a shortest path between node and and okay and obviously i need to give path as a third argument and this is my shortest path okay so now i got the shortest path between let's say paris and new york okay so what do i need to do so first i need to check if sp because see this function sometimes written none so you want to make sure you take care of that case and now the first iteration so let me create another variable called shortest path which is initialized to non-initially because we don't know at the beginning what the shortest path is and if this is none for example if let's say i don't have any shortest path then whatever shortest path i get i want to keep it but in the later iteration i will have a shortest path so i i want to measure a length of that sp so what is the length of the sp so if the path is like this then the length of the sp is four because one two three four it is an array of city names so sp will be array of the city name so if the length of that is less than the length of shortest path that we have seen so far then i want to keep shortest path to be sp and then you return that path so now let's see the path between mumbai and new york so here is this mumbai parish new york see mumbai parish new york there is another path which is mumbai dubai new york but i'm just returning just one path out of it if you look at paths between let's say paris to new york there are two parts like paris to new york and paris dubai new york so let's try that here it says paris new york it did not tell me paris dubai new york all right that's all i have for this tutorial i'm gonna link my github for this code in the video description below so clone that git code try to run this code on your own try to play with it try to play with different set of route and how look at how it goes i don't have an exercise for this video but in the future i'm gonna cover graph traversal and you know i can create maybe 10 videos on graph alone so i will be adding more videos on more data structures in the future and i will try to cover algorithms as well and i will have more exercises for you in the future i hope you are enjoying this data structure series so far if you are not seen my previous videos on different data structures such as linkedin hashmap and so on please watch them and give this video a thumbs up or leave it leave a comment i'm putting a lot of effort in making this video so please make sure you share with your friends if you find this useful give it a thumbs up and subscribe to my channel thank you ",
            "url": "www.youtube.com/watch?v=j0IYCyBdzfA",
            "source": "Youtube",
            "difficulty": 3
        }
    ]
}